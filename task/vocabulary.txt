{ ' abstract ' :   ' In   this   paper   we   study   data   collection   in   an   energy   renewable   sensor   network   for   scenarios   such   as   traffic   monitoring   on   busy   highways ,   where   sensors   are   deployed   along   a   predefined   path   ( the   highway )   and   a   mobile   sink   travels   along   the   path   to   collect   data   from   one - hop   sensors   periodically .   As   sensors   are   powered   by   renewable   energy   sources ,   time - varying   characteristics   of   ambient   energy   sources   poses   great   challenges   in   the   design   of   efficient   routing   protocols   for   data   collection   in   such   networks .   In   this   paper   we   first   formulate   a   novel   data   collection   maximization   problem   by   adopting   multi - rate   data   transmissions   and   performing   transmission   time   slot   scheduling ,   and   show   that   the   problem   is   NP - hard .   We   then   devise   an   offline   algorithm   with   a   provable   approximation   ratio   for   the   problem   by   exploiting   the   combinatorial   property   of   the   problem ,   assuming   that   the   harvested   energy   at   each   node   is   given   and   link   communications   in   the   network   are   reliable .   We   also   extend   the   proposed   algorithm   by   minor   modifications   to   a   general   case   of   the   problem   where   the   harvested   energy   at   each   sensor   is   not   known   in   advance   and   link   communications   are   not   reliable .   We   thirdly   develop   a   fast ,   scalable   online   distributed   algorithm   for   the   problem   in   realistic   sensor   networks   in   which   neither   the   global   knowledge   of   the   network   topology   nor   sensor   profiles   such   as   sensor   locations   and   their   harvested   energy   profiles   is   given .   Furthermore ,   we   also   consider   a   special   case   of   the   problem   where   each   node   has   only   a   fixed   transmission   power ,   for   which   we   propose   an   exact   solution   to   the   problem .   We   finally   conduct   extensive   experiments   by   simulations   to   evaluate   the   performance   of   the   proposed   algorithms .   Experimental   results   demonstrate   that   the   proposed   algorithms   are   efficient   and   the   solutions   obtained   are   fractional   of   the   optimum . ' ,   ' title ' :   ' Data   Collection   Maximization   in   Renewable   Sensor   Networks   via   Time - Slot   Scheduling ' } 
{ ' abstract ' :   ' An   increasing   number   of   businesses   are   migrating   their   IT   operations   to   the   cloud .   Likewise   there   is   an   increased   emphasis   on   data   analytics   based   on   multiple   datasets   and   sources   to   derive   information   not   derivable   when   a   dataset   is   mined   in   isolation .   While   ensuring   security   of   data   and   computation   outsourced   to   a   third   party   cloud   service   provider   is   in   itself   challenging ,   supporting   mash - ups   and   analytics   of   data   from   different   parties   hosted   across   different   services   is   even   more   so .   In   this   paper   we   propose   a   cloud - based   service   allowing   multiple   parties   to   perform   secure   multi - party   secure   sum   computation   using   their   clouds   as   delegates .   Our   scheme   provides   data   privacy   both   from   the   delegates   as   well   as   from   the   other   data   owners   under   a   lazy - and - curious   adversary   ( semi - honest )   model .   We   then   describe   how   such   a   secure   sum   primitive   may   be   used   in   various   collaborative ,   cloud - based   distributed   data   mining   tasks   ( classification ,   association   rule   mining   and   clustering ) .   We   implement   a   prototype   and   benchmark   the   service ,   both   as   a   stand - alone   secure   sum   service ,   and   as   a   building   block   for   more   complex   analytics .   The   results   suggest   reasonable   overhead   and   demonstrate   the   practicality   of   carrying   out   privacy   preserved   distributed   analytics   despite   migrating   ( encrypted )   data   to   pos -   sibly   different   and   untrusted   ( semi - honest )   cloud   services . ' ,   ' title ' :   ' Delegated   Secure   Sum   Service   for   Distributed   Data   Mining   in   Multi - Cloud   Settings ' } 
{ ' abstract ' :   ' This   paper   fundamentally   investigates   the   performance   of   evolutionary   multiobjective   optimization   ( EMO )   algorithms   for   computationally   hard   0 - 1   combinatorial   optimization ,   where   a   strict   theoretical   analysis   is   generally   out   of   reach   due   to   the   high   complexity   of   the   underlying   problem .   Based   on   the   examination   of   problem   features   from   a   multiobjective   perspective ,   we   improve   the   understanding   of   the   efficiency   of   a   simple   dominance - based   EMO   algorithm   with   unbounded   archive   for   multiobjective   NK - landscapes   with   correlated   objective   values .   More   particularly ,   we   adopt   a   statistical   approach ,   based   on   simple   and   multiple   linear   regression   analysis ,   to   enquire   the   expected   running   time   of   global   SEMO   with   restart   for   identifying   a   ( 1 + e ) - approximation   of   the   Pareto   set   for   small - size   enumerable   instances .   Our   analysis   provides   further   insights   on   the   EMO   search   behavior   and   on   the   most   important   features   that   characterize   the   difficulty   of   an   instance   for   this   class   of   problems   and   algorithms . ' ,   ' title ' :   ' A   feature - based   performance   analysis   in   evolutionary   multiobjective   optimization ' } 
{ ' abstract ' :   ' Functional   biological   sequences ,   which   typically   come   in   families ,   have   retained   some   level   of   similarity   and   function   during   evolution .   Finding   consensus   regions ,   alignment   of   sequences ,   and   identifying   the   relationship   between   a   sequence   and   a   family   allow   inferences   about   the   function   of   the   sequences .   Profile   hidden   Markov   models   ( HMMs )   are   generally   used   to   identify   those   relationships .   A   profile   HMM   can   be   trained   on   unaligned   members   of   the   family   using   conventional   algorithms   such   as   Baum - Welch ,   Viterbi ,   and   their   modifications .   The   overall   quality   of   the   alignment   depends   on   the   quality   of   the   trained   model .   Unfortunately ,   the   conventional   training   algorithms   converge   to   suboptimal   models   most   of   the   time .   This   work   proposes   a   training   algorithm   that   early   identifies   many   imperfect   models .   The   method   is   based   on   the   Simulated   Annealing   approach   widely   used   in   discrete   optimization   problems .   The   training   algorithm   is   implemented   as   a   component   in   HMMER .   The   performance   of   the   algorithm   is   discussed   on   protein   sequence   data . ' ,   ' title ' :   ' Simulated   annealing   algorithm   with   biased   neighborhood   distribution   for   training   profile   models ' } 
{ ' abstract ' :   ' The   Canny   algorithm   is   a   well   known   edge   detector   that   is   widely   used   in   the   previous   processing   stages   in   several   algorithms   related   to   computer   vision .   An   alternative ,   the   LIP - Canny   algorithm ,   is   based   on   a   robust   mathematical   model   closer   to   the   human   vision   system ,   obtaining   better   results   in   terms   of   edge   detection .   In   this   work   we   describe   LIP - Canny   algorithm   under   the   perspective   from   its   parallelization   and   optimization   by   using   the   NVIDIA   CUDA   framework .   Furthermore ,   we   present   comparative   results   between   an   implementation   of   this   algorithm   using   NVIDIA   CUDA   and   the   analogue   using   a   C / C++   approach . ' ,   ' title ' :   ' Parallelizing   and   optimizing   LIP - canny   using   NVIDIA   CUDA ' } 
{ ' abstract ' :   ' This   paper   presents   an   efficient   Bayesian   blind   multiuser   receiver   for   long   code   multipath   CDMA   systems .   The   proposed   receiver   employs   the   adaptive   sampling   method   for   the   Bayesian   inference   procedure   to   estimate   the   data   symbols   and   multipath   parameters .   Compared   to   the   other   reported   Bayesian   Monte   Carlo   receivers   for   long   code   multipath   CDMA   systems ,   the   proposed   one   achieves   a   faster   convergence   and   a   lower   computational   complexity   to   attain   comparable   performance .   Simulation   results   are   presented   to   demonstrate   the   effectiveness   of   the   proposed   Bayesian   blind   multiuser   receiver . ' ,   ' title ' :   ' Blind   Multiuser   Detection   for   Long   Code   Multipath   DS - CDMA   Systems   with   Bayesian   MC   Techniques ' } 
{ ' abstract ' :   ' Spreadsheets   are   by   far   the   most   prominent   example   of   end - user   programs   of   ample   size   and   substantial   structural   complexity .   In   addition ,   spreadsheets   are   usually   not   tested   very   rigorously   and   thus   comprise   faults .   Locating   faults   is   a   hard   task   due   to   the   size   and   the   structure ,   which   is   usually   not   directly   visible   to   the   user ,   i . e . ,   the   functions   are   hidden   behind   the   cells   and   only   the   computed   values   are   presented .   Hence ,   there   is   a   strong   need   for   debugging   support .   In   this   paper ,   we   adapt   three   program - debugging   approaches   that   have   been   designed   for   more   traditional   procedural   or   object - oriented   programming   languages .   These   techniques   are   Spectrum - based   Fault   Localization ,   Spectrum - Enhanced   Dynamic   Slicing ,   and   Constraint - based   Debugging .   Beside   the   theoretical   foundations ,   we   present   a   more   sophisticated   empirical   evaluation   including   a   comparison   of   these   approaches .   The   empirical   evaluation   shows   that   Sfl   ( Spectrum - based   Fault   Localization )   and   Sendys   ( Spectrum   ENhanced   Dynamic   Slicing )   are   the   most   promising   techniques . ' ,   ' title ' :   ' On   the   empirical   evaluation   of   fault   localization   techniques   for   spreadsheets ' } 
{ ' abstract ' :   ' This   work   provides   elements   to   highlight   the   reliability   challenges   related   to   the   technology   scaling   and   the   BTI   variability .   Through   main   milestones   including   device   reliability   scaling   model   ( for   both   mean   and   spread ) ,   a   discussion   on   the   physical   origin   of   BTI   variability   and   a   digital   IP   failure   rate   analytical   model ,   the   evolution   of   digital   IP   failure   rates   along   the   ITRS   scaling   roadmap   is   assessed .   and   an   analysis   of   the   ITRS   roadmap   on   digital   IP   failure   rates .   This   study   offers   new   perspectives   towards   product   hardening   and   qualification   with   respect   to   both   fresh   and   BTI - related   local   variability ,   especially   in   context   where   Adaptive   Voltage   Scaling   ( AVS )   is   used   to   compensate   for   process   centerings . ' ,   ' title ' :   ' From   BTI   variability   to   product   failure   rate :   A   technology   scaling   perspective ' } 
{ ' abstract ' :   ' In   this   paper   we   discuss   the   problem   of   calculating   the   reachable   states   of   a   dynamical   system   defined   by   ordinary   differential   equations   or   inclusions .   We   present   a   prototype   system   for   approximating   this   set   and   demonstrate   some   experimental   results . ' ,   ' title ' :   ' Reachability   Analysis   via   Face   Lifting ' } 
{ ' abstract ' :   ' By   introducing   the   new   concepts   of   fuzzy     β   - covering   and   fuzzy     β   - neighborhood ,   we   define   two   new   types   of   fuzzy   covering   rough   set   models   which   can   be   regarded   as   bridges   linking   covering   rough   set   theory   and   fuzzy   rough   set   theory .   We   show   the   properties   of   the   two   models ,   and   reveal   the   relationships   between   the   two   models   and   some   others .   Moreover ,   we   present   the   matrix   representations   of   the   newly   defined   lower   and   upper   approximation   operators   so   that   the   calculation   of   lower   and   upper   approximations   of   subsets   can   be   converted   into   operations   on   matrices .   Finally ,   we   generalize   the   models   and   their   matrix   representations   to     L   - fuzzy   covering   rough   sets   which   are   defined   over   fuzzy   lattices . ' ,   ' title ' :   ' Two   fuzzy   covering   rough   set   models   and   their   generalizations   over   fuzzy   lattices ' } 
{ ' abstract ' :   ' Mobile   applications   are   becoming   complex   software   systems   that   must   be   developed   quickly   and   evolve   regularly   to   fit   new   user   requirements   and   execution   contexts .   However ,   addressing   these   constraints   may   result   in   poor   design   choices ,   known   as   antipatterns ,   which   may   degrade   software   quality   and   performance .   Thus ,   the   automatic   detection   of   antipatterns   is   an   important   activity   that   eases   the   future   maintenance   and   evolution   tasks .   Moreover ,   it   helps   developers   to   refactor   their   applications   and   thus ,   to   improve   their   quality .   While   antipatterns   are   well - known   in   object - oriented   applications ,   their   study   in   mobile   applications   is   still   in   their   infancy .   In   this   paper ,   we   presents   a   tooled   approach ,   called   P   aprika   ,   to   analyze   Android   applications   and   to   detect   object - oriented   and   Android - specific   antipatterns   from   binaries   of   applications . ' ,   ' title ' :   ' An   approach   to   detect   Android   antipatterns ' } 
{ ' abstract ' :   ' In   this   paper   we   present   a   new   method   for   object   categorization .   Firstly   an   image   representation   is   obtained   by   the   proposed   hierarchical   learning   method   consisting   of   alternating   between   local   coding   and   maximum   pooling   operations ,   where   the   local   coding   operation   induces   discrimination   while   the   image   descriptor   and   maximum   pooling   operation   induces   invariance   in   hierarchical   architecture .   Then   the   obtained   effective   image   representation   is   passed   to   a   linear   classifier   which   is   suitable   for   large   databases   for   object   categorization .   We   have   demonstrated   that   the   proposed   method   is   robust   to   image   variations   and   has   low   sample   complexity . ' ,   ' title ' :   ' Object   categorization   based   on   hierarchical   learning ' } 
{ ' abstract ' :   ' We   have   previously   proposed   a   howling   canceller   which   cancels   howling   by   using   a   cascade   notch   filter   designed   from   a   distance   between   a   loudspeaker   and   a   microphone .   This   method   utilizes   a   pilot   signal   to   estimate   the   distance .   In   this   paper ,   we   introduce   two   methods   into   the   distance - based   howling   canceller   to   improve   speech   quality .   The   first   one   is   an   adaptive   cascade   notch   filter   which   adaptively   adjusts   the   nulls   to   eliminate   howling   and   to   keep   speech   components .   The   second   one   is   a   silent   pilot   signal   whose   frequencies   exist   in   the   ultrasonic   band ,   and   it   is   inaudible   while   on   transmission .   We   implement   the   proposed   howling   canceller   on   a   DSP   to   evaluate   its   capability .   The   experimental   results   show   that   the   proposed   howling   canceller   improves   speech   quality   in   comparison   to   the   conventional   one . ' ,   ' title ' :   ' A   High   Speech   Quality   Distance - Based   Howling   Canceller   with   Adaptive   Cascade   Notch   Filter   and   Silent   Pilot   Signal ' } 
{ ' abstract ' :   ' Purpose   –   This   paper   aims   to   look   at   how   varying   terminology   is   used   on   school   library   web   sites   and   how   that   compares   to   student   preferences . Design / methodology / approach   –   Provides   research   conduced   by   surveying   practicing   school   librarians   and   k ‐ 12   students . Findings   –   Terminology   varies   greatly   on   school   library   web   sites .   Further ,   students   prefer   common   language   use . Practical   implications   –   Practicing   librarians   may   consider   revising   their   web   sites   in   order   to   make   them   more   accessible   for   their   students . Originality / value   –   This   paper   provides   original   research   into   school   library   web   sites ,   an   area   that   is   lacking . ' ,   ' title ' :   ' School   library   web   site   terminology ' } 
{ ' abstract ' :   ' Recently ,   numerous   multireceiver   identity - based   encryption   or   identity - based   broadcast   encryption   schemes   have   been   introduced   with   bilinear   pairing   and   probabilistic   map - to - point   MTP   function .   As   the   bilinear   pairing   and   MTP   functions   are   expensive   operations ,   any   cryptographic   schemes   based   on   these   operations   experience   high   computational   burden .   The   certificateless   public   key   cryptography   sidesteps   the   private   key   escrow   problem   occurring   in   identity - based   cryptosystem   and   certificate   management   troubles   of   certificate   authority - based   public   key   cryptography   CA - PKC .   We   observed   that   certificateless   multireceiver   encryption   CL - MRE   scheme   without   pairing   and   MTP   hash   function   has   not   yet   been   considered   in   the   literature .   In   this   paper ,   we   proposed   a   bilinear   pairing   and   MTP   hash - function - free   CL - MRE   scheme   with   chosen   ciphertext   attack   resilience .   The   detailed   analyses   provide   evidence   that   our   scheme   achieves   forward   secrecy ,   backward   secrecy ,   and   low   computation   costs   than   others .   The   scheme   also   provides   confidentiality   of   the   message   and   receiver   anonymity   in   the   random   oracle   model   with   the   hardness   of   computational   Diffie - Hellman   problem .   Copyright   ©   2014   John   Wiley   &   Sons ,   Ltd . ' ,   ' title ' :   ' Anonymous   and   provably   secure   certificateless   multireceiver   encryption   without   bilinear   pairing ' } 
{ ' abstract ' :   ' We   study   the   problem   of   approximating   one - dimensional   nonintegrable   codistributions   by   integrable   ones   and   apply   the   resulting   approximations   to   approximate   feedback   linearization   of   single - input   systems .   The   approach   derived   in   this   paper   allows   a   linearizable   nonlinear   system   to   be   found   that   is   close   to   the   given   system   in   a   least - squares   ( L2 )   sense .   A   linearly   controllable   single - input   affine   nonlinear   system   is   feedback   linearizable   if   and   only   if   its   characteristic   distribution   is   involutive   ( hence   integrable )   or ,   equivalently ,   any   characteristic   one - form   ( a   one - form   that   annihilates   the   characteristic   distribution )   is   integrable .   We   study   the   problem   of   finding   ( least - squares   approximate )   integrating   factors   that   make   a   fixed   characteristic   one - form   close   to   being   exact   in   anL2   sense .   A   given   one - form   can   be   decomposed   into   exact   and   inexact   parts   using   the   Hodge   decomposition .   We   derive   an   upper   bound   on   the   size   of   the   inexact   part   of   a   scaled   characteristic   one - form   and   show   that   a   least - squares   integrating   factor   provides   the   minimum   value   for   this   upper   bound .   We   also   consider   higher - order   approximate   integrating   factors   that   scale   a   nonintegrable   one - form   in   a   way   that   the   scaled   form   is   closer   to   being   integrable   inL2   together   with   some   derivatives   and   derive   similar   bounds   for   the   inexact   part .   This   allows   a   linearizable   nonlinear   system   that   is   close   to   the   given   system   in   a   least - squares   ( L2 )   sense   together   with   some   derivatives   to   be   found .   The   Sobolev   embedding   techniques   allow   us   to   obtain   an   upper   bound   on   the   uniform   ( L ∞ )   distance   between   the   nonlinear   system   and   its   linearizable   approximation . ' ,   ' title ' :   ' Least - squares   integration   of   one - dimensional   codistributions   with   application   to   approximate   feedback   linearization ' } 
{ ' abstract ' :   ' Latent   sector   errors   in   disk   drives   affect   only   a   few   data   sectors .   They   occur   silently   and   are   detected   only   when   the   affected   area   is   accessed   again .   If   a   latent   error   is   detected   while   the   storage   system   is   operating   under   reduced   redundancy ,   i . e . ,   during   a   RAID   rebuild ,   then   data   loss   may   occur .   Various   features   such   as   scrubbing   and   intra - disk   data   redundancy   are   proposed   to   detect   and / or   recover   from   latent   errors   and   avoid   data   loss .   While   such   features   enhance   data   availability   in   the   storage   system ,   their   execution   may   cause   performance   degradation .   In   this   paper ,   we   evaluate   the   effectiveness   of   scrubbing   and   intra - disk   data   redundancy   in   improving   data   availability   while   the   overall   goal   is   to   maintain   user   performance   within   predefined   bounds .   We   show   that   by   treating   them   as   low   priority   background   activities   and   scheduling   them   efficiently   during   idle   times ,   these   features   remain   performance - wise   transparent   to   the   storage   system   user   while   still   improving   data   reliability .   Detailed   trace - driven   simulations   show   that   the   mean   time   to   data   loss   ( MTTDL )   improves   by   up   to   5   orders   of   magnitude   if   these   features   are   implemented   independently .   By   scheduling   concurrently   both   scrubbing   and   intra - disk   parity   updates   during   idle   times   in   disk   drives ,   MTTDL   improves   by   as   much   as   8   orders   of   magnitude . ' ,   ' title ' :   ' Enhancing   data   availability   in   disk   drives   through   background   activities ' } 
{ ' abstract ' :   ' Financial   crisis   forecasting   has   been   a   long - standing   challenge   that   often   involves   couplings   between   indicators   of   multiple   markets .   Such   couplings   include   implicit   relations   that   might   not   be   effectively   detected   from   raw   market   observations .   However ,   most   methods   for   crisis   forecasting   rely   directly   on   market   observations   and   might   not   detect   the   hidden   interactions   between   markets .   To   this   end ,   the   authors   explore   coupled   market   state   analysis   ( CMSA ) ,   assuming   that   the   observations   of   markets   are   governed   by   a   collection   of   intra -   and   intercoupled   hidden   market   states .   Accordingly ,   they   built   a   forecaster   based   on   these   coupled   market   states   instead   of   observations . ' ,   ' title ' :   ' Financial   Crisis   Forecasting   via   Coupled   Market   State   Analysis ' } 
{ ' abstract ' :   ' In   this   paper ,   an   “ intelligent ”   isolated   intersection   control   system   was   developed .   The   developed   “ intelligent ”   system   makes   “ real   time ”   decisions   as   to   whether   to   extend   ( and   how   much )   current   green   time .   The   model   developed   is   based   on   the   combination   of   the   dynamic   programming   and   neural   networks .   Many   tests   show   that   the   outcome   ( the   extension   of   the   green   time )   of   the   proposed   neural   network   is   nearly   equal   to   the   best   solution .   Practically   negligible   CPU   times   were   achieved ,   and   were   thus   absolutely   acceptable   for   the   “ real   time ”   application   of   the   developed   algorithm . ' ,   ' title ' :   ' Dynamic   programming — neural   network   real - time   traffic   adaptive   signal   control   algorithm ' } 
{ ' abstract ' :   ' This   issue   features   expanded   versions   of   articles   selected   from   the   2014   AAAI   Conference   on   Innovative   Applications   of   Artificial   Intelligence   held   in   Quebec   City ,   Canada .   We   present   a   selection   of   four   articles   describing   deployed   applications   plus   two   more   articles   that   discuss   work   on   emerging   applications . ' ,   ' title ' :   ' Introduction   to   the   Special   Issue   on   Innovative   Applications   of   Artificial   Intelligence   2014 ' } 
{ ' abstract ' :   ' Although   frequently   used   in   fractal   compression   quadrant - based   classification   exhibits   a   significant   defect   which   has   not   been   described   in   the   literature .   We   give   an   efficient   solution   to   this   problem   by   controlling   the   class   structure   based   on   an   adaptive   threshold .   This   makes   this   classification   technique   a   very   efficient   and   competitive   one   also   for   block   matching   motion   compensation   algorithms   in   video   coding . ' ,   ' title ' :   ' Resolving   a   defect   in   quadrant - based   classification   for   fast   block - matching ' } 
{ ' abstract ' :   ' Where   there   are   infinitely   many   possible   basic   states   of   the   world ,   a   standard   probability   function   must   assign   zero   probability   to   each   state   –   since   any   finite   probability   would   sum   to   over   one .   This   generates   problems   for   any   decision   theory   that   appeals   to   expected   utility   or   related   notions .   For   it   leads   to   the   view   that   a   situation   in   which   one   wins   a   million   dollars   if   any   of   a   thousand   of   the   equally   probable   states   is   realized   has   an   expected   value   of   zero   ( since   each   such   state   has   probability   zero ) .   But   such   a   situation   dominates   the   situation   in   which   one   wins   nothing   no   matter   what   ( which   also   has   an   expected   value   of   zero ) ,   and   so   surely   is   more   desirable .   I   formulate   and   defend   some   principles   for   evaluating   options   where   standard   probability   functions   cannot   strictly   represent   probability   –   and   in   particular   for   where   there   is   an   infinitely   spread ,   uniform   distribution   of   probability .   The   principles   appeal   to   standard   probability   functions ,   but   overcome   at   least   some   of   their   limitations   in   such   cases . ' ,   ' title ' :   ' Standard   decision   theory   corrected ' } 
{ ' abstract ' :   ' Backed   by   the   European   Commission ,   a   consortium   of   partners   from   European   industry ,   financial   institutions ,   and   academia   has   embarked   on   a   research   project   to   develop   the   fundamentals   of   secure   electronic   commerce .   The   goal   of   the   9 - million   ECU   project ,   SEMPER   ( Secure   Electronic   Marketplace   for   Europe ) ,   is   to   provide   the   first   open   and   comprehensive   solutions   for   secure   commerce   over   the   Internet   and   other   public   information   networks .   We   describe   the   objectives   and   summarise   the   initial   architecture   of   SEMPER .   A   wide   range   of   businesses   are   rapidly   moving   to   explore   the   huge   potential   of   net -   worked   information   systems ,   especially   with   the   Internet - based   WWW   ( World - wide   Web ) .   The   Internet ,   which   already   connects   more   than   3   million   computers   and   a   sub -   stantially   larger   number   of   users ,   is   growing   at   a   breathtaking   pace   with   thousands   of   newcomers   every   day .   Although   the   Internet   has   its   roots   in   academia   and   is   still   domi -   nated   by   free - of - charge   information ,   dramatic   changes   are   expected   in   the   near   future .   For   instance ,   the   WWW   will   be   used   for   a   wide   variety   of   electronic   commerce   such   as   on - line   trade   or   delivery   of   advanced   multimedia   information   services .   The   evolution   of   broadband   networks   and   " information   highways "   will   intensify   this   trend .   The   need   for   secure   transactions   in   this   new   business   environment ,   which   involves   networks   available   to   the   general   public ,   has   triggered   a   number   of   related   efforts .   These   initial   developments   are   based   almost   exclusively   in   the   US   and   most   of   them   are   limited   to   proprietary ,   or   otherwise   closed   solutions ,   involving   only   electronic   payment   issues .   In   contrast ,   SEMPER   is   directed   towards   a   comprehensive   solution   for   secure   electronic   commerce ,   considering   legal ,   commercial ,   social ,   and   technical   requirements   as   well   as   different   options   for   an   electronic   marketplace . ' ,   ' title ' :   ' Development   of   a   Secure   Electronic   Marketplace   for   Europe ' } 
{ ' abstract ' :   ' Through   the   use   of   a   global   geometric   symmetry ,   detection   ellipses   are   proposed   in   this   paper .   Based   on   the   geometric   symmetry ,   the   proposed   method   first   locates   candidates   of   ellipses   centers .   In   the   meantime ,   according   to   these   candidate   centers ,   all   feature   points   in   an   input   image   are   grouped   into   several   subimages .   Then ,   for   each   subimage ,   by   using   geometric   properties   again ,   all   ellipses   are   extracted .   The   method   significantly   reduces   the   time   required   to   evaluate   all   possible   parameters   without   using   edge   direction   information .   Experimental   results   are   given   to   show   the   correctness   and   effectiveness   of   the   proposed   method . ' ,   ' title ' :   ' Detection   ellipses   by   finding   lines   of   symmetry   in   the   images   via   an   hough   transform   applied   to   straight   lines ' } 
{ ' abstract ' :   ' Automatic   crawling   of   Rich   Internet   Applications   ( RIAs )   is   a   challenge   because   client - side   code   modifies   the   client   dynamically ,   fetch -   ing   server - side   data   asynchronously .   Most   existing   solutions   model   RIAs   as   state   machines   with   DOMs   as   states   and   JavaScript   events   execution   as   transitions .   This   approach   fails   when   used   with   " real - life " ,   complex   RIAs ,   because   the   size   of   the   produced   model   is   much   too   large   to   be   practical .   In   this   paper ,   we   propose   a   new   method   to   crawl   AJAX - based   RIAs   in   an   efficient   manner   by   detecting   " components " ,   which   are   areas   of   the   DOM   that   are   independent   from   each   other ,   and   by   crawling   each   component   separately .   This   leads   to   a   dramatic   reduction   of   the   required   state   space   for   the   model ,   without   loss   of   content   coverage .   Our   method   does   not   require   prior   knowledge   of   the   RIA   nor   predefined   definition   of   components .   Instead ,   we   infer   the   components   by   observing   the   be -   havior   of   the   RIA   during   crawling .   Our   experimental   results   show   that   our   method   can   index   quickly   and   completely   industrial   RIAs   that   are   simply   out   of   reach   for   traditional   methods . ' ,   ' title ' :   ' Indexing   Rich   Internet   Applications   Using   Components - Based   Crawling ' } 
{ ' abstract ' :   ' One   important   aspect   of   constructing   an   overlay   network   is   how   to   exploit   network   locality   in   the   underlying   network .   In   this   paper ,   we   propose   a   scalable   protocol   for   constructing   an   overlay   network   that   takes   account   of   locality   of   network   hosts .   The   constructed   overlay   network   can   significantly   decrease   the   communication   cost   between   end - hosts .   Our   simulation   results   show   that   the   average   distance   between   a   pair   of   hosts   in   the   constructed   overlay   network   is   only   about   11%   of   the   one   in   a   traditional ,   randomly   connected   overlay   network .   Furthermore ,   our   proposed   overlay   considered   to   be   more   scalable   than   tree - based   or   mesh - based   overlays . ' ,   ' title ' :   ' Measurement - based   construction   of   locality - aware   overlay   networks ' } 
{ ' abstract ' :   ' This   paper   presents   a   low   cost ,   flexible   and   customizable   delay   measurement   system   developed   to   assess   the   performance   of   the   VTPE - hBEB   protocol .   The   proposed   system   can   be   used   to   evaluate   other   communication   protocols   as   well   as   to   measure   the   delay   between   two   repetitive   events . ' ,   ' title ' :   ' Delay   measurement   system   for   real - time   serial   data   streams ' } 
{ ' abstract ' :   " Service   robots   have   become   increasingly   important   subjects   in   our   lives .   However ,   they   are   still   facing   problems   like   adaptability   to   their   users .   While   major   work   has   focused   on   intelligent   service   robots ,   the   proposed   approaches   were   mostly   user   independent .   Our   work   is   part   of   the   FUI - RoboPopuli   project ,   which   concentrates   on   endowing   entertainment   companion   robots   with   adaptive   and   social   behaviour .   In   particular ,   we   are   interested   in   robots   that   are   able   to   learn   and   plan   so   that   they   adapt   and   personalize   their   behaviour   according   to   their   users .   Markov   Decision   Processes   ( MDPs )   are   largely   used   for   adaptive   robots   applications .   However ,   one   challenging   point   is   reducing   the   sample   complexity   required   to   learn   an   MDP   model ,   including   the   reward   function .   In   this   article ,   we   present   our   contribution   regarding   the   representation   and   the   learning   of   the   reward   function   through   analysing   interaction   traces   ( i . e .   the   interaction   history   between   the   robot   and   their   users ,   including   users '   feedback ) .   Our   approach   permits   to   generalise   the   learned   rewards   so   that   when   new   users   are   introduced ,   the   robot   may   quickly   adapt   using   what   it   learned   from   previous   experiences   with   other   users .   We   propose ,   in   this   article ,   two   algorithms   to   learn   the   reward   function .   The   first   is   direct   and   certain ,   the   robot   applies   with   a   user   what   it   learned   during   interaction   with   same   kind   of   users   ( i . e .   users   with   similar   profiles ) .   The   second   algorithm   generalises   what   it   learns   to   be   applied   to   all   kinds   of   users .   Through   simulation ,   we   show   that   the   generalised   algorithm   converges   to   an   optimal   reward   function   with   less   than   half   the   samples   needed   by   the   direct   algorithm . " ,   ' title ' :   " Adaptive   and   Personalised   Robots   -   Learning   from   Users '   Feedback " } 
{ ' abstract ' :   " Researches   of   sensor   networks   collecting   patients '   data   with   computerized   triage   tags ,   called   Triage   Network ,   are   attracting   attention .   The   listening   power   used   in   triage   tags   is   the   major   factor   of   lots   of   energy   consumption ,   and   consumption   of   energy   increases   when   sensor   nodes   always   communicate   with   other   nodes   in   active   state .   Hence ,   we   suppose   that   sensor   nodes   are   put   to   sleep   periodically   to   avoid   running   out   of   battery .   However ,   some   nodes   have   mobility   and   nodes   secede   from   the   network   according   to   patients   conditions   in   Triage   Network .   The   paths   are   failed   and   it   is   needed   to   reconstruct   paths   when   these   forwarding   nodes   move   or   secede   from   network .   Therefore ,   data   arrival   ratio   decreases   and   consumption   of   battery   increases   due   to   reconstruction   of   other   paths .   In   this   paper ,   we   propose   a   data   collection   method   using   two   types   of   forwarding   nodes ,   Stable   Nodes   and   Energy   Efficient   Nodes .   This   method   uses   two   types   of   forwarding   nodes   according   to   priority   of   data   and   avoids   loss   of   high   priority   data ,   improves   the   data   arrival   ratio   and   saves   the   energy   consumption .   We   evaluate   the   proposed   method   and   show   its   effectiveness   using   computer   simulations . " ,   ' title ' :   ' Data   collection   method   using   two   types   of   forwarding   nodes   for   energy   saving   in   triage   network ' } 
{ ' abstract ' :   ' This   paper   introduces   Golay - paired   Hadamard   matrices   for   fast   compressed   sensing   of   sparse   signals   in   the   time   or   spectral   domain .   These   sampling   operators   feature   low - memory   requirement ,   hardware - friendly   implementation   and   fast   computation   in   reconstruction .   We   show   that   they   require   a   nearly   optimal   number   of   measurements   for   faithful   reconstruction   of   a   sparse   signal   in   the   time   or   frequency   domain .   Simulation   results   demonstrate   that   the   proposed   sensing   matrices   offer   a   reconstruction   performance   similar   to   that   of   fully   random   matrices . ' ,   ' title ' :   ' Golay   meets   Hadamard :   Golay - paired   Hadamard   matrices   for   fast   compressed   sensing ' } 
{ ' abstract ' :   ' In   this   technical   note ,   the   problem   of   finite - time   output   regulation   control   for   a   class   of   disturbed   system   under   mismatching   condition   is   investigated   via   a   composite   control   design   manner .   The   composite   controller   is   developed   by   using   a   finite   time   control   technique   and   a   finite   time   disturbance   observer   ( FTDO ) .   A   key   idea   is   to   design   virtual   control   laws   based   on   estimation   values   of   the   disturbances   and   the   ith   ( 1 ≤ i ≤ n - 1   where   n   is   the   order   of   the   system )   order   derivative   of   disturbances .   Finite   time   stability   analysis   for   the   augmented   system   is   presented   by   means   of   Lyapunov   stability   theorems ,   which   shows   that   the   system   output   is   regulated   to   zero   in   finite   time   even   in   the   presence   of   mismatched   disturbances .   A   motion   control   application   demonstrates   the   effectiveness   and   attractive   properties   of   the   proposed   method . ' ,   ' title ' :   ' Continuous   Finite - Time   Output   Regulation   for   Disturbed   Systems   Under   Mismatching   Condition ' } 
{ ' abstract ' :   ' In   this   paper   we   propose   an   approach   for   enhanced   data   protection   in   the   cloud ,   based   upon   accountability   governance .   Specifically ,   the   relationships   between   accountability ,   risk   and   trust   are   analyzed   in   order   to   suggest   characteristics   and   means   to   address   data   governance   issues   involved   when   organizations   or   individuals   adopt   cloud   computing .   This   analysis   takes   into   account   insights   from   a   variety   of   stakeholders   within   cloud   ecosystems   obtained   by   running   an   elicitation   workshop . ' ,   ' title ' :   ' Accountability ,   Risk ,   and   Trust   in   Cloud   Services :   Towards   an   Accountability - Based   Approach   to   Risk   and   Trust   Governance ' } 
{ ' abstract ' :   ' Xue   et   al .   recently   proposed   an   innovative   mutual   authentication   and   key   agreement   scheme   for   wireless   sensor   networks   based   on   temporal   credential   using   smart   cards .   However ,   in   this   paper   we   demonstrate   that   their   scheme   is   vulnerable   to   password   guessing   attacks ,   node   capture   attacks   and   denial - of - service   attacks .   Furthermore   we   show   that   their   scheme   has   some   inconsistencies   which   make   it   less   secure   and   more   computationally   costly   than   originally   presented . ' ,   ' title ' :   ' Notes   on   A   Temporal - Credential - Based   Mutual   Authentication   and   Key   Agreement   Scheme   for   Wireless   Sensor   Networks ' } 
{ ' abstract ' :   ' Persistent   Scatterer   Interferometry   ( PSI )   has   been   widely   used   for   landslide   studies   in   recent   years .   This   paper   investigated   the   spatial   patterns   of   PSI   point   targets   and   landslide   occurrences   in   the   Arno   River   basin   in   Central   Italy .   The   main   purpose   is   to   analyze   whether   spatial   patterns   of   Persistent   Scatterers   ( PS )   can   be   recognized   as   indicators   of   landslide   occurrences   throughout   the   whole   basin .   The   bivariate   K - function   was   employed   to   assess   spatial   relationships   between   PS   and   landslides .   The   PSI   point   targets   were   acquired   from   almost   4   years   ( from   March   2003   to   January   2007 )   of   RADARSAT - 1   images .   The   landslide   inventory   was   collected   from   15   years   ( from     1992 – 2007 )   of   surveying   and   mapping   data ,   mainly   including   remote   sensing   data ,   topographic   maps   and   field   investigations .   The   proposed   approach   is   able   to   assess   spatial   patterns   between   a   variety   of   PS   and   landslides ,   in   particular ,   to   understand   if   PSI   point   targets   are   spatially   clustered   ( spatial   attraction )   or   randomly   distributed   ( spatial   independency )   on   various   types   of   landslides   across   the   basin .   Additionally ,   the   degree   and   scale   distances   of   PS   clustering   on   a   variety   of   landslides   can   be   characterized .   The   results   rejected   the   null   hypothesis   that   PSI   point   targets   appear   to   cluster   similarly   on   four   types   of   landslides   ( slides ,   flows ,   falls   and   creeps )   in   the   Arno   River   basin .   Significant   influence   of   PS   velocities   and   acquisition   orbits   can   be   noticed   on   detecting   landslides   with   different   states   of   activities .   Despite   that   the   assessment   may   be   influenced   by   the   quality   of   landslide   inventory   and   Synthetic   Aperture   Radar   ( SAR )   images ,   the   proposed   approach   is   expected   to   provide   guidelines   for   studies   trying   to   detect   and   investigate   landslide   occurrences   at   a   regional   scale   through   spatial   statistical   analysis   of   PS ,   for   which   an   advanced   understanding   of   the   impact   of   scale   distances   on   landslide   clustering   is   fundamentally   needed . ' ,   ' title ' :   ' Investigating   Spatial   Patterns   of   Persistent   Scatterer   Interferometry   Point   Targets   and   Landslide   Occurrences   in   the   Arno   River   Basin ' } 
{ ' abstract ' :   ' This   article   describes   a   middleware   used   in   display   cluster   of   real   time   visual   simulation   system .   This   middleware   which   based   on   TCP / IP   protocol   provides   the   communication   infrastructure   for   visual   simulation   system .   It   provides   unified   process   logic   and   interfaces   for   various   status   and   frame   data   and   the   packing / unpacking   functions   of   simulation   data   without   concerning   the   details   of   the   data .   We   found   two   classes   of   display   synchronization   problems   and   provided   the   resolution   of   them .   The   middleware   provides   a   group   of   APIs   which   hide   the   details   of   data   packing / unpacking ,   processing   and   transmission   and   meets   the   requirement   of   flexibility ,   efficiency   and   extensibility .   This   middleware   has   been   successfully   implemented   to   the   display   cluster   of   several   tower   simulation   system . ' ,   ' title ' :   ' The   Research   of   High   Level   Data   Communication   Middleware   of   Display   Cluster   Used   in   Real   Time   Simulation   Environment ' } 
{ ' abstract ' :   ' The   scattering   parameters   are   fundamental   in   the   characterization   of   electrical   devices   at   high   frequencies .   They   are   particularly   useful   for   analyzing   multiport   high - frequency   and   microwave   networks .   However ,   they   are   not   adequately   presented   in   most ,   if   not   all ,   microwave   engineering   books .   This   paper   identifies   two   common   deficiencies   in   the   way   scattering   parameters   are   being   presented   in   these   books .   It   provides   additional   information   that   should   supplement   those   books   or   book   chapters   on   scattering   parameters . ' ,   ' title ' :   ' Deficiencies   in   the   way   scattering   parameters   are   taught ' } 
{ ' abstract ' :   ' We   study   the   reliability   maximization   problem   in   WDM   networks   with   random   link   failures .   Reliability   in   these   networks   is   defined   as   the   probability   that   the   logical   network   is   connected ,   and   it   is   determined   by   the   underlying   lightpath   routing   and   the   link   failure   probability .   We   show   that   in   general   the   optimal   lightpath   routing   depends   on   the   link   failure   probability ,   and   characterize   the   properties   of   lightpath   routings   that   maximize   the   reliability   in   different   failure   probability   regimes .   In   particular ,   we   show   that   in   the   low   failure   probability   regime ,   maximizing   the   ` ` cross - layer "   min   cut   of   the   ( layered )   network   maximizes   reliability ,   whereas   in   the   high   failure   probability   regime ,   minimizing   the   spanning   tree   of   the   network   maximizes   reliability .   Motivated   by   these   results ,   we   develop   lightpath   routing   algorithms   for   reliability   maximization . ' ,   ' title ' :   ' Maximizing   Reliability   in   WDM   Networks   through   Lightpath   Routing ' } 
{ ' abstract ' :   ' The   slope   of   the   active   distances   is   an   important   parameter   when   investigating   the   error - correcting   capability   of   convolutional   codes   and   the   distance   behavior   of   concatenated   convolutional   codes .   The   slope   of   the   active   distances   is   equal   to   the   minimum   average   weight   cycle   in   the   state - transition   diagram   of   the   encoder .   A   general   upper   bound   on   the   slope   depending   on   the   free   distance   of   the   convolutional   code   and   new   upper   bounds   on   the   slope   of   special   classes   of   binary   convolutional   codes   are   derived .   Moreover ,   a   search   technique ,   resulting   in   new   tables   of   rate   R = 1 / 2   and   rate   R = 1 / 3   convolutional   encoders   with   high   memories   and   large   active   distance - slopes   is   presented .   Furthermore ,   we   show   that   convolutional   codes   with   large   slopes   can   be   used   to   obtain   new   tailbiting   block   codes   with   large   minimum   distances .   Tables   of   rate   R = 1 / 2   and   rate   R = 1 / 3   tailbiting   codes   with   larger   minimum   distances   than   the   best   previously   known   quasi - cyclic   codes   are   given .   Two   new   tailbiting   codes   also   have   larger   minimum   distances   than   the   best   previously   known   binary   linear   block   codes   with   same   size   and   length .   One   of   them   is   also   superior   in   terms   of   minimum   distance   to   any   previously   known   binary   nonlinear   block   code   with   the   same   set   of   parameters . ' ,   ' title ' :   ' Tailbiting   codes   obtained   via   convolutional   codes   with   large   active   distance - slopes ' } 
{ ' abstract ' :   ' MIMO   wireless   technology   is   required   to   increase   the   data   rates   for   a   broad   range   of   applications ,   including   low   cost   mobile   devices .   In   this   paper   we   present   a   very   low   area   reconfigurable   MIMO   detector   which   achieves   a   high   throughput   of   103Mbps   and   uses   27   Kilo   Gates   when   implemented   in   a   commercial   180nm   CMOS   process .   The   low   area   is   achieved   by   the   proposed   in - place   architecture .   This   architecture   implements   the   K - best   algorithm   and   reduces   area   4 - fold   compared   to   the   widely   used   multi - stage   architecture ,   while   provides   reconfigurability   in   terms   of   antenna   configuration   during   real - time   operation . ' ,   ' title ' :   ' A   low - area   flexible   MIMO   detector   for   WiFi / WiMAX   standards ' } 
{ ' abstract ' :   ' Because   human   cognition   is   creative   and   socially   situated ,   knowledge   accumulates ,   diffuses ,   and   gets   applied   in   new   contexts ,   generating   cultural   analogs   of   phenomena   observed   in   population   genetics   such   as   adaptation   and   drift .   It   is   therefore   commonly   thought   that   elements   of   culture   evolve   through   natural   selection .   However ,   natural   selection   was   proposed   to   explain   how   change   accumulates   despite   lack   of   inheritance   of   acquired   traits ,   as   occurs   with   template - mediated   replication .   It   cannot   accommodate   a   process   with   significant   retention   of   acquired   or   horizontally   ( e . g .   socially )   transmitted   traits .   Moreover ,   elements   of   culture   cannot   be   treated   as   discrete   lineages   because   they   constantly   interact   and   influence   one   another .   It   is   proposed   that   what   evolves   through   culture   is   the   mind ;   ideas   and   artifacts   are   merely   reflections   of   its   current   evolved   state .   Interacting   minds   transform   ( in   part )   through   a   non - Darwinian   autopoietic   process   similar   to   that   by   which   early   life   evolved ,   involving   not   survival   of   the   fittest   but   actualization   of   their   potential . ' ,   ' title ' :   ' The   cultural   evolution   of   socially   situated   cognition ' } 
{ ' abstract ' :   ' Event   Extraction   is   a   complex   and   interesting   topic   in   Information   Extraction   that   includes   event   extraction   methods   from   free   text   or   web   data .   The   result   of   event   extraction   systems   can   be   used   in   several   fields   such   as   risk   analysis   systems ,   online   monitoring   systems   or   decide   support   tools .   In   this   paper ,   we   introduce   a   method   that   combines   lexico   - -   semantic   and   machine   learning   to   extract   event   from   Vietnamese   news .   Furthermore ,   we   concentrate   to   describe   event   online   monitoring   system   named   VnLoc   based   on   the   method   that   was   proposed   above   to   extract   event   in   Vietnamese   language .   Besides ,   in   experiment   phase ,   we   have   evaluated   this   method   based   on   precision ,   recall   and   F1   measure .   At   this   time   of   experiment ,   we   on   investigated   on   three   types   of   event :   FIRE ,   CRIME   and   TRANSPORT   ACCIDENT . ' ,   ' title ' :   ' VnLoc :   A   Real   - -   Time   News   Event   Extraction   Framework   for   Vietnamese ' } 
{ ' abstract ' :   ' Reliability   analysis   using   error   probabilities   for   combinational   logic   circuits   has   been   investigated   widely   in   the   literature .   Reliability   analysis   for   sequential   logic   circuits   using   these   methods   would   be   inaccurate   because   of   existence   of   loops   in   their   architecture .   In   this   paper   a   new   method   based   on   conversion   of   sequential   circuit   to   combinational   one   and   applying   an   iterative   reliability   analysis   is   developed .   A   Monte   Carlo   method - based   reliability   analysis   is   introduced   for   sequential   circuits ,   which   is   used   for   first   method   validation .   Experimental   results   demonstrate   good   accuracy   of   the   method . ' ,   ' title ' :   ' SEQUENTIAL   LOGIC   CIRCUITS   RELIABILITY   ANALYSIS ' } 
{ ' abstract ' :   ' According   to   the   Journey   to   Crime   theory ,   offenders   have   a   directionality   preference ,   in   the   form   of   an   activity   path ,   when   they   are   moving   about   in   their   environment   in   search   for   criminal   activities .   Using   clustering   techniques ,   this   theory   is   tested   using   crime   data   for   the   Province   of   British   Columbia ,   Canada .   The   activities   of   57 , 962   offenders   who   were   either   charged ,   chargeable ,   or   for   whom   charges   were   recommended   were   analyzed   by   mapping   their   offense   locations   with   respect   to   their   home   locations   to   determine   directionality .   Once   directionality   was   established ,   a   unique   clustering   technique ,   based   on   K - Means   clustering   and   modified   for   angles ,   was   applied   to   find   the   number   of   activity   paths   for   each   offender .   Although   the   number   of   activity   paths   varies   from   individual   to   individual ,   the   aggregate   pattern   was   very   consistent   with   theory .   It   was   found   that   people   only   have   a   few   activity   paths ,   even   if   they   are   highly   prolific   offenders . ' ,   ' title ' :   ' How   Many   Ways   Do   Offenders   Travel   - -   Evaluating   the   Activity   Paths   of   Offenders ' } 
{ ' abstract ' :   ' Pulse   Coupled   Neural   Network ( PCNN )   is   widely   used   in   the   field   of   image   processing ,   but   it   is   a   difficult   task   to   define   the   relative   parameters   properly   in   the   research   of   the   applications   of   PCNN .   So   far   the   determination   of   parameters   of   its   model   needs   a   lot   of   experiments .   To   deal   with   the   above   problem ,   a   document   segmentation   based   on   the   improved   PCNN   is   proposed .   It   uses   the   maximum   entropy   function   as   the   fitness   function   of   bacterial   foraging   optimization   algorithm ,   adopts   bacterial   foraging   optimization   algorithm   to   search   the   optimal   parameters ,   and   eliminates   the   trouble   of   manually   set   the   experiment   parameters .   Experimental   results   show   that   the   proposed   algorithm   can   effectively   complete   document   segmentation .   And   result   of   the   segmentation   is   better   than   the   contrast   algorithms .   ©   ( 2014 )   COPYRIGHT   Society   of   Photo - Optical   Instrumentation   Engineers   ( SPIE ) .   Downloading   of   the   abstract   is   permitted   for   personal   use   only . ' ,   ' title ' :   ' PCNN   document   segmentation   method   based   on   bacterial   foraging   optimization   algorithm ' } 
{ ' abstract ' :   ' Undirected   graphical   models   encode   in   a   graph   G   the   dependency   structure   of   a   random   vector   Y .   In   many   applications ,   it   is   of   interest   to   model   Y   given   another   random   vector   X   as   input .   We   refer   to   the   problem   of   estimating   the   graph   G ( x )   of   Y   conditioned   on   X   =   x   as   " graph - valued   regression " .   In   this   paper ,   we   propose   a   semiparametric   method   for   estimating   G ( x )   that   builds   a   tree   on   the   X   space   just   as   in   CART   ( classification   and   regression   trees ) ,   but   at   each   leaf   of   the   tree   estimates   a   graph .   We   call   the   method   " Graph - optimized   CART " ,   or   Go - CART .   We   study   the   theoretical   properties   of   Go - CART   using   dyadic   partitioning   trees ,   establishing   oracle   inequalities   on   risk   minimization   and   tree   partition   consistency .   We   also   demonstrate   the   application   of   Go - CART   to   a   meteorological   dataset ,   showing   how   graph - valued   regression   can   provide   a   useful   tool   for   analyzing   complex   data . ' ,   ' title ' :   ' Graph - Valued   Regression ' } 
{ ' abstract ' :   ' Over   the   last   two   decades ,   doubts   have   been   expressed   about   the   adequacy   of   materialism   as   the   correct   framework   for   explaining   phenomenal   consciousness   ( the   experience   of   saturated   greenness   one   has   when   looking   at   a   lush   lawn ,   for   example ) .   This   paper   reconstructs   a   generic   form   of   the   various   arguments   that   have   been   used   to   defend   the   view   of   the   materialistically   inexplicable   nature   of   consciousness   ( MINC ) .   This   reconstruction   reveals   that   the   arguments   turn   on   an   impoverished   notion   of   explanation .   By   discussing   some   examples   from   the   history   of   science ,   the   paper   shows   that   a   reasonable   notion   of   explanation   has   to   be   wider   than   the   one   utilized   in   the   argument   for   MINC ,   which   opens   the   possibility   for   the   materialistic   explicability   of   consciousness .   The   author   ends   the   paper   by   raising   a   question   about   the   very   intelligibility   of   the   project   of   trying   to   explain   the   so - called   nature   of   consciousness   as   opposed   to   the   regularities   characteristic   of   the   relation   between   states   of   consciousness   and   ... ' ,   ' title ' :   ' On   explaining   phenomenal   consciousness ' } 
{ ' abstract ' :   ' Successful   replication   within   an   infected   host   and   successful   transmission   between   hosts   are   key   to   the   continued   spread   of   most   pathogens .   Competing   selection   pressures   exerted   at   these   different   scales   can   lead   to   evolutionary   trade - offs   between   the   determinants   of   fitness   within   and   between   hosts .   Here ,   we   examine   such   a   trade - off   in   the   context   of   influenza   A   viruses   and   the   differential   pressures   exerted   by   temperature - dependent   virus   persistence .   For   a   panel   of   avian   influenza   A   virus   strains ,   we   find   evidence   for   a   trade - off   between   the   persistence   at   high   versus   low   temperatures .   Combining   a   within - host   model   of   influenza   infection   dynamics   with   a   between - host   transmission   model ,   we   study   how   such   a   trade - off   affects   virus   fitness   on   the   host   population   level .   We   show   that   conclusions   regarding   overall   fitness   are   affected   by   the   type   of   link   assumed   between   the   within -   and   between - host   levels   and   the   main   route   of   transmission   ( direct   or   environmental ) .   The   relative   importance   of   virulence   and   immune   response   mediated   virus   clearance   are   also   found   to   influence   the   fitness   impacts   of   virus   persistence   at   low   versus   high   temperatures .   Based   on   our   results ,   we   predict   that   if   transmission   occurs   mainly   directly   and   scales   linearly   with   virus   load ,   and   virulence   or   immune   responses   are   negligible ,   the   evolutionary   pressure   for   influenza   viruses   to   evolve   toward   good   persistence   at   high   within - host   temperatures   dominates .   For   all   other   scenarios ,   influenza   viruses   with   good   environmental   persistence   at   low   temperatures   seem   to   be   favored . ' ,   ' title ' :   ' A   Multi - scale   Analysis   of   Influenza   A   Virus   Fitness   Trade - offs   due   to   Temperature - dependent   Virus   Persistence ' } 
{ ' abstract ' :   ' Peer - to - Peer   ( P2P )   networks   are   largely   used   for   file - sharing   and   hence   must   provide   efficient   mechanisms   for   searching   the   files   stored   at   various   nodes .   The   existing   structuredP2P   overlays   support   only   ” exact - match ”   look - up   which   is   hardly   sufficient   in   a   file   sharing   network .   This   paper   addresses   the   problem   of   keyword - based   search   in   structured   P2P   networks .   We   propose   a   new   keyword - based   searching   algorithm   which   can   be   implemented   on   top   of   any   structured   P2P   overlay .   We   demonstrate   that   the   proposed   algorithm   achieves   very   good   searching   results   as   it   requires   the   minimum   number   of   messages   to   be   sent   in   order   to   find   all   the   references   to   files   containing   at   least   the   given   set   of   keywords . ' ,   ' title ' :   ' A   Keyword   Search   Algorithm   for   Structured   Peer - to - Peer   Networks ' } 
{ ' abstract ' :   ' In   this   paper ,   we   propose   an   adaptive   power   allocation   method   for   hybrid   relay   systems   that   employ   the   amplify - and - forward   and   decode - and - forward   protocols   simultaneously .   The   total   transmission   power   is   analytically   allocated   to   a   source   and   two   selected   relays   by   the   proposed   power   allocation   criterion   to   maximize   the   overall   received   signal - to - noise   ratio   at   the   destination .   Simulation   results   show   that   the   proposed   scheme   achieves   better   performance   than   that   of   conventional   cooperative   schemes   or   hybrid   systems   with   equal   power   allocation . ' ,   ' title ' :   ' Adaptive   relay   selection   and   power   allocation   for   hybrid   relay   systems ' } 
{ ' abstract ' :   ' The   unitary   rotation   of   square - pixellated   images   is   based   on   the   finite   su ( 2 ) - oscillator   model ,   which   describes   systems   whose   values   for   position ,   momentum   and   energy ,   are   discrete   and   finite .   In   a   two - dimensional   position   space ,   this   allows   the   construction   of   angular   momentum   states ,   orthonormal   and   complete ,   for   which   rotations   are   defined   as   multiplication   by   phases   that   carry   the   rotation   angle .   The   decomposition   of   a   digital   square   images   in   terms   of   these   angular   momentum   states   determines   a   unitary   ( hence   invertible )   rotation   of   the   image ,   whose   kernel   can   be   computed   as   a   four - dimensional   array   of   real   numbers . ' ,   ' title ' :   ' Unitary   rotation   of   square - pixellated   images ' } 
{ ' abstract ' :   ' As   more   mobile   storage   devices   are   used   in   consumer   electronics ,   possibility   of   user   confidential   data   leakage   increases .   To   make   things   worse ,   data   of   deleted   file   in   mobile   storage   such   as   USB   drives   can   be   easily   recovered   and ,   thus ,   can   be   vulnerable   to   data   leakage .   To   prevent   this   type   of   data   leakage ,   efficient   secure   deletion   techniques   are   required   and   we   present   two   secure   deletion   techniques ,   namely   block   cleaning   and   zero   overwriting ,   for   flash   memory   storage .   Also ,   we   propose   cost   and   benefit   models   of   both   techniques .   The   models   imply   an   existence   of   an   efficient   adaptive   hybrid   secure   deletion   scheme   that   applies   one   of   the   techniques   based   on   their   costs   and   benefits   at   given   data   arrangements .   Experimental   results   measured   on   an   embedded   board   show   that   the   adaptive   hybrid   scheme   deletes   data   securely   and   efficiently   for   various   data   patterns   on   flash   memory   storage . ' ,   ' title ' :   ' Models   and   Design   of   an   Adaptive   Hybrid   Scheme   for   Secure   Deletion   of   Data   in   Consumer   Electronics ' } 
{ ' abstract ' :   ' In   heterogeneous   and   dynamic   environments ,   efficient   execution   of   parallel   computations   can   require   mappings   of   tasks   to   processors   whose   performance   is   both   irregular   ( because   of   heterogeneity )   and   time - varying   ( because   of   dynamicity ) .   While   adaptive   domain   decomposition   techniques   have   been   used   to   address   heterogeneous   resource   capabilities ,   temporal   variations   in   those   capabilities   have   seldom   been   considered .   We   propose   a   conservative   scheduling   policy   that   uses   information   about   expected   future   variance   in   resource   capabilities   to   produce   more   efficient   data   mapping   decisions .   We   first   present   techniques ,   based   on   time   series   predictors   that   we   developed   in   previous   work ,   for   predicting   CPU   load   at   some   future   time   point ,   average   CPU   load   for   some   future   time   interval ,   and   variation   of   CPU   load   over   some   future   time   interval .   We   then   present   a   family   of   stochastic   scheduling   algorithms   that   exploit   such   predictions   of   future   availability   and   variability   when   making   data   mapping   decisions .   Finally ,   we   describe   experiments   in   which   we   apply   our   techniques   to   an   astrophysics   application .   The   results   of   these   experiments   demonstrate   that   conservative   scheduling   can   produce   execution   times   that   are   both   significantly   faster   and   less   variable   than   other   techniques . ' ,   ' title ' :   ' Conservative   Scheduling :   Using   Predicted   Variance   to   Improve   Scheduling   Decisions   in   Dynamic   Environments ' } 
{ ' abstract ' :   ' We   consider   a   class   of   restless   multi - armed   bandit   problems   that   arises   in   multi - channel   opportunistic   communications ,   where   channels   are   modeled   as   independent   and   stochastically   identical   Gilbert - Elliot   channels   and   channel   state   observations   are   subject   to   errors .   We   show   that   the   myopic   channel   selection   policy   has   a   semi - universal   structure   that   obviates   the   need   to   know   the   Markovian   transition   probabilities   of   the   channel   states .   Based   on   this   structure ,   we   establish   closed - form   lower   and   upper   bounds   on   the   steady - state   throughput   achieved   by   the   myopic   policy .   Furthermore ,   we   characterize   the   approximation   factor   of   the   myopic   policy   to   bound   its   worst - case   performance   loss   with   respect   to   the   optimal   performance . ' ,   ' title ' :   ' On   the   myopic   policy   for   a   class   of   restless   bandit   problems   with   applications   in   dynamic   multichannel   access ' } 
{ ' abstract ' :   ' We   show   that   the   optimum   length - / spl   nu /   guard   sequence   for   block   transmission   over   a   linear   Gaussian - noise   dispersive   channel   with   memory   / spl   nu /   is   a   linear   combination   of   the   N   information   symbols   of   the   block .   A   closed - form   expression   for   the   optimum   guard   sequence   is   derived   subject   to   a   total   average   energy   constraint   on   the   information   and   guard   symbols .   The   achievable   channel   block   throughput   with   the   optimum   guard   sequence   is   compared   with   that   achievable   with   two   common   guard   sequence   types ,   namely   zero   stuffing   and   cyclic   prefix . ' ,   ' title ' :   ' Guard   sequence   optimization   for   block   transmission   over   linear   frequency - selective   channels ' } 
{ ' abstract ' :   " A   modular   program   analysis   considers   components   independently   and   provides   a   succinct   summary   for   each   component ,   which   is   used   when   checking   the   rest   of   the   system .   Consider   a   system   consisting   of   a   library   and   a   client .   A   temporal   summary ,   or     interface   ,   of   the   library   specifies   legal   sequences   of   library   calls .   The   interface   is     safe     if   no   call   sequence   violates   the   library ' s   internal   invariants ;   the   interface   is     permissive     if   it   contains   every   such   sequence .   Modular   program   analysis   requires     full     interfaces ,   which   are   both   safe   and   permissive :   the   client   does   not   cause   errors   in   the   library   if   and   only   if   it   makes   only   sequences   of   library   calls   that   are   allowed   by   the   full   interface   of   the   library . Previous   interface - based   methods   have   focused   on   safe   interfaces ,   which   may   be   too   restrictive   and   thus   reject   good   clients .   We   present   an   algorithm   for   automatically   synthesizing   software   interfaces   that   are   both   safe   and   permissive .   The   algorithm   generates   interfaces   as   graphs   whose   vertices   are   labeled   with   predicates   over   the   library ' s   internal   state ,   and   whose   edges   are   labeled   with   library   calls .   The   interface   state   is   refined   incrementally   until   the   full   interface   is   constructed .   In   other   words ,   the   algorithm   automatically   synthesizes   a   typestate   system   for   the   library ,   against   which   any   client   can   be   checked   for   compatibility .   We   present   an   implementation   of   the   algorithm   which   is   based   on   the   BLAST   model   checker ,   and   we   evaluate   some   case   studies . " ,   ' title ' :   ' Permissive   interfaces ' } 
{ ' abstract ' :   ' In   this   paper ,   we   propose   a   new   method   for   the   motion   planning   problem   of   rigid   object   dexterous   manipulation   with   a   robotic   multi - fingered   hand ,   under   quasi - static   movement   assumption .   This   method   computes   both   object   and   finger   trajectories   as   well   as   the   finger   relocation   sequence .   Its   specificity   is   to   use   a   special   structuring   of   the   research   space   that   allows   to   search   for   paths   directly   in   the   particular   subspace   GS   n     which   is   the   subspace   of   all   the   grasps   that   can   be   achieved   with   n   grasping   fingers .   The   solving   of   the   dexterous   manipulation   planning   problem   is   based   upon   the   exploration   of   this   subspace .   The   proposed   approach   captures   the   connectivity   of   GS   n     in   a   graph   structure .   The   answer   of   the   manipulation   planning   query   is   then   given   by   searching   a   path   in   the   computed   graph .   Simulation   experiments   were   conducted   for   different   dexterous   manipulation   task   examples   to   validate   the   proposed   method . ' ,   ' title ' :   ' Dexterous   manipulation   planning   using   probabilistic   roadmaps   in   continuous   grasp   subspaces ' } 
{ ' abstract ' :   ' This   paper   presents   an   experimental   evaluation   of   different   line   extraction   algorithms   applied   to   2D   laser   scans   for   indoor   environments .   Six   popular   algorithms   in   mobile   robotics   and   computer   vision   are   selected   and   tested .   Real   scan   data   collected   from   two   office   environments   by   using   different   platforms   are   used   in   the   experiments   in   order   to   evaluate   the   algorithms .   Several   comparison   criteria   are   proposed   and   discussed   to   highlight   the   advantages   and   drawbacks   of   each   algorithm ,   including   speed ,   complexity ,   correctness   and   precision .   The   results   of   the   algorithms   are   compared   with   ground   truth   using   standard   statistical   methods .   An   extended   case   study   is   performed   to   further   evaluate   the   algorithms   in   a   SLAM   application . ' ,   ' title ' :   ' A   comparison   of   line   extraction   algorithms   using   2D   range   data   for   indoor   mobile   robotics ' } 
{ ' abstract ' :   ' This   study   investigates   the   use   of   force - stiffness   feedback ,   i . e . ,   a   combination   of   force   offset   and   extra   spring   load ,   in   UAV   tele - operation   with   transmission   time   delay .   The   goal   was   to   further   increase   the   level   of   safety   of   tele - operation   with   a   reduction   in   operator   workload   with   respect   to   force   feedback ,   i . e . ,   using   force   offset   alone .   A   theoretical   analysis   is   given   of   using   force - stiffness   feedback   to   improve   collision   avoidance .   Wave   variables   are   included   to   reduce   time   delay   effects .   An   experiment   was   conducted   to   investigate   the   effects   of   force - stiffness   feedback   on   safety   of   operation ,   operator   performance ,   control   activity ,   and   workload .   Results   indicate   that   force - stiffness   feedback   improves   the   haptic   interface   with   respect   to   force   feedback   alone .   Safety   of   tele - operation   increases   without   increasing   operator   workload   with   respect   to   force   feedback . ' ,   ' title ' :   ' Haptic   interface   in   UAV   tele - operation   using   force - stiffness   feedback ' } 
{ ' abstract ' :   ' Due   to   the   spread   of   the   internet   and   the   ever   increasing   number   of   web   applications ,   the   issue   of   compatibility   across   browsers   has   become   very   important .   This   compatibility   issue   is   also   referred   as   Cross   Browser   Inconsistency   ( XBI )   wherein   same   website   looks   or   behaves   differently   in   different   web   browsers .   In   this   paper   our   aim   is   to   address   this   issue   of   compatibility   and   propose   an   automated   approach   of   detecting   XBIs .   Cross   Browser   Inconsistencies   can   either   be   in   the   content ,   structure   or   behavior   of   the   webpage .   In   order   to   get   a   grasp   of   the   above   mentioned   types   of   inconsistencies ,   we   surveyed   some   random   websites   and   analyzed   them   in   different   browsers .   We   also   studied   the   basic   working   of   browser ,   in   order   to   establish   its   connection   with   the   occurrences   of   XBIs .   Each   browser   has   its   own   rendering   mechanisms ,   which   sometimes   differs   from   standards .   Hence ,   the   execution   of   these   websites   is   different   in   different   browsers .   Finally   we   have   proposed   an   automated   approach   for   XBI   detection . ' ,   ' title ' :   ' An   Automated   Approach   for   Cross - Browser   Inconsistency   ( XBI )   Detection ' } 
{ ' abstract ' :   ' We   present   a   formal   framework   that   combines   high - level   representation   and   causality - based   reasoning   with   low - level   geometric   reasoning   and   motion   planning .   The   frame - work   features   bilateral   interaction   between   task   and   motion   planning ,   and   embeds   geometric   reasoning   in   causal   reasoning ,   thanks   to   several   advantages   inherited   from   its   underlying   components .   In   particular ,   our   choice   of   using   a   causality - based   high - level   formalism   for   describing   action   domains   allows   us   to   represent   ramifications   and   state / transition   constraints ,   and   embed   in   such   formal   domain   descriptions   externally   defined   functions   implemented   in   some   programming   language   ( e . g . ,   C++ ) .   Moreover ,   given   such   a   domain   description ,   the   causal   reasoner   based   on   this   formalism   ( i . e . ,   the   Causal   Calculator )   allows   us   to   compute   optimal   solutions   ( e . g . ,   shortest   plans )   for   elaborate   planning / prediction   problems   with   temporal   constraints .   Utilizing   these   features   of   high - level   representation   and   reasoning ,   we   can   combine   causal   reasoning ,   motion   planning   and   geometric   planning   to   find   feasible   kinematic   solutions   to   task - level   problems .   In   our   framework ,   the   causal   reasoner   guides   the   motion   planner   by   finding   an   optimal   task - plan ;   if   there   is   no   feasible   kinematic   solution   for   that   task - plan   then   the   motion   planner   guides   the   causal   reasoner   by   modifying   the   planning   problem   with   new   temporal   constraints .   Furthermore ,   while   computing   a   task - plan ,   the   causal   reasoner   takes   into   account   geometric   models   and   kinematic   relations   by   means   of   external   predicates   implemented   for   geometric   reasoning   ( e . g . ,   to   check   some   collisions ) ;   in   that   sense   the   geometric   reasoner   guides   the   causal   reasoner   to   find   feasible   kinematic   solutions .   We   illustrate   an   application   of   this   framework   to   robotic   manipulation ,   with   two   pantograph   robots   on   a   complex   assembly   task   that   requires   concurrent   execution   of   actions .   A   short   video   of   this   application   accompanies   the   paper . ' ,   ' title ' :   ' Combining   high - level   causal   reasoning   with   low - level   geometric   reasoning   and   motion   planning   for   robotic   manipulation ' } 
{ ' abstract ' :   ' This   paper   presents   a   novel   template   matching   method   to   detect   and   track   pedestrians   for   people   counting   in   real - time .   Firstly ,   a   novel   background   subtraction   method   is   proposed   for   extracting   all   foreground   objects   from   background .   Then ,   a   shadow   elimination   method   is   used   to   remove   unwanted   shadow   from   the   background .   In   order   to   identify   pedestrians   from   non - pedestrian   objects ,   this   paper   proposed   a   novel   grid - based   template   matching   scheme   to   robustly   verify   each   pedestrian .   Usually ,   a   pedestrian   will   have   different   appearances   at   different   positions .   The   grid - based   approach   can   effectively   reduce   the   perspective   effects   into   a   minimum   since   it   uses   different   templates   to   record   the   appearance   changes   at   each   grid .   When   more   templates   are   used ,   the   detection   process   will   become   more   inefficient .   To   speed   up   its   efficiency ,   an   integral   image   is   used   to   filter   out   all   impossible   candidates   in   advance .   Lastly ,   a   tracking   method   is   applied   to   tracking   the   direction   of   each   moving   pedestrian   so   that   the   real   number   of   passing   people   per   direction   can   be   counted   more   accurately .   Experimental   results   have   proved   that   the   proposed   method   is   robust ,   accurate ,   and   powerful   in   people   counting . ' ,   ' title ' :   ' Grid - based   Template   Matching   for   People   Counting ' } 
{ ' abstract ' :   ' A   tomographic   image   reconstruction   algorithm   that   we   have   been   studying   requires   the   nth - order   Hankel   transform   for   the   nth   function   in   a   series ,   where   n   varies   over   a   set   of   integers .   Unfortunately ,   most   previously   proposed   algorithms   have   either   dealt   with   only   zeroth - order   transforms   or   cannot   be   applied   conveniently   to   our   problem .   We   propose   an   algorithm   for   computing   general   integer - order   Hankel   transforms .   The   algorithm   takes   samples   of   equally   spaced   input   functions   and   gives   equally   spaced   samples   of   the   transforms . ' ,   ' title ' :   ' An   algorithm   for   computing   general   integer - order   Hankel   transforms ' } 
{ ' abstract ' :   ' In   this   paper ,   we   present   a   real - time   approach   that   allows   tracking   deformable   structures   in   3D   ultrasound   sequences .   Our   method   consists   in   obtaining   the   target   displacements   by   combining   robust   dense   motion   estimation   and   mechanical   model   simulation .   We   perform   evaluation   of   our   method   through   simulated   data ,   phantom   data ,   and   real - data .   Results   demonstrate   that   this   novel   approach   has   the   advantage   of   providing   correct   motion   estimation   regarding   different   ultrasound   shortcomings   including   speckle   noise ,   large   shadows   and   ultrasound   gain   variation .   Furthermore ,   we   show   the   good   performance   of   our   method   with   respect   to   state - of - the - art   techniques   by   testing   on   the   3D   databases   provided   by   MICCAI   CLUST ’ 14   and   CLUST ’ 15   challenges . ' ,   ' title ' :   ' Real - time   target   tracking   of   soft   tissues   in   3D   ultrasound   images   based   on   robust   visual   information   and   mechanical   simulation ' } 
{ ' abstract ' :   ' For   two   given   graphs   G1G1   and   G2G2 ,   the   Ramsey   number   R ( G1 , G2 ) R ( G1 , G2 )   is   the   smallest   integer   NN   such   that   for   any   graph   of   order   NN ,   either   GG   contains   a   copy   of   G1G1   or   its   complement   contains   a   copy   of   G2G2 .   Let   CmCm   be   a   cycle   of   length   mm   and   K1 , nK1 , n   a   star   of   order   n + 1n + 1 .   Parsons   ( 1975 )   shows   that   R ( C4 , K1 , n ) ≤ n + ⌊ n − 1 ⌋ + 2   and   if   nn   is   the   square   of   a   prime   power ,   then   the   equality   holds .   In   this   paper ,   by   discussing   the   properties   of   polarity   graphs   whose   vertices   are   points   in   the   projective   planes   over   Galois   fields ,   we   prove   that   R ( C4 , K1 , q2 − t ) = q2 + q − ( t − 1 ) R ( C4 , K1 , q2 − t ) = q2 + q − ( t − 1 )   if   qq   is   an   odd   prime   power ,   1 ≤ t ≤ 2 ⌈ q4 ⌉   and   t ≠ 2 ⌈ q4 ⌉ − 1 ,   which   extends   a   result   on   R ( C4 , K1 , q2 − t ) R ( C4 , K1 , q2 − t )   obtained   by   Parsons   ( 1976 ) . ' ,   ' title ' :   ' Polarity   graphs   and   Ramsey   numbers   for   C   4   versus   stars ' } 
{ ' abstract ' :   ' This   paper   deals   with   the   problem   of   assuring   strict   QoS   guarantees   for   the   end   to   end   connections   that   originate   from   Ethernet   access   network .   It   shows   that   despite   high   link   capacities   in   some   cases   Ethernet   network   might   be   the   reason   of   QoS   deterioration .   The   primary   reason   is   the   lack   of   appropriate   QoS   differentiation   and   traffic   isolation   mechanisms .   The   shared   buffers   and   priority   schedulers   available   in   most   of   Ethernet   switches   appear   to   be   not   sufficient   to   guarantee   strict   QoS .   For   these   cases   new   solution   is   proposed   which   relies   on   additional   traffic   control   mechanisms   available   in   other   network   elements .   Only   additional   mechanism   supporting   typical   functionality   of   Ethernet   switch   can   provide   strict   QoS   guarantees   what   was   verified   in   simulations   studies . ' ,   ' title ' :   ' On   assuring   QoS   in   Ethernet   access   network ' } 
{ ' abstract ' :   ' The   federal   Medicare   regulations   reimburse   hospitals   on   a   pro   rata   share   of   the   hospital \ ' s   cost .   Hence ,   to   meet   its   financial   requirements ,   a   hospital   is   forced   to   shift   more   of   the   financial   burdens   onto   its   private   patients .   This   procedure   has   contributed   to   double   digit   inflation   in   hospital   prices   and   to   proposed   federal   regulation   to   control   the   rate   of   increase   in   hospital   revenues .   In   this   regulatory   environment ,   we   develop   nonlinear   programming   pricing   and   cost   allocation   models   to   aid   hospital   administrators   in   meeting   their   profit   maximizing   and   profit   satisficing   goals .   The   model   enables   administrators   to   explore   tactical   issues   such   as :   i   studying   the   relationship   between   a   voluntary   or   legislated   cap   on   a   hospital \ ' s   total   revenues   and   the   hospital \ ' s   profitability ,   ii   identifying   those   departments   within   the   hospital   that   are   the   most   attractive   candidates   for   cost   reduction   or   cost   containment   efforts ,   and   iii   isolating   those   services   that   should   be   singled   out   by   the   hospital   manager   for   renegotiation   of   the   prospective   or   " customary   and   reasonable "   cap .   Finally ,   the   modeling   approach   is   helpful   in   explaining   the   departmental   cross   subsidies   observed   in   practice ,   and   can   be   of   aid   to   federal   administrators   in   assessing   the   impacts   of   proposed   changes   in   the   Medicare   reimbursement   formula . ' ,   ' title ' :   ' Hospital   Profit   Planning   under   Medicare   Reimbursement ' } 
{ ' abstract ' :   ' We   present   a   ( 4   +   epsilon )   approximation   algorithm   for   weighted   graph   matching   which   applies   in   the   semistreaming ,   sliding   window ,   and   MapReduce   models ;   this   single   algorithm   improves   the   previous   best   algorithm   in   each   model .   The   algorithm   operates   by   reducing   the   maximum - weight   matching   problem   to   a   polylog   number   of   copies   of   the   maximum - cardinality   matching   problem .   The   algorithm   also   extends   to   provide   approximation   guarantees   for   the   more   general   problem   of   finding   weighted   independent   sets   in   p - systems   ( which   include   intersections   of   p   matroids   and   p - bounded   hypergraph   matching ) . ' ,   ' title ' :   ' Improved   Streaming   Algorithms   for   Weighted   Matching ,   via   Unweighted   Matching ' } 
{ ' abstract ' :   ' This   paper   presents   a   novel   approach   to   efficiently   solve   parameter - dependent   ( PD )   linear   matrix   inequality   ( LMI )   problems   for ,   amongst   others ,   linear   parameter - varying   ( LPV )   control   design .   Typically ,   stability   and   performance   is   guaranteed   by   finding   a   PD   Lyapunov   function   such   that   a   PD   LMI   is   feasible   on   a   parameter   domain .   To   solve   the   resulting   semi - infinite   problems ,   we   propose   a   novel   LMI   relaxation   technique   relying   on   B - spline   basis   functions .   This   technique   provides   less   conservative   solutions   and / or   a   reduced   numerical   burden   compared   to   existing   approaches .   Moreover ,   an   elegant   generalization   of   worst - case   optimization   to   the   optimization   of   any   signal   norm   is   obtained   by   expressing   performance   bounds   as   a   function   of   the   system   parameters .   This   generalization   yields   better   performance   bounds   in   a   large   part   of   the   parameter   domain .   Numerical   comparisons   with   the   current   state - of - the - art   demonstrate   the   generality   and   effectiveness   of   our   approach . ' ,   ' title ' :   ' Control   of   linear   parameter - varying   systems   using   B - splines ' } 
{ ' abstract ' :   ' There   is   a   growing   interest   in   simulating   natural   phenomena   in   computer   graphics   applications .   Animating   natural   scenes   in   real   time   is   one   of   the   most   challenging   problems   due   to   the   inherent   complexity   of   their   structure ,   formed   by   millions   of   geometric   entities ,   and   the   interactions   that   happen   within .   An   example   of   natural   scenario   that   is   needed   for   games   or   simulation   programs   are   forests .   Forests   are   difficult   to   render   because   the   huge   amount   of   geometric   entities   and   the   large   amount   of   detail   to   be   represented .   Moreover ,   the   interactions   between   the   objects   ( grass ,   leaves )   and   external   forces   such   as   wind   are   complex   to   model .   In   this   paper   we   concentrate   in   the   rendering   of   falling   leaves   at   low   cost .   We   present   a   technique   that   exploits   graphics   hardware   in   order   to   render   thousands   of   leaves   with   different   falling   paths   in   real   time   and   low   memory   requirements . ' ,   ' title ' :   ' Rendering   falling   leaves   on   graphics   hardware ' } 
{ ' abstract ' :   ' We   previously   presented   DriverDB ,   a   database   that   incorporates   ∼ 6000   cases   of   exome - seq   data ,   in   addition   to   annotation   databases   and   published   bioinformatics   algorithms   dedicated   to   driver   gene / mutation   identification .   The   database   provides   two   points   of   view ,   ‘ Cancer ’   and   ‘ Gene ’ ,   to   help   researchers   visualize   the   relationships   between   cancers   and   driver   genes / mutations .   In   the   updated   DriverDBv2   database   ( http : / / ngs . ym . edu . tw / driverdb )   presented   herein ,   we   incorporated   > 9500   cancer - related   RNA - seq   datasets   and   > 7000   more   exome - seq   datasets   from   The   Cancer   Genome   Atlas   ( TCGA ) ,   International   Cancer   Genome   Consortium   ( ICGC ) ,   and   published   papers .   Seven   additional   computational   algorithms   ( meaning   that   the   updated   database   contains   15   in   total ) ,   which   were   developed   for   driver   gene   identification ,   are   incorporated   into   our   analysis   pipeline ,   and   the   results   are   provided   in   the   ‘ Cancer ’   section .   Furthermore ,   there   are   two   main   new   features ,   ‘ Expression ’   and   ‘ Hotspot ’ ,   in   the   ‘ Gene ’   section .   ‘ Expression ’   displays   two   expression   profiles   of   a   gene   in   terms   of   sample   types   and   mutation   types ,   respectively .   ‘ Hotspot ’   indicates   the   hotspot   mutation   regions   of   a   gene   according   to   the   results   provided   by   four   bioinformatics   tools .   A   new   function ,   ‘ Gene   Set ’ ,   allows   users   to   investigate   the   relationships   among   mutations ,   expression   levels   and   clinical   data   for   a   set   of   genes ,   a   specific   dataset   and   clinical   features . ' ,   ' title ' :   ' DriverDBv2 :   a   database   for   human   cancer   driver   gene   research ' } 
{ ' abstract ' :   ' Thousands   of   deep   and   wide   pipelines   working   concurrently   make   GPGPU   high   power   consuming   parts .   Energy - efficiency   techniques   employ   voltage   overscaling   that   increases   timing   sensitivity   to   variations   and   hence   aggravating   the   energy   use   issues .   This   paper   proposes   a   method   to   increase   spatiotemporal   reuse   of   computational   effort   by   a   combination   of   compilation   and   micro - architectural   design .   An   associative   memristive   memory   ( AMM )   module   is   integrated   with   the   floating   point   units   ( FPUs ) .   Together ,   we   enable   fine - grained   partitioning   of   values   and   find   high - frequency   sets   of   values   for   the   FPUs   by   searching   the   space   of   possible   inputs ,   with   the   help   of   application - specific   profile   feedback .   For   every   kernel   execution ,   the   compiler   pre - stores   these   high - frequent   sets   of   values   in   AMM   modules   - -   representing   partial   functionality   of   the   associated   FPU - -   that   are   concurrently   evaluated   over   two   clock   cycles .   Our   simulation   results   show   high   hit   rates   with   32 - entry   AMM   modules   that   enable   36%   reduction   in   average   energy   use   by   the   kernel   codes .   Compared   to   voltage   overscaling ,   this   technique   enhances   robustness   against   timing   errors   with   39%   average   energy   saving . ' ,   ' title ' :   ' Energy - Efficient   GPGPU   Architectures   via   Collaborative   Compilation   and   Memristive   Memory - Based   Computing ' } 
{ ' abstract ' :   ' Quasi - cyclic   codes   are   renowned   for   their   structural   design   and   low - complexity   shift   register   encoding .   However ,   existing   design   techniques   based   on   difference   families   have   limited   code   size   options   due   to   algebraic   constraints .   We   introduce   in   this   paper   a   notation   of   extended   difference   family   ( EDF )   and   provide   a   systematic   code   design   based   on   EDFs   with   a   high   degree   of   flexibility   in   code   size .   Short / medium - length   codes   of   high   rate   ( / spl   ges /   0.9 )   can   be   easily   constructed . ' ,   ' title ' :   ' Quasi - cyclic   codes   from   extended   difference   families ' } 
{ ' abstract ' :   ' Lexical   cohesion   arises   from   a   chain   of   lexical   items   that   establish   links   between   sentences   in   a   text .   In   this   paper   we   propose   three   different   models   to   capture   lexical   cohesion   for   document - level   machine   translation :   ( a )   a   direct   reward   model   where   translation   hypotheses   are   rewarded   whenever   lexical   cohesion   devices   occur   in   them ,   ( b )   a   conditional   probability   model   where   the   appropriateness   of   using   lexical   cohesion   devices   is   measured ,   and   ( c )   a   mutual   information   trigger   model   where   a   lexical   cohesion   relation   is   considered   as   a   trigger   pair   and   the   strength   of   the   association   between   the   trigger   and   the   triggered   item   is   estimated   by   mutual   information .   We   integrate   the   three   models   into   hierarchical   phrase - based   machine   translation   and   evaluate   their   effectiveness   on   the   NIST   Chinese - English   translation   tasks   with   large - scale   training   data .   Experiment   results   show   that   all   three   models   can   achieve   substantial   improvements   over   the   baseline   and   that   the   mutual   information   trigger   model   performs   better   than   the   others . ' ,   ' title ' :   ' Modeling   lexical   cohesion   for   document - level   machine   translation ' } 
{ ' abstract ' :   ' This   paper   presents   a   lightweight   sketching   system   that   enables   interactive   illustration   of   complex   fluid   systems .   Users   can   sketch   on   a   2.5 - dimensional   ( 2.5 D )   canvas   to   design   the   shapes   and   connections   of   a   fluid   circuit .   These   input   sketches   are   automatically   analyzed   and   abstracted   into   a   hydraulic   graph ,   and   a   new   hybrid   fluid   model   is   used   in   the   background   to   enhance   the   illustrations .   The   system   provides   rich   simple   operations   for   users   to   edit   the   fluid   system   incrementally ,   and   the   new   internal   flow   patterns   can   be   simulated   in   real   time .   Our   system   is   used   to   illustrate   various   fluid   systems   in   medicine ,   biology ,   and   engineering .   We   asked   professional   medical   doctors   to   try   our   system   and   obtained   positive   feedback   from   them . ' ,   ' title ' :   ' Sketch - based   Dynamic   Illustration   of   Fluid   Systems ' } 
{ ' abstract ' :   ' We   present   an   improved   zone   content   classification   method   and   its   performance   evaluation .   We   added   two   new   features   to   the   feature   vector   from   one   previously   published   method   ( Sivaramakrishnan   et   al . ,   1995 ) .   We   assumed   different   independence   relationships   in   two   zone   sets .   We   used   an   optimized   binary   decision   tree   to   estimate   the   maximum   zone   content   class   probability   in   one   set   while   using   the   Viterbi   algorithm   to   find   the   optimal   solution   for   a   zone   sequence   in   the   other   set .   The   training ,   pruning   and   testing   data   set   for   the   algorithm   include   1 , 600   images   drawn   from   the   UWCDROM   III   document   image   database .   The   classifier   is   able   to   classify   each   given   scientific   and   technical   document   zone   into   one   of   the   nine   classes ,   2   text   classes   ( of   font   size   4   -   18pt   and   font   size   19   -   32   pt ) ,   math ,   table ,   halftone ,   map / drawing ,   ruling ,   logo ,   and   others .   Compared   with   our   previous   work   ( Wang   et   al . ,   2000 ) ,   it   raised   the   accuracy   rate   to   98.52%   from   97.53%   and   reduced   the   mean   false   alarm   rate   to   0.53%   from   1.26% . ' ,   ' title ' :   ' Zone   content   classification   and   its   performance   evaluation ' } 
{ ' abstract ' :   ' Big   Data   applications   require   real - time   processing   of   complex   computations   on   streaming   and   static   information .   Applications   such   as   the   diagnosis   of   power   generating   turbines   require   the   integration   of   high   velocity   streaming   and   large   volume   of   static   data   from   multiple   sources .   In   this   paper   we   study   various   optimisations   related   to   efficiently   processing   of   streaming   and   static   information .   We   introduce   novel   indexing   structures   for   stream   processing ,   a   query - planner   component   that   decides   when   their   creation   is   beneficial ,   and   we   examine   precomputed   summarisations   on   archived   measurements   to   accelerate   streaming   and   static   information   processing .   To   put   our   ideas   into   practise ,   we   have   developed   Exa   Stream ,   a   data   stream   management   system   that   is   scalable ,   has   declarative   semantics ,   supports   user   defined   functions ,   and   allows   efficient   execution   of   complex   analytical   queries   on   streaming   and   static   data .   Our   work   is   accompanied   by   an   empirical   evaluation   of   our   optimisation   techniques . ' ,   ' title ' :   ' Real   time   processing   of   streaming   and   static   information ' } 
{ ' abstract ' :   " In   the   last   ten   years ,   speech   recognition   has   evolved   from   a   science   fiction   dream   to   a   widespread   input   method   for   mobile   devices .   In   this   talk ,   I   will   describe   how   speech   recognition   works ,   the   problems   we   have   solved   and   the   challenges   that   remain .   I   will   touch   upon   some   of   Google ' s   main   efforts   in   language   and   pronunciation   modeling ,   and   describe   how   the   adoption   of   neural   networks   for   acoustic   modeling   marked   the   beginning   of   a   technology   revolution   in   the   field ,   with   approaches   such   as   Long   Short   Term   Memory   models   and   Connectionist   Temporal   Classification .   I   will   also   share   my   learnings   on   how   Machine   Learning   and   Human   Knowledge   can   be   harmoniously   combined   to   build   state - of - the - art   technology   that   helps   and   delights   users   across   the   world . " ,   ' title ' :   ' Learnings   and   innovations   in   speech   recognition ' } 
{ ' abstract ' :   ' Nowadays ,   the   explosive   growth   and   variety   of   information   available   on   the   Web   frequently   overwhelms   users   and   leads   users   to   make   poor   decisions .   Consequently ,   recommender   systems   have   become   more   and   more   important   to   assist   people   to   make   decisions   faster .   Among   all   related   techniques ,   collaborative   filtering   approach   is   currently   one   of   the   effective   and   widely   used   techniques   to   build   recommender   systems .   However ,   there   are   major   challenges   like   data   sparsity   and   scalability .   Meanwhile   it   is   hard   to   integrate   demographic   statistical   information   ( Age ,   gender   and   occupation   etc . )   to   collaborative   filtering   model .   Unfortunately ,   it   is   significant   to   take   account   into   these   information ,   especially   user   occupation   when   making   recommendation .   As   we   all   know ,   people   with   different   occupations   may   have   totally   different   tastes .   It   has   been   proved   that   restricted   Boltzmann   machines ( RBM )   model   can   infer   lower - dimensional   representations   automatically   and   is   potential   in   handling   large   and   sparse   dataset .   In   this   paper ,   we   propose   an   improved   User   Occupation   aware   Conditional   Restricted   Boltzmann   Machine   Frame ( UO - CRBMF )   model ,   which   employs   an   improved   RBM   and   takes   full   use   of   user   occupation   information   by   adding   a   conditional   layer   with   user   occupation   information .   Experimental   studies   on   the   standard   benchmark   datasets   of   MovieLens   100k   and   MovieLens   1M   have   shown   its   potential   and   advantages   beyond   baseline   methods . ' ,   ' title ' :   ' User   Occupation   Aware   Conditional   Restricted   Boltzmann   Machine   Based   Recommendation ' } 
{ ' abstract ' :   ' Microservices   complement   approaches   like   DevOps   and   continuous   delivery   in   terms   of   software   architecture .   Along   with   this   architectural   style ,   several   important   deployment   technologies ,   such   as   container - based   virtualization   and   container   orchestration   solutions ,   have   emerged .   These   technologies   allow   to   efficiently   exploit   cloud   platforms ,   providing   a   high   degree   of   scalability ,   availability ,   and   portability   for   microservices .# R ## N ## R ## N # Despite   the   obvious   importance   of   a   sufficient   level   of   performance ,   there   is   still   a   lack   of   performance   engineering   approaches   explicitly   taking   into   account   the   particularities   of   microservices .   In   this   paper ,   we   argue   why   new   solutions   to   performance   engineering   for   microservices   are   needed .   Furthermore ,   we   identify   open   issues   and   outline   possible   research   directions   with   regard   to   performance - aware   testing ,   monitoring ,   and   modeling   of   microservices . ' ,   ' title ' :   ' Performance   Engineering   for   Microservices :   Research   Challenges   and   Directions ' } 
{ ' abstract ' :   ' Intelligent   agents ,   such   as   robots ,   have   to   serve   a   multitude   of   autonomous   functions .   Examples   are ,   e . g . ,   collision   avoidance ,   navigation   and   route   planning ,   active   sensing   of   its   environment ,   or   the   interaction   and   non - verbal   communication   with   people   in   the   extended   reach   space .   Here ,   we   focus   on   the   recognition   of   the   action   of   a   human   agent   based   on   a   biologically   inspired   visual   architecture   of   analyzing   articulated   movements .   The   proposed   processing   architecture   builds   upon   coarsely   segregated   streams   of   sensory   processing   along   different   pathways   which   separately   process   form   and   motion   information   ( Layher   et   al . ,   2014 ) .   Action   recognition   is   performed   in   an   event - based   scheme   by   identifying   representations   of   characteristic   pose   configurations   ( key   poses )   in   an   image   sequence .   In   line   with   perceptual   studies ,   key   poses   are   selected   unsupervised   utilizing   a   feature   driven   criterion   which   combines   extrema   in   the   motion   energy   with   the   horizontal   and   the   vertical   extendedness   of   a   body   shape .   Per   class   representations   of   key   pose   frames   are   learned   using   a   deep   convolutional   neural   network   consisting   of   15   convolutional   layers .   The   network   is   trained   using   the   energy - efficient   deep   neuromorphic   networks   ( Eedn )   framework   ( Esser   et   al . ,   2016 ) ,   which   realizes   the   mapping   of   the   trained   synaptic   weights   onto   the   IBM   Neurosynaptic   System   platform   ( Merolla   et   al . ,   2014 ) .   After   the   mapping ,   the   trained   network   achieves   real - time   capabilities   for   processing   input   streams   and   classify   input   images   at   about   1 , 000   frames   per   second   while   the   computational   stages   only   consume   about   70   mW   of   energy   ( without   spike   transduction ) .   Particularly   regarding   mobile   robotic   systems ,   a   low   energy   profile   might   be   crucial   in   a   variety   application   scenarios .   Cross - validation   results   are   reported   for   two   different   datasets   and   compared   to   state - of - the - art   action   recognition   approaches .   The   results   demonstrate ,   that   ( I )   the   presented   approach   is   on   par   with   other   key   pose   based   methods   described   in   the   literature ,   which   select   key   pose   frames   by   optimizing   classification   accuracy ,   ( II )   compared   to   the   training   on   the   full   set   of   frames ,   representations   trained   on   key   pose   frames   result   in   a   higher   confidence   in   class   assignments ,   and   ( III )   key   pose   representations   show   promising   generalization   capabilities   in   a   cross - dataset   evaluation . ' ,   ' title ' :   ' Real - Time   Biologically   Inspired   Action   Recognition   from   Key   Poses   Using   a   Neuromorphic   Architecture ' } 
{ ' abstract ' :   ' Contents   carried   in   an   image   are   valuable   information   sources   for   many   scientific   and   engineering   applications .   However ,   if   the   image   is   captured   under   low   illumination   conditions   a   large   portion   of   the   image   appears   dark   and   this   heavily   degrades   the   image   quality .   In   order   to   solve   this   problem ,   a   restoration   algorithm   is   developed   here   that   transforms   the   low   input   brightness   to   a   higher   value   using   a   logarithmic   mapping   function .   The   mapping   is   further   refined   by   a   linear   weighting   with   the   input   to   reduce   the   un - necessary   amplification   at   regions   with   high   brightness .   Moreover ,   fine   details   in   the   image   are   preserved   by   applying   the   Retinex   principle   to   extract   and   then   re - insert   object   edges .   Results   from   experiments   using   low   and   normal   illumination   images   have   shown   satisfactory   performances   with   regard   to   the   improvement   in   information   contents   and   the   mitigation   of   viewing   artifacts . ' ,   ' title ' :   ' Logarithmic   profile   mapping   and   Retinex   edge   preserving   for   restoration   of   low   illumination   images ' } 
{ ' abstract ' :   ' We   propose   a   principled   approach   for   the   problem   of   aligning   multiple   partially   overlapping   networks .   The   objective   is   to   map   multiple   graphs   into   a   single   graph   while   preserving   vertex   and   edge   similarities .   The   problem   is   inspired   by   the   task   of   integrating   partial   views   of   a   family   tree   ( genealogical   network )   into   one   unified   network ,   but   it   also   has   applications ,   for   example ,   in   social   and   biological   networks .   Our   approach ,   called   Flan ,   introduces   the   idea   of   generalizing   the   facility   location   problem   by   adding   a   non - linear   term   to   capture   edge   similarities   and   to   infer   the   underlying   entity   network .   The   problem   is   solved   using   an   alternating   optimization   procedure   with   a   Lagrangian   relaxation .   Flan   has   the   advantage   of   being   able   to   leverage   prior   information   on   the   number   of   entities ,   so   that   when   this   information   is   available ,   Flan   is   shown   to   work   robustly   without   the   need   to   use   any   ground   truth   data   for   fine - tuning   method   parameters .   Additionally ,   we   present   three   multiple - network   extensions   to   an   existing   state - of - the - art   pairwise   alignment   method   called   Natalie .   Extensive   experiments   on   synthetic ,   as   well   as   real - world   datasets   on   social   networks   and   genealogical   networks ,   attest   to   the   effectiveness   of   the   proposed   approaches   which   clearly   outperform   a   popular   multiple   network   alignment   method   called   IsoRankN . ' ,   ' title ' :   ' Lagrangian   relaxations   for   multiple   network   alignment ' } 
{ ' abstract ' :   ' Heterogeneous   ultra - dense   networks   enable   ultra - high   data   rates   and   ultra - low   latency   through   the   use   of   dense   sub - 6   GHz   and   millimeter   wave   ( mmWave )   small   cells   with   different   antenna   configurations .   Existing   work   has   widely   studied   spectral   and   energy   efficiency   in   such   networks   and   shown   that   high   spectral   and   energy   efficiency   can   be   achieved .   This   article   investigates   the   benefits   of   heterogeneous   ultra - dense   network   architecture   from   the   perspectives   of   three   promising   technologies ,   i . e . ,   physical   layer   security ,   caching ,   and   wireless   energy   harvesting ,   and   provides   enthusiastic   outlook   towards   application   of   these   technologies   in   heterogeneous   ultra - dense   networks .   Based   on   the   rationale   of   each   technology ,   opportunities   and   challenges   are   identified   to   advance   the   research   in   this   emerging   network . ' ,   ' title ' :   ' A   New   Look   at   Physical   Layer   Security ,   Caching ,   and   Wireless   Energy   Harvesting   for   Heterogeneous   Ultra - dense   Networks ' } 
{ ' abstract ' :   ' We   consider   the   problem   of   joint   modeling   of   videos   and   their   corresponding   textual   descriptions   ( e . g .   sentences   or   phrases ) .   Our   approach   consists   of   three   components :   the   video   representation ,   the   textual   representation ,   and   a   joint   model   that   links   videos   and   text .   Our   video   representation   uses   the   state - of - the - art   deep   3D   ConvNet   to   capture   the   semantic   information   in   the   video .   Our   textual   representation   uses   the   recent   advancement   in   learning   word   and   sentence   vectors   from   large   text   corpus .   The   joint   model   is   learned   to   score   the   correct   ( video ,   text )   pairs   higher   than   the   incorrect   ones .   We   demonstrate   our   approach   in   several   applications :   1 )   retrieving   sentences   given   a   video ;   2 )   retrieving   videos   given   a   sentence ;   3 )   zero - shot   action   recognition   in   videos . ' ,   ' title ' :   ' Beyond   verbs :   Understanding   actions   in   videos   with   text ' } 
{ ' abstract ' :   ' This   paper   presents   a   multi - agent   model   for   simulating   attitude   formation   and   change   based   on   perception   and   communication   in   the   context   of   stabilization   operations .   The   originality   of   our   model   comes   from   ( 1 )   attitude   computation   that   evaluates   information   as   part   of   a   history   relative   to   the   individual   ( 2 )   a   notion   of   co - responsibility   for   attitude   attribution .   We   present   a   military   scenario   of   French   operations   in   Afghanistan   along   with   polls   results   about   the   opinion   of   citizen   toward   present   Forces .   Based   on   these   field   data ,   we   calibrate   the   model   and   show   the   resulting   attitude   dynamics .   We   study   the   sensibility   of   the   model   to   the   co - responsibility   factor . ' ,   ' title ' :   ' From   Field   Data   to   Attitude   Formation ' } 
{ ' abstract ' :   ' This   paper   proposes   two   low - complexity   iterative   algorithms   to   compute   the   capacity   of   a   single - user   multiple - input   multiple - output   channel   with   per - antenna   power   constraint .   The   first   method   results   from   manipulating   the   optimality   conditions   of   the   considered   problem   and   applying   fixed - point   iteration .   In   the   second   approach ,   we   transform   the   considered   problem   into   a   minimax   optimization   program   using   the   well - known   MAC -   BC   duality ,   and   then   solve   it   by   a   novel   alternating   optimization   method .   In   both   proposed   iterative   methods ,   each   iteration   involves   an   optimization   problem   which   can   be   efficiently   solved   by   the   water - filling   algorithm .   The   proposed   iterative   methods   are   provably   convergent .   Complexity   analysis   and   extensive   numerical   experiments   are   carried   out   to   demonstrate   the   superior   performance   of   the   proposed   algorithms   over   an   existing   approach   known   as   the   mode - dropping   algorithm . ' ,   ' title ' :   ' Low - complexity   Approaches   for   MIMO   Capacity   with   Per - antenna   Power   Constraint ' } 
{ ' abstract ' :   ' Inventory - Aware   Pathfinding   is   concerned   with   finding   paths   while   taking   into   account   that   picking   up   items ,   e . g . ,   keys ,   allow   the   character   to   unlock   blocked   pathways ,   e . g . ,   locked   doors .   In   this   work   we   present   a   pruning   method   and   a   preprocessing   method   that   can   improve   significantly   the   scalability   of   such   approaches .   We   apply   our   methods   to   the   recent   approach   of   Inventory - Driven   Jump - Point   Search   ( InvJPS ) .   First ,   we   introduce   InvJPS +   that   allows   to   prune   large   parts   of   the   search   space   by   favoring   short   detours   to   pick   up   items ,   offering   a   trade - off   between   efficiency   and   optimality .   Second ,   we   propose   a   preprocessing   step   that   allows   to   decide   on   runtime   which   items ,   e . g . ,   keys ,   are   worth   using   thus   pruning   potentially   unnecessary   items   before   the   search   starts .   We   show   results   for   combinations   of   the   pruning   and   preprocessing   methods   illustrating   the   best   choices   over   various   scenarios . ' ,   ' title ' :   ' Pruning   and   preprocessing   methods   for   inventory - aware   pathfinding ' } 
{ ' abstract ' :   ' This   paper   proposes   a   method   for   proper   names   extraction   from   Myanmar   text   by   using   latent   Dirichlet   allocation   ( LDA ) .   Our   method   aims   to   extract   proper   names   that   provide   important   information   on   the   contents   of   Myanmar   text .   Our   method   consists   of   two   steps .   In   the   first   step ,   we   extract   topic   words   from   Myanmar   news   articles   by   using   LDA .   In   the   second   step ,   we   make   a   post - processing ,   because   the   resulting   topic   words   contain   some   noisy   words .   Our   post - processing ,   first   of   all ,   eliminates   the   topic   words   whose   prefixes   are   Myanmar   digits   and   suffixes   are   noun   and   verb   particles .   We   then   remove   the   duplicate   words   and   discard   the   topic   words   that   are   contained   in   the   existing   dictionary .   Consequently ,   we   obtain   the   words   as   candidate   of   proper   names ,   namely   personal   names ,   geographical   names ,   unique   object   names ,   organization   names ,   single   event   names ,   and   so   on .   The   evaluation   is   performed   both   from   the   subjective   and   quantitative   perspectives .   From   the   subjective   perspective ,   we   compare   the   accuracy   of   proper   names   extracted   by   our   method   with   those   extracted   by   latent   semantic   indexing   ( LSI )   and   rule - based   method .   It   is   shown   that   both   LS ]   and   our   method   can   improve   the   accuracy   of   those   obtained   by   rule - based   method .   However ,   our   method   can   provide   more   interesting   proper   names   than   LSI .   From   the   quantitative   perspective ,   we   use   the   extracted   proper   names   as   additional   features   in   K - means   clustering .   The   experimental   results   show   that   the   document   clusters   given   by   our   method   are   better   than   those   given   by   LSI   and   rule - based   method   in   precision ,   recall   and   F - score . ' ,   ' title ' :   ' Extraction   of   proper   names   from   myanmar   text   using   latent   dirichlet   allocation ' } 
{ ' abstract ' :   ' Large   scale   assessment   of   aboveground   biomass   ( AGB )   in   tropical   forests   is   often   limited   by   the   saturation   of   remote   sensing   signals   at   high   AGB   values .   Fourier   Transform   Textural   Ordination   ( FOTO )   performs   well   in   quantifying   canopy   texture   from   very   high - resolution   ( VHR )   imagery ,   from   which   stand   structure   parameters   can   be   retrieved   with   no   saturation   effect   for   AGB   values   up   to   650   Mg · ha − 1 .   The   method   is   robust   when   tested   on   wet   evergreen   forests   but   is   more   demanding   when   applied   across   different   forest   types   characterized   by   varying   structures   and   allometries .   The   present   study   focuses   on   a   gradient   of   forest   types   ranging   from   dry   deciduous   to   wet   evergreen   forests   in   the   Western   Ghats   ( WG )   of   India ,   where   we   applied   FOTO   to   Cartosat - 1a   images   with   2.5   m   resolution .   Based   on   21   1 - ha   ground   control   forest   plots ,   we   calibrated   independent   texture – AGB   models   for   the   dry   and   wet   zone   forests   in   the   area ,   as   delineated   from   the   distribution   of   NDVI   values   computed   from   LISS - 4   multispectral   images .   This   stratification   largely   improved   the   relationship   between   texture - derived   and   field - derived   AGB   estimates ,   which   exhibited   a   R2   of   0.82   for   a   mean   rRMSE   of   ca .   17% .   By   inverting   the   texture – AGB   models ,   we   finally   mapped   AGB   predictions   at   1.6 - ha   resolution   over   a   heterogeneous   landscape   of   ca .   1500   km2   in   the   WG ,   with   a   mean   relative   per - pixel   propagated   error   < 20%   for   wet   zone   forests ,   i . e . ,   below   the   recommended   IPCC   criteria   for   Monitoring ,   Reporting   and   Verification   ( MRV )   methods .   The   method   proved   to   perform   well   in   predicting   high - resolution   AGB   values   over   heterogeneous   tropical   landscape   encompassing   diversified   forest   types ,   and   thus   presents   a   promising   option   for   affordable   regional   monitoring   systems   of   greenhouse   gas   ( GhG )   emissions   related   to   forest   degradation . ' ,   ' title ' :   ' Inverting   Aboveground   Biomass – Canopy   Texture   Relationships   in   a   Landscape   of   Forest   Mosaic   in   the   Western   Ghats   of   India   Using   Very   High   Resolution   Cartosat   Imagery ' } 
{ ' abstract ' :   ' Self - driving   vehicle   technologies   are   progressing   rapidly   and   are   expected   to   play   a   significant   role   in   the   future   of   transportation .   One   of   the   main   challenges   for   self - driving   vehicles   on   public   roads   is   the   safe   cooperation   and   collaboration   among   multiple   vehicles   using   sensor - based   perception   and   inter - vehicle   communications .   When   self - driving   vehicles   try   to   occupy   the   same   spatial   area   simultaneously ,   they   might   collide   with   one   another ,   might   become   deadlocked ,   or   might   slam   on   the   brakes   making   it   uncomfortable   or   unsafe   for   passengers   in   a   self - driving   vehicle .   In   this   paper ,   we   study   how   a   self - driving   vehicle   can   safely   navigate   merge   points ,   where   two   lanes   with   different   priorities   meet .   We   present   a   safe   protocol   for   merge   points   named   Autonomous   Vehicle   Protocol   for   Merge   Points ,   where   self - driving   vehicles   use   both   vehicular   communications   and   their   own   perception   systems   for   cooperating   with   other   self - driving   and / or   human - driven   vehicles .   Our   simulation   results   show   that   our   traffic   protocol   has   higher   traffic   throughput ,   compared   to   simple   traffic   protocols ,   while   ensuring   safety . ' ,   ' title ' :   ' A   merging   protocol   for   self - driving   vehicles ' } 
{ ' abstract ' :   ' System   Portfolio   Selection   ( SPS )   problem   is   equivalent   to   multi - objective   optimization   problem ,   with   multi - function   requirements   incommensurable .   In   the   paper ,   the   SPS   problem   is   re - specified   with   a   more   practical   formulation ,   comparing   to   general   portfolio   problem .   Then ,   both   feasible   and   non - inferior   solution   is   re - defined   considering   characteristics   of   SPS   problem ,   specifically ,   four   rules   of   system   function   combinations   are   proposed   according   to   practical   cases .   Then ,   the   instability   of   system   performance   is   involved   in   SPS   problem ,   and   the   robust   theory   is   employed   to   solving   the   uncertainty   of   system   function   values   with   definition   of   robust   non - inferior   solution .   Next ,   the   paper   proposes   an   immediately   updating   algorithm   to   solve   the   problem   of   solution   space   exponentially   growing .   Finally ,   a   case   study   is   used   to   demonstrate   the   usefulness   and   effectiveness   of   the   proposed   approaches .   It   shows   that   the   approach   can   provide   an   efficient   guidance   for   decision - makers   in   the   process   of   making   a   SPS . ' ,   ' title ' :   ' Robust   system   portfolio   selection   with   multi - function   requirements   and   system   instability ' } 
{ ' abstract ' :   ' This   study   explores   the   impact   of   high - photovoltaic   ( PV )   penetration   on   the   inter - area   oscillation   modes   of   large - scale   power   grids .   A   series   of   dynamic   models   with   various   PV   penetration   levels   are   developed   based   on   a   detailed   model   representing   the   U . S .   Eastern   Interconnection   ( EI ) .   Transient   simulations   are   performed   to   investigate   the   change   of   inter - area   oscillation   modes   with   PV   penetration .   The   impact   of   PV   control   strategies   and   parameter   settings   on   inter - area   oscillations   is   studied .   This   paper   finds   that   as   PV   increases ,   the   damping   of   the   dominant   oscillation   mode   decreases   monotonically .   It   is   also   observed   that   the   mode   shape   varies   with   the   PV   control   strategy   and   new   oscillation   modes   may   emerge   under   inappropriate   parameter   settings   in   PV   plant   controls . ' ,   ' title ' :   ' Impact   of   High   PV   Penetration   on   the   Inter - Area   Oscillations   in   the   U . S .   Eastern   Interconnection ' } 
{ ' abstract ' :   ' The   objective   of   this   research   is   to   compare   the   effectiveness   of   different   tracking   devices   underwater .   There   have   been   few   works   in   aquatic   virtual   reality   ( VR )   —   i . e . ,   VR   systems   that   can   be   used   in   a   real   underwater   environment .   Moreover ,   the   works   that   have   been   done   have   noted   limitations   on   tracking   accuracy .   Our   initial   test   results   suggest   that   inertial   measurement   units   work   well   underwater   for   orientation   tracking   but   a   different   approach   is   needed   for   position   tracking .   Towards   this   goal ,   we   have   waterproofed   and   evaluated   several   consumer   tracking   systems   intended   for   gaming   to   determine   the   most   effective   approaches .   First ,   we   informally   tested   infrared   systems   and   fiducial   marker   based   systems ,   which   demonstrated   significant   limitations   of   optical   approaches .   Next ,   we   quantitatively   compared   inertial   measurement   units   ( IMU )   and   a   magnetic   tracking   system   both   above   water   ( as   a   baseline )   and   underwater .   By   comparing   the   devices   rotation   data ,   we   have   discovered   that   the   magnetic   tracking   system   implemented   by   the   Razer   Hydra   is   more   accurate   underwater   as   compared   to   a   phone - based   IMU .   This   suggests   that   magnetic   tracking   systems   should   be   further   explored   for   underwater   VR   applications . ' ,   ' title ' :   ' Towards   usable   underwater   virtual   reality   systems ' } 
{ ' abstract ' :   ' A   faulty   network   GG   is   under   the   conditional   fault   model ,   i . e . , \ xa0every   fault - free   vertex   of   GG   is   incident   to   at   least   two   fault - free   edges .   Let   FFvFFv   and   FFeFFe   be   the   set   of   faulty   vertices   and   faulty   edges   in   FQnFQn ,   respectively .   In   this   paper ,   we   consider   FQnFQn   under   the   conditional   fault   model   and   prove   that   if   | FFv | + | FFe | ≤ 2n − 4 | FFv | + | FFe | ≤ 2n − 4   and   n ≥ 3n ≥ 3 ,   then   FQn − FFv − FFeFQn − FFv − FFe   contains   a   fault - free   cycle   of   every   even   length   from   4   to   2n − 2 | FFv | 2n − 2 | FFv | ;   if   | FFv | + | FFe | ≤ 2n − 5 | FFv | + | FFe | ≤ 2n − 5   and   n ≥ 4n ≥ 4   is   even ,   then   FQn − FFv − FFeFQn − FFv − FFe   contains   a   fault - free   cycle   of   every   odd   length   from   n + 1n + 1   to   2n − 2 | FFv | − 12n − 2 | FFv | − 1 . ' ,   ' title ' :   ' Cycles   embedding   in   folded   hypercubes   under   the   conditional   fault   model ' } 
{ ' abstract ' :   ' Companies   have   invested   considerable   resources   in   the   implementation   of   enterprise   resource   planning   ( ERP )   systems .   The   results   initially   expected   have   rarely   been   reached .   The   optimisation   ( or   efficient   use )   of   such   information   systems   is   nowadays   becoming   a   major   factor   for   firms   striving   to   reach   their   performance   objectives .   After   presenting   a   synthesis   of   several   studies   on   ERP   projects ,   we   build   on   the   findings   of   a   French   investigation   into   the   assessment   and   optimisation   of   ERP   performance .   A   classification   of   company   positions   regarding   their   ERP   use ,   based   on   both   software   maturity   and   strategic   deployment   directions ,   and   an   improvement   process   are   proposed .   Industrial   cases   allow   validation   of   this   approach . ' ,   ' title ' :   ' A   classification   for   better   use   of   ERP   systems ' } 
{ ' abstract ' :   ' This   paper   presents   a   time - domain   biosensor   array   that   uses   a   capacitor - less   current - mode   analog - to - time   converter   ( CMATC )   and   logarithmic   cyclic   time - attenuation - based   TDC   with   discharging   acceleration .   Combining   the   exponential   function   of   the   CMATC   and   logarithmic   function   of   the   proposed   TDC   offers   linear   input - output   characteristics .   The   time - domain   property   enables   bio - imaging   at   a   high   spatial   resolution   and   large   scale   while   maintaining   scalability .   Measurement   results   with   a   0.25 - μ m   test   chip   successfully   demonstrated   linear   input - output   characteristics . ' ,   ' title ' :   ' A   scalable   time - domain   biosensor   array   using   logarithmic   cyclic   time - attenuation - based   TDC   for   high - resolution   and   large - scale   bio - imaging ' } 
{ ' abstract ' :   ' Compared   to   current   mobile   networks ,   next - generation   mobile   networks   are   expected   to   support   higher   numbers   of   simultaneously   connected   devices   and   to   achieve   higher   system   spectrum   efficiency   and   lower   power   consumption .   To   achieve   these   goals ,   we   study   the   multi - sharing   device - to - device   ( D2D )   communication ,   which   allows   any   cellular   user   equipment   to   share   its   radio   resource   with   multiple   D2D   devices .   We   jointly   consider   resource   block   reuse   and   power   control   and   then   develop   the   MISS   algorithm .   Simulation   results   show   that   MISS   performs   very   well   in   terms   of   transmission   power   consumption ,   system   throughput ,   and   the   number   of   permitted   D2D   devices . ' ,   ' title ' :   ' Joint   Resource   Block   Reuse   and   Power   Control   for   Multi - Sharing   Device - to - Device   Communication ' } 
{ ' abstract ' :   ' This   paper   is   concerned   with   event - triggered   H ∞ H ∞   filtering   for   delayed   neural   networks   via   sampled   data .   A   novel   event - triggered   scheme   is   proposed ,   which   can   lead   to   a   significant   reduction   of   the   information   communication   burden   in   the   network ;   the   feature   of   this   scheme   is   that   whether   or   not   the   sampled   data   should   be   transmitted   is   determined   by   the   current   sampled   data   and   the   error   between   the   current   sampled   data   and   the   latest   transmitted   data .   By   constructing   a   proper   Lyapunov – Krasovskii   functional ,   utilizing   the   reciprocally   convex   combination   technique   and   Jensen ’ s   inequality   sufficient   conditions   are   derived   to   ensure   that   the   resultant   filtering   error   system   is   asymptotically   stable .   Based   on   the   derived   H ∞ H ∞   performance   analysis   results ,   the   H ∞ H ∞   filter   design   is   formulated   in   terms   of   Linear   Matrix   Inequalities   ( LMIs ) .   Finally ,   the   proposed   stability   conditions   are   demonstrated   with   numerical   example . ' ,   ' title ' :   ' Event - triggered   H   ∞   filtering   for   delayed   neural   networks   via   sampled - data ' } 
{ ' abstract ' :   ' For   the   double   integrator   with   matched   Lipschitz   disturbances   we   propose   a   continuous   homogeneous   controller   providing   finite - time   stability   of   the   origin .   The   disturbance   is   compensated   exactly   in   finite   time   using   a   discontinuous   function   through   an   integral   action .   Since   the   controller   is   dynamic ,   the   closed   loop   is   a   third   order   system   that   achieves   a   third   order   sliding   mode   in   the   steady   state .   The   stability   and   robustness   properties   of   the   controller   are   proven   using   a   smooth   and   homogeneous   strict   Lyapunov   function   ( LF ) .   In   a   first   stage ,   the   gains   of   the   controller   and   the   LF   are   designed   using   a   method   based   on   Polya ’ s   Theorem .   In   a   second   stage   the   controller ’ s   gains   are   adjusted   through   a   sum   of   squares   representation   of   the   LF . ' ,   ' title ' :   ' Design   of   Continuous   Twisting   Algorithm ' } 
{ ' abstract ' :   ' Big   data   is   now   rapidly   expanding   into   various   domains   such   as   banking ,   insurance   and   e - commerce .   Data   analysis   and   related   studies   have   attracted   more   attentions .   In   health   insurance ,   abuse   of   diagnosis   is   one   of   the   key   fraud   problems ,   which   damages   the   interests   of   insured   people .   To   address   this   issue ,   numbers   of   studies   have   focused   on   this   topic .   This   paper   develops   a   healthcare   fraud   detection   approach   based   on   the   trustworthiness   of   doctors   to   distinguish   fraud   cases   from   normal   records .   Compared   to   conventional   methods ,   our   approach   can   detect   healthcare   fraud   in   a   good   accuracy   by   only   little   feature   information   from   healthcare   data   without   the   violation   of   privacy .   This   approach   combines   a   weighted   HITS   algorithm   with   a   frequent   pattern   mining   algorithm   to   calculate   a   rational   treatment   model   of   a   certain   disease .   In   addition ,   this   paper   also   introduces   the   copy   precision   behavior   in   the   treatment   sequences   of   patients ,   which   is   a   critical   metric   to   learn   the   trustworthiness   of   doctors .   The   numerical   validation   with   a   healthcare   dataset   demonstrates   that   healthcare   fraud   by   misdiagnosis   in   healthcare   treatments   can   be   successfully   detected   by   employing   the   developed   fraud   detection   approach . ' ,   ' title ' :   ' Healthcare   Fraud   Detection   Based   on   Trustworthiness   of   Doctors ' } 
{ ' abstract ' :   ' In   this   paper   we   study   data   collection   in   an   energy   renewable   sensor   network   for   scenarios   such   as   traffic   monitoring   on   busy   highways ,   where   sensors   are   deployed   along   a   predefined   path   ( the   highway )   and   a   mobile   sink   travels   along   the   path   to   collect   data   from   one - hop   sensors   periodically .   As   sensors   are   powered   by   renewable   energy   sources ,   time - varying   characteristics   of   ambient   energy   sources   poses   great   challenges   in   the   design   of   efficient   routing   protocols   for   data   collection   in   such   networks .   In   this   paper   we   first   formulate   a   novel   data   collection   maximization   problem   by   adopting   multi - rate   data   transmissions   and   performing   transmission   time   slot   scheduling ,   and   show   that   the   problem   is   NP - hard .   We   then   devise   an   offline   algorithm   with   a   provable   approximation   ratio   for   the   problem   by   exploiting   the   combinatorial   property   of   the   problem ,   assuming   that   the   harvested   energy   at   each   node   is   given   and   link   communications   in   the   network   are   reliable .   We   also   extend   the   proposed   algorithm   by   minor   modifications   to   a   general   case   of   the   problem   where   the   harvested   energy   at   each   sensor   is   not   known   in   advance   and   link   communications   are   not   reliable .   We   thirdly   develop   a   fast ,   scalable   online   distributed   algorithm   for   the   problem   in   realistic   sensor   networks   in   which   neither   the   global   knowledge   of   the   network   topology   nor   sensor   profiles   such   as   sensor   locations   and   their   harvested   energy   profiles   is   given .   Furthermore ,   we   also   consider   a   special   case   of   the   problem   where   each   node   has   only   a   fixed   transmission   power ,   for   which   we   propose   an   exact   solution   to   the   problem .   We   finally   conduct   extensive   experiments   by   simulations   to   evaluate   the   performance   of   the   proposed   algorithms .   Experimental   results   demonstrate   that   the   proposed   algorithms   are   efficient   and   the   solutions   obtained   are   fractional   of   the   optimum . ' ,   ' title ' :   ' Data   Collection   Maximization   in   Renewable   Sensor   Networks   via   Time - Slot   Scheduling ' } 
{ ' abstract ' :   ' An   increasing   number   of   businesses   are   migrating   their   IT   operations   to   the   cloud .   Likewise   there   is   an   increased   emphasis   on   data   analytics   based   on   multiple   datasets   and   sources   to   derive   information   not   derivable   when   a   dataset   is   mined   in   isolation .   While   ensuring   security   of   data   and   computation   outsourced   to   a   third   party   cloud   service   provider   is   in   itself   challenging ,   supporting   mash - ups   and   analytics   of   data   from   different   parties   hosted   across   different   services   is   even   more   so .   In   this   paper   we   propose   a   cloud - based   service   allowing   multiple   parties   to   perform   secure   multi - party   secure   sum   computation   using   their   clouds   as   delegates .   Our   scheme   provides   data   privacy   both   from   the   delegates   as   well   as   from   the   other   data   owners   under   a   lazy - and - curious   adversary   ( semi - honest )   model .   We   then   describe   how   such   a   secure   sum   primitive   may   be   used   in   various   collaborative ,   cloud - based   distributed   data   mining   tasks   ( classification ,   association   rule   mining   and   clustering ) .   We   implement   a   prototype   and   benchmark   the   service ,   both   as   a   stand - alone   secure   sum   service ,   and   as   a   building   block   for   more   complex   analytics .   The   results   suggest   reasonable   overhead   and   demonstrate   the   practicality   of   carrying   out   privacy   preserved   distributed   analytics   despite   migrating   ( encrypted )   data   to   pos -   sibly   different   and   untrusted   ( semi - honest )   cloud   services . ' ,   ' title ' :   ' Delegated   Secure   Sum   Service   for   Distributed   Data   Mining   in   Multi - Cloud   Settings ' } 
{ ' abstract ' :   ' This   paper   fundamentally   investigates   the   performance   of   evolutionary   multiobjective   optimization   ( EMO )   algorithms   for   computationally   hard   0 - 1   combinatorial   optimization ,   where   a   strict   theoretical   analysis   is   generally   out   of   reach   due   to   the   high   complexity   of   the   underlying   problem .   Based   on   the   examination   of   problem   features   from   a   multiobjective   perspective ,   we   improve   the   understanding   of   the   efficiency   of   a   simple   dominance - based   EMO   algorithm   with   unbounded   archive   for   multiobjective   NK - landscapes   with   correlated   objective   values .   More   particularly ,   we   adopt   a   statistical   approach ,   based   on   simple   and   multiple   linear   regression   analysis ,   to   enquire   the   expected   running   time   of   global   SEMO   with   restart   for   identifying   a   ( 1 + e ) - approximation   of   the   Pareto   set   for   small - size   enumerable   instances .   Our   analysis   provides   further   insights   on   the   EMO   search   behavior   and   on   the   most   important   features   that   characterize   the   difficulty   of   an   instance   for   this   class   of   problems   and   algorithms . ' ,   ' title ' :   ' A   feature - based   performance   analysis   in   evolutionary   multiobjective   optimization ' } 
{ ' abstract ' :   ' Functional   biological   sequences ,   which   typically   come   in   families ,   have   retained   some   level   of   similarity   and   function   during   evolution .   Finding   consensus   regions ,   alignment   of   sequences ,   and   identifying   the   relationship   between   a   sequence   and   a   family   allow   inferences   about   the   function   of   the   sequences .   Profile   hidden   Markov   models   ( HMMs )   are   generally   used   to   identify   those   relationships .   A   profile   HMM   can   be   trained   on   unaligned   members   of   the   family   using   conventional   algorithms   such   as   Baum - Welch ,   Viterbi ,   and   their   modifications .   The   overall   quality   of   the   alignment   depends   on   the   quality   of   the   trained   model .   Unfortunately ,   the   conventional   training   algorithms   converge   to   suboptimal   models   most   of   the   time .   This   work   proposes   a   training   algorithm   that   early   identifies   many   imperfect   models .   The   method   is   based   on   the   Simulated   Annealing   approach   widely   used   in   discrete   optimization   problems .   The   training   algorithm   is   implemented   as   a   component   in   HMMER .   The   performance   of   the   algorithm   is   discussed   on   protein   sequence   data . ' ,   ' title ' :   ' Simulated   annealing   algorithm   with   biased   neighborhood   distribution   for   training   profile   models ' } 
{ ' abstract ' :   ' The   Canny   algorithm   is   a   well   known   edge   detector   that   is   widely   used   in   the   previous   processing   stages   in   several   algorithms   related   to   computer   vision .   An   alternative ,   the   LIP - Canny   algorithm ,   is   based   on   a   robust   mathematical   model   closer   to   the   human   vision   system ,   obtaining   better   results   in   terms   of   edge   detection .   In   this   work   we   describe   LIP - Canny   algorithm   under   the   perspective   from   its   parallelization   and   optimization   by   using   the   NVIDIA   CUDA   framework .   Furthermore ,   we   present   comparative   results   between   an   implementation   of   this   algorithm   using   NVIDIA   CUDA   and   the   analogue   using   a   C / C++   approach . ' ,   ' title ' :   ' Parallelizing   and   optimizing   LIP - canny   using   NVIDIA   CUDA ' } 
{ ' abstract ' :   ' This   paper   presents   an   efficient   Bayesian   blind   multiuser   receiver   for   long   code   multipath   CDMA   systems .   The   proposed   receiver   employs   the   adaptive   sampling   method   for   the   Bayesian   inference   procedure   to   estimate   the   data   symbols   and   multipath   parameters .   Compared   to   the   other   reported   Bayesian   Monte   Carlo   receivers   for   long   code   multipath   CDMA   systems ,   the   proposed   one   achieves   a   faster   convergence   and   a   lower   computational   complexity   to   attain   comparable   performance .   Simulation   results   are   presented   to   demonstrate   the   effectiveness   of   the   proposed   Bayesian   blind   multiuser   receiver . ' ,   ' title ' :   ' Blind   Multiuser   Detection   for   Long   Code   Multipath   DS - CDMA   Systems   with   Bayesian   MC   Techniques ' } 
{ ' abstract ' :   ' Spreadsheets   are   by   far   the   most   prominent   example   of   end - user   programs   of   ample   size   and   substantial   structural   complexity .   In   addition ,   spreadsheets   are   usually   not   tested   very   rigorously   and   thus   comprise   faults .   Locating   faults   is   a   hard   task   due   to   the   size   and   the   structure ,   which   is   usually   not   directly   visible   to   the   user ,   i . e . ,   the   functions   are   hidden   behind   the   cells   and   only   the   computed   values   are   presented .   Hence ,   there   is   a   strong   need   for   debugging   support .   In   this   paper ,   we   adapt   three   program - debugging   approaches   that   have   been   designed   for   more   traditional   procedural   or   object - oriented   programming   languages .   These   techniques   are   Spectrum - based   Fault   Localization ,   Spectrum - Enhanced   Dynamic   Slicing ,   and   Constraint - based   Debugging .   Beside   the   theoretical   foundations ,   we   present   a   more   sophisticated   empirical   evaluation   including   a   comparison   of   these   approaches .   The   empirical   evaluation   shows   that   Sfl   ( Spectrum - based   Fault   Localization )   and   Sendys   ( Spectrum   ENhanced   Dynamic   Slicing )   are   the   most   promising   techniques . ' ,   ' title ' :   ' On   the   empirical   evaluation   of   fault   localization   techniques   for   spreadsheets ' } 
{ ' abstract ' :   ' This   work   provides   elements   to   highlight   the   reliability   challenges   related   to   the   technology   scaling   and   the   BTI   variability .   Through   main   milestones   including   device   reliability   scaling   model   ( for   both   mean   and   spread ) ,   a   discussion   on   the   physical   origin   of   BTI   variability   and   a   digital   IP   failure   rate   analytical   model ,   the   evolution   of   digital   IP   failure   rates   along   the   ITRS   scaling   roadmap   is   assessed .   and   an   analysis   of   the   ITRS   roadmap   on   digital   IP   failure   rates .   This   study   offers   new   perspectives   towards   product   hardening   and   qualification   with   respect   to   both   fresh   and   BTI - related   local   variability ,   especially   in   context   where   Adaptive   Voltage   Scaling   ( AVS )   is   used   to   compensate   for   process   centerings . ' ,   ' title ' :   ' From   BTI   variability   to   product   failure   rate :   A   technology   scaling   perspective ' } 
{ ' abstract ' :   ' In   this   paper   we   discuss   the   problem   of   calculating   the   reachable   states   of   a   dynamical   system   defined   by   ordinary   differential   equations   or   inclusions .   We   present   a   prototype   system   for   approximating   this   set   and   demonstrate   some   experimental   results . ' ,   ' title ' :   ' Reachability   Analysis   via   Face   Lifting ' } 
{ ' abstract ' :   ' By   introducing   the   new   concepts   of   fuzzy     β   - covering   and   fuzzy     β   - neighborhood ,   we   define   two   new   types   of   fuzzy   covering   rough   set   models   which   can   be   regarded   as   bridges   linking   covering   rough   set   theory   and   fuzzy   rough   set   theory .   We   show   the   properties   of   the   two   models ,   and   reveal   the   relationships   between   the   two   models   and   some   others .   Moreover ,   we   present   the   matrix   representations   of   the   newly   defined   lower   and   upper   approximation   operators   so   that   the   calculation   of   lower   and   upper   approximations   of   subsets   can   be   converted   into   operations   on   matrices .   Finally ,   we   generalize   the   models   and   their   matrix   representations   to     L   - fuzzy   covering   rough   sets   which   are   defined   over   fuzzy   lattices . ' ,   ' title ' :   ' Two   fuzzy   covering   rough   set   models   and   their   generalizations   over   fuzzy   lattices ' } 
{ ' abstract ' :   ' Mobile   applications   are   becoming   complex   software   systems   that   must   be   developed   quickly   and   evolve   regularly   to   fit   new   user   requirements   and   execution   contexts .   However ,   addressing   these   constraints   may   result   in   poor   design   choices ,   known   as   antipatterns ,   which   may   degrade   software   quality   and   performance .   Thus ,   the   automatic   detection   of   antipatterns   is   an   important   activity   that   eases   the   future   maintenance   and   evolution   tasks .   Moreover ,   it   helps   developers   to   refactor   their   applications   and   thus ,   to   improve   their   quality .   While   antipatterns   are   well - known   in   object - oriented   applications ,   their   study   in   mobile   applications   is   still   in   their   infancy .   In   this   paper ,   we   presents   a   tooled   approach ,   called   P   aprika   ,   to   analyze   Android   applications   and   to   detect   object - oriented   and   Android - specific   antipatterns   from   binaries   of   applications . ' ,   ' title ' :   ' An   approach   to   detect   Android   antipatterns ' } 
{ ' abstract ' :   ' In   this   paper   we   present   a   new   method   for   object   categorization .   Firstly   an   image   representation   is   obtained   by   the   proposed   hierarchical   learning   method   consisting   of   alternating   between   local   coding   and   maximum   pooling   operations ,   where   the   local   coding   operation   induces   discrimination   while   the   image   descriptor   and   maximum   pooling   operation   induces   invariance   in   hierarchical   architecture .   Then   the   obtained   effective   image   representation   is   passed   to   a   linear   classifier   which   is   suitable   for   large   databases   for   object   categorization .   We   have   demonstrated   that   the   proposed   method   is   robust   to   image   variations   and   has   low   sample   complexity . ' ,   ' title ' :   ' Object   categorization   based   on   hierarchical   learning ' } 
{ ' abstract ' :   ' We   have   previously   proposed   a   howling   canceller   which   cancels   howling   by   using   a   cascade   notch   filter   designed   from   a   distance   between   a   loudspeaker   and   a   microphone .   This   method   utilizes   a   pilot   signal   to   estimate   the   distance .   In   this   paper ,   we   introduce   two   methods   into   the   distance - based   howling   canceller   to   improve   speech   quality .   The   first   one   is   an   adaptive   cascade   notch   filter   which   adaptively   adjusts   the   nulls   to   eliminate   howling   and   to   keep   speech   components .   The   second   one   is   a   silent   pilot   signal   whose   frequencies   exist   in   the   ultrasonic   band ,   and   it   is   inaudible   while   on   transmission .   We   implement   the   proposed   howling   canceller   on   a   DSP   to   evaluate   its   capability .   The   experimental   results   show   that   the   proposed   howling   canceller   improves   speech   quality   in   comparison   to   the   conventional   one . ' ,   ' title ' :   ' A   High   Speech   Quality   Distance - Based   Howling   Canceller   with   Adaptive   Cascade   Notch   Filter   and   Silent   Pilot   Signal ' } 
{ ' abstract ' :   ' Purpose   –   This   paper   aims   to   look   at   how   varying   terminology   is   used   on   school   library   web   sites   and   how   that   compares   to   student   preferences . Design / methodology / approach   –   Provides   research   conduced   by   surveying   practicing   school   librarians   and   k ‐ 12   students . Findings   –   Terminology   varies   greatly   on   school   library   web   sites .   Further ,   students   prefer   common   language   use . Practical   implications   –   Practicing   librarians   may   consider   revising   their   web   sites   in   order   to   make   them   more   accessible   for   their   students . Originality / value   –   This   paper   provides   original   research   into   school   library   web   sites ,   an   area   that   is   lacking . ' ,   ' title ' :   ' School   library   web   site   terminology ' } 
{ ' abstract ' :   ' Recently ,   numerous   multireceiver   identity - based   encryption   or   identity - based   broadcast   encryption   schemes   have   been   introduced   with   bilinear   pairing   and   probabilistic   map - to - point   MTP   function .   As   the   bilinear   pairing   and   MTP   functions   are   expensive   operations ,   any   cryptographic   schemes   based   on   these   operations   experience   high   computational   burden .   The   certificateless   public   key   cryptography   sidesteps   the   private   key   escrow   problem   occurring   in   identity - based   cryptosystem   and   certificate   management   troubles   of   certificate   authority - based   public   key   cryptography   CA - PKC .   We   observed   that   certificateless   multireceiver   encryption   CL - MRE   scheme   without   pairing   and   MTP   hash   function   has   not   yet   been   considered   in   the   literature .   In   this   paper ,   we   proposed   a   bilinear   pairing   and   MTP   hash - function - free   CL - MRE   scheme   with   chosen   ciphertext   attack   resilience .   The   detailed   analyses   provide   evidence   that   our   scheme   achieves   forward   secrecy ,   backward   secrecy ,   and   low   computation   costs   than   others .   The   scheme   also   provides   confidentiality   of   the   message   and   receiver   anonymity   in   the   random   oracle   model   with   the   hardness   of   computational   Diffie - Hellman   problem .   Copyright   ©   2014   John   Wiley   &   Sons ,   Ltd . ' ,   ' title ' :   ' Anonymous   and   provably   secure   certificateless   multireceiver   encryption   without   bilinear   pairing ' } 
{ ' abstract ' :   ' We   study   the   problem   of   approximating   one - dimensional   nonintegrable   codistributions   by   integrable   ones   and   apply   the   resulting   approximations   to   approximate   feedback   linearization   of   single - input   systems .   The   approach   derived   in   this   paper   allows   a   linearizable   nonlinear   system   to   be   found   that   is   close   to   the   given   system   in   a   least - squares   ( L2 )   sense .   A   linearly   controllable   single - input   affine   nonlinear   system   is   feedback   linearizable   if   and   only   if   its   characteristic   distribution   is   involutive   ( hence   integrable )   or ,   equivalently ,   any   characteristic   one - form   ( a   one - form   that   annihilates   the   characteristic   distribution )   is   integrable .   We   study   the   problem   of   finding   ( least - squares   approximate )   integrating   factors   that   make   a   fixed   characteristic   one - form   close   to   being   exact   in   anL2   sense .   A   given   one - form   can   be   decomposed   into   exact   and   inexact   parts   using   the   Hodge   decomposition .   We   derive   an   upper   bound   on   the   size   of   the   inexact   part   of   a   scaled   characteristic   one - form   and   show   that   a   least - squares   integrating   factor   provides   the   minimum   value   for   this   upper   bound .   We   also   consider   higher - order   approximate   integrating   factors   that   scale   a   nonintegrable   one - form   in   a   way   that   the   scaled   form   is   closer   to   being   integrable   inL2   together   with   some   derivatives   and   derive   similar   bounds   for   the   inexact   part .   This   allows   a   linearizable   nonlinear   system   that   is   close   to   the   given   system   in   a   least - squares   ( L2 )   sense   together   with   some   derivatives   to   be   found .   The   Sobolev   embedding   techniques   allow   us   to   obtain   an   upper   bound   on   the   uniform   ( L ∞ )   distance   between   the   nonlinear   system   and   its   linearizable   approximation . ' ,   ' title ' :   ' Least - squares   integration   of   one - dimensional   codistributions   with   application   to   approximate   feedback   linearization ' } 
{ ' abstract ' :   ' Latent   sector   errors   in   disk   drives   affect   only   a   few   data   sectors .   They   occur   silently   and   are   detected   only   when   the   affected   area   is   accessed   again .   If   a   latent   error   is   detected   while   the   storage   system   is   operating   under   reduced   redundancy ,   i . e . ,   during   a   RAID   rebuild ,   then   data   loss   may   occur .   Various   features   such   as   scrubbing   and   intra - disk   data   redundancy   are   proposed   to   detect   and / or   recover   from   latent   errors   and   avoid   data   loss .   While   such   features   enhance   data   availability   in   the   storage   system ,   their   execution   may   cause   performance   degradation .   In   this   paper ,   we   evaluate   the   effectiveness   of   scrubbing   and   intra - disk   data   redundancy   in   improving   data   availability   while   the   overall   goal   is   to   maintain   user   performance   within   predefined   bounds .   We   show   that   by   treating   them   as   low   priority   background   activities   and   scheduling   them   efficiently   during   idle   times ,   these   features   remain   performance - wise   transparent   to   the   storage   system   user   while   still   improving   data   reliability .   Detailed   trace - driven   simulations   show   that   the   mean   time   to   data   loss   ( MTTDL )   improves   by   up   to   5   orders   of   magnitude   if   these   features   are   implemented   independently .   By   scheduling   concurrently   both   scrubbing   and   intra - disk   parity   updates   during   idle   times   in   disk   drives ,   MTTDL   improves   by   as   much   as   8   orders   of   magnitude . ' ,   ' title ' :   ' Enhancing   data   availability   in   disk   drives   through   background   activities ' } 
{ ' abstract ' :   ' Financial   crisis   forecasting   has   been   a   long - standing   challenge   that   often   involves   couplings   between   indicators   of   multiple   markets .   Such   couplings   include   implicit   relations   that   might   not   be   effectively   detected   from   raw   market   observations .   However ,   most   methods   for   crisis   forecasting   rely   directly   on   market   observations   and   might   not   detect   the   hidden   interactions   between   markets .   To   this   end ,   the   authors   explore   coupled   market   state   analysis   ( CMSA ) ,   assuming   that   the   observations   of   markets   are   governed   by   a   collection   of   intra -   and   intercoupled   hidden   market   states .   Accordingly ,   they   built   a   forecaster   based   on   these   coupled   market   states   instead   of   observations . ' ,   ' title ' :   ' Financial   Crisis   Forecasting   via   Coupled   Market   State   Analysis ' } 
{ ' abstract ' :   ' In   this   paper ,   an   “ intelligent ”   isolated   intersection   control   system   was   developed .   The   developed   “ intelligent ”   system   makes   “ real   time ”   decisions   as   to   whether   to   extend   ( and   how   much )   current   green   time .   The   model   developed   is   based   on   the   combination   of   the   dynamic   programming   and   neural   networks .   Many   tests   show   that   the   outcome   ( the   extension   of   the   green   time )   of   the   proposed   neural   network   is   nearly   equal   to   the   best   solution .   Practically   negligible   CPU   times   were   achieved ,   and   were   thus   absolutely   acceptable   for   the   “ real   time ”   application   of   the   developed   algorithm . ' ,   ' title ' :   ' Dynamic   programming — neural   network   real - time   traffic   adaptive   signal   control   algorithm ' } 
{ ' abstract ' :   ' This   issue   features   expanded   versions   of   articles   selected   from   the   2014   AAAI   Conference   on   Innovative   Applications   of   Artificial   Intelligence   held   in   Quebec   City ,   Canada .   We   present   a   selection   of   four   articles   describing   deployed   applications   plus   two   more   articles   that   discuss   work   on   emerging   applications . ' ,   ' title ' :   ' Introduction   to   the   Special   Issue   on   Innovative   Applications   of   Artificial   Intelligence   2014 ' } 
{ ' abstract ' :   ' Although   frequently   used   in   fractal   compression   quadrant - based   classification   exhibits   a   significant   defect   which   has   not   been   described   in   the   literature .   We   give   an   efficient   solution   to   this   problem   by   controlling   the   class   structure   based   on   an   adaptive   threshold .   This   makes   this   classification   technique   a   very   efficient   and   competitive   one   also   for   block   matching   motion   compensation   algorithms   in   video   coding . ' ,   ' title ' :   ' Resolving   a   defect   in   quadrant - based   classification   for   fast   block - matching ' } 
{ ' abstract ' :   ' Where   there   are   infinitely   many   possible   basic   states   of   the   world ,   a   standard   probability   function   must   assign   zero   probability   to   each   state   –   since   any   finite   probability   would   sum   to   over   one .   This   generates   problems   for   any   decision   theory   that   appeals   to   expected   utility   or   related   notions .   For   it   leads   to   the   view   that   a   situation   in   which   one   wins   a   million   dollars   if   any   of   a   thousand   of   the   equally   probable   states   is   realized   has   an   expected   value   of   zero   ( since   each   such   state   has   probability   zero ) .   But   such   a   situation   dominates   the   situation   in   which   one   wins   nothing   no   matter   what   ( which   also   has   an   expected   value   of   zero ) ,   and   so   surely   is   more   desirable .   I   formulate   and   defend   some   principles   for   evaluating   options   where   standard   probability   functions   cannot   strictly   represent   probability   –   and   in   particular   for   where   there   is   an   infinitely   spread ,   uniform   distribution   of   probability .   The   principles   appeal   to   standard   probability   functions ,   but   overcome   at   least   some   of   their   limitations   in   such   cases . ' ,   ' title ' :   ' Standard   decision   theory   corrected ' } 
{ ' abstract ' :   ' Backed   by   the   European   Commission ,   a   consortium   of   partners   from   European   industry ,   financial   institutions ,   and   academia   has   embarked   on   a   research   project   to   develop   the   fundamentals   of   secure   electronic   commerce .   The   goal   of   the   9 - million   ECU   project ,   SEMPER   ( Secure   Electronic   Marketplace   for   Europe ) ,   is   to   provide   the   first   open   and   comprehensive   solutions   for   secure   commerce   over   the   Internet   and   other   public   information   networks .   We   describe   the   objectives   and   summarise   the   initial   architecture   of   SEMPER .   A   wide   range   of   businesses   are   rapidly   moving   to   explore   the   huge   potential   of   net -   worked   information   systems ,   especially   with   the   Internet - based   WWW   ( World - wide   Web ) .   The   Internet ,   which   already   connects   more   than   3   million   computers   and   a   sub -   stantially   larger   number   of   users ,   is   growing   at   a   breathtaking   pace   with   thousands   of   newcomers   every   day .   Although   the   Internet   has   its   roots   in   academia   and   is   still   domi -   nated   by   free - of - charge   information ,   dramatic   changes   are   expected   in   the   near   future .   For   instance ,   the   WWW   will   be   used   for   a   wide   variety   of   electronic   commerce   such   as   on - line   trade   or   delivery   of   advanced   multimedia   information   services .   The   evolution   of   broadband   networks   and   " information   highways "   will   intensify   this   trend .   The   need   for   secure   transactions   in   this   new   business   environment ,   which   involves   networks   available   to   the   general   public ,   has   triggered   a   number   of   related   efforts .   These   initial   developments   are   based   almost   exclusively   in   the   US   and   most   of   them   are   limited   to   proprietary ,   or   otherwise   closed   solutions ,   involving   only   electronic   payment   issues .   In   contrast ,   SEMPER   is   directed   towards   a   comprehensive   solution   for   secure   electronic   commerce ,   considering   legal ,   commercial ,   social ,   and   technical   requirements   as   well   as   different   options   for   an   electronic   marketplace . ' ,   ' title ' :   ' Development   of   a   Secure   Electronic   Marketplace   for   Europe ' } 
{ ' abstract ' :   ' Through   the   use   of   a   global   geometric   symmetry ,   detection   ellipses   are   proposed   in   this   paper .   Based   on   the   geometric   symmetry ,   the   proposed   method   first   locates   candidates   of   ellipses   centers .   In   the   meantime ,   according   to   these   candidate   centers ,   all   feature   points   in   an   input   image   are   grouped   into   several   subimages .   Then ,   for   each   subimage ,   by   using   geometric   properties   again ,   all   ellipses   are   extracted .   The   method   significantly   reduces   the   time   required   to   evaluate   all   possible   parameters   without   using   edge   direction   information .   Experimental   results   are   given   to   show   the   correctness   and   effectiveness   of   the   proposed   method . ' ,   ' title ' :   ' Detection   ellipses   by   finding   lines   of   symmetry   in   the   images   via   an   hough   transform   applied   to   straight   lines ' } 
{ ' abstract ' :   ' Automatic   crawling   of   Rich   Internet   Applications   ( RIAs )   is   a   challenge   because   client - side   code   modifies   the   client   dynamically ,   fetch -   ing   server - side   data   asynchronously .   Most   existing   solutions   model   RIAs   as   state   machines   with   DOMs   as   states   and   JavaScript   events   execution   as   transitions .   This   approach   fails   when   used   with   " real - life " ,   complex   RIAs ,   because   the   size   of   the   produced   model   is   much   too   large   to   be   practical .   In   this   paper ,   we   propose   a   new   method   to   crawl   AJAX - based   RIAs   in   an   efficient   manner   by   detecting   " components " ,   which   are   areas   of   the   DOM   that   are   independent   from   each   other ,   and   by   crawling   each   component   separately .   This   leads   to   a   dramatic   reduction   of   the   required   state   space   for   the   model ,   without   loss   of   content   coverage .   Our   method   does   not   require   prior   knowledge   of   the   RIA   nor   predefined   definition   of   components .   Instead ,   we   infer   the   components   by   observing   the   be -   havior   of   the   RIA   during   crawling .   Our   experimental   results   show   that   our   method   can   index   quickly   and   completely   industrial   RIAs   that   are   simply   out   of   reach   for   traditional   methods . ' ,   ' title ' :   ' Indexing   Rich   Internet   Applications   Using   Components - Based   Crawling ' } 
{ ' abstract ' :   ' One   important   aspect   of   constructing   an   overlay   network   is   how   to   exploit   network   locality   in   the   underlying   network .   In   this   paper ,   we   propose   a   scalable   protocol   for   constructing   an   overlay   network   that   takes   account   of   locality   of   network   hosts .   The   constructed   overlay   network   can   significantly   decrease   the   communication   cost   between   end - hosts .   Our   simulation   results   show   that   the   average   distance   between   a   pair   of   hosts   in   the   constructed   overlay   network   is   only   about   11%   of   the   one   in   a   traditional ,   randomly   connected   overlay   network .   Furthermore ,   our   proposed   overlay   considered   to   be   more   scalable   than   tree - based   or   mesh - based   overlays . ' ,   ' title ' :   ' Measurement - based   construction   of   locality - aware   overlay   networks ' } 
{ ' abstract ' :   ' This   paper   presents   a   low   cost ,   flexible   and   customizable   delay   measurement   system   developed   to   assess   the   performance   of   the   VTPE - hBEB   protocol .   The   proposed   system   can   be   used   to   evaluate   other   communication   protocols   as   well   as   to   measure   the   delay   between   two   repetitive   events . ' ,   ' title ' :   ' Delay   measurement   system   for   real - time   serial   data   streams ' } 
{ ' abstract ' :   " Service   robots   have   become   increasingly   important   subjects   in   our   lives .   However ,   they   are   still   facing   problems   like   adaptability   to   their   users .   While   major   work   has   focused   on   intelligent   service   robots ,   the   proposed   approaches   were   mostly   user   independent .   Our   work   is   part   of   the   FUI - RoboPopuli   project ,   which   concentrates   on   endowing   entertainment   companion   robots   with   adaptive   and   social   behaviour .   In   particular ,   we   are   interested   in   robots   that   are   able   to   learn   and   plan   so   that   they   adapt   and   personalize   their   behaviour   according   to   their   users .   Markov   Decision   Processes   ( MDPs )   are   largely   used   for   adaptive   robots   applications .   However ,   one   challenging   point   is   reducing   the   sample   complexity   required   to   learn   an   MDP   model ,   including   the   reward   function .   In   this   article ,   we   present   our   contribution   regarding   the   representation   and   the   learning   of   the   reward   function   through   analysing   interaction   traces   ( i . e .   the   interaction   history   between   the   robot   and   their   users ,   including   users '   feedback ) .   Our   approach   permits   to   generalise   the   learned   rewards   so   that   when   new   users   are   introduced ,   the   robot   may   quickly   adapt   using   what   it   learned   from   previous   experiences   with   other   users .   We   propose ,   in   this   article ,   two   algorithms   to   learn   the   reward   function .   The   first   is   direct   and   certain ,   the   robot   applies   with   a   user   what   it   learned   during   interaction   with   same   kind   of   users   ( i . e .   users   with   similar   profiles ) .   The   second   algorithm   generalises   what   it   learns   to   be   applied   to   all   kinds   of   users .   Through   simulation ,   we   show   that   the   generalised   algorithm   converges   to   an   optimal   reward   function   with   less   than   half   the   samples   needed   by   the   direct   algorithm . " ,   ' title ' :   " Adaptive   and   Personalised   Robots   -   Learning   from   Users '   Feedback " } 
{ ' abstract ' :   " Researches   of   sensor   networks   collecting   patients '   data   with   computerized   triage   tags ,   called   Triage   Network ,   are   attracting   attention .   The   listening   power   used   in   triage   tags   is   the   major   factor   of   lots   of   energy   consumption ,   and   consumption   of   energy   increases   when   sensor   nodes   always   communicate   with   other   nodes   in   active   state .   Hence ,   we   suppose   that   sensor   nodes   are   put   to   sleep   periodically   to   avoid   running   out   of   battery .   However ,   some   nodes   have   mobility   and   nodes   secede   from   the   network   according   to   patients   conditions   in   Triage   Network .   The   paths   are   failed   and   it   is   needed   to   reconstruct   paths   when   these   forwarding   nodes   move   or   secede   from   network .   Therefore ,   data   arrival   ratio   decreases   and   consumption   of   battery   increases   due   to   reconstruction   of   other   paths .   In   this   paper ,   we   propose   a   data   collection   method   using   two   types   of   forwarding   nodes ,   Stable   Nodes   and   Energy   Efficient   Nodes .   This   method   uses   two   types   of   forwarding   nodes   according   to   priority   of   data   and   avoids   loss   of   high   priority   data ,   improves   the   data   arrival   ratio   and   saves   the   energy   consumption .   We   evaluate   the   proposed   method   and   show   its   effectiveness   using   computer   simulations . " ,   ' title ' :   ' Data   collection   method   using   two   types   of   forwarding   nodes   for   energy   saving   in   triage   network ' } 
{ ' abstract ' :   ' This   paper   introduces   Golay - paired   Hadamard   matrices   for   fast   compressed   sensing   of   sparse   signals   in   the   time   or   spectral   domain .   These   sampling   operators   feature   low - memory   requirement ,   hardware - friendly   implementation   and   fast   computation   in   reconstruction .   We   show   that   they   require   a   nearly   optimal   number   of   measurements   for   faithful   reconstruction   of   a   sparse   signal   in   the   time   or   frequency   domain .   Simulation   results   demonstrate   that   the   proposed   sensing   matrices   offer   a   reconstruction   performance   similar   to   that   of   fully   random   matrices . ' ,   ' title ' :   ' Golay   meets   Hadamard :   Golay - paired   Hadamard   matrices   for   fast   compressed   sensing ' } 
{ ' abstract ' :   ' In   this   technical   note ,   the   problem   of   finite - time   output   regulation   control   for   a   class   of   disturbed   system   under   mismatching   condition   is   investigated   via   a   composite   control   design   manner .   The   composite   controller   is   developed   by   using   a   finite   time   control   technique   and   a   finite   time   disturbance   observer   ( FTDO ) .   A   key   idea   is   to   design   virtual   control   laws   based   on   estimation   values   of   the   disturbances   and   the   ith   ( 1 ≤ i ≤ n - 1   where   n   is   the   order   of   the   system )   order   derivative   of   disturbances .   Finite   time   stability   analysis   for   the   augmented   system   is   presented   by   means   of   Lyapunov   stability   theorems ,   which   shows   that   the   system   output   is   regulated   to   zero   in   finite   time   even   in   the   presence   of   mismatched   disturbances .   A   motion   control   application   demonstrates   the   effectiveness   and   attractive   properties   of   the   proposed   method . ' ,   ' title ' :   ' Continuous   Finite - Time   Output   Regulation   for   Disturbed   Systems   Under   Mismatching   Condition ' } 
{ ' abstract ' :   ' In   this   paper   we   propose   an   approach   for   enhanced   data   protection   in   the   cloud ,   based   upon   accountability   governance .   Specifically ,   the   relationships   between   accountability ,   risk   and   trust   are   analyzed   in   order   to   suggest   characteristics   and   means   to   address   data   governance   issues   involved   when   organizations   or   individuals   adopt   cloud   computing .   This   analysis   takes   into   account   insights   from   a   variety   of   stakeholders   within   cloud   ecosystems   obtained   by   running   an   elicitation   workshop . ' ,   ' title ' :   ' Accountability ,   Risk ,   and   Trust   in   Cloud   Services :   Towards   an   Accountability - Based   Approach   to   Risk   and   Trust   Governance ' } 
{ ' abstract ' :   ' Xue   et   al .   recently   proposed   an   innovative   mutual   authentication   and   key   agreement   scheme   for   wireless   sensor   networks   based   on   temporal   credential   using   smart   cards .   However ,   in   this   paper   we   demonstrate   that   their   scheme   is   vulnerable   to   password   guessing   attacks ,   node   capture   attacks   and   denial - of - service   attacks .   Furthermore   we   show   that   their   scheme   has   some   inconsistencies   which   make   it   less   secure   and   more   computationally   costly   than   originally   presented . ' ,   ' title ' :   ' Notes   on   A   Temporal - Credential - Based   Mutual   Authentication   and   Key   Agreement   Scheme   for   Wireless   Sensor   Networks ' } 
{ ' abstract ' :   ' Persistent   Scatterer   Interferometry   ( PSI )   has   been   widely   used   for   landslide   studies   in   recent   years .   This   paper   investigated   the   spatial   patterns   of   PSI   point   targets   and   landslide   occurrences   in   the   Arno   River   basin   in   Central   Italy .   The   main   purpose   is   to   analyze   whether   spatial   patterns   of   Persistent   Scatterers   ( PS )   can   be   recognized   as   indicators   of   landslide   occurrences   throughout   the   whole   basin .   The   bivariate   K - function   was   employed   to   assess   spatial   relationships   between   PS   and   landslides .   The   PSI   point   targets   were   acquired   from   almost   4   years   ( from   March   2003   to   January   2007 )   of   RADARSAT - 1   images .   The   landslide   inventory   was   collected   from   15   years   ( from     1992 – 2007 )   of   surveying   and   mapping   data ,   mainly   including   remote   sensing   data ,   topographic   maps   and   field   investigations .   The   proposed   approach   is   able   to   assess   spatial   patterns   between   a   variety   of   PS   and   landslides ,   in   particular ,   to   understand   if   PSI   point   targets   are   spatially   clustered   ( spatial   attraction )   or   randomly   distributed   ( spatial   independency )   on   various   types   of   landslides   across   the   basin .   Additionally ,   the   degree   and   scale   distances   of   PS   clustering   on   a   variety   of   landslides   can   be   characterized .   The   results   rejected   the   null   hypothesis   that   PSI   point   targets   appear   to   cluster   similarly   on   four   types   of   landslides   ( slides ,   flows ,   falls   and   creeps )   in   the   Arno   River   basin .   Significant   influence   of   PS   velocities   and   acquisition   orbits   can   be   noticed   on   detecting   landslides   with   different   states   of   activities .   Despite   that   the   assessment   may   be   influenced   by   the   quality   of   landslide   inventory   and   Synthetic   Aperture   Radar   ( SAR )   images ,   the   proposed   approach   is   expected   to   provide   guidelines   for   studies   trying   to   detect   and   investigate   landslide   occurrences   at   a   regional   scale   through   spatial   statistical   analysis   of   PS ,   for   which   an   advanced   understanding   of   the   impact   of   scale   distances   on   landslide   clustering   is   fundamentally   needed . ' ,   ' title ' :   ' Investigating   Spatial   Patterns   of   Persistent   Scatterer   Interferometry   Point   Targets   and   Landslide   Occurrences   in   the   Arno   River   Basin ' } 
{ ' abstract ' :   ' This   article   describes   a   middleware   used   in   display   cluster   of   real   time   visual   simulation   system .   This   middleware   which   based   on   TCP / IP   protocol   provides   the   communication   infrastructure   for   visual   simulation   system .   It   provides   unified   process   logic   and   interfaces   for   various   status   and   frame   data   and   the   packing / unpacking   functions   of   simulation   data   without   concerning   the   details   of   the   data .   We   found   two   classes   of   display   synchronization   problems   and   provided   the   resolution   of   them .   The   middleware   provides   a   group   of   APIs   which   hide   the   details   of   data   packing / unpacking ,   processing   and   transmission   and   meets   the   requirement   of   flexibility ,   efficiency   and   extensibility .   This   middleware   has   been   successfully   implemented   to   the   display   cluster   of   several   tower   simulation   system . ' ,   ' title ' :   ' The   Research   of   High   Level   Data   Communication   Middleware   of   Display   Cluster   Used   in   Real   Time   Simulation   Environment ' } 
{ ' abstract ' :   ' The   scattering   parameters   are   fundamental   in   the   characterization   of   electrical   devices   at   high   frequencies .   They   are   particularly   useful   for   analyzing   multiport   high - frequency   and   microwave   networks .   However ,   they   are   not   adequately   presented   in   most ,   if   not   all ,   microwave   engineering   books .   This   paper   identifies   two   common   deficiencies   in   the   way   scattering   parameters   are   being   presented   in   these   books .   It   provides   additional   information   that   should   supplement   those   books   or   book   chapters   on   scattering   parameters . ' ,   ' title ' :   ' Deficiencies   in   the   way   scattering   parameters   are   taught ' } 
{ ' abstract ' :   ' We   study   the   reliability   maximization   problem   in   WDM   networks   with   random   link   failures .   Reliability   in   these   networks   is   defined   as   the   probability   that   the   logical   network   is   connected ,   and   it   is   determined   by   the   underlying   lightpath   routing   and   the   link   failure   probability .   We   show   that   in   general   the   optimal   lightpath   routing   depends   on   the   link   failure   probability ,   and   characterize   the   properties   of   lightpath   routings   that   maximize   the   reliability   in   different   failure   probability   regimes .   In   particular ,   we   show   that   in   the   low   failure   probability   regime ,   maximizing   the   ` ` cross - layer "   min   cut   of   the   ( layered )   network   maximizes   reliability ,   whereas   in   the   high   failure   probability   regime ,   minimizing   the   spanning   tree   of   the   network   maximizes   reliability .   Motivated   by   these   results ,   we   develop   lightpath   routing   algorithms   for   reliability   maximization . ' ,   ' title ' :   ' Maximizing   Reliability   in   WDM   Networks   through   Lightpath   Routing ' } 
{ ' abstract ' :   ' The   slope   of   the   active   distances   is   an   important   parameter   when   investigating   the   error - correcting   capability   of   convolutional   codes   and   the   distance   behavior   of   concatenated   convolutional   codes .   The   slope   of   the   active   distances   is   equal   to   the   minimum   average   weight   cycle   in   the   state - transition   diagram   of   the   encoder .   A   general   upper   bound   on   the   slope   depending   on   the   free   distance   of   the   convolutional   code   and   new   upper   bounds   on   the   slope   of   special   classes   of   binary   convolutional   codes   are   derived .   Moreover ,   a   search   technique ,   resulting   in   new   tables   of   rate   R = 1 / 2   and   rate   R = 1 / 3   convolutional   encoders   with   high   memories   and   large   active   distance - slopes   is   presented .   Furthermore ,   we   show   that   convolutional   codes   with   large   slopes   can   be   used   to   obtain   new   tailbiting   block   codes   with   large   minimum   distances .   Tables   of   rate   R = 1 / 2   and   rate   R = 1 / 3   tailbiting   codes   with   larger   minimum   distances   than   the   best   previously   known   quasi - cyclic   codes   are   given .   Two   new   tailbiting   codes   also   have   larger   minimum   distances   than   the   best   previously   known   binary   linear   block   codes   with   same   size   and   length .   One   of   them   is   also   superior   in   terms   of   minimum   distance   to   any   previously   known   binary   nonlinear   block   code   with   the   same   set   of   parameters . ' ,   ' title ' :   ' Tailbiting   codes   obtained   via   convolutional   codes   with   large   active   distance - slopes ' } 
{ ' abstract ' :   ' MIMO   wireless   technology   is   required   to   increase   the   data   rates   for   a   broad   range   of   applications ,   including   low   cost   mobile   devices .   In   this   paper   we   present   a   very   low   area   reconfigurable   MIMO   detector   which   achieves   a   high   throughput   of   103Mbps   and   uses   27   Kilo   Gates   when   implemented   in   a   commercial   180nm   CMOS   process .   The   low   area   is   achieved   by   the   proposed   in - place   architecture .   This   architecture   implements   the   K - best   algorithm   and   reduces   area   4 - fold   compared   to   the   widely   used   multi - stage   architecture ,   while   provides   reconfigurability   in   terms   of   antenna   configuration   during   real - time   operation . ' ,   ' title ' :   ' A   low - area   flexible   MIMO   detector   for   WiFi / WiMAX   standards ' } 
{ ' abstract ' :   ' Because   human   cognition   is   creative   and   socially   situated ,   knowledge   accumulates ,   diffuses ,   and   gets   applied   in   new   contexts ,   generating   cultural   analogs   of   phenomena   observed   in   population   genetics   such   as   adaptation   and   drift .   It   is   therefore   commonly   thought   that   elements   of   culture   evolve   through   natural   selection .   However ,   natural   selection   was   proposed   to   explain   how   change   accumulates   despite   lack   of   inheritance   of   acquired   traits ,   as   occurs   with   template - mediated   replication .   It   cannot   accommodate   a   process   with   significant   retention   of   acquired   or   horizontally   ( e . g .   socially )   transmitted   traits .   Moreover ,   elements   of   culture   cannot   be   treated   as   discrete   lineages   because   they   constantly   interact   and   influence   one   another .   It   is   proposed   that   what   evolves   through   culture   is   the   mind ;   ideas   and   artifacts   are   merely   reflections   of   its   current   evolved   state .   Interacting   minds   transform   ( in   part )   through   a   non - Darwinian   autopoietic   process   similar   to   that   by   which   early   life   evolved ,   involving   not   survival   of   the   fittest   but   actualization   of   their   potential . ' ,   ' title ' :   ' The   cultural   evolution   of   socially   situated   cognition ' } 
{ ' abstract ' :   ' Event   Extraction   is   a   complex   and   interesting   topic   in   Information   Extraction   that   includes   event   extraction   methods   from   free   text   or   web   data .   The   result   of   event   extraction   systems   can   be   used   in   several   fields   such   as   risk   analysis   systems ,   online   monitoring   systems   or   decide   support   tools .   In   this   paper ,   we   introduce   a   method   that   combines   lexico   - -   semantic   and   machine   learning   to   extract   event   from   Vietnamese   news .   Furthermore ,   we   concentrate   to   describe   event   online   monitoring   system   named   VnLoc   based   on   the   method   that   was   proposed   above   to   extract   event   in   Vietnamese   language .   Besides ,   in   experiment   phase ,   we   have   evaluated   this   method   based   on   precision ,   recall   and   F1   measure .   At   this   time   of   experiment ,   we   on   investigated   on   three   types   of   event :   FIRE ,   CRIME   and   TRANSPORT   ACCIDENT . ' ,   ' title ' :   ' VnLoc :   A   Real   - -   Time   News   Event   Extraction   Framework   for   Vietnamese ' } 
{ ' abstract ' :   ' Reliability   analysis   using   error   probabilities   for   combinational   logic   circuits   has   been   investigated   widely   in   the   literature .   Reliability   analysis   for   sequential   logic   circuits   using   these   methods   would   be   inaccurate   because   of   existence   of   loops   in   their   architecture .   In   this   paper   a   new   method   based   on   conversion   of   sequential   circuit   to   combinational   one   and   applying   an   iterative   reliability   analysis   is   developed .   A   Monte   Carlo   method - based   reliability   analysis   is   introduced   for   sequential   circuits ,   which   is   used   for   first   method   validation .   Experimental   results   demonstrate   good   accuracy   of   the   method . ' ,   ' title ' :   ' SEQUENTIAL   LOGIC   CIRCUITS   RELIABILITY   ANALYSIS ' } 
{ ' abstract ' :   ' According   to   the   Journey   to   Crime   theory ,   offenders   have   a   directionality   preference ,   in   the   form   of   an   activity   path ,   when   they   are   moving   about   in   their   environment   in   search   for   criminal   activities .   Using   clustering   techniques ,   this   theory   is   tested   using   crime   data   for   the   Province   of   British   Columbia ,   Canada .   The   activities   of   57 , 962   offenders   who   were   either   charged ,   chargeable ,   or   for   whom   charges   were   recommended   were   analyzed   by   mapping   their   offense   locations   with   respect   to   their   home   locations   to   determine   directionality .   Once   directionality   was   established ,   a   unique   clustering   technique ,   based   on   K - Means   clustering   and   modified   for   angles ,   was   applied   to   find   the   number   of   activity   paths   for   each   offender .   Although   the   number   of   activity   paths   varies   from   individual   to   individual ,   the   aggregate   pattern   was   very   consistent   with   theory .   It   was   found   that   people   only   have   a   few   activity   paths ,   even   if   they   are   highly   prolific   offenders . ' ,   ' title ' :   ' How   Many   Ways   Do   Offenders   Travel   - -   Evaluating   the   Activity   Paths   of   Offenders ' } 
{ ' abstract ' :   ' Pulse   Coupled   Neural   Network ( PCNN )   is   widely   used   in   the   field   of   image   processing ,   but   it   is   a   difficult   task   to   define   the   relative   parameters   properly   in   the   research   of   the   applications   of   PCNN .   So   far   the   determination   of   parameters   of   its   model   needs   a   lot   of   experiments .   To   deal   with   the   above   problem ,   a   document   segmentation   based   on   the   improved   PCNN   is   proposed .   It   uses   the   maximum   entropy   function   as   the   fitness   function   of   bacterial   foraging   optimization   algorithm ,   adopts   bacterial   foraging   optimization   algorithm   to   search   the   optimal   parameters ,   and   eliminates   the   trouble   of   manually   set   the   experiment   parameters .   Experimental   results   show   that   the   proposed   algorithm   can   effectively   complete   document   segmentation .   And   result   of   the   segmentation   is   better   than   the   contrast   algorithms .   ©   ( 2014 )   COPYRIGHT   Society   of   Photo - Optical   Instrumentation   Engineers   ( SPIE ) .   Downloading   of   the   abstract   is   permitted   for   personal   use   only . ' ,   ' title ' :   ' PCNN   document   segmentation   method   based   on   bacterial   foraging   optimization   algorithm ' } 
{ ' abstract ' :   ' Undirected   graphical   models   encode   in   a   graph   G   the   dependency   structure   of   a   random   vector   Y .   In   many   applications ,   it   is   of   interest   to   model   Y   given   another   random   vector   X   as   input .   We   refer   to   the   problem   of   estimating   the   graph   G ( x )   of   Y   conditioned   on   X   =   x   as   " graph - valued   regression " .   In   this   paper ,   we   propose   a   semiparametric   method   for   estimating   G ( x )   that   builds   a   tree   on   the   X   space   just   as   in   CART   ( classification   and   regression   trees ) ,   but   at   each   leaf   of   the   tree   estimates   a   graph .   We   call   the   method   " Graph - optimized   CART " ,   or   Go - CART .   We   study   the   theoretical   properties   of   Go - CART   using   dyadic   partitioning   trees ,   establishing   oracle   inequalities   on   risk   minimization   and   tree   partition   consistency .   We   also   demonstrate   the   application   of   Go - CART   to   a   meteorological   dataset ,   showing   how   graph - valued   regression   can   provide   a   useful   tool   for   analyzing   complex   data . ' ,   ' title ' :   ' Graph - Valued   Regression ' } 
{ ' abstract ' :   ' Over   the   last   two   decades ,   doubts   have   been   expressed   about   the   adequacy   of   materialism   as   the   correct   framework   for   explaining   phenomenal   consciousness   ( the   experience   of   saturated   greenness   one   has   when   looking   at   a   lush   lawn ,   for   example ) .   This   paper   reconstructs   a   generic   form   of   the   various   arguments   that   have   been   used   to   defend   the   view   of   the   materialistically   inexplicable   nature   of   consciousness   ( MINC ) .   This   reconstruction   reveals   that   the   arguments   turn   on   an   impoverished   notion   of   explanation .   By   discussing   some   examples   from   the   history   of   science ,   the   paper   shows   that   a   reasonable   notion   of   explanation   has   to   be   wider   than   the   one   utilized   in   the   argument   for   MINC ,   which   opens   the   possibility   for   the   materialistic   explicability   of   consciousness .   The   author   ends   the   paper   by   raising   a   question   about   the   very   intelligibility   of   the   project   of   trying   to   explain   the   so - called   nature   of   consciousness   as   opposed   to   the   regularities   characteristic   of   the   relation   between   states   of   consciousness   and   ... ' ,   ' title ' :   ' On   explaining   phenomenal   consciousness ' } 
{ ' abstract ' :   ' Successful   replication   within   an   infected   host   and   successful   transmission   between   hosts   are   key   to   the   continued   spread   of   most   pathogens .   Competing   selection   pressures   exerted   at   these   different   scales   can   lead   to   evolutionary   trade - offs   between   the   determinants   of   fitness   within   and   between   hosts .   Here ,   we   examine   such   a   trade - off   in   the   context   of   influenza   A   viruses   and   the   differential   pressures   exerted   by   temperature - dependent   virus   persistence .   For   a   panel   of   avian   influenza   A   virus   strains ,   we   find   evidence   for   a   trade - off   between   the   persistence   at   high   versus   low   temperatures .   Combining   a   within - host   model   of   influenza   infection   dynamics   with   a   between - host   transmission   model ,   we   study   how   such   a   trade - off   affects   virus   fitness   on   the   host   population   level .   We   show   that   conclusions   regarding   overall   fitness   are   affected   by   the   type   of   link   assumed   between   the   within -   and   between - host   levels   and   the   main   route   of   transmission   ( direct   or   environmental ) .   The   relative   importance   of   virulence   and   immune   response   mediated   virus   clearance   are   also   found   to   influence   the   fitness   impacts   of   virus   persistence   at   low   versus   high   temperatures .   Based   on   our   results ,   we   predict   that   if   transmission   occurs   mainly   directly   and   scales   linearly   with   virus   load ,   and   virulence   or   immune   responses   are   negligible ,   the   evolutionary   pressure   for   influenza   viruses   to   evolve   toward   good   persistence   at   high   within - host   temperatures   dominates .   For   all   other   scenarios ,   influenza   viruses   with   good   environmental   persistence   at   low   temperatures   seem   to   be   favored . ' ,   ' title ' :   ' A   Multi - scale   Analysis   of   Influenza   A   Virus   Fitness   Trade - offs   due   to   Temperature - dependent   Virus   Persistence ' } 
{ ' abstract ' :   ' Peer - to - Peer   ( P2P )   networks   are   largely   used   for   file - sharing   and   hence   must   provide   efficient   mechanisms   for   searching   the   files   stored   at   various   nodes .   The   existing   structuredP2P   overlays   support   only   ” exact - match ”   look - up   which   is   hardly   sufficient   in   a   file   sharing   network .   This   paper   addresses   the   problem   of   keyword - based   search   in   structured   P2P   networks .   We   propose   a   new   keyword - based   searching   algorithm   which   can   be   implemented   on   top   of   any   structured   P2P   overlay .   We   demonstrate   that   the   proposed   algorithm   achieves   very   good   searching   results   as   it   requires   the   minimum   number   of   messages   to   be   sent   in   order   to   find   all   the   references   to   files   containing   at   least   the   given   set   of   keywords . ' ,   ' title ' :   ' A   Keyword   Search   Algorithm   for   Structured   Peer - to - Peer   Networks ' } 
{ ' abstract ' :   ' In   this   paper ,   we   propose   an   adaptive   power   allocation   method   for   hybrid   relay   systems   that   employ   the   amplify - and - forward   and   decode - and - forward   protocols   simultaneously .   The   total   transmission   power   is   analytically   allocated   to   a   source   and   two   selected   relays   by   the   proposed   power   allocation   criterion   to   maximize   the   overall   received   signal - to - noise   ratio   at   the   destination .   Simulation   results   show   that   the   proposed   scheme   achieves   better   performance   than   that   of   conventional   cooperative   schemes   or   hybrid   systems   with   equal   power   allocation . ' ,   ' title ' :   ' Adaptive   relay   selection   and   power   allocation   for   hybrid   relay   systems ' } 
{ ' abstract ' :   ' The   unitary   rotation   of   square - pixellated   images   is   based   on   the   finite   su ( 2 ) - oscillator   model ,   which   describes   systems   whose   values   for   position ,   momentum   and   energy ,   are   discrete   and   finite .   In   a   two - dimensional   position   space ,   this   allows   the   construction   of   angular   momentum   states ,   orthonormal   and   complete ,   for   which   rotations   are   defined   as   multiplication   by   phases   that   carry   the   rotation   angle .   The   decomposition   of   a   digital   square   images   in   terms   of   these   angular   momentum   states   determines   a   unitary   ( hence   invertible )   rotation   of   the   image ,   whose   kernel   can   be   computed   as   a   four - dimensional   array   of   real   numbers . ' ,   ' title ' :   ' Unitary   rotation   of   square - pixellated   images ' } 
{ ' abstract ' :   ' As   more   mobile   storage   devices   are   used   in   consumer   electronics ,   possibility   of   user   confidential   data   leakage   increases .   To   make   things   worse ,   data   of   deleted   file   in   mobile   storage   such   as   USB   drives   can   be   easily   recovered   and ,   thus ,   can   be   vulnerable   to   data   leakage .   To   prevent   this   type   of   data   leakage ,   efficient   secure   deletion   techniques   are   required   and   we   present   two   secure   deletion   techniques ,   namely   block   cleaning   and   zero   overwriting ,   for   flash   memory   storage .   Also ,   we   propose   cost   and   benefit   models   of   both   techniques .   The   models   imply   an   existence   of   an   efficient   adaptive   hybrid   secure   deletion   scheme   that   applies   one   of   the   techniques   based   on   their   costs   and   benefits   at   given   data   arrangements .   Experimental   results   measured   on   an   embedded   board   show   that   the   adaptive   hybrid   scheme   deletes   data   securely   and   efficiently   for   various   data   patterns   on   flash   memory   storage . ' ,   ' title ' :   ' Models   and   Design   of   an   Adaptive   Hybrid   Scheme   for   Secure   Deletion   of   Data   in   Consumer   Electronics ' } 
{ ' abstract ' :   ' In   heterogeneous   and   dynamic   environments ,   efficient   execution   of   parallel   computations   can   require   mappings   of   tasks   to   processors   whose   performance   is   both   irregular   ( because   of   heterogeneity )   and   time - varying   ( because   of   dynamicity ) .   While   adaptive   domain   decomposition   techniques   have   been   used   to   address   heterogeneous   resource   capabilities ,   temporal   variations   in   those   capabilities   have   seldom   been   considered .   We   propose   a   conservative   scheduling   policy   that   uses   information   about   expected   future   variance   in   resource   capabilities   to   produce   more   efficient   data   mapping   decisions .   We   first   present   techniques ,   based   on   time   series   predictors   that   we   developed   in   previous   work ,   for   predicting   CPU   load   at   some   future   time   point ,   average   CPU   load   for   some   future   time   interval ,   and   variation   of   CPU   load   over   some   future   time   interval .   We   then   present   a   family   of   stochastic   scheduling   algorithms   that   exploit   such   predictions   of   future   availability   and   variability   when   making   data   mapping   decisions .   Finally ,   we   describe   experiments   in   which   we   apply   our   techniques   to   an   astrophysics   application .   The   results   of   these   experiments   demonstrate   that   conservative   scheduling   can   produce   execution   times   that   are   both   significantly   faster   and   less   variable   than   other   techniques . ' ,   ' title ' :   ' Conservative   Scheduling :   Using   Predicted   Variance   to   Improve   Scheduling   Decisions   in   Dynamic   Environments ' } 
{ ' abstract ' :   ' We   consider   a   class   of   restless   multi - armed   bandit   problems   that   arises   in   multi - channel   opportunistic   communications ,   where   channels   are   modeled   as   independent   and   stochastically   identical   Gilbert - Elliot   channels   and   channel   state   observations   are   subject   to   errors .   We   show   that   the   myopic   channel   selection   policy   has   a   semi - universal   structure   that   obviates   the   need   to   know   the   Markovian   transition   probabilities   of   the   channel   states .   Based   on   this   structure ,   we   establish   closed - form   lower   and   upper   bounds   on   the   steady - state   throughput   achieved   by   the   myopic   policy .   Furthermore ,   we   characterize   the   approximation   factor   of   the   myopic   policy   to   bound   its   worst - case   performance   loss   with   respect   to   the   optimal   performance . ' ,   ' title ' :   ' On   the   myopic   policy   for   a   class   of   restless   bandit   problems   with   applications   in   dynamic   multichannel   access ' } 
{ ' abstract ' :   ' We   show   that   the   optimum   length - / spl   nu /   guard   sequence   for   block   transmission   over   a   linear   Gaussian - noise   dispersive   channel   with   memory   / spl   nu /   is   a   linear   combination   of   the   N   information   symbols   of   the   block .   A   closed - form   expression   for   the   optimum   guard   sequence   is   derived   subject   to   a   total   average   energy   constraint   on   the   information   and   guard   symbols .   The   achievable   channel   block   throughput   with   the   optimum   guard   sequence   is   compared   with   that   achievable   with   two   common   guard   sequence   types ,   namely   zero   stuffing   and   cyclic   prefix . ' ,   ' title ' :   ' Guard   sequence   optimization   for   block   transmission   over   linear   frequency - selective   channels ' } 
{ ' abstract ' :   " A   modular   program   analysis   considers   components   independently   and   provides   a   succinct   summary   for   each   component ,   which   is   used   when   checking   the   rest   of   the   system .   Consider   a   system   consisting   of   a   library   and   a   client .   A   temporal   summary ,   or     interface   ,   of   the   library   specifies   legal   sequences   of   library   calls .   The   interface   is     safe     if   no   call   sequence   violates   the   library ' s   internal   invariants ;   the   interface   is     permissive     if   it   contains   every   such   sequence .   Modular   program   analysis   requires     full     interfaces ,   which   are   both   safe   and   permissive :   the   client   does   not   cause   errors   in   the   library   if   and   only   if   it   makes   only   sequences   of   library   calls   that   are   allowed   by   the   full   interface   of   the   library . Previous   interface - based   methods   have   focused   on   safe   interfaces ,   which   may   be   too   restrictive   and   thus   reject   good   clients .   We   present   an   algorithm   for   automatically   synthesizing   software   interfaces   that   are   both   safe   and   permissive .   The   algorithm   generates   interfaces   as   graphs   whose   vertices   are   labeled   with   predicates   over   the   library ' s   internal   state ,   and   whose   edges   are   labeled   with   library   calls .   The   interface   state   is   refined   incrementally   until   the   full   interface   is   constructed .   In   other   words ,   the   algorithm   automatically   synthesizes   a   typestate   system   for   the   library ,   against   which   any   client   can   be   checked   for   compatibility .   We   present   an   implementation   of   the   algorithm   which   is   based   on   the   BLAST   model   checker ,   and   we   evaluate   some   case   studies . " ,   ' title ' :   ' Permissive   interfaces ' } 
{ ' abstract ' :   ' In   this   paper ,   we   propose   a   new   method   for   the   motion   planning   problem   of   rigid   object   dexterous   manipulation   with   a   robotic   multi - fingered   hand ,   under   quasi - static   movement   assumption .   This   method   computes   both   object   and   finger   trajectories   as   well   as   the   finger   relocation   sequence .   Its   specificity   is   to   use   a   special   structuring   of   the   research   space   that   allows   to   search   for   paths   directly   in   the   particular   subspace   GS   n     which   is   the   subspace   of   all   the   grasps   that   can   be   achieved   with   n   grasping   fingers .   The   solving   of   the   dexterous   manipulation   planning   problem   is   based   upon   the   exploration   of   this   subspace .   The   proposed   approach   captures   the   connectivity   of   GS   n     in   a   graph   structure .   The   answer   of   the   manipulation   planning   query   is   then   given   by   searching   a   path   in   the   computed   graph .   Simulation   experiments   were   conducted   for   different   dexterous   manipulation   task   examples   to   validate   the   proposed   method . ' ,   ' title ' :   ' Dexterous   manipulation   planning   using   probabilistic   roadmaps   in   continuous   grasp   subspaces ' } 
{ ' abstract ' :   ' This   paper   presents   an   experimental   evaluation   of   different   line   extraction   algorithms   applied   to   2D   laser   scans   for   indoor   environments .   Six   popular   algorithms   in   mobile   robotics   and   computer   vision   are   selected   and   tested .   Real   scan   data   collected   from   two   office   environments   by   using   different   platforms   are   used   in   the   experiments   in   order   to   evaluate   the   algorithms .   Several   comparison   criteria   are   proposed   and   discussed   to   highlight   the   advantages   and   drawbacks   of   each   algorithm ,   including   speed ,   complexity ,   correctness   and   precision .   The   results   of   the   algorithms   are   compared   with   ground   truth   using   standard   statistical   methods .   An   extended   case   study   is   performed   to   further   evaluate   the   algorithms   in   a   SLAM   application . ' ,   ' title ' :   ' A   comparison   of   line   extraction   algorithms   using   2D   range   data   for   indoor   mobile   robotics ' } 
{ ' abstract ' :   ' This   study   investigates   the   use   of   force - stiffness   feedback ,   i . e . ,   a   combination   of   force   offset   and   extra   spring   load ,   in   UAV   tele - operation   with   transmission   time   delay .   The   goal   was   to   further   increase   the   level   of   safety   of   tele - operation   with   a   reduction   in   operator   workload   with   respect   to   force   feedback ,   i . e . ,   using   force   offset   alone .   A   theoretical   analysis   is   given   of   using   force - stiffness   feedback   to   improve   collision   avoidance .   Wave   variables   are   included   to   reduce   time   delay   effects .   An   experiment   was   conducted   to   investigate   the   effects   of   force - stiffness   feedback   on   safety   of   operation ,   operator   performance ,   control   activity ,   and   workload .   Results   indicate   that   force - stiffness   feedback   improves   the   haptic   interface   with   respect   to   force   feedback   alone .   Safety   of   tele - operation   increases   without   increasing   operator   workload   with   respect   to   force   feedback . ' ,   ' title ' :   ' Haptic   interface   in   UAV   tele - operation   using   force - stiffness   feedback ' } 
{ ' abstract ' :   ' Due   to   the   spread   of   the   internet   and   the   ever   increasing   number   of   web   applications ,   the   issue   of   compatibility   across   browsers   has   become   very   important .   This   compatibility   issue   is   also   referred   as   Cross   Browser   Inconsistency   ( XBI )   wherein   same   website   looks   or   behaves   differently   in   different   web   browsers .   In   this   paper   our   aim   is   to   address   this   issue   of   compatibility   and   propose   an   automated   approach   of   detecting   XBIs .   Cross   Browser   Inconsistencies   can   either   be   in   the   content ,   structure   or   behavior   of   the   webpage .   In   order   to   get   a   grasp   of   the   above   mentioned   types   of   inconsistencies ,   we   surveyed   some   random   websites   and   analyzed   them   in   different   browsers .   We   also   studied   the   basic   working   of   browser ,   in   order   to   establish   its   connection   with   the   occurrences   of   XBIs .   Each   browser   has   its   own   rendering   mechanisms ,   which   sometimes   differs   from   standards .   Hence ,   the   execution   of   these   websites   is   different   in   different   browsers .   Finally   we   have   proposed   an   automated   approach   for   XBI   detection . ' ,   ' title ' :   ' An   Automated   Approach   for   Cross - Browser   Inconsistency   ( XBI )   Detection ' } 
{ ' abstract ' :   ' We   present   a   formal   framework   that   combines   high - level   representation   and   causality - based   reasoning   with   low - level   geometric   reasoning   and   motion   planning .   The   frame - work   features   bilateral   interaction   between   task   and   motion   planning ,   and   embeds   geometric   reasoning   in   causal   reasoning ,   thanks   to   several   advantages   inherited   from   its   underlying   components .   In   particular ,   our   choice   of   using   a   causality - based   high - level   formalism   for   describing   action   domains   allows   us   to   represent   ramifications   and   state / transition   constraints ,   and   embed   in   such   formal   domain   descriptions   externally   defined   functions   implemented   in   some   programming   language   ( e . g . ,   C++ ) .   Moreover ,   given   such   a   domain   description ,   the   causal   reasoner   based   on   this   formalism   ( i . e . ,   the   Causal   Calculator )   allows   us   to   compute   optimal   solutions   ( e . g . ,   shortest   plans )   for   elaborate   planning / prediction   problems   with   temporal   constraints .   Utilizing   these   features   of   high - level   representation   and   reasoning ,   we   can   combine   causal   reasoning ,   motion   planning   and   geometric   planning   to   find   feasible   kinematic   solutions   to   task - level   problems .   In   our   framework ,   the   causal   reasoner   guides   the   motion   planner   by   finding   an   optimal   task - plan ;   if   there   is   no   feasible   kinematic   solution   for   that   task - plan   then   the   motion   planner   guides   the   causal   reasoner   by   modifying   the   planning   problem   with   new   temporal   constraints .   Furthermore ,   while   computing   a   task - plan ,   the   causal   reasoner   takes   into   account   geometric   models   and   kinematic   relations   by   means   of   external   predicates   implemented   for   geometric   reasoning   ( e . g . ,   to   check   some   collisions ) ;   in   that   sense   the   geometric   reasoner   guides   the   causal   reasoner   to   find   feasible   kinematic   solutions .   We   illustrate   an   application   of   this   framework   to   robotic   manipulation ,   with   two   pantograph   robots   on   a   complex   assembly   task   that   requires   concurrent   execution   of   actions .   A   short   video   of   this   application   accompanies   the   paper . ' ,   ' title ' :   ' Combining   high - level   causal   reasoning   with   low - level   geometric   reasoning   and   motion   planning   for   robotic   manipulation ' } 
{ ' abstract ' :   ' This   paper   presents   a   novel   template   matching   method   to   detect   and   track   pedestrians   for   people   counting   in   real - time .   Firstly ,   a   novel   background   subtraction   method   is   proposed   for   extracting   all   foreground   objects   from   background .   Then ,   a   shadow   elimination   method   is   used   to   remove   unwanted   shadow   from   the   background .   In   order   to   identify   pedestrians   from   non - pedestrian   objects ,   this   paper   proposed   a   novel   grid - based   template   matching   scheme   to   robustly   verify   each   pedestrian .   Usually ,   a   pedestrian   will   have   different   appearances   at   different   positions .   The   grid - based   approach   can   effectively   reduce   the   perspective   effects   into   a   minimum   since   it   uses   different   templates   to   record   the   appearance   changes   at   each   grid .   When   more   templates   are   used ,   the   detection   process   will   become   more   inefficient .   To   speed   up   its   efficiency ,   an   integral   image   is   used   to   filter   out   all   impossible   candidates   in   advance .   Lastly ,   a   tracking   method   is   applied   to   tracking   the   direction   of   each   moving   pedestrian   so   that   the   real   number   of   passing   people   per   direction   can   be   counted   more   accurately .   Experimental   results   have   proved   that   the   proposed   method   is   robust ,   accurate ,   and   powerful   in   people   counting . ' ,   ' title ' :   ' Grid - based   Template   Matching   for   People   Counting ' } 
{ ' abstract ' :   ' A   tomographic   image   reconstruction   algorithm   that   we   have   been   studying   requires   the   nth - order   Hankel   transform   for   the   nth   function   in   a   series ,   where   n   varies   over   a   set   of   integers .   Unfortunately ,   most   previously   proposed   algorithms   have   either   dealt   with   only   zeroth - order   transforms   or   cannot   be   applied   conveniently   to   our   problem .   We   propose   an   algorithm   for   computing   general   integer - order   Hankel   transforms .   The   algorithm   takes   samples   of   equally   spaced   input   functions   and   gives   equally   spaced   samples   of   the   transforms . ' ,   ' title ' :   ' An   algorithm   for   computing   general   integer - order   Hankel   transforms ' } 
{ ' abstract ' :   ' In   this   paper ,   we   present   a   real - time   approach   that   allows   tracking   deformable   structures   in   3D   ultrasound   sequences .   Our   method   consists   in   obtaining   the   target   displacements   by   combining   robust   dense   motion   estimation   and   mechanical   model   simulation .   We   perform   evaluation   of   our   method   through   simulated   data ,   phantom   data ,   and   real - data .   Results   demonstrate   that   this   novel   approach   has   the   advantage   of   providing   correct   motion   estimation   regarding   different   ultrasound   shortcomings   including   speckle   noise ,   large   shadows   and   ultrasound   gain   variation .   Furthermore ,   we   show   the   good   performance   of   our   method   with   respect   to   state - of - the - art   techniques   by   testing   on   the   3D   databases   provided   by   MICCAI   CLUST ’ 14   and   CLUST ’ 15   challenges . ' ,   ' title ' :   ' Real - time   target   tracking   of   soft   tissues   in   3D   ultrasound   images   based   on   robust   visual   information   and   mechanical   simulation ' } 
{ ' abstract ' :   ' For   two   given   graphs   G1G1   and   G2G2 ,   the   Ramsey   number   R ( G1 , G2 ) R ( G1 , G2 )   is   the   smallest   integer   NN   such   that   for   any   graph   of   order   NN ,   either   GG   contains   a   copy   of   G1G1   or   its   complement   contains   a   copy   of   G2G2 .   Let   CmCm   be   a   cycle   of   length   mm   and   K1 , nK1 , n   a   star   of   order   n + 1n + 1 .   Parsons   ( 1975 )   shows   that   R ( C4 , K1 , n ) ≤ n + ⌊ n − 1 ⌋ + 2   and   if   nn   is   the   square   of   a   prime   power ,   then   the   equality   holds .   In   this   paper ,   by   discussing   the   properties   of   polarity   graphs   whose   vertices   are   points   in   the   projective   planes   over   Galois   fields ,   we   prove   that   R ( C4 , K1 , q2 − t ) = q2 + q − ( t − 1 ) R ( C4 , K1 , q2 − t ) = q2 + q − ( t − 1 )   if   qq   is   an   odd   prime   power ,   1 ≤ t ≤ 2 ⌈ q4 ⌉   and   t ≠ 2 ⌈ q4 ⌉ − 1 ,   which   extends   a   result   on   R ( C4 , K1 , q2 − t ) R ( C4 , K1 , q2 − t )   obtained   by   Parsons   ( 1976 ) . ' ,   ' title ' :   ' Polarity   graphs   and   Ramsey   numbers   for   C   4   versus   stars ' } 
{ ' abstract ' :   ' This   paper   deals   with   the   problem   of   assuring   strict   QoS   guarantees   for   the   end   to   end   connections   that   originate   from   Ethernet   access   network .   It   shows   that   despite   high   link   capacities   in   some   cases   Ethernet   network   might   be   the   reason   of   QoS   deterioration .   The   primary   reason   is   the   lack   of   appropriate   QoS   differentiation   and   traffic   isolation   mechanisms .   The   shared   buffers   and   priority   schedulers   available   in   most   of   Ethernet   switches   appear   to   be   not   sufficient   to   guarantee   strict   QoS .   For   these   cases   new   solution   is   proposed   which   relies   on   additional   traffic   control   mechanisms   available   in   other   network   elements .   Only   additional   mechanism   supporting   typical   functionality   of   Ethernet   switch   can   provide   strict   QoS   guarantees   what   was   verified   in   simulations   studies . ' ,   ' title ' :   ' On   assuring   QoS   in   Ethernet   access   network ' } 
{ ' abstract ' :   ' The   federal   Medicare   regulations   reimburse   hospitals   on   a   pro   rata   share   of   the   hospital \ ' s   cost .   Hence ,   to   meet   its   financial   requirements ,   a   hospital   is   forced   to   shift   more   of   the   financial   burdens   onto   its   private   patients .   This   procedure   has   contributed   to   double   digit   inflation   in   hospital   prices   and   to   proposed   federal   regulation   to   control   the   rate   of   increase   in   hospital   revenues .   In   this   regulatory   environment ,   we   develop   nonlinear   programming   pricing   and   cost   allocation   models   to   aid   hospital   administrators   in   meeting   their   profit   maximizing   and   profit   satisficing   goals .   The   model   enables   administrators   to   explore   tactical   issues   such   as :   i   studying   the   relationship   between   a   voluntary   or   legislated   cap   on   a   hospital \ ' s   total   revenues   and   the   hospital \ ' s   profitability ,   ii   identifying   those   departments   within   the   hospital   that   are   the   most   attractive   candidates   for   cost   reduction   or   cost   containment   efforts ,   and   iii   isolating   those   services   that   should   be   singled   out   by   the   hospital   manager   for   renegotiation   of   the   prospective   or   " customary   and   reasonable "   cap .   Finally ,   the   modeling   approach   is   helpful   in   explaining   the   departmental   cross   subsidies   observed   in   practice ,   and   can   be   of   aid   to   federal   administrators   in   assessing   the   impacts   of   proposed   changes   in   the   Medicare   reimbursement   formula . ' ,   ' title ' :   ' Hospital   Profit   Planning   under   Medicare   Reimbursement ' } 
{ ' abstract ' :   ' We   present   a   ( 4   +   epsilon )   approximation   algorithm   for   weighted   graph   matching   which   applies   in   the   semistreaming ,   sliding   window ,   and   MapReduce   models ;   this   single   algorithm   improves   the   previous   best   algorithm   in   each   model .   The   algorithm   operates   by   reducing   the   maximum - weight   matching   problem   to   a   polylog   number   of   copies   of   the   maximum - cardinality   matching   problem .   The   algorithm   also   extends   to   provide   approximation   guarantees   for   the   more   general   problem   of   finding   weighted   independent   sets   in   p - systems   ( which   include   intersections   of   p   matroids   and   p - bounded   hypergraph   matching ) . ' ,   ' title ' :   ' Improved   Streaming   Algorithms   for   Weighted   Matching ,   via   Unweighted   Matching ' } 
{ ' abstract ' :   ' This   paper   presents   a   novel   approach   to   efficiently   solve   parameter - dependent   ( PD )   linear   matrix   inequality   ( LMI )   problems   for ,   amongst   others ,   linear   parameter - varying   ( LPV )   control   design .   Typically ,   stability   and   performance   is   guaranteed   by   finding   a   PD   Lyapunov   function   such   that   a   PD   LMI   is   feasible   on   a   parameter   domain .   To   solve   the   resulting   semi - infinite   problems ,   we   propose   a   novel   LMI   relaxation   technique   relying   on   B - spline   basis   functions .   This   technique   provides   less   conservative   solutions   and / or   a   reduced   numerical   burden   compared   to   existing   approaches .   Moreover ,   an   elegant   generalization   of   worst - case   optimization   to   the   optimization   of   any   signal   norm   is   obtained   by   expressing   performance   bounds   as   a   function   of   the   system   parameters .   This   generalization   yields   better   performance   bounds   in   a   large   part   of   the   parameter   domain .   Numerical   comparisons   with   the   current   state - of - the - art   demonstrate   the   generality   and   effectiveness   of   our   approach . ' ,   ' title ' :   ' Control   of   linear   parameter - varying   systems   using   B - splines ' } 
{ ' abstract ' :   ' There   is   a   growing   interest   in   simulating   natural   phenomena   in   computer   graphics   applications .   Animating   natural   scenes   in   real   time   is   one   of   the   most   challenging   problems   due   to   the   inherent   complexity   of   their   structure ,   formed   by   millions   of   geometric   entities ,   and   the   interactions   that   happen   within .   An   example   of   natural   scenario   that   is   needed   for   games   or   simulation   programs   are   forests .   Forests   are   difficult   to   render   because   the   huge   amount   of   geometric   entities   and   the   large   amount   of   detail   to   be   represented .   Moreover ,   the   interactions   between   the   objects   ( grass ,   leaves )   and   external   forces   such   as   wind   are   complex   to   model .   In   this   paper   we   concentrate   in   the   rendering   of   falling   leaves   at   low   cost .   We   present   a   technique   that   exploits   graphics   hardware   in   order   to   render   thousands   of   leaves   with   different   falling   paths   in   real   time   and   low   memory   requirements . ' ,   ' title ' :   ' Rendering   falling   leaves   on   graphics   hardware ' } 
{ ' abstract ' :   ' We   previously   presented   DriverDB ,   a   database   that   incorporates   ∼ 6000   cases   of   exome - seq   data ,   in   addition   to   annotation   databases   and   published   bioinformatics   algorithms   dedicated   to   driver   gene / mutation   identification .   The   database   provides   two   points   of   view ,   ‘ Cancer ’   and   ‘ Gene ’ ,   to   help   researchers   visualize   the   relationships   between   cancers   and   driver   genes / mutations .   In   the   updated   DriverDBv2   database   ( http : / / ngs . ym . edu . tw / driverdb )   presented   herein ,   we   incorporated   > 9500   cancer - related   RNA - seq   datasets   and   > 7000   more   exome - seq   datasets   from   The   Cancer   Genome   Atlas   ( TCGA ) ,   International   Cancer   Genome   Consortium   ( ICGC ) ,   and   published   papers .   Seven   additional   computational   algorithms   ( meaning   that   the   updated   database   contains   15   in   total ) ,   which   were   developed   for   driver   gene   identification ,   are   incorporated   into   our   analysis   pipeline ,   and   the   results   are   provided   in   the   ‘ Cancer ’   section .   Furthermore ,   there   are   two   main   new   features ,   ‘ Expression ’   and   ‘ Hotspot ’ ,   in   the   ‘ Gene ’   section .   ‘ Expression ’   displays   two   expression   profiles   of   a   gene   in   terms   of   sample   types   and   mutation   types ,   respectively .   ‘ Hotspot ’   indicates   the   hotspot   mutation   regions   of   a   gene   according   to   the   results   provided   by   four   bioinformatics   tools .   A   new   function ,   ‘ Gene   Set ’ ,   allows   users   to   investigate   the   relationships   among   mutations ,   expression   levels   and   clinical   data   for   a   set   of   genes ,   a   specific   dataset   and   clinical   features . ' ,   ' title ' :   ' DriverDBv2 :   a   database   for   human   cancer   driver   gene   research ' } 
{ ' abstract ' :   ' Thousands   of   deep   and   wide   pipelines   working   concurrently   make   GPGPU   high   power   consuming   parts .   Energy - efficiency   techniques   employ   voltage   overscaling   that   increases   timing   sensitivity   to   variations   and   hence   aggravating   the   energy   use   issues .   This   paper   proposes   a   method   to   increase   spatiotemporal   reuse   of   computational   effort   by   a   combination   of   compilation   and   micro - architectural   design .   An   associative   memristive   memory   ( AMM )   module   is   integrated   with   the   floating   point   units   ( FPUs ) .   Together ,   we   enable   fine - grained   partitioning   of   values   and   find   high - frequency   sets   of   values   for   the   FPUs   by   searching   the   space   of   possible   inputs ,   with   the   help   of   application - specific   profile   feedback .   For   every   kernel   execution ,   the   compiler   pre - stores   these   high - frequent   sets   of   values   in   AMM   modules   - -   representing   partial   functionality   of   the   associated   FPU - -   that   are   concurrently   evaluated   over   two   clock   cycles .   Our   simulation   results   show   high   hit   rates   with   32 - entry   AMM   modules   that   enable   36%   reduction   in   average   energy   use   by   the   kernel   codes .   Compared   to   voltage   overscaling ,   this   technique   enhances   robustness   against   timing   errors   with   39%   average   energy   saving . ' ,   ' title ' :   ' Energy - Efficient   GPGPU   Architectures   via   Collaborative   Compilation   and   Memristive   Memory - Based   Computing ' } 
{ ' abstract ' :   ' Quasi - cyclic   codes   are   renowned   for   their   structural   design   and   low - complexity   shift   register   encoding .   However ,   existing   design   techniques   based   on   difference   families   have   limited   code   size   options   due   to   algebraic   constraints .   We   introduce   in   this   paper   a   notation   of   extended   difference   family   ( EDF )   and   provide   a   systematic   code   design   based   on   EDFs   with   a   high   degree   of   flexibility   in   code   size .   Short / medium - length   codes   of   high   rate   ( / spl   ges /   0.9 )   can   be   easily   constructed . ' ,   ' title ' :   ' Quasi - cyclic   codes   from   extended   difference   families ' } 
{ ' abstract ' :   ' Lexical   cohesion   arises   from   a   chain   of   lexical   items   that   establish   links   between   sentences   in   a   text .   In   this   paper   we   propose   three   different   models   to   capture   lexical   cohesion   for   document - level   machine   translation :   ( a )   a   direct   reward   model   where   translation   hypotheses   are   rewarded   whenever   lexical   cohesion   devices   occur   in   them ,   ( b )   a   conditional   probability   model   where   the   appropriateness   of   using   lexical   cohesion   devices   is   measured ,   and   ( c )   a   mutual   information   trigger   model   where   a   lexical   cohesion   relation   is   considered   as   a   trigger   pair   and   the   strength   of   the   association   between   the   trigger   and   the   triggered   item   is   estimated   by   mutual   information .   We   integrate   the   three   models   into   hierarchical   phrase - based   machine   translation   and   evaluate   their   effectiveness   on   the   NIST   Chinese - English   translation   tasks   with   large - scale   training   data .   Experiment   results   show   that   all   three   models   can   achieve   substantial   improvements   over   the   baseline   and   that   the   mutual   information   trigger   model   performs   better   than   the   others . ' ,   ' title ' :   ' Modeling   lexical   cohesion   for   document - level   machine   translation ' } 
{ ' abstract ' :   ' This   paper   presents   a   lightweight   sketching   system   that   enables   interactive   illustration   of   complex   fluid   systems .   Users   can   sketch   on   a   2.5 - dimensional   ( 2.5 D )   canvas   to   design   the   shapes   and   connections   of   a   fluid   circuit .   These   input   sketches   are   automatically   analyzed   and   abstracted   into   a   hydraulic   graph ,   and   a   new   hybrid   fluid   model   is   used   in   the   background   to   enhance   the   illustrations .   The   system   provides   rich   simple   operations   for   users   to   edit   the   fluid   system   incrementally ,   and   the   new   internal   flow   patterns   can   be   simulated   in   real   time .   Our   system   is   used   to   illustrate   various   fluid   systems   in   medicine ,   biology ,   and   engineering .   We   asked   professional   medical   doctors   to   try   our   system   and   obtained   positive   feedback   from   them . ' ,   ' title ' :   ' Sketch - based   Dynamic   Illustration   of   Fluid   Systems ' } 
{ ' abstract ' :   ' We   present   an   improved   zone   content   classification   method   and   its   performance   evaluation .   We   added   two   new   features   to   the   feature   vector   from   one   previously   published   method   ( Sivaramakrishnan   et   al . ,   1995 ) .   We   assumed   different   independence   relationships   in   two   zone   sets .   We   used   an   optimized   binary   decision   tree   to   estimate   the   maximum   zone   content   class   probability   in   one   set   while   using   the   Viterbi   algorithm   to   find   the   optimal   solution   for   a   zone   sequence   in   the   other   set .   The   training ,   pruning   and   testing   data   set   for   the   algorithm   include   1 , 600   images   drawn   from   the   UWCDROM   III   document   image   database .   The   classifier   is   able   to   classify   each   given   scientific   and   technical   document   zone   into   one   of   the   nine   classes ,   2   text   classes   ( of   font   size   4   -   18pt   and   font   size   19   -   32   pt ) ,   math ,   table ,   halftone ,   map / drawing ,   ruling ,   logo ,   and   others .   Compared   with   our   previous   work   ( Wang   et   al . ,   2000 ) ,   it   raised   the   accuracy   rate   to   98.52%   from   97.53%   and   reduced   the   mean   false   alarm   rate   to   0.53%   from   1.26% . ' ,   ' title ' :   ' Zone   content   classification   and   its   performance   evaluation ' } 
{ ' abstract ' :   ' Big   Data   applications   require   real - time   processing   of   complex   computations   on   streaming   and   static   information .   Applications   such   as   the   diagnosis   of   power   generating   turbines   require   the   integration   of   high   velocity   streaming   and   large   volume   of   static   data   from   multiple   sources .   In   this   paper   we   study   various   optimisations   related   to   efficiently   processing   of   streaming   and   static   information .   We   introduce   novel   indexing   structures   for   stream   processing ,   a   query - planner   component   that   decides   when   their   creation   is   beneficial ,   and   we   examine   precomputed   summarisations   on   archived   measurements   to   accelerate   streaming   and   static   information   processing .   To   put   our   ideas   into   practise ,   we   have   developed   Exa   Stream ,   a   data   stream   management   system   that   is   scalable ,   has   declarative   semantics ,   supports   user   defined   functions ,   and   allows   efficient   execution   of   complex   analytical   queries   on   streaming   and   static   data .   Our   work   is   accompanied   by   an   empirical   evaluation   of   our   optimisation   techniques . ' ,   ' title ' :   ' Real   time   processing   of   streaming   and   static   information ' } 
{ ' abstract ' :   " In   the   last   ten   years ,   speech   recognition   has   evolved   from   a   science   fiction   dream   to   a   widespread   input   method   for   mobile   devices .   In   this   talk ,   I   will   describe   how   speech   recognition   works ,   the   problems   we   have   solved   and   the   challenges   that   remain .   I   will   touch   upon   some   of   Google ' s   main   efforts   in   language   and   pronunciation   modeling ,   and   describe   how   the   adoption   of   neural   networks   for   acoustic   modeling   marked   the   beginning   of   a   technology   revolution   in   the   field ,   with   approaches   such   as   Long   Short   Term   Memory   models   and   Connectionist   Temporal   Classification .   I   will   also   share   my   learnings   on   how   Machine   Learning   and   Human   Knowledge   can   be   harmoniously   combined   to   build   state - of - the - art   technology   that   helps   and   delights   users   across   the   world . " ,   ' title ' :   ' Learnings   and   innovations   in   speech   recognition ' } 
{ ' abstract ' :   ' Nowadays ,   the   explosive   growth   and   variety   of   information   available   on   the   Web   frequently   overwhelms   users   and   leads   users   to   make   poor   decisions .   Consequently ,   recommender   systems   have   become   more   and   more   important   to   assist   people   to   make   decisions   faster .   Among   all   related   techniques ,   collaborative   filtering   approach   is   currently   one   of   the   effective   and   widely   used   techniques   to   build   recommender   systems .   However ,   there   are   major   challenges   like   data   sparsity   and   scalability .   Meanwhile   it   is   hard   to   integrate   demographic   statistical   information   ( Age ,   gender   and   occupation   etc . )   to   collaborative   filtering   model .   Unfortunately ,   it   is   significant   to   take   account   into   these   information ,   especially   user   occupation   when   making   recommendation .   As   we   all   know ,   people   with   different   occupations   may   have   totally   different   tastes .   It   has   been   proved   that   restricted   Boltzmann   machines ( RBM )   model   can   infer   lower - dimensional   representations   automatically   and   is   potential   in   handling   large   and   sparse   dataset .   In   this   paper ,   we   propose   an   improved   User   Occupation   aware   Conditional   Restricted   Boltzmann   Machine   Frame ( UO - CRBMF )   model ,   which   employs   an   improved   RBM   and   takes   full   use   of   user   occupation   information   by   adding   a   conditional   layer   with   user   occupation   information .   Experimental   studies   on   the   standard   benchmark   datasets   of   MovieLens   100k   and   MovieLens   1M   have   shown   its   potential   and   advantages   beyond   baseline   methods . ' ,   ' title ' :   ' User   Occupation   Aware   Conditional   Restricted   Boltzmann   Machine   Based   Recommendation ' } 
{ ' abstract ' :   ' Microservices   complement   approaches   like   DevOps   and   continuous   delivery   in   terms   of   software   architecture .   Along   with   this   architectural   style ,   several   important   deployment   technologies ,   such   as   container - based   virtualization   and   container   orchestration   solutions ,   have   emerged .   These   technologies   allow   to   efficiently   exploit   cloud   platforms ,   providing   a   high   degree   of   scalability ,   availability ,   and   portability   for   microservices .# R ## N ## R ## N # Despite   the   obvious   importance   of   a   sufficient   level   of   performance ,   there   is   still   a   lack   of   performance   engineering   approaches   explicitly   taking   into   account   the   particularities   of   microservices .   In   this   paper ,   we   argue   why   new   solutions   to   performance   engineering   for   microservices   are   needed .   Furthermore ,   we   identify   open   issues   and   outline   possible   research   directions   with   regard   to   performance - aware   testing ,   monitoring ,   and   modeling   of   microservices . ' ,   ' title ' :   ' Performance   Engineering   for   Microservices :   Research   Challenges   and   Directions ' } 
{ ' abstract ' :   ' Intelligent   agents ,   such   as   robots ,   have   to   serve   a   multitude   of   autonomous   functions .   Examples   are ,   e . g . ,   collision   avoidance ,   navigation   and   route   planning ,   active   sensing   of   its   environment ,   or   the   interaction   and   non - verbal   communication   with   people   in   the   extended   reach   space .   Here ,   we   focus   on   the   recognition   of   the   action   of   a   human   agent   based   on   a   biologically   inspired   visual   architecture   of   analyzing   articulated   movements .   The   proposed   processing   architecture   builds   upon   coarsely   segregated   streams   of   sensory   processing   along   different   pathways   which   separately   process   form   and   motion   information   ( Layher   et   al . ,   2014 ) .   Action   recognition   is   performed   in   an   event - based   scheme   by   identifying   representations   of   characteristic   pose   configurations   ( key   poses )   in   an   image   sequence .   In   line   with   perceptual   studies ,   key   poses   are   selected   unsupervised   utilizing   a   feature   driven   criterion   which   combines   extrema   in   the   motion   energy   with   the   horizontal   and   the   vertical   extendedness   of   a   body   shape .   Per   class   representations   of   key   pose   frames   are   learned   using   a   deep   convolutional   neural   network   consisting   of   15   convolutional   layers .   The   network   is   trained   using   the   energy - efficient   deep   neuromorphic   networks   ( Eedn )   framework   ( Esser   et   al . ,   2016 ) ,   which   realizes   the   mapping   of   the   trained   synaptic   weights   onto   the   IBM   Neurosynaptic   System   platform   ( Merolla   et   al . ,   2014 ) .   After   the   mapping ,   the   trained   network   achieves   real - time   capabilities   for   processing   input   streams   and   classify   input   images   at   about   1 , 000   frames   per   second   while   the   computational   stages   only   consume   about   70   mW   of   energy   ( without   spike   transduction ) .   Particularly   regarding   mobile   robotic   systems ,   a   low   energy   profile   might   be   crucial   in   a   variety   application   scenarios .   Cross - validation   results   are   reported   for   two   different   datasets   and   compared   to   state - of - the - art   action   recognition   approaches .   The   results   demonstrate ,   that   ( I )   the   presented   approach   is   on   par   with   other   key   pose   based   methods   described   in   the   literature ,   which   select   key   pose   frames   by   optimizing   classification   accuracy ,   ( II )   compared   to   the   training   on   the   full   set   of   frames ,   representations   trained   on   key   pose   frames   result   in   a   higher   confidence   in   class   assignments ,   and   ( III )   key   pose   representations   show   promising   generalization   capabilities   in   a   cross - dataset   evaluation . ' ,   ' title ' :   ' Real - Time   Biologically   Inspired   Action   Recognition   from   Key   Poses   Using   a   Neuromorphic   Architecture ' } 
{ ' abstract ' :   ' Contents   carried   in   an   image   are   valuable   information   sources   for   many   scientific   and   engineering   applications .   However ,   if   the   image   is   captured   under   low   illumination   conditions   a   large   portion   of   the   image   appears   dark   and   this   heavily   degrades   the   image   quality .   In   order   to   solve   this   problem ,   a   restoration   algorithm   is   developed   here   that   transforms   the   low   input   brightness   to   a   higher   value   using   a   logarithmic   mapping   function .   The   mapping   is   further   refined   by   a   linear   weighting   with   the   input   to   reduce   the   un - necessary   amplification   at   regions   with   high   brightness .   Moreover ,   fine   details   in   the   image   are   preserved   by   applying   the   Retinex   principle   to   extract   and   then   re - insert   object   edges .   Results   from   experiments   using   low   and   normal   illumination   images   have   shown   satisfactory   performances   with   regard   to   the   improvement   in   information   contents   and   the   mitigation   of   viewing   artifacts . ' ,   ' title ' :   ' Logarithmic   profile   mapping   and   Retinex   edge   preserving   for   restoration   of   low   illumination   images ' } 
{ ' abstract ' :   ' We   propose   a   principled   approach   for   the   problem   of   aligning   multiple   partially   overlapping   networks .   The   objective   is   to   map   multiple   graphs   into   a   single   graph   while   preserving   vertex   and   edge   similarities .   The   problem   is   inspired   by   the   task   of   integrating   partial   views   of   a   family   tree   ( genealogical   network )   into   one   unified   network ,   but   it   also   has   applications ,   for   example ,   in   social   and   biological   networks .   Our   approach ,   called   Flan ,   introduces   the   idea   of   generalizing   the   facility   location   problem   by   adding   a   non - linear   term   to   capture   edge   similarities   and   to   infer   the   underlying   entity   network .   The   problem   is   solved   using   an   alternating   optimization   procedure   with   a   Lagrangian   relaxation .   Flan   has   the   advantage   of   being   able   to   leverage   prior   information   on   the   number   of   entities ,   so   that   when   this   information   is   available ,   Flan   is   shown   to   work   robustly   without   the   need   to   use   any   ground   truth   data   for   fine - tuning   method   parameters .   Additionally ,   we   present   three   multiple - network   extensions   to   an   existing   state - of - the - art   pairwise   alignment   method   called   Natalie .   Extensive   experiments   on   synthetic ,   as   well   as   real - world   datasets   on   social   networks   and   genealogical   networks ,   attest   to   the   effectiveness   of   the   proposed   approaches   which   clearly   outperform   a   popular   multiple   network   alignment   method   called   IsoRankN . ' ,   ' title ' :   ' Lagrangian   relaxations   for   multiple   network   alignment ' } 
{ ' abstract ' :   ' Heterogeneous   ultra - dense   networks   enable   ultra - high   data   rates   and   ultra - low   latency   through   the   use   of   dense   sub - 6   GHz   and   millimeter   wave   ( mmWave )   small   cells   with   different   antenna   configurations .   Existing   work   has   widely   studied   spectral   and   energy   efficiency   in   such   networks   and   shown   that   high   spectral   and   energy   efficiency   can   be   achieved .   This   article   investigates   the   benefits   of   heterogeneous   ultra - dense   network   architecture   from   the   perspectives   of   three   promising   technologies ,   i . e . ,   physical   layer   security ,   caching ,   and   wireless   energy   harvesting ,   and   provides   enthusiastic   outlook   towards   application   of   these   technologies   in   heterogeneous   ultra - dense   networks .   Based   on   the   rationale   of   each   technology ,   opportunities   and   challenges   are   identified   to   advance   the   research   in   this   emerging   network . ' ,   ' title ' :   ' A   New   Look   at   Physical   Layer   Security ,   Caching ,   and   Wireless   Energy   Harvesting   for   Heterogeneous   Ultra - dense   Networks ' } 
{ ' abstract ' :   ' We   consider   the   problem   of   joint   modeling   of   videos   and   their   corresponding   textual   descriptions   ( e . g .   sentences   or   phrases ) .   Our   approach   consists   of   three   components :   the   video   representation ,   the   textual   representation ,   and   a   joint   model   that   links   videos   and   text .   Our   video   representation   uses   the   state - of - the - art   deep   3D   ConvNet   to   capture   the   semantic   information   in   the   video .   Our   textual   representation   uses   the   recent   advancement   in   learning   word   and   sentence   vectors   from   large   text   corpus .   The   joint   model   is   learned   to   score   the   correct   ( video ,   text )   pairs   higher   than   the   incorrect   ones .   We   demonstrate   our   approach   in   several   applications :   1 )   retrieving   sentences   given   a   video ;   2 )   retrieving   videos   given   a   sentence ;   3 )   zero - shot   action   recognition   in   videos . ' ,   ' title ' :   ' Beyond   verbs :   Understanding   actions   in   videos   with   text ' } 
{ ' abstract ' :   ' This   paper   presents   a   multi - agent   model   for   simulating   attitude   formation   and   change   based   on   perception   and   communication   in   the   context   of   stabilization   operations .   The   originality   of   our   model   comes   from   ( 1 )   attitude   computation   that   evaluates   information   as   part   of   a   history   relative   to   the   individual   ( 2 )   a   notion   of   co - responsibility   for   attitude   attribution .   We   present   a   military   scenario   of   French   operations   in   Afghanistan   along   with   polls   results   about   the   opinion   of   citizen   toward   present   Forces .   Based   on   these   field   data ,   we   calibrate   the   model   and   show   the   resulting   attitude   dynamics .   We   study   the   sensibility   of   the   model   to   the   co - responsibility   factor . ' ,   ' title ' :   ' From   Field   Data   to   Attitude   Formation ' } 
{ ' abstract ' :   ' This   paper   proposes   two   low - complexity   iterative   algorithms   to   compute   the   capacity   of   a   single - user   multiple - input   multiple - output   channel   with   per - antenna   power   constraint .   The   first   method   results   from   manipulating   the   optimality   conditions   of   the   considered   problem   and   applying   fixed - point   iteration .   In   the   second   approach ,   we   transform   the   considered   problem   into   a   minimax   optimization   program   using   the   well - known   MAC -   BC   duality ,   and   then   solve   it   by   a   novel   alternating   optimization   method .   In   both   proposed   iterative   methods ,   each   iteration   involves   an   optimization   problem   which   can   be   efficiently   solved   by   the   water - filling   algorithm .   The   proposed   iterative   methods   are   provably   convergent .   Complexity   analysis   and   extensive   numerical   experiments   are   carried   out   to   demonstrate   the   superior   performance   of   the   proposed   algorithms   over   an   existing   approach   known   as   the   mode - dropping   algorithm . ' ,   ' title ' :   ' Low - complexity   Approaches   for   MIMO   Capacity   with   Per - antenna   Power   Constraint ' } 
{ ' abstract ' :   ' Inventory - Aware   Pathfinding   is   concerned   with   finding   paths   while   taking   into   account   that   picking   up   items ,   e . g . ,   keys ,   allow   the   character   to   unlock   blocked   pathways ,   e . g . ,   locked   doors .   In   this   work   we   present   a   pruning   method   and   a   preprocessing   method   that   can   improve   significantly   the   scalability   of   such   approaches .   We   apply   our   methods   to   the   recent   approach   of   Inventory - Driven   Jump - Point   Search   ( InvJPS ) .   First ,   we   introduce   InvJPS +   that   allows   to   prune   large   parts   of   the   search   space   by   favoring   short   detours   to   pick   up   items ,   offering   a   trade - off   between   efficiency   and   optimality .   Second ,   we   propose   a   preprocessing   step   that   allows   to   decide   on   runtime   which   items ,   e . g . ,   keys ,   are   worth   using   thus   pruning   potentially   unnecessary   items   before   the   search   starts .   We   show   results   for   combinations   of   the   pruning   and   preprocessing   methods   illustrating   the   best   choices   over   various   scenarios . ' ,   ' title ' :   ' Pruning   and   preprocessing   methods   for   inventory - aware   pathfinding ' } 
{ ' abstract ' :   ' This   paper   proposes   a   method   for   proper   names   extraction   from   Myanmar   text   by   using   latent   Dirichlet   allocation   ( LDA ) .   Our   method   aims   to   extract   proper   names   that   provide   important   information   on   the   contents   of   Myanmar   text .   Our   method   consists   of   two   steps .   In   the   first   step ,   we   extract   topic   words   from   Myanmar   news   articles   by   using   LDA .   In   the   second   step ,   we   make   a   post - processing ,   because   the   resulting   topic   words   contain   some   noisy   words .   Our   post - processing ,   first   of   all ,   eliminates   the   topic   words   whose   prefixes   are   Myanmar   digits   and   suffixes   are   noun   and   verb   particles .   We   then   remove   the   duplicate   words   and   discard   the   topic   words   that   are   contained   in   the   existing   dictionary .   Consequently ,   we   obtain   the   words   as   candidate   of   proper   names ,   namely   personal   names ,   geographical   names ,   unique   object   names ,   organization   names ,   single   event   names ,   and   so   on .   The   evaluation   is   performed   both   from   the   subjective   and   quantitative   perspectives .   From   the   subjective   perspective ,   we   compare   the   accuracy   of   proper   names   extracted   by   our   method   with   those   extracted   by   latent   semantic   indexing   ( LSI )   and   rule - based   method .   It   is   shown   that   both   LS ]   and   our   method   can   improve   the   accuracy   of   those   obtained   by   rule - based   method .   However ,   our   method   can   provide   more   interesting   proper   names   than   LSI .   From   the   quantitative   perspective ,   we   use   the   extracted   proper   names   as   additional   features   in   K - means   clustering .   The   experimental   results   show   that   the   document   clusters   given   by   our   method   are   better   than   those   given   by   LSI   and   rule - based   method   in   precision ,   recall   and   F - score . ' ,   ' title ' :   ' Extraction   of   proper   names   from   myanmar   text   using   latent   dirichlet   allocation ' } 
{ ' abstract ' :   ' Large   scale   assessment   of   aboveground   biomass   ( AGB )   in   tropical   forests   is   often   limited   by   the   saturation   of   remote   sensing   signals   at   high   AGB   values .   Fourier   Transform   Textural   Ordination   ( FOTO )   performs   well   in   quantifying   canopy   texture   from   very   high - resolution   ( VHR )   imagery ,   from   which   stand   structure   parameters   can   be   retrieved   with   no   saturation   effect   for   AGB   values   up   to   650   Mg · ha − 1 .   The   method   is   robust   when   tested   on   wet   evergreen   forests   but   is   more   demanding   when   applied   across   different   forest   types   characterized   by   varying   structures   and   allometries .   The   present   study   focuses   on   a   gradient   of   forest   types   ranging   from   dry   deciduous   to   wet   evergreen   forests   in   the   Western   Ghats   ( WG )   of   India ,   where   we   applied   FOTO   to   Cartosat - 1a   images   with   2.5   m   resolution .   Based   on   21   1 - ha   ground   control   forest   plots ,   we   calibrated   independent   texture – AGB   models   for   the   dry   and   wet   zone   forests   in   the   area ,   as   delineated   from   the   distribution   of   NDVI   values   computed   from   LISS - 4   multispectral   images .   This   stratification   largely   improved   the   relationship   between   texture - derived   and   field - derived   AGB   estimates ,   which   exhibited   a   R2   of   0.82   for   a   mean   rRMSE   of   ca .   17% .   By   inverting   the   texture – AGB   models ,   we   finally   mapped   AGB   predictions   at   1.6 - ha   resolution   over   a   heterogeneous   landscape   of   ca .   1500   km2   in   the   WG ,   with   a   mean   relative   per - pixel   propagated   error   < 20%   for   wet   zone   forests ,   i . e . ,   below   the   recommended   IPCC   criteria   for   Monitoring ,   Reporting   and   Verification   ( MRV )   methods .   The   method   proved   to   perform   well   in   predicting   high - resolution   AGB   values   over   heterogeneous   tropical   landscape   encompassing   diversified   forest   types ,   and   thus   presents   a   promising   option   for   affordable   regional   monitoring   systems   of   greenhouse   gas   ( GhG )   emissions   related   to   forest   degradation . ' ,   ' title ' :   ' Inverting   Aboveground   Biomass – Canopy   Texture   Relationships   in   a   Landscape   of   Forest   Mosaic   in   the   Western   Ghats   of   India   Using   Very   High   Resolution   Cartosat   Imagery ' } 
{ ' abstract ' :   ' Self - driving   vehicle   technologies   are   progressing   rapidly   and   are   expected   to   play   a   significant   role   in   the   future   of   transportation .   One   of   the   main   challenges   for   self - driving   vehicles   on   public   roads   is   the   safe   cooperation   and   collaboration   among   multiple   vehicles   using   sensor - based   perception   and   inter - vehicle   communications .   When   self - driving   vehicles   try   to   occupy   the   same   spatial   area   simultaneously ,   they   might   collide   with   one   another ,   might   become   deadlocked ,   or   might   slam   on   the   brakes   making   it   uncomfortable   or   unsafe   for   passengers   in   a   self - driving   vehicle .   In   this   paper ,   we   study   how   a   self - driving   vehicle   can   safely   navigate   merge   points ,   where   two   lanes   with   different   priorities   meet .   We   present   a   safe   protocol   for   merge   points   named   Autonomous   Vehicle   Protocol   for   Merge   Points ,   where   self - driving   vehicles   use   both   vehicular   communications   and   their   own   perception   systems   for   cooperating   with   other   self - driving   and / or   human - driven   vehicles .   Our   simulation   results   show   that   our   traffic   protocol   has   higher   traffic   throughput ,   compared   to   simple   traffic   protocols ,   while   ensuring   safety . ' ,   ' title ' :   ' A   merging   protocol   for   self - driving   vehicles ' } 
{ ' abstract ' :   ' System   Portfolio   Selection   ( SPS )   problem   is   equivalent   to   multi - objective   optimization   problem ,   with   multi - function   requirements   incommensurable .   In   the   paper ,   the   SPS   problem   is   re - specified   with   a   more   practical   formulation ,   comparing   to   general   portfolio   problem .   Then ,   both   feasible   and   non - inferior   solution   is   re - defined   considering   characteristics   of   SPS   problem ,   specifically ,   four   rules   of   system   function   combinations   are   proposed   according   to   practical   cases .   Then ,   the   instability   of   system   performance   is   involved   in   SPS   problem ,   and   the   robust   theory   is   employed   to   solving   the   uncertainty   of   system   function   values   with   definition   of   robust   non - inferior   solution .   Next ,   the   paper   proposes   an   immediately   updating   algorithm   to   solve   the   problem   of   solution   space   exponentially   growing .   Finally ,   a   case   study   is   used   to   demonstrate   the   usefulness   and   effectiveness   of   the   proposed   approaches .   It   shows   that   the   approach   can   provide   an   efficient   guidance   for   decision - makers   in   the   process   of   making   a   SPS . ' ,   ' title ' :   ' Robust   system   portfolio   selection   with   multi - function   requirements   and   system   instability ' } 
{ ' abstract ' :   ' This   study   explores   the   impact   of   high - photovoltaic   ( PV )   penetration   on   the   inter - area   oscillation   modes   of   large - scale   power   grids .   A   series   of   dynamic   models   with   various   PV   penetration   levels   are   developed   based   on   a   detailed   model   representing   the   U . S .   Eastern   Interconnection   ( EI ) .   Transient   simulations   are   performed   to   investigate   the   change   of   inter - area   oscillation   modes   with   PV   penetration .   The   impact   of   PV   control   strategies   and   parameter   settings   on   inter - area   oscillations   is   studied .   This   paper   finds   that   as   PV   increases ,   the   damping   of   the   dominant   oscillation   mode   decreases   monotonically .   It   is   also   observed   that   the   mode   shape   varies   with   the   PV   control   strategy   and   new   oscillation   modes   may   emerge   under   inappropriate   parameter   settings   in   PV   plant   controls . ' ,   ' title ' :   ' Impact   of   High   PV   Penetration   on   the   Inter - Area   Oscillations   in   the   U . S .   Eastern   Interconnection ' } 
{ ' abstract ' :   ' The   objective   of   this   research   is   to   compare   the   effectiveness   of   different   tracking   devices   underwater .   There   have   been   few   works   in   aquatic   virtual   reality   ( VR )   —   i . e . ,   VR   systems   that   can   be   used   in   a   real   underwater   environment .   Moreover ,   the   works   that   have   been   done   have   noted   limitations   on   tracking   accuracy .   Our   initial   test   results   suggest   that   inertial   measurement   units   work   well   underwater   for   orientation   tracking   but   a   different   approach   is   needed   for   position   tracking .   Towards   this   goal ,   we   have   waterproofed   and   evaluated   several   consumer   tracking   systems   intended   for   gaming   to   determine   the   most   effective   approaches .   First ,   we   informally   tested   infrared   systems   and   fiducial   marker   based   systems ,   which   demonstrated   significant   limitations   of   optical   approaches .   Next ,   we   quantitatively   compared   inertial   measurement   units   ( IMU )   and   a   magnetic   tracking   system   both   above   water   ( as   a   baseline )   and   underwater .   By   comparing   the   devices   rotation   data ,   we   have   discovered   that   the   magnetic   tracking   system   implemented   by   the   Razer   Hydra   is   more   accurate   underwater   as   compared   to   a   phone - based   IMU .   This   suggests   that   magnetic   tracking   systems   should   be   further   explored   for   underwater   VR   applications . ' ,   ' title ' :   ' Towards   usable   underwater   virtual   reality   systems ' } 
{ ' abstract ' :   ' A   faulty   network   GG   is   under   the   conditional   fault   model ,   i . e . , \ xa0every   fault - free   vertex   of   GG   is   incident   to   at   least   two   fault - free   edges .   Let   FFvFFv   and   FFeFFe   be   the   set   of   faulty   vertices   and   faulty   edges   in   FQnFQn ,   respectively .   In   this   paper ,   we   consider   FQnFQn   under   the   conditional   fault   model   and   prove   that   if   | FFv | + | FFe | ≤ 2n − 4 | FFv | + | FFe | ≤ 2n − 4   and   n ≥ 3n ≥ 3 ,   then   FQn − FFv − FFeFQn − FFv − FFe   contains   a   fault - free   cycle   of   every   even   length   from   4   to   2n − 2 | FFv | 2n − 2 | FFv | ;   if   | FFv | + | FFe | ≤ 2n − 5 | FFv | + | FFe | ≤ 2n − 5   and   n ≥ 4n ≥ 4   is   even ,   then   FQn − FFv − FFeFQn − FFv − FFe   contains   a   fault - free   cycle   of   every   odd   length   from   n + 1n + 1   to   2n − 2 | FFv | − 12n − 2 | FFv | − 1 . ' ,   ' title ' :   ' Cycles   embedding   in   folded   hypercubes   under   the   conditional   fault   model ' } 
{ ' abstract ' :   ' Companies   have   invested   considerable   resources   in   the   implementation   of   enterprise   resource   planning   ( ERP )   systems .   The   results   initially   expected   have   rarely   been   reached .   The   optimisation   ( or   efficient   use )   of   such   information   systems   is   nowadays   becoming   a   major   factor   for   firms   striving   to   reach   their   performance   objectives .   After   presenting   a   synthesis   of   several   studies   on   ERP   projects ,   we   build   on   the   findings   of   a   French   investigation   into   the   assessment   and   optimisation   of   ERP   performance .   A   classification   of   company   positions   regarding   their   ERP   use ,   based   on   both   software   maturity   and   strategic   deployment   directions ,   and   an   improvement   process   are   proposed .   Industrial   cases   allow   validation   of   this   approach . ' ,   ' title ' :   ' A   classification   for   better   use   of   ERP   systems ' } 
{ ' abstract ' :   ' This   paper   presents   a   time - domain   biosensor   array   that   uses   a   capacitor - less   current - mode   analog - to - time   converter   ( CMATC )   and   logarithmic   cyclic   time - attenuation - based   TDC   with   discharging   acceleration .   Combining   the   exponential   function   of   the   CMATC   and   logarithmic   function   of   the   proposed   TDC   offers   linear   input - output   characteristics .   The   time - domain   property   enables   bio - imaging   at   a   high   spatial   resolution   and   large   scale   while   maintaining   scalability .   Measurement   results   with   a   0.25 - μ m   test   chip   successfully   demonstrated   linear   input - output   characteristics . ' ,   ' title ' :   ' A   scalable   time - domain   biosensor   array   using   logarithmic   cyclic   time - attenuation - based   TDC   for   high - resolution   and   large - scale   bio - imaging ' } 
{ ' abstract ' :   ' Compared   to   current   mobile   networks ,   next - generation   mobile   networks   are   expected   to   support   higher   numbers   of   simultaneously   connected   devices   and   to   achieve   higher   system   spectrum   efficiency   and   lower   power   consumption .   To   achieve   these   goals ,   we   study   the   multi - sharing   device - to - device   ( D2D )   communication ,   which   allows   any   cellular   user   equipment   to   share   its   radio   resource   with   multiple   D2D   devices .   We   jointly   consider   resource   block   reuse   and   power   control   and   then   develop   the   MISS   algorithm .   Simulation   results   show   that   MISS   performs   very   well   in   terms   of   transmission   power   consumption ,   system   throughput ,   and   the   number   of   permitted   D2D   devices . ' ,   ' title ' :   ' Joint   Resource   Block   Reuse   and   Power   Control   for   Multi - Sharing   Device - to - Device   Communication ' } 
{ ' abstract ' :   ' This   paper   is   concerned   with   event - triggered   H ∞ H ∞   filtering   for   delayed   neural   networks   via   sampled   data .   A   novel   event - triggered   scheme   is   proposed ,   which   can   lead   to   a   significant   reduction   of   the   information   communication   burden   in   the   network ;   the   feature   of   this   scheme   is   that   whether   or   not   the   sampled   data   should   be   transmitted   is   determined   by   the   current   sampled   data   and   the   error   between   the   current   sampled   data   and   the   latest   transmitted   data .   By   constructing   a   proper   Lyapunov – Krasovskii   functional ,   utilizing   the   reciprocally   convex   combination   technique   and   Jensen ’ s   inequality   sufficient   conditions   are   derived   to   ensure   that   the   resultant   filtering   error   system   is   asymptotically   stable .   Based   on   the   derived   H ∞ H ∞   performance   analysis   results ,   the   H ∞ H ∞   filter   design   is   formulated   in   terms   of   Linear   Matrix   Inequalities   ( LMIs ) .   Finally ,   the   proposed   stability   conditions   are   demonstrated   with   numerical   example . ' ,   ' title ' :   ' Event - triggered   H   ∞   filtering   for   delayed   neural   networks   via   sampled - data ' } 
{ ' abstract ' :   ' For   the   double   integrator   with   matched   Lipschitz   disturbances   we   propose   a   continuous   homogeneous   controller   providing   finite - time   stability   of   the   origin .   The   disturbance   is   compensated   exactly   in   finite   time   using   a   discontinuous   function   through   an   integral   action .   Since   the   controller   is   dynamic ,   the   closed   loop   is   a   third   order   system   that   achieves   a   third   order   sliding   mode   in   the   steady   state .   The   stability   and   robustness   properties   of   the   controller   are   proven   using   a   smooth   and   homogeneous   strict   Lyapunov   function   ( LF ) .   In   a   first   stage ,   the   gains   of   the   controller   and   the   LF   are   designed   using   a   method   based   on   Polya ’ s   Theorem .   In   a   second   stage   the   controller ’ s   gains   are   adjusted   through   a   sum   of   squares   representation   of   the   LF . ' ,   ' title ' :   ' Design   of   Continuous   Twisting   Algorithm ' } 
{ ' abstract ' :   ' Big   data   is   now   rapidly   expanding   into   various   domains   such   as   banking ,   insurance   and   e - commerce .   Data   analysis   and   related   studies   have   attracted   more   attentions .   In   health   insurance ,   abuse   of   diagnosis   is   one   of   the   key   fraud   problems ,   which   damages   the   interests   of   insured   people .   To   address   this   issue ,   numbers   of   studies   have   focused   on   this   topic .   This   paper   develops   a   healthcare   fraud   detection   approach   based   on   the   trustworthiness   of   doctors   to   distinguish   fraud   cases   from   normal   records .   Compared   to   conventional   methods ,   our   approach   can   detect   healthcare   fraud   in   a   good   accuracy   by   only   little   feature   information   from   healthcare   data   without   the   violation   of   privacy .   This   approach   combines   a   weighted   HITS   algorithm   with   a   frequent   pattern   mining   algorithm   to   calculate   a   rational   treatment   model   of   a   certain   disease .   In   addition ,   this   paper   also   introduces   the   copy   precision   behavior   in   the   treatment   sequences   of   patients ,   which   is   a   critical   metric   to   learn   the   trustworthiness   of   doctors .   The   numerical   validation   with   a   healthcare   dataset   demonstrates   that   healthcare   fraud   by   misdiagnosis   in   healthcare   treatments   can   be   successfully   detected   by   employing   the   developed   fraud   detection   approach . ' ,   ' title ' :   ' Healthcare   Fraud   Detection   Based   on   Trustworthiness   of   Doctors ' } 
{ ' abstract ' :   ' In   this   paper   we   study   data   collection   in   an   energy   renewable   sensor   network   for   scenarios   such   as   traffic   monitoring   on   busy   highways ,   where   sensors   are   deployed   along   a   predefined   path   ( the   highway )   and   a   mobile   sink   travels   along   the   path   to   collect   data   from   one - hop   sensors   periodically .   As   sensors   are   powered   by   renewable   energy   sources ,   time - varying   characteristics   of   ambient   energy   sources   poses   great   challenges   in   the   design   of   efficient   routing   protocols   for   data   collection   in   such   networks .   In   this   paper   we   first   formulate   a   novel   data   collection   maximization   problem   by   adopting   multi - rate   data   transmissions   and   performing   transmission   time   slot   scheduling ,   and   show   that   the   problem   is   NP - hard .   We   then   devise   an   offline   algorithm   with   a   provable   approximation   ratio   for   the   problem   by   exploiting   the   combinatorial   property   of   the   problem ,   assuming   that   the   harvested   energy   at   each   node   is   given   and   link   communications   in   the   network   are   reliable .   We   also   extend   the   proposed   algorithm   by   minor   modifications   to   a   general   case   of   the   problem   where   the   harvested   energy   at   each   sensor   is   not   known   in   advance   and   link   communications   are   not   reliable .   We   thirdly   develop   a   fast ,   scalable   online   distributed   algorithm   for   the   problem   in   realistic   sensor   networks   in   which   neither   the   global   knowledge   of   the   network   topology   nor   sensor   profiles   such   as   sensor   locations   and   their   harvested   energy   profiles   is   given .   Furthermore ,   we   also   consider   a   special   case   of   the   problem   where   each   node   has   only   a   fixed   transmission   power ,   for   which   we   propose   an   exact   solution   to   the   problem .   We   finally   conduct   extensive   experiments   by   simulations   to   evaluate   the   performance   of   the   proposed   algorithms .   Experimental   results   demonstrate   that   the   proposed   algorithms   are   efficient   and   the   solutions   obtained   are   fractional   of   the   optimum . ' ,   ' title ' :   ' Data   Collection   Maximization   in   Renewable   Sensor   Networks   via   Time - Slot   Scheduling ' } 
{ ' abstract ' :   ' An   increasing   number   of   businesses   are   migrating   their   IT   operations   to   the   cloud .   Likewise   there   is   an   increased   emphasis   on   data   analytics   based   on   multiple   datasets   and   sources   to   derive   information   not   derivable   when   a   dataset   is   mined   in   isolation .   While   ensuring   security   of   data   and   computation   outsourced   to   a   third   party   cloud   service   provider   is   in   itself   challenging ,   supporting   mash - ups   and   analytics   of   data   from   different   parties   hosted   across   different   services   is   even   more   so .   In   this   paper   we   propose   a   cloud - based   service   allowing   multiple   parties   to   perform   secure   multi - party   secure   sum   computation   using   their   clouds   as   delegates .   Our   scheme   provides   data   privacy   both   from   the   delegates   as   well   as   from   the   other   data   owners   under   a   lazy - and - curious   adversary   ( semi - honest )   model .   We   then   describe   how   such   a   secure   sum   primitive   may   be   used   in   various   collaborative ,   cloud - based   distributed   data   mining   tasks   ( classification ,   association   rule   mining   and   clustering ) .   We   implement   a   prototype   and   benchmark   the   service ,   both   as   a   stand - alone   secure   sum   service ,   and   as   a   building   block   for   more   complex   analytics .   The   results   suggest   reasonable   overhead   and   demonstrate   the   practicality   of   carrying   out   privacy   preserved   distributed   analytics   despite   migrating   ( encrypted )   data   to   pos -   sibly   different   and   untrusted   ( semi - honest )   cloud   services . ' ,   ' title ' :   ' Delegated   Secure   Sum   Service   for   Distributed   Data   Mining   in   Multi - Cloud   Settings ' } 
{ ' abstract ' :   ' This   paper   fundamentally   investigates   the   performance   of   evolutionary   multiobjective   optimization   ( EMO )   algorithms   for   computationally   hard   0 - 1   combinatorial   optimization ,   where   a   strict   theoretical   analysis   is   generally   out   of   reach   due   to   the   high   complexity   of   the   underlying   problem .   Based   on   the   examination   of   problem   features   from   a   multiobjective   perspective ,   we   improve   the   understanding   of   the   efficiency   of   a   simple   dominance - based   EMO   algorithm   with   unbounded   archive   for   multiobjective   NK - landscapes   with   correlated   objective   values .   More   particularly ,   we   adopt   a   statistical   approach ,   based   on   simple   and   multiple   linear   regression   analysis ,   to   enquire   the   expected   running   time   of   global   SEMO   with   restart   for   identifying   a   ( 1 + e ) - approximation   of   the   Pareto   set   for   small - size   enumerable   instances .   Our   analysis   provides   further   insights   on   the   EMO   search   behavior   and   on   the   most   important   features   that   characterize   the   difficulty   of   an   instance   for   this   class   of   problems   and   algorithms . ' ,   ' title ' :   ' A   feature - based   performance   analysis   in   evolutionary   multiobjective   optimization ' } 
{ ' abstract ' :   ' Functional   biological   sequences ,   which   typically   come   in   families ,   have   retained   some   level   of   similarity   and   function   during   evolution .   Finding   consensus   regions ,   alignment   of   sequences ,   and   identifying   the   relationship   between   a   sequence   and   a   family   allow   inferences   about   the   function   of   the   sequences .   Profile   hidden   Markov   models   ( HMMs )   are   generally   used   to   identify   those   relationships .   A   profile   HMM   can   be   trained   on   unaligned   members   of   the   family   using   conventional   algorithms   such   as   Baum - Welch ,   Viterbi ,   and   their   modifications .   The   overall   quality   of   the   alignment   depends   on   the   quality   of   the   trained   model .   Unfortunately ,   the   conventional   training   algorithms   converge   to   suboptimal   models   most   of   the   time .   This   work   proposes   a   training   algorithm   that   early   identifies   many   imperfect   models .   The   method   is   based   on   the   Simulated   Annealing   approach   widely   used   in   discrete   optimization   problems .   The   training   algorithm   is   implemented   as   a   component   in   HMMER .   The   performance   of   the   algorithm   is   discussed   on   protein   sequence   data . ' ,   ' title ' :   ' Simulated   annealing   algorithm   with   biased   neighborhood   distribution   for   training   profile   models ' } 
{ ' abstract ' :   ' The   Canny   algorithm   is   a   well   known   edge   detector   that   is   widely   used   in   the   previous   processing   stages   in   several   algorithms   related   to   computer   vision .   An   alternative ,   the   LIP - Canny   algorithm ,   is   based   on   a   robust   mathematical   model   closer   to   the   human   vision   system ,   obtaining   better   results   in   terms   of   edge   detection .   In   this   work   we   describe   LIP - Canny   algorithm   under   the   perspective   from   its   parallelization   and   optimization   by   using   the   NVIDIA   CUDA   framework .   Furthermore ,   we   present   comparative   results   between   an   implementation   of   this   algorithm   using   NVIDIA   CUDA   and   the   analogue   using   a   C / C++   approach . ' ,   ' title ' :   ' Parallelizing   and   optimizing   LIP - canny   using   NVIDIA   CUDA ' } 
{ ' abstract ' :   ' This   paper   presents   an   efficient   Bayesian   blind   multiuser   receiver   for   long   code   multipath   CDMA   systems .   The   proposed   receiver   employs   the   adaptive   sampling   method   for   the   Bayesian   inference   procedure   to   estimate   the   data   symbols   and   multipath   parameters .   Compared   to   the   other   reported   Bayesian   Monte   Carlo   receivers   for   long   code   multipath   CDMA   systems ,   the   proposed   one   achieves   a   faster   convergence   and   a   lower   computational   complexity   to   attain   comparable   performance .   Simulation   results   are   presented   to   demonstrate   the   effectiveness   of   the   proposed   Bayesian   blind   multiuser   receiver . ' ,   ' title ' :   ' Blind   Multiuser   Detection   for   Long   Code   Multipath   DS - CDMA   Systems   with   Bayesian   MC   Techniques ' } 
{ ' abstract ' :   ' Spreadsheets   are   by   far   the   most   prominent   example   of   end - user   programs   of   ample   size   and   substantial   structural   complexity .   In   addition ,   spreadsheets   are   usually   not   tested   very   rigorously   and   thus   comprise   faults .   Locating   faults   is   a   hard   task   due   to   the   size   and   the   structure ,   which   is   usually   not   directly   visible   to   the   user ,   i . e . ,   the   functions   are   hidden   behind   the   cells   and   only   the   computed   values   are   presented .   Hence ,   there   is   a   strong   need   for   debugging   support .   In   this   paper ,   we   adapt   three   program - debugging   approaches   that   have   been   designed   for   more   traditional   procedural   or   object - oriented   programming   languages .   These   techniques   are   Spectrum - based   Fault   Localization ,   Spectrum - Enhanced   Dynamic   Slicing ,   and   Constraint - based   Debugging .   Beside   the   theoretical   foundations ,   we   present   a   more   sophisticated   empirical   evaluation   including   a   comparison   of   these   approaches .   The   empirical   evaluation   shows   that   Sfl   ( Spectrum - based   Fault   Localization )   and   Sendys   ( Spectrum   ENhanced   Dynamic   Slicing )   are   the   most   promising   techniques . ' ,   ' title ' :   ' On   the   empirical   evaluation   of   fault   localization   techniques   for   spreadsheets ' } 
{ ' abstract ' :   ' This   work   provides   elements   to   highlight   the   reliability   challenges   related   to   the   technology   scaling   and   the   BTI   variability .   Through   main   milestones   including   device   reliability   scaling   model   ( for   both   mean   and   spread ) ,   a   discussion   on   the   physical   origin   of   BTI   variability   and   a   digital   IP   failure   rate   analytical   model ,   the   evolution   of   digital   IP   failure   rates   along   the   ITRS   scaling   roadmap   is   assessed .   and   an   analysis   of   the   ITRS   roadmap   on   digital   IP   failure   rates .   This   study   offers   new   perspectives   towards   product   hardening   and   qualification   with   respect   to   both   fresh   and   BTI - related   local   variability ,   especially   in   context   where   Adaptive   Voltage   Scaling   ( AVS )   is   used   to   compensate   for   process   centerings . ' ,   ' title ' :   ' From   BTI   variability   to   product   failure   rate :   A   technology   scaling   perspective ' } 
{ ' abstract ' :   ' In   this   paper   we   discuss   the   problem   of   calculating   the   reachable   states   of   a   dynamical   system   defined   by   ordinary   differential   equations   or   inclusions .   We   present   a   prototype   system   for   approximating   this   set   and   demonstrate   some   experimental   results . ' ,   ' title ' :   ' Reachability   Analysis   via   Face   Lifting ' } 
{ ' abstract ' :   ' By   introducing   the   new   concepts   of   fuzzy     β   - covering   and   fuzzy     β   - neighborhood ,   we   define   two   new   types   of   fuzzy   covering   rough   set   models   which   can   be   regarded   as   bridges   linking   covering   rough   set   theory   and   fuzzy   rough   set   theory .   We   show   the   properties   of   the   two   models ,   and   reveal   the   relationships   between   the   two   models   and   some   others .   Moreover ,   we   present   the   matrix   representations   of   the   newly   defined   lower   and   upper   approximation   operators   so   that   the   calculation   of   lower   and   upper   approximations   of   subsets   can   be   converted   into   operations   on   matrices .   Finally ,   we   generalize   the   models   and   their   matrix   representations   to     L   - fuzzy   covering   rough   sets   which   are   defined   over   fuzzy   lattices . ' ,   ' title ' :   ' Two   fuzzy   covering   rough   set   models   and   their   generalizations   over   fuzzy   lattices ' } 
{ ' abstract ' :   ' Mobile   applications   are   becoming   complex   software   systems   that   must   be   developed   quickly   and   evolve   regularly   to   fit   new   user   requirements   and   execution   contexts .   However ,   addressing   these   constraints   may   result   in   poor   design   choices ,   known   as   antipatterns ,   which   may   degrade   software   quality   and   performance .   Thus ,   the   automatic   detection   of   antipatterns   is   an   important   activity   that   eases   the   future   maintenance   and   evolution   tasks .   Moreover ,   it   helps   developers   to   refactor   their   applications   and   thus ,   to   improve   their   quality .   While   antipatterns   are   well - known   in   object - oriented   applications ,   their   study   in   mobile   applications   is   still   in   their   infancy .   In   this   paper ,   we   presents   a   tooled   approach ,   called   P   aprika   ,   to   analyze   Android   applications   and   to   detect   object - oriented   and   Android - specific   antipatterns   from   binaries   of   applications . ' ,   ' title ' :   ' An   approach   to   detect   Android   antipatterns ' } 
{ ' abstract ' :   ' In   this   paper   we   present   a   new   method   for   object   categorization .   Firstly   an   image   representation   is   obtained   by   the   proposed   hierarchical   learning   method   consisting   of   alternating   between   local   coding   and   maximum   pooling   operations ,   where   the   local   coding   operation   induces   discrimination   while   the   image   descriptor   and   maximum   pooling   operation   induces   invariance   in   hierarchical   architecture .   Then   the   obtained   effective   image   representation   is   passed   to   a   linear   classifier   which   is   suitable   for   large   databases   for   object   categorization .   We   have   demonstrated   that   the   proposed   method   is   robust   to   image   variations   and   has   low   sample   complexity . ' ,   ' title ' :   ' Object   categorization   based   on   hierarchical   learning ' } 
{ ' abstract ' :   ' We   have   previously   proposed   a   howling   canceller   which   cancels   howling   by   using   a   cascade   notch   filter   designed   from   a   distance   between   a   loudspeaker   and   a   microphone .   This   method   utilizes   a   pilot   signal   to   estimate   the   distance .   In   this   paper ,   we   introduce   two   methods   into   the   distance - based   howling   canceller   to   improve   speech   quality .   The   first   one   is   an   adaptive   cascade   notch   filter   which   adaptively   adjusts   the   nulls   to   eliminate   howling   and   to   keep   speech   components .   The   second   one   is   a   silent   pilot   signal   whose   frequencies   exist   in   the   ultrasonic   band ,   and   it   is   inaudible   while   on   transmission .   We   implement   the   proposed   howling   canceller   on   a   DSP   to   evaluate   its   capability .   The   experimental   results   show   that   the   proposed   howling   canceller   improves   speech   quality   in   comparison   to   the   conventional   one . ' ,   ' title ' :   ' A   High   Speech   Quality   Distance - Based   Howling   Canceller   with   Adaptive   Cascade   Notch   Filter   and   Silent   Pilot   Signal ' } 
{ ' abstract ' :   ' Purpose   –   This   paper   aims   to   look   at   how   varying   terminology   is   used   on   school   library   web   sites   and   how   that   compares   to   student   preferences . Design / methodology / approach   –   Provides   research   conduced   by   surveying   practicing   school   librarians   and   k ‐ 12   students . Findings   –   Terminology   varies   greatly   on   school   library   web   sites .   Further ,   students   prefer   common   language   use . Practical   implications   –   Practicing   librarians   may   consider   revising   their   web   sites   in   order   to   make   them   more   accessible   for   their   students . Originality / value   –   This   paper   provides   original   research   into   school   library   web   sites ,   an   area   that   is   lacking . ' ,   ' title ' :   ' School   library   web   site   terminology ' } 
{ ' abstract ' :   ' Recently ,   numerous   multireceiver   identity - based   encryption   or   identity - based   broadcast   encryption   schemes   have   been   introduced   with   bilinear   pairing   and   probabilistic   map - to - point   MTP   function .   As   the   bilinear   pairing   and   MTP   functions   are   expensive   operations ,   any   cryptographic   schemes   based   on   these   operations   experience   high   computational   burden .   The   certificateless   public   key   cryptography   sidesteps   the   private   key   escrow   problem   occurring   in   identity - based   cryptosystem   and   certificate   management   troubles   of   certificate   authority - based   public   key   cryptography   CA - PKC .   We   observed   that   certificateless   multireceiver   encryption   CL - MRE   scheme   without   pairing   and   MTP   hash   function   has   not   yet   been   considered   in   the   literature .   In   this   paper ,   we   proposed   a   bilinear   pairing   and   MTP   hash - function - free   CL - MRE   scheme   with   chosen   ciphertext   attack   resilience .   The   detailed   analyses   provide   evidence   that   our   scheme   achieves   forward   secrecy ,   backward   secrecy ,   and   low   computation   costs   than   others .   The   scheme   also   provides   confidentiality   of   the   message   and   receiver   anonymity   in   the   random   oracle   model   with   the   hardness   of   computational   Diffie - Hellman   problem .   Copyright   ©   2014   John   Wiley   &   Sons ,   Ltd . ' ,   ' title ' :   ' Anonymous   and   provably   secure   certificateless   multireceiver   encryption   without   bilinear   pairing ' } 
{ ' abstract ' :   ' We   study   the   problem   of   approximating   one - dimensional   nonintegrable   codistributions   by   integrable   ones   and   apply   the   resulting   approximations   to   approximate   feedback   linearization   of   single - input   systems .   The   approach   derived   in   this   paper   allows   a   linearizable   nonlinear   system   to   be   found   that   is   close   to   the   given   system   in   a   least - squares   ( L2 )   sense .   A   linearly   controllable   single - input   affine   nonlinear   system   is   feedback   linearizable   if   and   only   if   its   characteristic   distribution   is   involutive   ( hence   integrable )   or ,   equivalently ,   any   characteristic   one - form   ( a   one - form   that   annihilates   the   characteristic   distribution )   is   integrable .   We   study   the   problem   of   finding   ( least - squares   approximate )   integrating   factors   that   make   a   fixed   characteristic   one - form   close   to   being   exact   in   anL2   sense .   A   given   one - form   can   be   decomposed   into   exact   and   inexact   parts   using   the   Hodge   decomposition .   We   derive   an   upper   bound   on   the   size   of   the   inexact   part   of   a   scaled   characteristic   one - form   and   show   that   a   least - squares   integrating   factor   provides   the   minimum   value   for   this   upper   bound .   We   also   consider   higher - order   approximate   integrating   factors   that   scale   a   nonintegrable   one - form   in   a   way   that   the   scaled   form   is   closer   to   being   integrable   inL2   together   with   some   derivatives   and   derive   similar   bounds   for   the   inexact   part .   This   allows   a   linearizable   nonlinear   system   that   is   close   to   the   given   system   in   a   least - squares   ( L2 )   sense   together   with   some   derivatives   to   be   found .   The   Sobolev   embedding   techniques   allow   us   to   obtain   an   upper   bound   on   the   uniform   ( L ∞ )   distance   between   the   nonlinear   system   and   its   linearizable   approximation . ' ,   ' title ' :   ' Least - squares   integration   of   one - dimensional   codistributions   with   application   to   approximate   feedback   linearization ' } 
{ ' abstract ' :   ' Latent   sector   errors   in   disk   drives   affect   only   a   few   data   sectors .   They   occur   silently   and   are   detected   only   when   the   affected   area   is   accessed   again .   If   a   latent   error   is   detected   while   the   storage   system   is   operating   under   reduced   redundancy ,   i . e . ,   during   a   RAID   rebuild ,   then   data   loss   may   occur .   Various   features   such   as   scrubbing   and   intra - disk   data   redundancy   are   proposed   to   detect   and / or   recover   from   latent   errors   and   avoid   data   loss .   While   such   features   enhance   data   availability   in   the   storage   system ,   their   execution   may   cause   performance   degradation .   In   this   paper ,   we   evaluate   the   effectiveness   of   scrubbing   and   intra - disk   data   redundancy   in   improving   data   availability   while   the   overall   goal   is   to   maintain   user   performance   within   predefined   bounds .   We   show   that   by   treating   them   as   low   priority   background   activities   and   scheduling   them   efficiently   during   idle   times ,   these   features   remain   performance - wise   transparent   to   the   storage   system   user   while   still   improving   data   reliability .   Detailed   trace - driven   simulations   show   that   the   mean   time   to   data   loss   ( MTTDL )   improves   by   up   to   5   orders   of   magnitude   if   these   features   are   implemented   independently .   By   scheduling   concurrently   both   scrubbing   and   intra - disk   parity   updates   during   idle   times   in   disk   drives ,   MTTDL   improves   by   as   much   as   8   orders   of   magnitude . ' ,   ' title ' :   ' Enhancing   data   availability   in   disk   drives   through   background   activities ' } 
{ ' abstract ' :   ' Financial   crisis   forecasting   has   been   a   long - standing   challenge   that   often   involves   couplings   between   indicators   of   multiple   markets .   Such   couplings   include   implicit   relations   that   might   not   be   effectively   detected   from   raw   market   observations .   However ,   most   methods   for   crisis   forecasting   rely   directly   on   market   observations   and   might   not   detect   the   hidden   interactions   between   markets .   To   this   end ,   the   authors   explore   coupled   market   state   analysis   ( CMSA ) ,   assuming   that   the   observations   of   markets   are   governed   by   a   collection   of   intra -   and   intercoupled   hidden   market   states .   Accordingly ,   they   built   a   forecaster   based   on   these   coupled   market   states   instead   of   observations . ' ,   ' title ' :   ' Financial   Crisis   Forecasting   via   Coupled   Market   State   Analysis ' } 
{ ' abstract ' :   ' In   this   paper ,   an   “ intelligent ”   isolated   intersection   control   system   was   developed .   The   developed   “ intelligent ”   system   makes   “ real   time ”   decisions   as   to   whether   to   extend   ( and   how   much )   current   green   time .   The   model   developed   is   based   on   the   combination   of   the   dynamic   programming   and   neural   networks .   Many   tests   show   that   the   outcome   ( the   extension   of   the   green   time )   of   the   proposed   neural   network   is   nearly   equal   to   the   best   solution .   Practically   negligible   CPU   times   were   achieved ,   and   were   thus   absolutely   acceptable   for   the   “ real   time ”   application   of   the   developed   algorithm . ' ,   ' title ' :   ' Dynamic   programming — neural   network   real - time   traffic   adaptive   signal   control   algorithm ' } 
{ ' abstract ' :   ' This   issue   features   expanded   versions   of   articles   selected   from   the   2014   AAAI   Conference   on   Innovative   Applications   of   Artificial   Intelligence   held   in   Quebec   City ,   Canada .   We   present   a   selection   of   four   articles   describing   deployed   applications   plus   two   more   articles   that   discuss   work   on   emerging   applications . ' ,   ' title ' :   ' Introduction   to   the   Special   Issue   on   Innovative   Applications   of   Artificial   Intelligence   2014 ' } 
{ ' abstract ' :   ' Although   frequently   used   in   fractal   compression   quadrant - based   classification   exhibits   a   significant   defect   which   has   not   been   described   in   the   literature .   We   give   an   efficient   solution   to   this   problem   by   controlling   the   class   structure   based   on   an   adaptive   threshold .   This   makes   this   classification   technique   a   very   efficient   and   competitive   one   also   for   block   matching   motion   compensation   algorithms   in   video   coding . ' ,   ' title ' :   ' Resolving   a   defect   in   quadrant - based   classification   for   fast   block - matching ' } 
{ ' abstract ' :   ' Where   there   are   infinitely   many   possible   basic   states   of   the   world ,   a   standard   probability   function   must   assign   zero   probability   to   each   state   –   since   any   finite   probability   would   sum   to   over   one .   This   generates   problems   for   any   decision   theory   that   appeals   to   expected   utility   or   related   notions .   For   it   leads   to   the   view   that   a   situation   in   which   one   wins   a   million   dollars   if   any   of   a   thousand   of   the   equally   probable   states   is   realized   has   an   expected   value   of   zero   ( since   each   such   state   has   probability   zero ) .   But   such   a   situation   dominates   the   situation   in   which   one   wins   nothing   no   matter   what   ( which   also   has   an   expected   value   of   zero ) ,   and   so   surely   is   more   desirable .   I   formulate   and   defend   some   principles   for   evaluating   options   where   standard   probability   functions   cannot   strictly   represent   probability   –   and   in   particular   for   where   there   is   an   infinitely   spread ,   uniform   distribution   of   probability .   The   principles   appeal   to   standard   probability   functions ,   but   overcome   at   least   some   of   their   limitations   in   such   cases . ' ,   ' title ' :   ' Standard   decision   theory   corrected ' } 
{ ' abstract ' :   ' Backed   by   the   European   Commission ,   a   consortium   of   partners   from   European   industry ,   financial   institutions ,   and   academia   has   embarked   on   a   research   project   to   develop   the   fundamentals   of   secure   electronic   commerce .   The   goal   of   the   9 - million   ECU   project ,   SEMPER   ( Secure   Electronic   Marketplace   for   Europe ) ,   is   to   provide   the   first   open   and   comprehensive   solutions   for   secure   commerce   over   the   Internet   and   other   public   information   networks .   We   describe   the   objectives   and   summarise   the   initial   architecture   of   SEMPER .   A   wide   range   of   businesses   are   rapidly   moving   to   explore   the   huge   potential   of   net -   worked   information   systems ,   especially   with   the   Internet - based   WWW   ( World - wide   Web ) .   The   Internet ,   which   already   connects   more   than   3   million   computers   and   a   sub -   stantially   larger   number   of   users ,   is   growing   at   a   breathtaking   pace   with   thousands   of   newcomers   every   day .   Although   the   Internet   has   its   roots   in   academia   and   is   still   domi -   nated   by   free - of - charge   information ,   dramatic   changes   are   expected   in   the   near   future .   For   instance ,   the   WWW   will   be   used   for   a   wide   variety   of   electronic   commerce   such   as   on - line   trade   or   delivery   of   advanced   multimedia   information   services .   The   evolution   of   broadband   networks   and   " information   highways "   will   intensify   this   trend .   The   need   for   secure   transactions   in   this   new   business   environment ,   which   involves   networks   available   to   the   general   public ,   has   triggered   a   number   of   related   efforts .   These   initial   developments   are   based   almost   exclusively   in   the   US   and   most   of   them   are   limited   to   proprietary ,   or   otherwise   closed   solutions ,   involving   only   electronic   payment   issues .   In   contrast ,   SEMPER   is   directed   towards   a   comprehensive   solution   for   secure   electronic   commerce ,   considering   legal ,   commercial ,   social ,   and   technical   requirements   as   well   as   different   options   for   an   electronic   marketplace . ' ,   ' title ' :   ' Development   of   a   Secure   Electronic   Marketplace   for   Europe ' } 
{ ' abstract ' :   ' Through   the   use   of   a   global   geometric   symmetry ,   detection   ellipses   are   proposed   in   this   paper .   Based   on   the   geometric   symmetry ,   the   proposed   method   first   locates   candidates   of   ellipses   centers .   In   the   meantime ,   according   to   these   candidate   centers ,   all   feature   points   in   an   input   image   are   grouped   into   several   subimages .   Then ,   for   each   subimage ,   by   using   geometric   properties   again ,   all   ellipses   are   extracted .   The   method   significantly   reduces   the   time   required   to   evaluate   all   possible   parameters   without   using   edge   direction   information .   Experimental   results   are   given   to   show   the   correctness   and   effectiveness   of   the   proposed   method . ' ,   ' title ' :   ' Detection   ellipses   by   finding   lines   of   symmetry   in   the   images   via   an   hough   transform   applied   to   straight   lines ' } 
{ ' abstract ' :   ' Automatic   crawling   of   Rich   Internet   Applications   ( RIAs )   is   a   challenge   because   client - side   code   modifies   the   client   dynamically ,   fetch -   ing   server - side   data   asynchronously .   Most   existing   solutions   model   RIAs   as   state   machines   with   DOMs   as   states   and   JavaScript   events   execution   as   transitions .   This   approach   fails   when   used   with   " real - life " ,   complex   RIAs ,   because   the   size   of   the   produced   model   is   much   too   large   to   be   practical .   In   this   paper ,   we   propose   a   new   method   to   crawl   AJAX - based   RIAs   in   an   efficient   manner   by   detecting   " components " ,   which   are   areas   of   the   DOM   that   are   independent   from   each   other ,   and   by   crawling   each   component   separately .   This   leads   to   a   dramatic   reduction   of   the   required   state   space   for   the   model ,   without   loss   of   content   coverage .   Our   method   does   not   require   prior   knowledge   of   the   RIA   nor   predefined   definition   of   components .   Instead ,   we   infer   the   components   by   observing   the   be -   havior   of   the   RIA   during   crawling .   Our   experimental   results   show   that   our   method   can   index   quickly   and   completely   industrial   RIAs   that   are   simply   out   of   reach   for   traditional   methods . ' ,   ' title ' :   ' Indexing   Rich   Internet   Applications   Using   Components - Based   Crawling ' } 
{ ' abstract ' :   ' One   important   aspect   of   constructing   an   overlay   network   is   how   to   exploit   network   locality   in   the   underlying   network .   In   this   paper ,   we   propose   a   scalable   protocol   for   constructing   an   overlay   network   that   takes   account   of   locality   of   network   hosts .   The   constructed   overlay   network   can   significantly   decrease   the   communication   cost   between   end - hosts .   Our   simulation   results   show   that   the   average   distance   between   a   pair   of   hosts   in   the   constructed   overlay   network   is   only   about   11%   of   the   one   in   a   traditional ,   randomly   connected   overlay   network .   Furthermore ,   our   proposed   overlay   considered   to   be   more   scalable   than   tree - based   or   mesh - based   overlays . ' ,   ' title ' :   ' Measurement - based   construction   of   locality - aware   overlay   networks ' } 
{ ' abstract ' :   ' This   paper   presents   a   low   cost ,   flexible   and   customizable   delay   measurement   system   developed   to   assess   the   performance   of   the   VTPE - hBEB   protocol .   The   proposed   system   can   be   used   to   evaluate   other   communication   protocols   as   well   as   to   measure   the   delay   between   two   repetitive   events . ' ,   ' title ' :   ' Delay   measurement   system   for   real - time   serial   data   streams ' } 
{ ' abstract ' :   " Service   robots   have   become   increasingly   important   subjects   in   our   lives .   However ,   they   are   still   facing   problems   like   adaptability   to   their   users .   While   major   work   has   focused   on   intelligent   service   robots ,   the   proposed   approaches   were   mostly   user   independent .   Our   work   is   part   of   the   FUI - RoboPopuli   project ,   which   concentrates   on   endowing   entertainment   companion   robots   with   adaptive   and   social   behaviour .   In   particular ,   we   are   interested   in   robots   that   are   able   to   learn   and   plan   so   that   they   adapt   and   personalize   their   behaviour   according   to   their   users .   Markov   Decision   Processes   ( MDPs )   are   largely   used   for   adaptive   robots   applications .   However ,   one   challenging   point   is   reducing   the   sample   complexity   required   to   learn   an   MDP   model ,   including   the   reward   function .   In   this   article ,   we   present   our   contribution   regarding   the   representation   and   the   learning   of   the   reward   function   through   analysing   interaction   traces   ( i . e .   the   interaction   history   between   the   robot   and   their   users ,   including   users '   feedback ) .   Our   approach   permits   to   generalise   the   learned   rewards   so   that   when   new   users   are   introduced ,   the   robot   may   quickly   adapt   using   what   it   learned   from   previous   experiences   with   other   users .   We   propose ,   in   this   article ,   two   algorithms   to   learn   the   reward   function .   The   first   is   direct   and   certain ,   the   robot   applies   with   a   user   what   it   learned   during   interaction   with   same   kind   of   users   ( i . e .   users   with   similar   profiles ) .   The   second   algorithm   generalises   what   it   learns   to   be   applied   to   all   kinds   of   users .   Through   simulation ,   we   show   that   the   generalised   algorithm   converges   to   an   optimal   reward   function   with   less   than   half   the   samples   needed   by   the   direct   algorithm . " ,   ' title ' :   " Adaptive   and   Personalised   Robots   -   Learning   from   Users '   Feedback " } 
{ ' abstract ' :   " Researches   of   sensor   networks   collecting   patients '   data   with   computerized   triage   tags ,   called   Triage   Network ,   are   attracting   attention .   The   listening   power   used   in   triage   tags   is   the   major   factor   of   lots   of   energy   consumption ,   and   consumption   of   energy   increases   when   sensor   nodes   always   communicate   with   other   nodes   in   active   state .   Hence ,   we   suppose   that   sensor   nodes   are   put   to   sleep   periodically   to   avoid   running   out   of   battery .   However ,   some   nodes   have   mobility   and   nodes   secede   from   the   network   according   to   patients   conditions   in   Triage   Network .   The   paths   are   failed   and   it   is   needed   to   reconstruct   paths   when   these   forwarding   nodes   move   or   secede   from   network .   Therefore ,   data   arrival   ratio   decreases   and   consumption   of   battery   increases   due   to   reconstruction   of   other   paths .   In   this   paper ,   we   propose   a   data   collection   method   using   two   types   of   forwarding   nodes ,   Stable   Nodes   and   Energy   Efficient   Nodes .   This   method   uses   two   types   of   forwarding   nodes   according   to   priority   of   data   and   avoids   loss   of   high   priority   data ,   improves   the   data   arrival   ratio   and   saves   the   energy   consumption .   We   evaluate   the   proposed   method   and   show   its   effectiveness   using   computer   simulations . " ,   ' title ' :   ' Data   collection   method   using   two   types   of   forwarding   nodes   for   energy   saving   in   triage   network ' } 
{ ' abstract ' :   ' This   paper   introduces   Golay - paired   Hadamard   matrices   for   fast   compressed   sensing   of   sparse   signals   in   the   time   or   spectral   domain .   These   sampling   operators   feature   low - memory   requirement ,   hardware - friendly   implementation   and   fast   computation   in   reconstruction .   We   show   that   they   require   a   nearly   optimal   number   of   measurements   for   faithful   reconstruction   of   a   sparse   signal   in   the   time   or   frequency   domain .   Simulation   results   demonstrate   that   the   proposed   sensing   matrices   offer   a   reconstruction   performance   similar   to   that   of   fully   random   matrices . ' ,   ' title ' :   ' Golay   meets   Hadamard :   Golay - paired   Hadamard   matrices   for   fast   compressed   sensing ' } 
{ ' abstract ' :   ' In   this   technical   note ,   the   problem   of   finite - time   output   regulation   control   for   a   class   of   disturbed   system   under   mismatching   condition   is   investigated   via   a   composite   control   design   manner .   The   composite   controller   is   developed   by   using   a   finite   time   control   technique   and   a   finite   time   disturbance   observer   ( FTDO ) .   A   key   idea   is   to   design   virtual   control   laws   based   on   estimation   values   of   the   disturbances   and   the   ith   ( 1 ≤ i ≤ n - 1   where   n   is   the   order   of   the   system )   order   derivative   of   disturbances .   Finite   time   stability   analysis   for   the   augmented   system   is   presented   by   means   of   Lyapunov   stability   theorems ,   which   shows   that   the   system   output   is   regulated   to   zero   in   finite   time   even   in   the   presence   of   mismatched   disturbances .   A   motion   control   application   demonstrates   the   effectiveness   and   attractive   properties   of   the   proposed   method . ' ,   ' title ' :   ' Continuous   Finite - Time   Output   Regulation   for   Disturbed   Systems   Under   Mismatching   Condition ' } 
{ ' abstract ' :   ' In   this   paper   we   propose   an   approach   for   enhanced   data   protection   in   the   cloud ,   based   upon   accountability   governance .   Specifically ,   the   relationships   between   accountability ,   risk   and   trust   are   analyzed   in   order   to   suggest   characteristics   and   means   to   address   data   governance   issues   involved   when   organizations   or   individuals   adopt   cloud   computing .   This   analysis   takes   into   account   insights   from   a   variety   of   stakeholders   within   cloud   ecosystems   obtained   by   running   an   elicitation   workshop . ' ,   ' title ' :   ' Accountability ,   Risk ,   and   Trust   in   Cloud   Services :   Towards   an   Accountability - Based   Approach   to   Risk   and   Trust   Governance ' } 
{ ' abstract ' :   ' Xue   et   al .   recently   proposed   an   innovative   mutual   authentication   and   key   agreement   scheme   for   wireless   sensor   networks   based   on   temporal   credential   using   smart   cards .   However ,   in   this   paper   we   demonstrate   that   their   scheme   is   vulnerable   to   password   guessing   attacks ,   node   capture   attacks   and   denial - of - service   attacks .   Furthermore   we   show   that   their   scheme   has   some   inconsistencies   which   make   it   less   secure   and   more   computationally   costly   than   originally   presented . ' ,   ' title ' :   ' Notes   on   A   Temporal - Credential - Based   Mutual   Authentication   and   Key   Agreement   Scheme   for   Wireless   Sensor   Networks ' } 
{ ' abstract ' :   ' Persistent   Scatterer   Interferometry   ( PSI )   has   been   widely   used   for   landslide   studies   in   recent   years .   This   paper   investigated   the   spatial   patterns   of   PSI   point   targets   and   landslide   occurrences   in   the   Arno   River   basin   in   Central   Italy .   The   main   purpose   is   to   analyze   whether   spatial   patterns   of   Persistent   Scatterers   ( PS )   can   be   recognized   as   indicators   of   landslide   occurrences   throughout   the   whole   basin .   The   bivariate   K - function   was   employed   to   assess   spatial   relationships   between   PS   and   landslides .   The   PSI   point   targets   were   acquired   from   almost   4   years   ( from   March   2003   to   January   2007 )   of   RADARSAT - 1   images .   The   landslide   inventory   was   collected   from   15   years   ( from     1992 – 2007 )   of   surveying   and   mapping   data ,   mainly   including   remote   sensing   data ,   topographic   maps   and   field   investigations .   The   proposed   approach   is   able   to   assess   spatial   patterns   between   a   variety   of   PS   and   landslides ,   in   particular ,   to   understand   if   PSI   point   targets   are   spatially   clustered   ( spatial   attraction )   or   randomly   distributed   ( spatial   independency )   on   various   types   of   landslides   across   the   basin .   Additionally ,   the   degree   and   scale   distances   of   PS   clustering   on   a   variety   of   landslides   can   be   characterized .   The   results   rejected   the   null   hypothesis   that   PSI   point   targets   appear   to   cluster   similarly   on   four   types   of   landslides   ( slides ,   flows ,   falls   and   creeps )   in   the   Arno   River   basin .   Significant   influence   of   PS   velocities   and   acquisition   orbits   can   be   noticed   on   detecting   landslides   with   different   states   of   activities .   Despite   that   the   assessment   may   be   influenced   by   the   quality   of   landslide   inventory   and   Synthetic   Aperture   Radar   ( SAR )   images ,   the   proposed   approach   is   expected   to   provide   guidelines   for   studies   trying   to   detect   and   investigate   landslide   occurrences   at   a   regional   scale   through   spatial   statistical   analysis   of   PS ,   for   which   an   advanced   understanding   of   the   impact   of   scale   distances   on   landslide   clustering   is   fundamentally   needed . ' ,   ' title ' :   ' Investigating   Spatial   Patterns   of   Persistent   Scatterer   Interferometry   Point   Targets   and   Landslide   Occurrences   in   the   Arno   River   Basin ' } 
{ ' abstract ' :   ' This   article   describes   a   middleware   used   in   display   cluster   of   real   time   visual   simulation   system .   This   middleware   which   based   on   TCP / IP   protocol   provides   the   communication   infrastructure   for   visual   simulation   system .   It   provides   unified   process   logic   and   interfaces   for   various   status   and   frame   data   and   the   packing / unpacking   functions   of   simulation   data   without   concerning   the   details   of   the   data .   We   found   two   classes   of   display   synchronization   problems   and   provided   the   resolution   of   them .   The   middleware   provides   a   group   of   APIs   which   hide   the   details   of   data   packing / unpacking ,   processing   and   transmission   and   meets   the   requirement   of   flexibility ,   efficiency   and   extensibility .   This   middleware   has   been   successfully   implemented   to   the   display   cluster   of   several   tower   simulation   system . ' ,   ' title ' :   ' The   Research   of   High   Level   Data   Communication   Middleware   of   Display   Cluster   Used   in   Real   Time   Simulation   Environment ' } 
{ ' abstract ' :   ' The   scattering   parameters   are   fundamental   in   the   characterization   of   electrical   devices   at   high   frequencies .   They   are   particularly   useful   for   analyzing   multiport   high - frequency   and   microwave   networks .   However ,   they   are   not   adequately   presented   in   most ,   if   not   all ,   microwave   engineering   books .   This   paper   identifies   two   common   deficiencies   in   the   way   scattering   parameters   are   being   presented   in   these   books .   It   provides   additional   information   that   should   supplement   those   books   or   book   chapters   on   scattering   parameters . ' ,   ' title ' :   ' Deficiencies   in   the   way   scattering   parameters   are   taught ' } 
{ ' abstract ' :   ' We   study   the   reliability   maximization   problem   in   WDM   networks   with   random   link   failures .   Reliability   in   these   networks   is   defined   as   the   probability   that   the   logical   network   is   connected ,   and   it   is   determined   by   the   underlying   lightpath   routing   and   the   link   failure   probability .   We   show   that   in   general   the   optimal   lightpath   routing   depends   on   the   link   failure   probability ,   and   characterize   the   properties   of   lightpath   routings   that   maximize   the   reliability   in   different   failure   probability   regimes .   In   particular ,   we   show   that   in   the   low   failure   probability   regime ,   maximizing   the   ` ` cross - layer "   min   cut   of   the   ( layered )   network   maximizes   reliability ,   whereas   in   the   high   failure   probability   regime ,   minimizing   the   spanning   tree   of   the   network   maximizes   reliability .   Motivated   by   these   results ,   we   develop   lightpath   routing   algorithms   for   reliability   maximization . ' ,   ' title ' :   ' Maximizing   Reliability   in   WDM   Networks   through   Lightpath   Routing ' } 
{ ' abstract ' :   ' The   slope   of   the   active   distances   is   an   important   parameter   when   investigating   the   error - correcting   capability   of   convolutional   codes   and   the   distance   behavior   of   concatenated   convolutional   codes .   The   slope   of   the   active   distances   is   equal   to   the   minimum   average   weight   cycle   in   the   state - transition   diagram   of   the   encoder .   A   general   upper   bound   on   the   slope   depending   on   the   free   distance   of   the   convolutional   code   and   new   upper   bounds   on   the   slope   of   special   classes   of   binary   convolutional   codes   are   derived .   Moreover ,   a   search   technique ,   resulting   in   new   tables   of   rate   R = 1 / 2   and   rate   R = 1 / 3   convolutional   encoders   with   high   memories   and   large   active   distance - slopes   is   presented .   Furthermore ,   we   show   that   convolutional   codes   with   large   slopes   can   be   used   to   obtain   new   tailbiting   block   codes   with   large   minimum   distances .   Tables   of   rate   R = 1 / 2   and   rate   R = 1 / 3   tailbiting   codes   with   larger   minimum   distances   than   the   best   previously   known   quasi - cyclic   codes   are   given .   Two   new   tailbiting   codes   also   have   larger   minimum   distances   than   the   best   previously   known   binary   linear   block   codes   with   same   size   and   length .   One   of   them   is   also   superior   in   terms   of   minimum   distance   to   any   previously   known   binary   nonlinear   block   code   with   the   same   set   of   parameters . ' ,   ' title ' :   ' Tailbiting   codes   obtained   via   convolutional   codes   with   large   active   distance - slopes ' } 
{ ' abstract ' :   ' MIMO   wireless   technology   is   required   to   increase   the   data   rates   for   a   broad   range   of   applications ,   including   low   cost   mobile   devices .   In   this   paper   we   present   a   very   low   area   reconfigurable   MIMO   detector   which   achieves   a   high   throughput   of   103Mbps   and   uses   27   Kilo   Gates   when   implemented   in   a   commercial   180nm   CMOS   process .   The   low   area   is   achieved   by   the   proposed   in - place   architecture .   This   architecture   implements   the   K - best   algorithm   and   reduces   area   4 - fold   compared   to   the   widely   used   multi - stage   architecture ,   while   provides   reconfigurability   in   terms   of   antenna   configuration   during   real - time   operation . ' ,   ' title ' :   ' A   low - area   flexible   MIMO   detector   for   WiFi / WiMAX   standards ' } 
{ ' abstract ' :   ' Because   human   cognition   is   creative   and   socially   situated ,   knowledge   accumulates ,   diffuses ,   and   gets   applied   in   new   contexts ,   generating   cultural   analogs   of   phenomena   observed   in   population   genetics   such   as   adaptation   and   drift .   It   is   therefore   commonly   thought   that   elements   of   culture   evolve   through   natural   selection .   However ,   natural   selection   was   proposed   to   explain   how   change   accumulates   despite   lack   of   inheritance   of   acquired   traits ,   as   occurs   with   template - mediated   replication .   It   cannot   accommodate   a   process   with   significant   retention   of   acquired   or   horizontally   ( e . g .   socially )   transmitted   traits .   Moreover ,   elements   of   culture   cannot   be   treated   as   discrete   lineages   because   they   constantly   interact   and   influence   one   another .   It   is   proposed   that   what   evolves   through   culture   is   the   mind ;   ideas   and   artifacts   are   merely   reflections   of   its   current   evolved   state .   Interacting   minds   transform   ( in   part )   through   a   non - Darwinian   autopoietic   process   similar   to   that   by   which   early   life   evolved ,   involving   not   survival   of   the   fittest   but   actualization   of   their   potential . ' ,   ' title ' :   ' The   cultural   evolution   of   socially   situated   cognition ' } 
{ ' abstract ' :   ' Event   Extraction   is   a   complex   and   interesting   topic   in   Information   Extraction   that   includes   event   extraction   methods   from   free   text   or   web   data .   The   result   of   event   extraction   systems   can   be   used   in   several   fields   such   as   risk   analysis   systems ,   online   monitoring   systems   or   decide   support   tools .   In   this   paper ,   we   introduce   a   method   that   combines   lexico   - -   semantic   and   machine   learning   to   extract   event   from   Vietnamese   news .   Furthermore ,   we   concentrate   to   describe   event   online   monitoring   system   named   VnLoc   based   on   the   method   that   was   proposed   above   to   extract   event   in   Vietnamese   language .   Besides ,   in   experiment   phase ,   we   have   evaluated   this   method   based   on   precision ,   recall   and   F1   measure .   At   this   time   of   experiment ,   we   on   investigated   on   three   types   of   event :   FIRE ,   CRIME   and   TRANSPORT   ACCIDENT . ' ,   ' title ' :   ' VnLoc :   A   Real   - -   Time   News   Event   Extraction   Framework   for   Vietnamese ' } 
{ ' abstract ' :   ' Reliability   analysis   using   error   probabilities   for   combinational   logic   circuits   has   been   investigated   widely   in   the   literature .   Reliability   analysis   for   sequential   logic   circuits   using   these   methods   would   be   inaccurate   because   of   existence   of   loops   in   their   architecture .   In   this   paper   a   new   method   based   on   conversion   of   sequential   circuit   to   combinational   one   and   applying   an   iterative   reliability   analysis   is   developed .   A   Monte   Carlo   method - based   reliability   analysis   is   introduced   for   sequential   circuits ,   which   is   used   for   first   method   validation .   Experimental   results   demonstrate   good   accuracy   of   the   method . ' ,   ' title ' :   ' SEQUENTIAL   LOGIC   CIRCUITS   RELIABILITY   ANALYSIS ' } 
{ ' abstract ' :   ' According   to   the   Journey   to   Crime   theory ,   offenders   have   a   directionality   preference ,   in   the   form   of   an   activity   path ,   when   they   are   moving   about   in   their   environment   in   search   for   criminal   activities .   Using   clustering   techniques ,   this   theory   is   tested   using   crime   data   for   the   Province   of   British   Columbia ,   Canada .   The   activities   of   57 , 962   offenders   who   were   either   charged ,   chargeable ,   or   for   whom   charges   were   recommended   were   analyzed   by   mapping   their   offense   locations   with   respect   to   their   home   locations   to   determine   directionality .   Once   directionality   was   established ,   a   unique   clustering   technique ,   based   on   K - Means   clustering   and   modified   for   angles ,   was   applied   to   find   the   number   of   activity   paths   for   each   offender .   Although   the   number   of   activity   paths   varies   from   individual   to   individual ,   the   aggregate   pattern   was   very   consistent   with   theory .   It   was   found   that   people   only   have   a   few   activity   paths ,   even   if   they   are   highly   prolific   offenders . ' ,   ' title ' :   ' How   Many   Ways   Do   Offenders   Travel   - -   Evaluating   the   Activity   Paths   of   Offenders ' } 
{ ' abstract ' :   ' Pulse   Coupled   Neural   Network ( PCNN )   is   widely   used   in   the   field   of   image   processing ,   but   it   is   a   difficult   task   to   define   the   relative   parameters   properly   in   the   research   of   the   applications   of   PCNN .   So   far   the   determination   of   parameters   of   its   model   needs   a   lot   of   experiments .   To   deal   with   the   above   problem ,   a   document   segmentation   based   on   the   improved   PCNN   is   proposed .   It   uses   the   maximum   entropy   function   as   the   fitness   function   of   bacterial   foraging   optimization   algorithm ,   adopts   bacterial   foraging   optimization   algorithm   to   search   the   optimal   parameters ,   and   eliminates   the   trouble   of   manually   set   the   experiment   parameters .   Experimental   results   show   that   the   proposed   algorithm   can   effectively   complete   document   segmentation .   And   result   of   the   segmentation   is   better   than   the   contrast   algorithms .   ©   ( 2014 )   COPYRIGHT   Society   of   Photo - Optical   Instrumentation   Engineers   ( SPIE ) .   Downloading   of   the   abstract   is   permitted   for   personal   use   only . ' ,   ' title ' :   ' PCNN   document   segmentation   method   based   on   bacterial   foraging   optimization   algorithm ' } 
{ ' abstract ' :   ' Undirected   graphical   models   encode   in   a   graph   G   the   dependency   structure   of   a   random   vector   Y .   In   many   applications ,   it   is   of   interest   to   model   Y   given   another   random   vector   X   as   input .   We   refer   to   the   problem   of   estimating   the   graph   G ( x )   of   Y   conditioned   on   X   =   x   as   " graph - valued   regression " .   In   this   paper ,   we   propose   a   semiparametric   method   for   estimating   G ( x )   that   builds   a   tree   on   the   X   space   just   as   in   CART   ( classification   and   regression   trees ) ,   but   at   each   leaf   of   the   tree   estimates   a   graph .   We   call   the   method   " Graph - optimized   CART " ,   or   Go - CART .   We   study   the   theoretical   properties   of   Go - CART   using   dyadic   partitioning   trees ,   establishing   oracle   inequalities   on   risk   minimization   and   tree   partition   consistency .   We   also   demonstrate   the   application   of   Go - CART   to   a   meteorological   dataset ,   showing   how   graph - valued   regression   can   provide   a   useful   tool   for   analyzing   complex   data . ' ,   ' title ' :   ' Graph - Valued   Regression ' } 
{ ' abstract ' :   ' Over   the   last   two   decades ,   doubts   have   been   expressed   about   the   adequacy   of   materialism   as   the   correct   framework   for   explaining   phenomenal   consciousness   ( the   experience   of   saturated   greenness   one   has   when   looking   at   a   lush   lawn ,   for   example ) .   This   paper   reconstructs   a   generic   form   of   the   various   arguments   that   have   been   used   to   defend   the   view   of   the   materialistically   inexplicable   nature   of   consciousness   ( MINC ) .   This   reconstruction   reveals   that   the   arguments   turn   on   an   impoverished   notion   of   explanation .   By   discussing   some   examples   from   the   history   of   science ,   the   paper   shows   that   a   reasonable   notion   of   explanation   has   to   be   wider   than   the   one   utilized   in   the   argument   for   MINC ,   which   opens   the   possibility   for   the   materialistic   explicability   of   consciousness .   The   author   ends   the   paper   by   raising   a   question   about   the   very   intelligibility   of   the   project   of   trying   to   explain   the   so - called   nature   of   consciousness   as   opposed   to   the   regularities   characteristic   of   the   relation   between   states   of   consciousness   and   ... ' ,   ' title ' :   ' On   explaining   phenomenal   consciousness ' } 
{ ' abstract ' :   ' Successful   replication   within   an   infected   host   and   successful   transmission   between   hosts   are   key   to   the   continued   spread   of   most   pathogens .   Competing   selection   pressures   exerted   at   these   different   scales   can   lead   to   evolutionary   trade - offs   between   the   determinants   of   fitness   within   and   between   hosts .   Here ,   we   examine   such   a   trade - off   in   the   context   of   influenza   A   viruses   and   the   differential   pressures   exerted   by   temperature - dependent   virus   persistence .   For   a   panel   of   avian   influenza   A   virus   strains ,   we   find   evidence   for   a   trade - off   between   the   persistence   at   high   versus   low   temperatures .   Combining   a   within - host   model   of   influenza   infection   dynamics   with   a   between - host   transmission   model ,   we   study   how   such   a   trade - off   affects   virus   fitness   on   the   host   population   level .   We   show   that   conclusions   regarding   overall   fitness   are   affected   by   the   type   of   link   assumed   between   the   within -   and   between - host   levels   and   the   main   route   of   transmission   ( direct   or   environmental ) .   The   relative   importance   of   virulence   and   immune   response   mediated   virus   clearance   are   also   found   to   influence   the   fitness   impacts   of   virus   persistence   at   low   versus   high   temperatures .   Based   on   our   results ,   we   predict   that   if   transmission   occurs   mainly   directly   and   scales   linearly   with   virus   load ,   and   virulence   or   immune   responses   are   negligible ,   the   evolutionary   pressure   for   influenza   viruses   to   evolve   toward   good   persistence   at   high   within - host   temperatures   dominates .   For   all   other   scenarios ,   influenza   viruses   with   good   environmental   persistence   at   low   temperatures   seem   to   be   favored . ' ,   ' title ' :   ' A   Multi - scale   Analysis   of   Influenza   A   Virus   Fitness   Trade - offs   due   to   Temperature - dependent   Virus   Persistence ' } 
{ ' abstract ' :   ' Peer - to - Peer   ( P2P )   networks   are   largely   used   for   file - sharing   and   hence   must   provide   efficient   mechanisms   for   searching   the   files   stored   at   various   nodes .   The   existing   structuredP2P   overlays   support   only   ” exact - match ”   look - up   which   is   hardly   sufficient   in   a   file   sharing   network .   This   paper   addresses   the   problem   of   keyword - based   search   in   structured   P2P   networks .   We   propose   a   new   keyword - based   searching   algorithm   which   can   be   implemented   on   top   of   any   structured   P2P   overlay .   We   demonstrate   that   the   proposed   algorithm   achieves   very   good   searching   results   as   it   requires   the   minimum   number   of   messages   to   be   sent   in   order   to   find   all   the   references   to   files   containing   at   least   the   given   set   of   keywords . ' ,   ' title ' :   ' A   Keyword   Search   Algorithm   for   Structured   Peer - to - Peer   Networks ' } 
{ ' abstract ' :   ' In   this   paper ,   we   propose   an   adaptive   power   allocation   method   for   hybrid   relay   systems   that   employ   the   amplify - and - forward   and   decode - and - forward   protocols   simultaneously .   The   total   transmission   power   is   analytically   allocated   to   a   source   and   two   selected   relays   by   the   proposed   power   allocation   criterion   to   maximize   the   overall   received   signal - to - noise   ratio   at   the   destination .   Simulation   results   show   that   the   proposed   scheme   achieves   better   performance   than   that   of   conventional   cooperative   schemes   or   hybrid   systems   with   equal   power   allocation . ' ,   ' title ' :   ' Adaptive   relay   selection   and   power   allocation   for   hybrid   relay   systems ' } 
{ ' abstract ' :   ' The   unitary   rotation   of   square - pixellated   images   is   based   on   the   finite   su ( 2 ) - oscillator   model ,   which   describes   systems   whose   values   for   position ,   momentum   and   energy ,   are   discrete   and   finite .   In   a   two - dimensional   position   space ,   this   allows   the   construction   of   angular   momentum   states ,   orthonormal   and   complete ,   for   which   rotations   are   defined   as   multiplication   by   phases   that   carry   the   rotation   angle .   The   decomposition   of   a   digital   square   images   in   terms   of   these   angular   momentum   states   determines   a   unitary   ( hence   invertible )   rotation   of   the   image ,   whose   kernel   can   be   computed   as   a   four - dimensional   array   of   real   numbers . ' ,   ' title ' :   ' Unitary   rotation   of   square - pixellated   images ' } 
{ ' abstract ' :   ' As   more   mobile   storage   devices   are   used   in   consumer   electronics ,   possibility   of   user   confidential   data   leakage   increases .   To   make   things   worse ,   data   of   deleted   file   in   mobile   storage   such   as   USB   drives   can   be   easily   recovered   and ,   thus ,   can   be   vulnerable   to   data   leakage .   To   prevent   this   type   of   data   leakage ,   efficient   secure   deletion   techniques   are   required   and   we   present   two   secure   deletion   techniques ,   namely   block   cleaning   and   zero   overwriting ,   for   flash   memory   storage .   Also ,   we   propose   cost   and   benefit   models   of   both   techniques .   The   models   imply   an   existence   of   an   efficient   adaptive   hybrid   secure   deletion   scheme   that   applies   one   of   the   techniques   based   on   their   costs   and   benefits   at   given   data   arrangements .   Experimental   results   measured   on   an   embedded   board   show   that   the   adaptive   hybrid   scheme   deletes   data   securely   and   efficiently   for   various   data   patterns   on   flash   memory   storage . ' ,   ' title ' :   ' Models   and   Design   of   an   Adaptive   Hybrid   Scheme   for   Secure   Deletion   of   Data   in   Consumer   Electronics ' } 
{ ' abstract ' :   ' In   heterogeneous   and   dynamic   environments ,   efficient   execution   of   parallel   computations   can   require   mappings   of   tasks   to   processors   whose   performance   is   both   irregular   ( because   of   heterogeneity )   and   time - varying   ( because   of   dynamicity ) .   While   adaptive   domain   decomposition   techniques   have   been   used   to   address   heterogeneous   resource   capabilities ,   temporal   variations   in   those   capabilities   have   seldom   been   considered .   We   propose   a   conservative   scheduling   policy   that   uses   information   about   expected   future   variance   in   resource   capabilities   to   produce   more   efficient   data   mapping   decisions .   We   first   present   techniques ,   based   on   time   series   predictors   that   we   developed   in   previous   work ,   for   predicting   CPU   load   at   some   future   time   point ,   average   CPU   load   for   some   future   time   interval ,   and   variation   of   CPU   load   over   some   future   time   interval .   We   then   present   a   family   of   stochastic   scheduling   algorithms   that   exploit   such   predictions   of   future   availability   and   variability   when   making   data   mapping   decisions .   Finally ,   we   describe   experiments   in   which   we   apply   our   techniques   to   an   astrophysics   application .   The   results   of   these   experiments   demonstrate   that   conservative   scheduling   can   produce   execution   times   that   are   both   significantly   faster   and   less   variable   than   other   techniques . ' ,   ' title ' :   ' Conservative   Scheduling :   Using   Predicted   Variance   to   Improve   Scheduling   Decisions   in   Dynamic   Environments ' } 
{ ' abstract ' :   ' We   consider   a   class   of   restless   multi - armed   bandit   problems   that   arises   in   multi - channel   opportunistic   communications ,   where   channels   are   modeled   as   independent   and   stochastically   identical   Gilbert - Elliot   channels   and   channel   state   observations   are   subject   to   errors .   We   show   that   the   myopic   channel   selection   policy   has   a   semi - universal   structure   that   obviates   the   need   to   know   the   Markovian   transition   probabilities   of   the   channel   states .   Based   on   this   structure ,   we   establish   closed - form   lower   and   upper   bounds   on   the   steady - state   throughput   achieved   by   the   myopic   policy .   Furthermore ,   we   characterize   the   approximation   factor   of   the   myopic   policy   to   bound   its   worst - case   performance   loss   with   respect   to   the   optimal   performance . ' ,   ' title ' :   ' On   the   myopic   policy   for   a   class   of   restless   bandit   problems   with   applications   in   dynamic   multichannel   access ' } 
{ ' abstract ' :   ' We   show   that   the   optimum   length - / spl   nu /   guard   sequence   for   block   transmission   over   a   linear   Gaussian - noise   dispersive   channel   with   memory   / spl   nu /   is   a   linear   combination   of   the   N   information   symbols   of   the   block .   A   closed - form   expression   for   the   optimum   guard   sequence   is   derived   subject   to   a   total   average   energy   constraint   on   the   information   and   guard   symbols .   The   achievable   channel   block   throughput   with   the   optimum   guard   sequence   is   compared   with   that   achievable   with   two   common   guard   sequence   types ,   namely   zero   stuffing   and   cyclic   prefix . ' ,   ' title ' :   ' Guard   sequence   optimization   for   block   transmission   over   linear   frequency - selective   channels ' } 
{ ' abstract ' :   " A   modular   program   analysis   considers   components   independently   and   provides   a   succinct   summary   for   each   component ,   which   is   used   when   checking   the   rest   of   the   system .   Consider   a   system   consisting   of   a   library   and   a   client .   A   temporal   summary ,   or     interface   ,   of   the   library   specifies   legal   sequences   of   library   calls .   The   interface   is     safe     if   no   call   sequence   violates   the   library ' s   internal   invariants ;   the   interface   is     permissive     if   it   contains   every   such   sequence .   Modular   program   analysis   requires     full     interfaces ,   which   are   both   safe   and   permissive :   the   client   does   not   cause   errors   in   the   library   if   and   only   if   it   makes   only   sequences   of   library   calls   that   are   allowed   by   the   full   interface   of   the   library . Previous   interface - based   methods   have   focused   on   safe   interfaces ,   which   may   be   too   restrictive   and   thus   reject   good   clients .   We   present   an   algorithm   for   automatically   synthesizing   software   interfaces   that   are   both   safe   and   permissive .   The   algorithm   generates   interfaces   as   graphs   whose   vertices   are   labeled   with   predicates   over   the   library ' s   internal   state ,   and   whose   edges   are   labeled   with   library   calls .   The   interface   state   is   refined   incrementally   until   the   full   interface   is   constructed .   In   other   words ,   the   algorithm   automatically   synthesizes   a   typestate   system   for   the   library ,   against   which   any   client   can   be   checked   for   compatibility .   We   present   an   implementation   of   the   algorithm   which   is   based   on   the   BLAST   model   checker ,   and   we   evaluate   some   case   studies . " ,   ' title ' :   ' Permissive   interfaces ' } 
{ ' abstract ' :   ' In   this   paper ,   we   propose   a   new   method   for   the   motion   planning   problem   of   rigid   object   dexterous   manipulation   with   a   robotic   multi - fingered   hand ,   under   quasi - static   movement   assumption .   This   method   computes   both   object   and   finger   trajectories   as   well   as   the   finger   relocation   sequence .   Its   specificity   is   to   use   a   special   structuring   of   the   research   space   that   allows   to   search   for   paths   directly   in   the   particular   subspace   GS   n     which   is   the   subspace   of   all   the   grasps   that   can   be   achieved   with   n   grasping   fingers .   The   solving   of   the   dexterous   manipulation   planning   problem   is   based   upon   the   exploration   of   this   subspace .   The   proposed   approach   captures   the   connectivity   of   GS   n     in   a   graph   structure .   The   answer   of   the   manipulation   planning   query   is   then   given   by   searching   a   path   in   the   computed   graph .   Simulation   experiments   were   conducted   for   different   dexterous   manipulation   task   examples   to   validate   the   proposed   method . ' ,   ' title ' :   ' Dexterous   manipulation   planning   using   probabilistic   roadmaps   in   continuous   grasp   subspaces ' } 
{ ' abstract ' :   ' This   paper   presents   an   experimental   evaluation   of   different   line   extraction   algorithms   applied   to   2D   laser   scans   for   indoor   environments .   Six   popular   algorithms   in   mobile   robotics   and   computer   vision   are   selected   and   tested .   Real   scan   data   collected   from   two   office   environments   by   using   different   platforms   are   used   in   the   experiments   in   order   to   evaluate   the   algorithms .   Several   comparison   criteria   are   proposed   and   discussed   to   highlight   the   advantages   and   drawbacks   of   each   algorithm ,   including   speed ,   complexity ,   correctness   and   precision .   The   results   of   the   algorithms   are   compared   with   ground   truth   using   standard   statistical   methods .   An   extended   case   study   is   performed   to   further   evaluate   the   algorithms   in   a   SLAM   application . ' ,   ' title ' :   ' A   comparison   of   line   extraction   algorithms   using   2D   range   data   for   indoor   mobile   robotics ' } 
{ ' abstract ' :   ' This   study   investigates   the   use   of   force - stiffness   feedback ,   i . e . ,   a   combination   of   force   offset   and   extra   spring   load ,   in   UAV   tele - operation   with   transmission   time   delay .   The   goal   was   to   further   increase   the   level   of   safety   of   tele - operation   with   a   reduction   in   operator   workload   with   respect   to   force   feedback ,   i . e . ,   using   force   offset   alone .   A   theoretical   analysis   is   given   of   using   force - stiffness   feedback   to   improve   collision   avoidance .   Wave   variables   are   included   to   reduce   time   delay   effects .   An   experiment   was   conducted   to   investigate   the   effects   of   force - stiffness   feedback   on   safety   of   operation ,   operator   performance ,   control   activity ,   and   workload .   Results   indicate   that   force - stiffness   feedback   improves   the   haptic   interface   with   respect   to   force   feedback   alone .   Safety   of   tele - operation   increases   without   increasing   operator   workload   with   respect   to   force   feedback . ' ,   ' title ' :   ' Haptic   interface   in   UAV   tele - operation   using   force - stiffness   feedback ' } 
{ ' abstract ' :   ' Due   to   the   spread   of   the   internet   and   the   ever   increasing   number   of   web   applications ,   the   issue   of   compatibility   across   browsers   has   become   very   important .   This   compatibility   issue   is   also   referred   as   Cross   Browser   Inconsistency   ( XBI )   wherein   same   website   looks   or   behaves   differently   in   different   web   browsers .   In   this   paper   our   aim   is   to   address   this   issue   of   compatibility   and   propose   an   automated   approach   of   detecting   XBIs .   Cross   Browser   Inconsistencies   can   either   be   in   the   content ,   structure   or   behavior   of   the   webpage .   In   order   to   get   a   grasp   of   the   above   mentioned   types   of   inconsistencies ,   we   surveyed   some   random   websites   and   analyzed   them   in   different   browsers .   We   also   studied   the   basic   working   of   browser ,   in   order   to   establish   its   connection   with   the   occurrences   of   XBIs .   Each   browser   has   its   own   rendering   mechanisms ,   which   sometimes   differs   from   standards .   Hence ,   the   execution   of   these   websites   is   different   in   different   browsers .   Finally   we   have   proposed   an   automated   approach   for   XBI   detection . ' ,   ' title ' :   ' An   Automated   Approach   for   Cross - Browser   Inconsistency   ( XBI )   Detection ' } 
{ ' abstract ' :   ' We   present   a   formal   framework   that   combines   high - level   representation   and   causality - based   reasoning   with   low - level   geometric   reasoning   and   motion   planning .   The   frame - work   features   bilateral   interaction   between   task   and   motion   planning ,   and   embeds   geometric   reasoning   in   causal   reasoning ,   thanks   to   several   advantages   inherited   from   its   underlying   components .   In   particular ,   our   choice   of   using   a   causality - based   high - level   formalism   for   describing   action   domains   allows   us   to   represent   ramifications   and   state / transition   constraints ,   and   embed   in   such   formal   domain   descriptions   externally   defined   functions   implemented   in   some   programming   language   ( e . g . ,   C++ ) .   Moreover ,   given   such   a   domain   description ,   the   causal   reasoner   based   on   this   formalism   ( i . e . ,   the   Causal   Calculator )   allows   us   to   compute   optimal   solutions   ( e . g . ,   shortest   plans )   for   elaborate   planning / prediction   problems   with   temporal   constraints .   Utilizing   these   features   of   high - level   representation   and   reasoning ,   we   can   combine   causal   reasoning ,   motion   planning   and   geometric   planning   to   find   feasible   kinematic   solutions   to   task - level   problems .   In   our   framework ,   the   causal   reasoner   guides   the   motion   planner   by   finding   an   optimal   task - plan ;   if   there   is   no   feasible   kinematic   solution   for   that   task - plan   then   the   motion   planner   guides   the   causal   reasoner   by   modifying   the   planning   problem   with   new   temporal   constraints .   Furthermore ,   while   computing   a   task - plan ,   the   causal   reasoner   takes   into   account   geometric   models   and   kinematic   relations   by   means   of   external   predicates   implemented   for   geometric   reasoning   ( e . g . ,   to   check   some   collisions ) ;   in   that   sense   the   geometric   reasoner   guides   the   causal   reasoner   to   find   feasible   kinematic   solutions .   We   illustrate   an   application   of   this   framework   to   robotic   manipulation ,   with   two   pantograph   robots   on   a   complex   assembly   task   that   requires   concurrent   execution   of   actions .   A   short   video   of   this   application   accompanies   the   paper . ' ,   ' title ' :   ' Combining   high - level   causal   reasoning   with   low - level   geometric   reasoning   and   motion   planning   for   robotic   manipulation ' } 
{ ' abstract ' :   ' This   paper   presents   a   novel   template   matching   method   to   detect   and   track   pedestrians   for   people   counting   in   real - time .   Firstly ,   a   novel   background   subtraction   method   is   proposed   for   extracting   all   foreground   objects   from   background .   Then ,   a   shadow   elimination   method   is   used   to   remove   unwanted   shadow   from   the   background .   In   order   to   identify   pedestrians   from   non - pedestrian   objects ,   this   paper   proposed   a   novel   grid - based   template   matching   scheme   to   robustly   verify   each   pedestrian .   Usually ,   a   pedestrian   will   have   different   appearances   at   different   positions .   The   grid - based   approach   can   effectively   reduce   the   perspective   effects   into   a   minimum   since   it   uses   different   templates   to   record   the   appearance   changes   at   each   grid .   When   more   templates   are   used ,   the   detection   process   will   become   more   inefficient .   To   speed   up   its   efficiency ,   an   integral   image   is   used   to   filter   out   all   impossible   candidates   in   advance .   Lastly ,   a   tracking   method   is   applied   to   tracking   the   direction   of   each   moving   pedestrian   so   that   the   real   number   of   passing   people   per   direction   can   be   counted   more   accurately .   Experimental   results   have   proved   that   the   proposed   method   is   robust ,   accurate ,   and   powerful   in   people   counting . ' ,   ' title ' :   ' Grid - based   Template   Matching   for   People   Counting ' } 
{ ' abstract ' :   ' A   tomographic   image   reconstruction   algorithm   that   we   have   been   studying   requires   the   nth - order   Hankel   transform   for   the   nth   function   in   a   series ,   where   n   varies   over   a   set   of   integers .   Unfortunately ,   most   previously   proposed   algorithms   have   either   dealt   with   only   zeroth - order   transforms   or   cannot   be   applied   conveniently   to   our   problem .   We   propose   an   algorithm   for   computing   general   integer - order   Hankel   transforms .   The   algorithm   takes   samples   of   equally   spaced   input   functions   and   gives   equally   spaced   samples   of   the   transforms . ' ,   ' title ' :   ' An   algorithm   for   computing   general   integer - order   Hankel   transforms ' } 
{ ' abstract ' :   ' In   this   paper ,   we   present   a   real - time   approach   that   allows   tracking   deformable   structures   in   3D   ultrasound   sequences .   Our   method   consists   in   obtaining   the   target   displacements   by   combining   robust   dense   motion   estimation   and   mechanical   model   simulation .   We   perform   evaluation   of   our   method   through   simulated   data ,   phantom   data ,   and   real - data .   Results   demonstrate   that   this   novel   approach   has   the   advantage   of   providing   correct   motion   estimation   regarding   different   ultrasound   shortcomings   including   speckle   noise ,   large   shadows   and   ultrasound   gain   variation .   Furthermore ,   we   show   the   good   performance   of   our   method   with   respect   to   state - of - the - art   techniques   by   testing   on   the   3D   databases   provided   by   MICCAI   CLUST ’ 14   and   CLUST ’ 15   challenges . ' ,   ' title ' :   ' Real - time   target   tracking   of   soft   tissues   in   3D   ultrasound   images   based   on   robust   visual   information   and   mechanical   simulation ' } 
{ ' abstract ' :   ' For   two   given   graphs   G1G1   and   G2G2 ,   the   Ramsey   number   R ( G1 , G2 ) R ( G1 , G2 )   is   the   smallest   integer   NN   such   that   for   any   graph   of   order   NN ,   either   GG   contains   a   copy   of   G1G1   or   its   complement   contains   a   copy   of   G2G2 .   Let   CmCm   be   a   cycle   of   length   mm   and   K1 , nK1 , n   a   star   of   order   n + 1n + 1 .   Parsons   ( 1975 )   shows   that   R ( C4 , K1 , n ) ≤ n + ⌊ n − 1 ⌋ + 2   and   if   nn   is   the   square   of   a   prime   power ,   then   the   equality   holds .   In   this   paper ,   by   discussing   the   properties   of   polarity   graphs   whose   vertices   are   points   in   the   projective   planes   over   Galois   fields ,   we   prove   that   R ( C4 , K1 , q2 − t ) = q2 + q − ( t − 1 ) R ( C4 , K1 , q2 − t ) = q2 + q − ( t − 1 )   if   qq   is   an   odd   prime   power ,   1 ≤ t ≤ 2 ⌈ q4 ⌉   and   t ≠ 2 ⌈ q4 ⌉ − 1 ,   which   extends   a   result   on   R ( C4 , K1 , q2 − t ) R ( C4 , K1 , q2 − t )   obtained   by   Parsons   ( 1976 ) . ' ,   ' title ' :   ' Polarity   graphs   and   Ramsey   numbers   for   C   4   versus   stars ' } 
{ ' abstract ' :   ' This   paper   deals   with   the   problem   of   assuring   strict   QoS   guarantees   for   the   end   to   end   connections   that   originate   from   Ethernet   access   network .   It   shows   that   despite   high   link   capacities   in   some   cases   Ethernet   network   might   be   the   reason   of   QoS   deterioration .   The   primary   reason   is   the   lack   of   appropriate   QoS   differentiation   and   traffic   isolation   mechanisms .   The   shared   buffers   and   priority   schedulers   available   in   most   of   Ethernet   switches   appear   to   be   not   sufficient   to   guarantee   strict   QoS .   For   these   cases   new   solution   is   proposed   which   relies   on   additional   traffic   control   mechanisms   available   in   other   network   elements .   Only   additional   mechanism   supporting   typical   functionality   of   Ethernet   switch   can   provide   strict   QoS   guarantees   what   was   verified   in   simulations   studies . ' ,   ' title ' :   ' On   assuring   QoS   in   Ethernet   access   network ' } 
{ ' abstract ' :   ' The   federal   Medicare   regulations   reimburse   hospitals   on   a   pro   rata   share   of   the   hospital \ ' s   cost .   Hence ,   to   meet   its   financial   requirements ,   a   hospital   is   forced   to   shift   more   of   the   financial   burdens   onto   its   private   patients .   This   procedure   has   contributed   to   double   digit   inflation   in   hospital   prices   and   to   proposed   federal   regulation   to   control   the   rate   of   increase   in   hospital   revenues .   In   this   regulatory   environment ,   we   develop   nonlinear   programming   pricing   and   cost   allocation   models   to   aid   hospital   administrators   in   meeting   their   profit   maximizing   and   profit   satisficing   goals .   The   model   enables   administrators   to   explore   tactical   issues   such   as :   i   studying   the   relationship   between   a   voluntary   or   legislated   cap   on   a   hospital \ ' s   total   revenues   and   the   hospital \ ' s   profitability ,   ii   identifying   those   departments   within   the   hospital   that   are   the   most   attractive   candidates   for   cost   reduction   or   cost   containment   efforts ,   and   iii   isolating   those   services   that   should   be   singled   out   by   the   hospital   manager   for   renegotiation   of   the   prospective   or   " customary   and   reasonable "   cap .   Finally ,   the   modeling   approach   is   helpful   in   explaining   the   departmental   cross   subsidies   observed   in   practice ,   and   can   be   of   aid   to   federal   administrators   in   assessing   the   impacts   of   proposed   changes   in   the   Medicare   reimbursement   formula . ' ,   ' title ' :   ' Hospital   Profit   Planning   under   Medicare   Reimbursement ' } 
{ ' abstract ' :   ' We   present   a   ( 4   +   epsilon )   approximation   algorithm   for   weighted   graph   matching   which   applies   in   the   semistreaming ,   sliding   window ,   and   MapReduce   models ;   this   single   algorithm   improves   the   previous   best   algorithm   in   each   model .   The   algorithm   operates   by   reducing   the   maximum - weight   matching   problem   to   a   polylog   number   of   copies   of   the   maximum - cardinality   matching   problem .   The   algorithm   also   extends   to   provide   approximation   guarantees   for   the   more   general   problem   of   finding   weighted   independent   sets   in   p - systems   ( which   include   intersections   of   p   matroids   and   p - bounded   hypergraph   matching ) . ' ,   ' title ' :   ' Improved   Streaming   Algorithms   for   Weighted   Matching ,   via   Unweighted   Matching ' } 
{ ' abstract ' :   ' This   paper   presents   a   novel   approach   to   efficiently   solve   parameter - dependent   ( PD )   linear   matrix   inequality   ( LMI )   problems   for ,   amongst   others ,   linear   parameter - varying   ( LPV )   control   design .   Typically ,   stability   and   performance   is   guaranteed   by   finding   a   PD   Lyapunov   function   such   that   a   PD   LMI   is   feasible   on   a   parameter   domain .   To   solve   the   resulting   semi - infinite   problems ,   we   propose   a   novel   LMI   relaxation   technique   relying   on   B - spline   basis   functions .   This   technique   provides   less   conservative   solutions   and / or   a   reduced   numerical   burden   compared   to   existing   approaches .   Moreover ,   an   elegant   generalization   of   worst - case   optimization   to   the   optimization   of   any   signal   norm   is   obtained   by   expressing   performance   bounds   as   a   function   of   the   system   parameters .   This   generalization   yields   better   performance   bounds   in   a   large   part   of   the   parameter   domain .   Numerical   comparisons   with   the   current   state - of - the - art   demonstrate   the   generality   and   effectiveness   of   our   approach . ' ,   ' title ' :   ' Control   of   linear   parameter - varying   systems   using   B - splines ' } 
{ ' abstract ' :   ' There   is   a   growing   interest   in   simulating   natural   phenomena   in   computer   graphics   applications .   Animating   natural   scenes   in   real   time   is   one   of   the   most   challenging   problems   due   to   the   inherent   complexity   of   their   structure ,   formed   by   millions   of   geometric   entities ,   and   the   interactions   that   happen   within .   An   example   of   natural   scenario   that   is   needed   for   games   or   simulation   programs   are   forests .   Forests   are   difficult   to   render   because   the   huge   amount   of   geometric   entities   and   the   large   amount   of   detail   to   be   represented .   Moreover ,   the   interactions   between   the   objects   ( grass ,   leaves )   and   external   forces   such   as   wind   are   complex   to   model .   In   this   paper   we   concentrate   in   the   rendering   of   falling   leaves   at   low   cost .   We   present   a   technique   that   exploits   graphics   hardware   in   order   to   render   thousands   of   leaves   with   different   falling   paths   in   real   time   and   low   memory   requirements . ' ,   ' title ' :   ' Rendering   falling   leaves   on   graphics   hardware ' } 
{ ' abstract ' :   ' We   previously   presented   DriverDB ,   a   database   that   incorporates   ∼ 6000   cases   of   exome - seq   data ,   in   addition   to   annotation   databases   and   published   bioinformatics   algorithms   dedicated   to   driver   gene / mutation   identification .   The   database   provides   two   points   of   view ,   ‘ Cancer ’   and   ‘ Gene ’ ,   to   help   researchers   visualize   the   relationships   between   cancers   and   driver   genes / mutations .   In   the   updated   DriverDBv2   database   ( http : / / ngs . ym . edu . tw / driverdb )   presented   herein ,   we   incorporated   > 9500   cancer - related   RNA - seq   datasets   and   > 7000   more   exome - seq   datasets   from   The   Cancer   Genome   Atlas   ( TCGA ) ,   International   Cancer   Genome   Consortium   ( ICGC ) ,   and   published   papers .   Seven   additional   computational   algorithms   ( meaning   that   the   updated   database   contains   15   in   total ) ,   which   were   developed   for   driver   gene   identification ,   are   incorporated   into   our   analysis   pipeline ,   and   the   results   are   provided   in   the   ‘ Cancer ’   section .   Furthermore ,   there   are   two   main   new   features ,   ‘ Expression ’   and   ‘ Hotspot ’ ,   in   the   ‘ Gene ’   section .   ‘ Expression ’   displays   two   expression   profiles   of   a   gene   in   terms   of   sample   types   and   mutation   types ,   respectively .   ‘ Hotspot ’   indicates   the   hotspot   mutation   regions   of   a   gene   according   to   the   results   provided   by   four   bioinformatics   tools .   A   new   function ,   ‘ Gene   Set ’ ,   allows   users   to   investigate   the   relationships   among   mutations ,   expression   levels   and   clinical   data   for   a   set   of   genes ,   a   specific   dataset   and   clinical   features . ' ,   ' title ' :   ' DriverDBv2 :   a   database   for   human   cancer   driver   gene   research ' } 
{ ' abstract ' :   ' Thousands   of   deep   and   wide   pipelines   working   concurrently   make   GPGPU   high   power   consuming   parts .   Energy - efficiency   techniques   employ   voltage   overscaling   that   increases   timing   sensitivity   to   variations   and   hence   aggravating   the   energy   use   issues .   This   paper   proposes   a   method   to   increase   spatiotemporal   reuse   of   computational   effort   by   a   combination   of   compilation   and   micro - architectural   design .   An   associative   memristive   memory   ( AMM )   module   is   integrated   with   the   floating   point   units   ( FPUs ) .   Together ,   we   enable   fine - grained   partitioning   of   values   and   find   high - frequency   sets   of   values   for   the   FPUs   by   searching   the   space   of   possible   inputs ,   with   the   help   of   application - specific   profile   feedback .   For   every   kernel   execution ,   the   compiler   pre - stores   these   high - frequent   sets   of   values   in   AMM   modules   - -   representing   partial   functionality   of   the   associated   FPU - -   that   are   concurrently   evaluated   over   two   clock   cycles .   Our   simulation   results   show   high   hit   rates   with   32 - entry   AMM   modules   that   enable   36%   reduction   in   average   energy   use   by   the   kernel   codes .   Compared   to   voltage   overscaling ,   this   technique   enhances   robustness   against   timing   errors   with   39%   average   energy   saving . ' ,   ' title ' :   ' Energy - Efficient   GPGPU   Architectures   via   Collaborative   Compilation   and   Memristive   Memory - Based   Computing ' } 
{ ' abstract ' :   ' Quasi - cyclic   codes   are   renowned   for   their   structural   design   and   low - complexity   shift   register   encoding .   However ,   existing   design   techniques   based   on   difference   families   have   limited   code   size   options   due   to   algebraic   constraints .   We   introduce   in   this   paper   a   notation   of   extended   difference   family   ( EDF )   and   provide   a   systematic   code   design   based   on   EDFs   with   a   high   degree   of   flexibility   in   code   size .   Short / medium - length   codes   of   high   rate   ( / spl   ges /   0.9 )   can   be   easily   constructed . ' ,   ' title ' :   ' Quasi - cyclic   codes   from   extended   difference   families ' } 
{ ' abstract ' :   ' Lexical   cohesion   arises   from   a   chain   of   lexical   items   that   establish   links   between   sentences   in   a   text .   In   this   paper   we   propose   three   different   models   to   capture   lexical   cohesion   for   document - level   machine   translation :   ( a )   a   direct   reward   model   where   translation   hypotheses   are   rewarded   whenever   lexical   cohesion   devices   occur   in   them ,   ( b )   a   conditional   probability   model   where   the   appropriateness   of   using   lexical   cohesion   devices   is   measured ,   and   ( c )   a   mutual   information   trigger   model   where   a   lexical   cohesion   relation   is   considered   as   a   trigger   pair   and   the   strength   of   the   association   between   the   trigger   and   the   triggered   item   is   estimated   by   mutual   information .   We   integrate   the   three   models   into   hierarchical   phrase - based   machine   translation   and   evaluate   their   effectiveness   on   the   NIST   Chinese - English   translation   tasks   with   large - scale   training   data .   Experiment   results   show   that   all   three   models   can   achieve   substantial   improvements   over   the   baseline   and   that   the   mutual   information   trigger   model   performs   better   than   the   others . ' ,   ' title ' :   ' Modeling   lexical   cohesion   for   document - level   machine   translation ' } 
{ ' abstract ' :   ' This   paper   presents   a   lightweight   sketching   system   that   enables   interactive   illustration   of   complex   fluid   systems .   Users   can   sketch   on   a   2.5 - dimensional   ( 2.5 D )   canvas   to   design   the   shapes   and   connections   of   a   fluid   circuit .   These   input   sketches   are   automatically   analyzed   and   abstracted   into   a   hydraulic   graph ,   and   a   new   hybrid   fluid   model   is   used   in   the   background   to   enhance   the   illustrations .   The   system   provides   rich   simple   operations   for   users   to   edit   the   fluid   system   incrementally ,   and   the   new   internal   flow   patterns   can   be   simulated   in   real   time .   Our   system   is   used   to   illustrate   various   fluid   systems   in   medicine ,   biology ,   and   engineering .   We   asked   professional   medical   doctors   to   try   our   system   and   obtained   positive   feedback   from   them . ' ,   ' title ' :   ' Sketch - based   Dynamic   Illustration   of   Fluid   Systems ' } 
{ ' abstract ' :   ' We   present   an   improved   zone   content   classification   method   and   its   performance   evaluation .   We   added   two   new   features   to   the   feature   vector   from   one   previously   published   method   ( Sivaramakrishnan   et   al . ,   1995 ) .   We   assumed   different   independence   relationships   in   two   zone   sets .   We   used   an   optimized   binary   decision   tree   to   estimate   the   maximum   zone   content   class   probability   in   one   set   while   using   the   Viterbi   algorithm   to   find   the   optimal   solution   for   a   zone   sequence   in   the   other   set .   The   training ,   pruning   and   testing   data   set   for   the   algorithm   include   1 , 600   images   drawn   from   the   UWCDROM   III   document   image   database .   The   classifier   is   able   to   classify   each   given   scientific   and   technical   document   zone   into   one   of   the   nine   classes ,   2   text   classes   ( of   font   size   4   -   18pt   and   font   size   19   -   32   pt ) ,   math ,   table ,   halftone ,   map / drawing ,   ruling ,   logo ,   and   others .   Compared   with   our   previous   work   ( Wang   et   al . ,   2000 ) ,   it   raised   the   accuracy   rate   to   98.52%   from   97.53%   and   reduced   the   mean   false   alarm   rate   to   0.53%   from   1.26% . ' ,   ' title ' :   ' Zone   content   classification   and   its   performance   evaluation ' } 
{ ' abstract ' :   ' Big   Data   applications   require   real - time   processing   of   complex   computations   on   streaming   and   static   information .   Applications   such   as   the   diagnosis   of   power   generating   turbines   require   the   integration   of   high   velocity   streaming   and   large   volume   of   static   data   from   multiple   sources .   In   this   paper   we   study   various   optimisations   related   to   efficiently   processing   of   streaming   and   static   information .   We   introduce   novel   indexing   structures   for   stream   processing ,   a   query - planner   component   that   decides   when   their   creation   is   beneficial ,   and   we   examine   precomputed   summarisations   on   archived   measurements   to   accelerate   streaming   and   static   information   processing .   To   put   our   ideas   into   practise ,   we   have   developed   Exa   Stream ,   a   data   stream   management   system   that   is   scalable ,   has   declarative   semantics ,   supports   user   defined   functions ,   and   allows   efficient   execution   of   complex   analytical   queries   on   streaming   and   static   data .   Our   work   is   accompanied   by   an   empirical   evaluation   of   our   optimisation   techniques . ' ,   ' title ' :   ' Real   time   processing   of   streaming   and   static   information ' } 
{ ' abstract ' :   " In   the   last   ten   years ,   speech   recognition   has   evolved   from   a   science   fiction   dream   to   a   widespread   input   method   for   mobile   devices .   In   this   talk ,   I   will   describe   how   speech   recognition   works ,   the   problems   we   have   solved   and   the   challenges   that   remain .   I   will   touch   upon   some   of   Google ' s   main   efforts   in   language   and   pronunciation   modeling ,   and   describe   how   the   adoption   of   neural   networks   for   acoustic   modeling   marked   the   beginning   of   a   technology   revolution   in   the   field ,   with   approaches   such   as   Long   Short   Term   Memory   models   and   Connectionist   Temporal   Classification .   I   will   also   share   my   learnings   on   how   Machine   Learning   and   Human   Knowledge   can   be   harmoniously   combined   to   build   state - of - the - art   technology   that   helps   and   delights   users   across   the   world . " ,   ' title ' :   ' Learnings   and   innovations   in   speech   recognition ' } 
{ ' abstract ' :   ' Nowadays ,   the   explosive   growth   and   variety   of   information   available   on   the   Web   frequently   overwhelms   users   and   leads   users   to   make   poor   decisions .   Consequently ,   recommender   systems   have   become   more   and   more   important   to   assist   people   to   make   decisions   faster .   Among   all   related   techniques ,   collaborative   filtering   approach   is   currently   one   of   the   effective   and   widely   used   techniques   to   build   recommender   systems .   However ,   there   are   major   challenges   like   data   sparsity   and   scalability .   Meanwhile   it   is   hard   to   integrate   demographic   statistical   information   ( Age ,   gender   and   occupation   etc . )   to   collaborative   filtering   model .   Unfortunately ,   it   is   significant   to   take   account   into   these   information ,   especially   user   occupation   when   making   recommendation .   As   we   all   know ,   people   with   different   occupations   may   have   totally   different   tastes .   It   has   been   proved   that   restricted   Boltzmann   machines ( RBM )   model   can   infer   lower - dimensional   representations   automatically   and   is   potential   in   handling   large   and   sparse   dataset .   In   this   paper ,   we   propose   an   improved   User   Occupation   aware   Conditional   Restricted   Boltzmann   Machine   Frame ( UO - CRBMF )   model ,   which   employs   an   improved   RBM   and   takes   full   use   of   user   occupation   information   by   adding   a   conditional   layer   with   user   occupation   information .   Experimental   studies   on   the   standard   benchmark   datasets   of   MovieLens   100k   and   MovieLens   1M   have   shown   its   potential   and   advantages   beyond   baseline   methods . ' ,   ' title ' :   ' User   Occupation   Aware   Conditional   Restricted   Boltzmann   Machine   Based   Recommendation ' } 
{ ' abstract ' :   ' Microservices   complement   approaches   like   DevOps   and   continuous   delivery   in   terms   of   software   architecture .   Along   with   this   architectural   style ,   several   important   deployment   technologies ,   such   as   container - based   virtualization   and   container   orchestration   solutions ,   have   emerged .   These   technologies   allow   to   efficiently   exploit   cloud   platforms ,   providing   a   high   degree   of   scalability ,   availability ,   and   portability   for   microservices .# R ## N ## R ## N # Despite   the   obvious   importance   of   a   sufficient   level   of   performance ,   there   is   still   a   lack   of   performance   engineering   approaches   explicitly   taking   into   account   the   particularities   of   microservices .   In   this   paper ,   we   argue   why   new   solutions   to   performance   engineering   for   microservices   are   needed .   Furthermore ,   we   identify   open   issues   and   outline   possible   research   directions   with   regard   to   performance - aware   testing ,   monitoring ,   and   modeling   of   microservices . ' ,   ' title ' :   ' Performance   Engineering   for   Microservices :   Research   Challenges   and   Directions ' } 
{ ' abstract ' :   ' Intelligent   agents ,   such   as   robots ,   have   to   serve   a   multitude   of   autonomous   functions .   Examples   are ,   e . g . ,   collision   avoidance ,   navigation   and   route   planning ,   active   sensing   of   its   environment ,   or   the   interaction   and   non - verbal   communication   with   people   in   the   extended   reach   space .   Here ,   we   focus   on   the   recognition   of   the   action   of   a   human   agent   based   on   a   biologically   inspired   visual   architecture   of   analyzing   articulated   movements .   The   proposed   processing   architecture   builds   upon   coarsely   segregated   streams   of   sensory   processing   along   different   pathways   which   separately   process   form   and   motion   information   ( Layher   et   al . ,   2014 ) .   Action   recognition   is   performed   in   an   event - based   scheme   by   identifying   representations   of   characteristic   pose   configurations   ( key   poses )   in   an   image   sequence .   In   line   with   perceptual   studies ,   key   poses   are   selected   unsupervised   utilizing   a   feature   driven   criterion   which   combines   extrema   in   the   motion   energy   with   the   horizontal   and   the   vertical   extendedness   of   a   body   shape .   Per   class   representations   of   key   pose   frames   are   learned   using   a   deep   convolutional   neural   network   consisting   of   15   convolutional   layers .   The   network   is   trained   using   the   energy - efficient   deep   neuromorphic   networks   ( Eedn )   framework   ( Esser   et   al . ,   2016 ) ,   which   realizes   the   mapping   of   the   trained   synaptic   weights   onto   the   IBM   Neurosynaptic   System   platform   ( Merolla   et   al . ,   2014 ) .   After   the   mapping ,   the   trained   network   achieves   real - time   capabilities   for   processing   input   streams   and   classify   input   images   at   about   1 , 000   frames   per   second   while   the   computational   stages   only   consume   about   70   mW   of   energy   ( without   spike   transduction ) .   Particularly   regarding   mobile   robotic   systems ,   a   low   energy   profile   might   be   crucial   in   a   variety   application   scenarios .   Cross - validation   results   are   reported   for   two   different   datasets   and   compared   to   state - of - the - art   action   recognition   approaches .   The   results   demonstrate ,   that   ( I )   the   presented   approach   is   on   par   with   other   key   pose   based   methods   described   in   the   literature ,   which   select   key   pose   frames   by   optimizing   classification   accuracy ,   ( II )   compared   to   the   training   on   the   full   set   of   frames ,   representations   trained   on   key   pose   frames   result   in   a   higher   confidence   in   class   assignments ,   and   ( III )   key   pose   representations   show   promising   generalization   capabilities   in   a   cross - dataset   evaluation . ' ,   ' title ' :   ' Real - Time   Biologically   Inspired   Action   Recognition   from   Key   Poses   Using   a   Neuromorphic   Architecture ' } 
{ ' abstract ' :   ' Contents   carried   in   an   image   are   valuable   information   sources   for   many   scientific   and   engineering   applications .   However ,   if   the   image   is   captured   under   low   illumination   conditions   a   large   portion   of   the   image   appears   dark   and   this   heavily   degrades   the   image   quality .   In   order   to   solve   this   problem ,   a   restoration   algorithm   is   developed   here   that   transforms   the   low   input   brightness   to   a   higher   value   using   a   logarithmic   mapping   function .   The   mapping   is   further   refined   by   a   linear   weighting   with   the   input   to   reduce   the   un - necessary   amplification   at   regions   with   high   brightness .   Moreover ,   fine   details   in   the   image   are   preserved   by   applying   the   Retinex   principle   to   extract   and   then   re - insert   object   edges .   Results   from   experiments   using   low   and   normal   illumination   images   have   shown   satisfactory   performances   with   regard   to   the   improvement   in   information   contents   and   the   mitigation   of   viewing   artifacts . ' ,   ' title ' :   ' Logarithmic   profile   mapping   and   Retinex   edge   preserving   for   restoration   of   low   illumination   images ' } 
{ ' abstract ' :   ' We   propose   a   principled   approach   for   the   problem   of   aligning   multiple   partially   overlapping   networks .   The   objective   is   to   map   multiple   graphs   into   a   single   graph   while   preserving   vertex   and   edge   similarities .   The   problem   is   inspired   by   the   task   of   integrating   partial   views   of   a   family   tree   ( genealogical   network )   into   one   unified   network ,   but   it   also   has   applications ,   for   example ,   in   social   and   biological   networks .   Our   approach ,   called   Flan ,   introduces   the   idea   of   generalizing   the   facility   location   problem   by   adding   a   non - linear   term   to   capture   edge   similarities   and   to   infer   the   underlying   entity   network .   The   problem   is   solved   using   an   alternating   optimization   procedure   with   a   Lagrangian   relaxation .   Flan   has   the   advantage   of   being   able   to   leverage   prior   information   on   the   number   of   entities ,   so   that   when   this   information   is   available ,   Flan   is   shown   to   work   robustly   without   the   need   to   use   any   ground   truth   data   for   fine - tuning   method   parameters .   Additionally ,   we   present   three   multiple - network   extensions   to   an   existing   state - of - the - art   pairwise   alignment   method   called   Natalie .   Extensive   experiments   on   synthetic ,   as   well   as   real - world   datasets   on   social   networks   and   genealogical   networks ,   attest   to   the   effectiveness   of   the   proposed   approaches   which   clearly   outperform   a   popular   multiple   network   alignment   method   called   IsoRankN . ' ,   ' title ' :   ' Lagrangian   relaxations   for   multiple   network   alignment ' } 
{ ' abstract ' :   ' Heterogeneous   ultra - dense   networks   enable   ultra - high   data   rates   and   ultra - low   latency   through   the   use   of   dense   sub - 6   GHz   and   millimeter   wave   ( mmWave )   small   cells   with   different   antenna   configurations .   Existing   work   has   widely   studied   spectral   and   energy   efficiency   in   such   networks   and   shown   that   high   spectral   and   energy   efficiency   can   be   achieved .   This   article   investigates   the   benefits   of   heterogeneous   ultra - dense   network   architecture   from   the   perspectives   of   three   promising   technologies ,   i . e . ,   physical   layer   security ,   caching ,   and   wireless   energy   harvesting ,   and   provides   enthusiastic   outlook   towards   application   of   these   technologies   in   heterogeneous   ultra - dense   networks .   Based   on   the   rationale   of   each   technology ,   opportunities   and   challenges   are   identified   to   advance   the   research   in   this   emerging   network . ' ,   ' title ' :   ' A   New   Look   at   Physical   Layer   Security ,   Caching ,   and   Wireless   Energy   Harvesting   for   Heterogeneous   Ultra - dense   Networks ' } 
{ ' abstract ' :   ' We   consider   the   problem   of   joint   modeling   of   videos   and   their   corresponding   textual   descriptions   ( e . g .   sentences   or   phrases ) .   Our   approach   consists   of   three   components :   the   video   representation ,   the   textual   representation ,   and   a   joint   model   that   links   videos   and   text .   Our   video   representation   uses   the   state - of - the - art   deep   3D   ConvNet   to   capture   the   semantic   information   in   the   video .   Our   textual   representation   uses   the   recent   advancement   in   learning   word   and   sentence   vectors   from   large   text   corpus .   The   joint   model   is   learned   to   score   the   correct   ( video ,   text )   pairs   higher   than   the   incorrect   ones .   We   demonstrate   our   approach   in   several   applications :   1 )   retrieving   sentences   given   a   video ;   2 )   retrieving   videos   given   a   sentence ;   3 )   zero - shot   action   recognition   in   videos . ' ,   ' title ' :   ' Beyond   verbs :   Understanding   actions   in   videos   with   text ' } 
{ ' abstract ' :   ' This   paper   presents   a   multi - agent   model   for   simulating   attitude   formation   and   change   based   on   perception   and   communication   in   the   context   of   stabilization   operations .   The   originality   of   our   model   comes   from   ( 1 )   attitude   computation   that   evaluates   information   as   part   of   a   history   relative   to   the   individual   ( 2 )   a   notion   of   co - responsibility   for   attitude   attribution .   We   present   a   military   scenario   of   French   operations   in   Afghanistan   along   with   polls   results   about   the   opinion   of   citizen   toward   present   Forces .   Based   on   these   field   data ,   we   calibrate   the   model   and   show   the   resulting   attitude   dynamics .   We   study   the   sensibility   of   the   model   to   the   co - responsibility   factor . ' ,   ' title ' :   ' From   Field   Data   to   Attitude   Formation ' } 
{ ' abstract ' :   ' This   paper   proposes   two   low - complexity   iterative   algorithms   to   compute   the   capacity   of   a   single - user   multiple - input   multiple - output   channel   with   per - antenna   power   constraint .   The   first   method   results   from   manipulating   the   optimality   conditions   of   the   considered   problem   and   applying   fixed - point   iteration .   In   the   second   approach ,   we   transform   the   considered   problem   into   a   minimax   optimization   program   using   the   well - known   MAC -   BC   duality ,   and   then   solve   it   by   a   novel   alternating   optimization   method .   In   both   proposed   iterative   methods ,   each   iteration   involves   an   optimization   problem   which   can   be   efficiently   solved   by   the   water - filling   algorithm .   The   proposed   iterative   methods   are   provably   convergent .   Complexity   analysis   and   extensive   numerical   experiments   are   carried   out   to   demonstrate   the   superior   performance   of   the   proposed   algorithms   over   an   existing   approach   known   as   the   mode - dropping   algorithm . ' ,   ' title ' :   ' Low - complexity   Approaches   for   MIMO   Capacity   with   Per - antenna   Power   Constraint ' } 
{ ' abstract ' :   ' Inventory - Aware   Pathfinding   is   concerned   with   finding   paths   while   taking   into   account   that   picking   up   items ,   e . g . ,   keys ,   allow   the   character   to   unlock   blocked   pathways ,   e . g . ,   locked   doors .   In   this   work   we   present   a   pruning   method   and   a   preprocessing   method   that   can   improve   significantly   the   scalability   of   such   approaches .   We   apply   our   methods   to   the   recent   approach   of   Inventory - Driven   Jump - Point   Search   ( InvJPS ) .   First ,   we   introduce   InvJPS +   that   allows   to   prune   large   parts   of   the   search   space   by   favoring   short   detours   to   pick   up   items ,   offering   a   trade - off   between   efficiency   and   optimality .   Second ,   we   propose   a   preprocessing   step   that   allows   to   decide   on   runtime   which   items ,   e . g . ,   keys ,   are   worth   using   thus   pruning   potentially   unnecessary   items   before   the   search   starts .   We   show   results   for   combinations   of   the   pruning   and   preprocessing   methods   illustrating   the   best   choices   over   various   scenarios . ' ,   ' title ' :   ' Pruning   and   preprocessing   methods   for   inventory - aware   pathfinding ' } 
{ ' abstract ' :   ' This   paper   proposes   a   method   for   proper   names   extraction   from   Myanmar   text   by   using   latent   Dirichlet   allocation   ( LDA ) .   Our   method   aims   to   extract   proper   names   that   provide   important   information   on   the   contents   of   Myanmar   text .   Our   method   consists   of   two   steps .   In   the   first   step ,   we   extract   topic   words   from   Myanmar   news   articles   by   using   LDA .   In   the   second   step ,   we   make   a   post - processing ,   because   the   resulting   topic   words   contain   some   noisy   words .   Our   post - processing ,   first   of   all ,   eliminates   the   topic   words   whose   prefixes   are   Myanmar   digits   and   suffixes   are   noun   and   verb   particles .   We   then   remove   the   duplicate   words   and   discard   the   topic   words   that   are   contained   in   the   existing   dictionary .   Consequently ,   we   obtain   the   words   as   candidate   of   proper   names ,   namely   personal   names ,   geographical   names ,   unique   object   names ,   organization   names ,   single   event   names ,   and   so   on .   The   evaluation   is   performed   both   from   the   subjective   and   quantitative   perspectives .   From   the   subjective   perspective ,   we   compare   the   accuracy   of   proper   names   extracted   by   our   method   with   those   extracted   by   latent   semantic   indexing   ( LSI )   and   rule - based   method .   It   is   shown   that   both   LS ]   and   our   method   can   improve   the   accuracy   of   those   obtained   by   rule - based   method .   However ,   our   method   can   provide   more   interesting   proper   names   than   LSI .   From   the   quantitative   perspective ,   we   use   the   extracted   proper   names   as   additional   features   in   K - means   clustering .   The   experimental   results   show   that   the   document   clusters   given   by   our   method   are   better   than   those   given   by   LSI   and   rule - based   method   in   precision ,   recall   and   F - score . ' ,   ' title ' :   ' Extraction   of   proper   names   from   myanmar   text   using   latent   dirichlet   allocation ' } 
{ ' abstract ' :   ' Large   scale   assessment   of   aboveground   biomass   ( AGB )   in   tropical   forests   is   often   limited   by   the   saturation   of   remote   sensing   signals   at   high   AGB   values .   Fourier   Transform   Textural   Ordination   ( FOTO )   performs   well   in   quantifying   canopy   texture   from   very   high - resolution   ( VHR )   imagery ,   from   which   stand   structure   parameters   can   be   retrieved   with   no   saturation   effect   for   AGB   values   up   to   650   Mg · ha − 1 .   The   method   is   robust   when   tested   on   wet   evergreen   forests   but   is   more   demanding   when   applied   across   different   forest   types   characterized   by   varying   structures   and   allometries .   The   present   study   focuses   on   a   gradient   of   forest   types   ranging   from   dry   deciduous   to   wet   evergreen   forests   in   the   Western   Ghats   ( WG )   of   India ,   where   we   applied   FOTO   to   Cartosat - 1a   images   with   2.5   m   resolution .   Based   on   21   1 - ha   ground   control   forest   plots ,   we   calibrated   independent   texture – AGB   models   for   the   dry   and   wet   zone   forests   in   the   area ,   as   delineated   from   the   distribution   of   NDVI   values   computed   from   LISS - 4   multispectral   images .   This   stratification   largely   improved   the   relationship   between   texture - derived   and   field - derived   AGB   estimates ,   which   exhibited   a   R2   of   0.82   for   a   mean   rRMSE   of   ca .   17% .   By   inverting   the   texture – AGB   models ,   we   finally   mapped   AGB   predictions   at   1.6 - ha   resolution   over   a   heterogeneous   landscape   of   ca .   1500   km2   in   the   WG ,   with   a   mean   relative   per - pixel   propagated   error   < 20%   for   wet   zone   forests ,   i . e . ,   below   the   recommended   IPCC   criteria   for   Monitoring ,   Reporting   and   Verification   ( MRV )   methods .   The   method   proved   to   perform   well   in   predicting   high - resolution   AGB   values   over   heterogeneous   tropical   landscape   encompassing   diversified   forest   types ,   and   thus   presents   a   promising   option   for   affordable   regional   monitoring   systems   of   greenhouse   gas   ( GhG )   emissions   related   to   forest   degradation . ' ,   ' title ' :   ' Inverting   Aboveground   Biomass – Canopy   Texture   Relationships   in   a   Landscape   of   Forest   Mosaic   in   the   Western   Ghats   of   India   Using   Very   High   Resolution   Cartosat   Imagery ' } 
{ ' abstract ' :   ' Self - driving   vehicle   technologies   are   progressing   rapidly   and   are   expected   to   play   a   significant   role   in   the   future   of   transportation .   One   of   the   main   challenges   for   self - driving   vehicles   on   public   roads   is   the   safe   cooperation   and   collaboration   among   multiple   vehicles   using   sensor - based   perception   and   inter - vehicle   communications .   When   self - driving   vehicles   try   to   occupy   the   same   spatial   area   simultaneously ,   they   might   collide   with   one   another ,   might   become   deadlocked ,   or   might   slam   on   the   brakes   making   it   uncomfortable   or   unsafe   for   passengers   in   a   self - driving   vehicle .   In   this   paper ,   we   study   how   a   self - driving   vehicle   can   safely   navigate   merge   points ,   where   two   lanes   with   different   priorities   meet .   We   present   a   safe   protocol   for   merge   points   named   Autonomous   Vehicle   Protocol   for   Merge   Points ,   where   self - driving   vehicles   use   both   vehicular   communications   and   their   own   perception   systems   for   cooperating   with   other   self - driving   and / or   human - driven   vehicles .   Our   simulation   results   show   that   our   traffic   protocol   has   higher   traffic   throughput ,   compared   to   simple   traffic   protocols ,   while   ensuring   safety . ' ,   ' title ' :   ' A   merging   protocol   for   self - driving   vehicles ' } 
{ ' abstract ' :   ' System   Portfolio   Selection   ( SPS )   problem   is   equivalent   to   multi - objective   optimization   problem ,   with   multi - function   requirements   incommensurable .   In   the   paper ,   the   SPS   problem   is   re - specified   with   a   more   practical   formulation ,   comparing   to   general   portfolio   problem .   Then ,   both   feasible   and   non - inferior   solution   is   re - defined   considering   characteristics   of   SPS   problem ,   specifically ,   four   rules   of   system   function   combinations   are   proposed   according   to   practical   cases .   Then ,   the   instability   of   system   performance   is   involved   in   SPS   problem ,   and   the   robust   theory   is   employed   to   solving   the   uncertainty   of   system   function   values   with   definition   of   robust   non - inferior   solution .   Next ,   the   paper   proposes   an   immediately   updating   algorithm   to   solve   the   problem   of   solution   space   exponentially   growing .   Finally ,   a   case   study   is   used   to   demonstrate   the   usefulness   and   effectiveness   of   the   proposed   approaches .   It   shows   that   the   approach   can   provide   an   efficient   guidance   for   decision - makers   in   the   process   of   making   a   SPS . ' ,   ' title ' :   ' Robust   system   portfolio   selection   with   multi - function   requirements   and   system   instability ' } 
{ ' abstract ' :   ' This   study   explores   the   impact   of   high - photovoltaic   ( PV )   penetration   on   the   inter - area   oscillation   modes   of   large - scale   power   grids .   A   series   of   dynamic   models   with   various   PV   penetration   levels   are   developed   based   on   a   detailed   model   representing   the   U . S .   Eastern   Interconnection   ( EI ) .   Transient   simulations   are   performed   to   investigate   the   change   of   inter - area   oscillation   modes   with   PV   penetration .   The   impact   of   PV   control   strategies   and   parameter   settings   on   inter - area   oscillations   is   studied .   This   paper   finds   that   as   PV   increases ,   the   damping   of   the   dominant   oscillation   mode   decreases   monotonically .   It   is   also   observed   that   the   mode   shape   varies   with   the   PV   control   strategy   and   new   oscillation   modes   may   emerge   under   inappropriate   parameter   settings   in   PV   plant   controls . ' ,   ' title ' :   ' Impact   of   High   PV   Penetration   on   the   Inter - Area   Oscillations   in   the   U . S .   Eastern   Interconnection ' } 
{ ' abstract ' :   ' The   objective   of   this   research   is   to   compare   the   effectiveness   of   different   tracking   devices   underwater .   There   have   been   few   works   in   aquatic   virtual   reality   ( VR )   —   i . e . ,   VR   systems   that   can   be   used   in   a   real   underwater   environment .   Moreover ,   the   works   that   have   been   done   have   noted   limitations   on   tracking   accuracy .   Our   initial   test   results   suggest   that   inertial   measurement   units   work   well   underwater   for   orientation   tracking   but   a   different   approach   is   needed   for   position   tracking .   Towards   this   goal ,   we   have   waterproofed   and   evaluated   several   consumer   tracking   systems   intended   for   gaming   to   determine   the   most   effective   approaches .   First ,   we   informally   tested   infrared   systems   and   fiducial   marker   based   systems ,   which   demonstrated   significant   limitations   of   optical   approaches .   Next ,   we   quantitatively   compared   inertial   measurement   units   ( IMU )   and   a   magnetic   tracking   system   both   above   water   ( as   a   baseline )   and   underwater .   By   comparing   the   devices   rotation   data ,   we   have   discovered   that   the   magnetic   tracking   system   implemented   by   the   Razer   Hydra   is   more   accurate   underwater   as   compared   to   a   phone - based   IMU .   This   suggests   that   magnetic   tracking   systems   should   be   further   explored   for   underwater   VR   applications . ' ,   ' title ' :   ' Towards   usable   underwater   virtual   reality   systems ' } 
{ ' abstract ' :   ' A   faulty   network   GG   is   under   the   conditional   fault   model ,   i . e . , \ xa0every   fault - free   vertex   of   GG   is   incident   to   at   least   two   fault - free   edges .   Let   FFvFFv   and   FFeFFe   be   the   set   of   faulty   vertices   and   faulty   edges   in   FQnFQn ,   respectively .   In   this   paper ,   we   consider   FQnFQn   under   the   conditional   fault   model   and   prove   that   if   | FFv | + | FFe | ≤ 2n − 4 | FFv | + | FFe | ≤ 2n − 4   and   n ≥ 3n ≥ 3 ,   then   FQn − FFv − FFeFQn − FFv − FFe   contains   a   fault - free   cycle   of   every   even   length   from   4   to   2n − 2 | FFv | 2n − 2 | FFv | ;   if   | FFv | + | FFe | ≤ 2n − 5 | FFv | + | FFe | ≤ 2n − 5   and   n ≥ 4n ≥ 4   is   even ,   then   FQn − FFv − FFeFQn − FFv − FFe   contains   a   fault - free   cycle   of   every   odd   length   from   n + 1n + 1   to   2n − 2 | FFv | − 12n − 2 | FFv | − 1 . ' ,   ' title ' :   ' Cycles   embedding   in   folded   hypercubes   under   the   conditional   fault   model ' } 
{ ' abstract ' :   ' Companies   have   invested   considerable   resources   in   the   implementation   of   enterprise   resource   planning   ( ERP )   systems .   The   results   initially   expected   have   rarely   been   reached .   The   optimisation   ( or   efficient   use )   of   such   information   systems   is   nowadays   becoming   a   major   factor   for   firms   striving   to   reach   their   performance   objectives .   After   presenting   a   synthesis   of   several   studies   on   ERP   projects ,   we   build   on   the   findings   of   a   French   investigation   into   the   assessment   and   optimisation   of   ERP   performance .   A   classification   of   company   positions   regarding   their   ERP   use ,   based   on   both   software   maturity   and   strategic   deployment   directions ,   and   an   improvement   process   are   proposed .   Industrial   cases   allow   validation   of   this   approach . ' ,   ' title ' :   ' A   classification   for   better   use   of   ERP   systems ' } 
{ ' abstract ' :   ' This   paper   presents   a   time - domain   biosensor   array   that   uses   a   capacitor - less   current - mode   analog - to - time   converter   ( CMATC )   and   logarithmic   cyclic   time - attenuation - based   TDC   with   discharging   acceleration .   Combining   the   exponential   function   of   the   CMATC   and   logarithmic   function   of   the   proposed   TDC   offers   linear   input - output   characteristics .   The   time - domain   property   enables   bio - imaging   at   a   high   spatial   resolution   and   large   scale   while   maintaining   scalability .   Measurement   results   with   a   0.25 - μ m   test   chip   successfully   demonstrated   linear   input - output   characteristics . ' ,   ' title ' :   ' A   scalable   time - domain   biosensor   array   using   logarithmic   cyclic   time - attenuation - based   TDC   for   high - resolution   and   large - scale   bio - imaging ' } 
{ ' abstract ' :   ' Compared   to   current   mobile   networks ,   next - generation   mobile   networks   are   expected   to   support   higher   numbers   of   simultaneously   connected   devices   and   to   achieve   higher   system   spectrum   efficiency   and   lower   power   consumption .   To   achieve   these   goals ,   we   study   the   multi - sharing   device - to - device   ( D2D )   communication ,   which   allows   any   cellular   user   equipment   to   share   its   radio   resource   with   multiple   D2D   devices .   We   jointly   consider   resource   block   reuse   and   power   control   and   then   develop   the   MISS   algorithm .   Simulation   results   show   that   MISS   performs   very   well   in   terms   of   transmission   power   consumption ,   system   throughput ,   and   the   number   of   permitted   D2D   devices . ' ,   ' title ' :   ' Joint   Resource   Block   Reuse   and   Power   Control   for   Multi - Sharing   Device - to - Device   Communication ' } 
{ ' abstract ' :   ' This   paper   is   concerned   with   event - triggered   H ∞ H ∞   filtering   for   delayed   neural   networks   via   sampled   data .   A   novel   event - triggered   scheme   is   proposed ,   which   can   lead   to   a   significant   reduction   of   the   information   communication   burden   in   the   network ;   the   feature   of   this   scheme   is   that   whether   or   not   the   sampled   data   should   be   transmitted   is   determined   by   the   current   sampled   data   and   the   error   between   the   current   sampled   data   and   the   latest   transmitted   data .   By   constructing   a   proper   Lyapunov – Krasovskii   functional ,   utilizing   the   reciprocally   convex   combination   technique   and   Jensen ’ s   inequality   sufficient   conditions   are   derived   to   ensure   that   the   resultant   filtering   error   system   is   asymptotically   stable .   Based   on   the   derived   H ∞ H ∞   performance   analysis   results ,   the   H ∞ H ∞   filter   design   is   formulated   in   terms   of   Linear   Matrix   Inequalities   ( LMIs ) .   Finally ,   the   proposed   stability   conditions   are   demonstrated   with   numerical   example . ' ,   ' title ' :   ' Event - triggered   H   ∞   filtering   for   delayed   neural   networks   via   sampled - data ' } 
{ ' abstract ' :   ' For   the   double   integrator   with   matched   Lipschitz   disturbances   we   propose   a   continuous   homogeneous   controller   providing   finite - time   stability   of   the   origin .   The   disturbance   is   compensated   exactly   in   finite   time   using   a   discontinuous   function   through   an   integral   action .   Since   the   controller   is   dynamic ,   the   closed   loop   is   a   third   order   system   that   achieves   a   third   order   sliding   mode   in   the   steady   state .   The   stability   and   robustness   properties   of   the   controller   are   proven   using   a   smooth   and   homogeneous   strict   Lyapunov   function   ( LF ) .   In   a   first   stage ,   the   gains   of   the   controller   and   the   LF   are   designed   using   a   method   based   on   Polya ’ s   Theorem .   In   a   second   stage   the   controller ’ s   gains   are   adjusted   through   a   sum   of   squares   representation   of   the   LF . ' ,   ' title ' :   ' Design   of   Continuous   Twisting   Algorithm ' } 
{ ' abstract ' :   ' Big   data   is   now   rapidly   expanding   into   various   domains   such   as   banking ,   insurance   and   e - commerce .   Data   analysis   and   related   studies   have   attracted   more   attentions .   In   health   insurance ,   abuse   of   diagnosis   is   one   of   the   key   fraud   problems ,   which   damages   the   interests   of   insured   people .   To   address   this   issue ,   numbers   of   studies   have   focused   on   this   topic .   This   paper   develops   a   healthcare   fraud   detection   approach   based   on   the   trustworthiness   of   doctors   to   distinguish   fraud   cases   from   normal   records .   Compared   to   conventional   methods ,   our   approach   can   detect   healthcare   fraud   in   a   good   accuracy   by   only   little   feature   information   from   healthcare   data   without   the   violation   of   privacy .   This   approach   combines   a   weighted   HITS   algorithm   with   a   frequent   pattern   mining   algorithm   to   calculate   a   rational   treatment   model   of   a   certain   disease .   In   addition ,   this   paper   also   introduces   the   copy   precision   behavior   in   the   treatment   sequences   of   patients ,   which   is   a   critical   metric   to   learn   the   trustworthiness   of   doctors .   The   numerical   validation   with   a   healthcare   dataset   demonstrates   that   healthcare   fraud   by   misdiagnosis   in   healthcare   treatments   can   be   successfully   detected   by   employing   the   developed   fraud   detection   approach . ' ,   ' title ' :   ' Healthcare   Fraud   Detection   Based   on   Trustworthiness   of   Doctors ' } 
{ ' abstract ' :   ' In   this   paper   we   study   data   collection   in   an   energy   renewable   sensor   network   for   scenarios   such   as   traffic   monitoring   on   busy   highways ,   where   sensors   are   deployed   along   a   predefined   path   ( the   highway )   and   a   mobile   sink   travels   along   the   path   to   collect   data   from   one - hop   sensors   periodically .   As   sensors   are   powered   by   renewable   energy   sources ,   time - varying   characteristics   of   ambient   energy   sources   poses   great   challenges   in   the   design   of   efficient   routing   protocols   for   data   collection   in   such   networks .   In   this   paper   we   first   formulate   a   novel   data   collection   maximization   problem   by   adopting   multi - rate   data   transmissions   and   performing   transmission   time   slot   scheduling ,   and   show   that   the   problem   is   NP - hard .   We   then   devise   an   offline   algorithm   with   a   provable   approximation   ratio   for   the   problem   by   exploiting   the   combinatorial   property   of   the   problem ,   assuming   that   the   harvested   energy   at   each   node   is   given   and   link   communications   in   the   network   are   reliable .   We   also   extend   the   proposed   algorithm   by   minor   modifications   to   a   general   case   of   the   problem   where   the   harvested   energy   at   each   sensor   is   not   known   in   advance   and   link   communications   are   not   reliable .   We   thirdly   develop   a   fast ,   scalable   online   distributed   algorithm   for   the   problem   in   realistic   sensor   networks   in   which   neither   the   global   knowledge   of   the   network   topology   nor   sensor   profiles   such   as   sensor   locations   and   their   harvested   energy   profiles   is   given .   Furthermore ,   we   also   consider   a   special   case   of   the   problem   where   each   node   has   only   a   fixed   transmission   power ,   for   which   we   propose   an   exact   solution   to   the   problem .   We   finally   conduct   extensive   experiments   by   simulations   to   evaluate   the   performance   of   the   proposed   algorithms .   Experimental   results   demonstrate   that   the   proposed   algorithms   are   efficient   and   the   solutions   obtained   are   fractional   of   the   optimum . ' ,   ' title ' :   ' Data   Collection   Maximization   in   Renewable   Sensor   Networks   via   Time - Slot   Scheduling ' } 
{ ' abstract ' :   ' An   increasing   number   of   businesses   are   migrating   their   IT   operations   to   the   cloud .   Likewise   there   is   an   increased   emphasis   on   data   analytics   based   on   multiple   datasets   and   sources   to   derive   information   not   derivable   when   a   dataset   is   mined   in   isolation .   While   ensuring   security   of   data   and   computation   outsourced   to   a   third   party   cloud   service   provider   is   in   itself   challenging ,   supporting   mash - ups   and   analytics   of   data   from   different   parties   hosted   across   different   services   is   even   more   so .   In   this   paper   we   propose   a   cloud - based   service   allowing   multiple   parties   to   perform   secure   multi - party   secure   sum   computation   using   their   clouds   as   delegates .   Our   scheme   provides   data   privacy   both   from   the   delegates   as   well   as   from   the   other   data   owners   under   a   lazy - and - curious   adversary   ( semi - honest )   model .   We   then   describe   how   such   a   secure   sum   primitive   may   be   used   in   various   collaborative ,   cloud - based   distributed   data   mining   tasks   ( classification ,   association   rule   mining   and   clustering ) .   We   implement   a   prototype   and   benchmark   the   service ,   both   as   a   stand - alone   secure   sum   service ,   and   as   a   building   block   for   more   complex   analytics .   The   results   suggest   reasonable   overhead   and   demonstrate   the   practicality   of   carrying   out   privacy   preserved   distributed   analytics   despite   migrating   ( encrypted )   data   to   pos -   sibly   different   and   untrusted   ( semi - honest )   cloud   services . ' ,   ' title ' :   ' Delegated   Secure   Sum   Service   for   Distributed   Data   Mining   in   Multi - Cloud   Settings ' } 
{ ' abstract ' :   ' This   paper   fundamentally   investigates   the   performance   of   evolutionary   multiobjective   optimization   ( EMO )   algorithms   for   computationally   hard   0 - 1   combinatorial   optimization ,   where   a   strict   theoretical   analysis   is   generally   out   of   reach   due   to   the   high   complexity   of   the   underlying   problem .   Based   on   the   examination   of   problem   features   from   a   multiobjective   perspective ,   we   improve   the   understanding   of   the   efficiency   of   a   simple   dominance - based   EMO   algorithm   with   unbounded   archive   for   multiobjective   NK - landscapes   with   correlated   objective   values .   More   particularly ,   we   adopt   a   statistical   approach ,   based   on   simple   and   multiple   linear   regression   analysis ,   to   enquire   the   expected   running   time   of   global   SEMO   with   restart   for   identifying   a   ( 1 + e ) - approximation   of   the   Pareto   set   for   small - size   enumerable   instances .   Our   analysis   provides   further   insights   on   the   EMO   search   behavior   and   on   the   most   important   features   that   characterize   the   difficulty   of   an   instance   for   this   class   of   problems   and   algorithms . ' ,   ' title ' :   ' A   feature - based   performance   analysis   in   evolutionary   multiobjective   optimization ' } 
{ ' abstract ' :   ' Functional   biological   sequences ,   which   typically   come   in   families ,   have   retained   some   level   of   similarity   and   function   during   evolution .   Finding   consensus   regions ,   alignment   of   sequences ,   and   identifying   the   relationship   between   a   sequence   and   a   family   allow   inferences   about   the   function   of   the   sequences .   Profile   hidden   Markov   models   ( HMMs )   are   generally   used   to   identify   those   relationships .   A   profile   HMM   can   be   trained   on   unaligned   members   of   the   family   using   conventional   algorithms   such   as   Baum - Welch ,   Viterbi ,   and   their   modifications .   The   overall   quality   of   the   alignment   depends   on   the   quality   of   the   trained   model .   Unfortunately ,   the   conventional   training   algorithms   converge   to   suboptimal   models   most   of   the   time .   This   work   proposes   a   training   algorithm   that   early   identifies   many   imperfect   models .   The   method   is   based   on   the   Simulated   Annealing   approach   widely   used   in   discrete   optimization   problems .   The   training   algorithm   is   implemented   as   a   component   in   HMMER .   The   performance   of   the   algorithm   is   discussed   on   protein   sequence   data . ' ,   ' title ' :   ' Simulated   annealing   algorithm   with   biased   neighborhood   distribution   for   training   profile   models ' } 
{ ' abstract ' :   ' The   Canny   algorithm   is   a   well   known   edge   detector   that   is   widely   used   in   the   previous   processing   stages   in   several   algorithms   related   to   computer   vision .   An   alternative ,   the   LIP - Canny   algorithm ,   is   based   on   a   robust   mathematical   model   closer   to   the   human   vision   system ,   obtaining   better   results   in   terms   of   edge   detection .   In   this   work   we   describe   LIP - Canny   algorithm   under   the   perspective   from   its   parallelization   and   optimization   by   using   the   NVIDIA   CUDA   framework .   Furthermore ,   we   present   comparative   results   between   an   implementation   of   this   algorithm   using   NVIDIA   CUDA   and   the   analogue   using   a   C / C++   approach . ' ,   ' title ' :   ' Parallelizing   and   optimizing   LIP - canny   using   NVIDIA   CUDA ' } 
{ ' abstract ' :   ' This   paper   presents   an   efficient   Bayesian   blind   multiuser   receiver   for   long   code   multipath   CDMA   systems .   The   proposed   receiver   employs   the   adaptive   sampling   method   for   the   Bayesian   inference   procedure   to   estimate   the   data   symbols   and   multipath   parameters .   Compared   to   the   other   reported   Bayesian   Monte   Carlo   receivers   for   long   code   multipath   CDMA   systems ,   the   proposed   one   achieves   a   faster   convergence   and   a   lower   computational   complexity   to   attain   comparable   performance .   Simulation   results   are   presented   to   demonstrate   the   effectiveness   of   the   proposed   Bayesian   blind   multiuser   receiver . ' ,   ' title ' :   ' Blind   Multiuser   Detection   for   Long   Code   Multipath   DS - CDMA   Systems   with   Bayesian   MC   Techniques ' } 
{ ' abstract ' :   ' Spreadsheets   are   by   far   the   most   prominent   example   of   end - user   programs   of   ample   size   and   substantial   structural   complexity .   In   addition ,   spreadsheets   are   usually   not   tested   very   rigorously   and   thus   comprise   faults .   Locating   faults   is   a   hard   task   due   to   the   size   and   the   structure ,   which   is   usually   not   directly   visible   to   the   user ,   i . e . ,   the   functions   are   hidden   behind   the   cells   and   only   the   computed   values   are   presented .   Hence ,   there   is   a   strong   need   for   debugging   support .   In   this   paper ,   we   adapt   three   program - debugging   approaches   that   have   been   designed   for   more   traditional   procedural   or   object - oriented   programming   languages .   These   techniques   are   Spectrum - based   Fault   Localization ,   Spectrum - Enhanced   Dynamic   Slicing ,   and   Constraint - based   Debugging .   Beside   the   theoretical   foundations ,   we   present   a   more   sophisticated   empirical   evaluation   including   a   comparison   of   these   approaches .   The   empirical   evaluation   shows   that   Sfl   ( Spectrum - based   Fault   Localization )   and   Sendys   ( Spectrum   ENhanced   Dynamic   Slicing )   are   the   most   promising   techniques . ' ,   ' title ' :   ' On   the   empirical   evaluation   of   fault   localization   techniques   for   spreadsheets ' } 
{ ' abstract ' :   ' This   work   provides   elements   to   highlight   the   reliability   challenges   related   to   the   technology   scaling   and   the   BTI   variability .   Through   main   milestones   including   device   reliability   scaling   model   ( for   both   mean   and   spread ) ,   a   discussion   on   the   physical   origin   of   BTI   variability   and   a   digital   IP   failure   rate   analytical   model ,   the   evolution   of   digital   IP   failure   rates   along   the   ITRS   scaling   roadmap   is   assessed .   and   an   analysis   of   the   ITRS   roadmap   on   digital   IP   failure   rates .   This   study   offers   new   perspectives   towards   product   hardening   and   qualification   with   respect   to   both   fresh   and   BTI - related   local   variability ,   especially   in   context   where   Adaptive   Voltage   Scaling   ( AVS )   is   used   to   compensate   for   process   centerings . ' ,   ' title ' :   ' From   BTI   variability   to   product   failure   rate :   A   technology   scaling   perspective ' } 
{ ' abstract ' :   ' In   this   paper   we   discuss   the   problem   of   calculating   the   reachable   states   of   a   dynamical   system   defined   by   ordinary   differential   equations   or   inclusions .   We   present   a   prototype   system   for   approximating   this   set   and   demonstrate   some   experimental   results . ' ,   ' title ' :   ' Reachability   Analysis   via   Face   Lifting ' } 
{ ' abstract ' :   ' By   introducing   the   new   concepts   of   fuzzy     β   - covering   and   fuzzy     β   - neighborhood ,   we   define   two   new   types   of   fuzzy   covering   rough   set   models   which   can   be   regarded   as   bridges   linking   covering   rough   set   theory   and   fuzzy   rough   set   theory .   We   show   the   properties   of   the   two   models ,   and   reveal   the   relationships   between   the   two   models   and   some   others .   Moreover ,   we   present   the   matrix   representations   of   the   newly   defined   lower   and   upper   approximation   operators   so   that   the   calculation   of   lower   and   upper   approximations   of   subsets   can   be   converted   into   operations   on   matrices .   Finally ,   we   generalize   the   models   and   their   matrix   representations   to     L   - fuzzy   covering   rough   sets   which   are   defined   over   fuzzy   lattices . ' ,   ' title ' :   ' Two   fuzzy   covering   rough   set   models   and   their   generalizations   over   fuzzy   lattices ' } 
{ ' abstract ' :   ' Mobile   applications   are   becoming   complex   software   systems   that   must   be   developed   quickly   and   evolve   regularly   to   fit   new   user   requirements   and   execution   contexts .   However ,   addressing   these   constraints   may   result   in   poor   design   choices ,   known   as   antipatterns ,   which   may   degrade   software   quality   and   performance .   Thus ,   the   automatic   detection   of   antipatterns   is   an   important   activity   that   eases   the   future   maintenance   and   evolution   tasks .   Moreover ,   it   helps   developers   to   refactor   their   applications   and   thus ,   to   improve   their   quality .   While   antipatterns   are   well - known   in   object - oriented   applications ,   their   study   in   mobile   applications   is   still   in   their   infancy .   In   this   paper ,   we   presents   a   tooled   approach ,   called   P   aprika   ,   to   analyze   Android   applications   and   to   detect   object - oriented   and   Android - specific   antipatterns   from   binaries   of   applications . ' ,   ' title ' :   ' An   approach   to   detect   Android   antipatterns ' } 
{ ' abstract ' :   ' In   this   paper   we   present   a   new   method   for   object   categorization .   Firstly   an   image   representation   is   obtained   by   the   proposed   hierarchical   learning   method   consisting   of   alternating   between   local   coding   and   maximum   pooling   operations ,   where   the   local   coding   operation   induces   discrimination   while   the   image   descriptor   and   maximum   pooling   operation   induces   invariance   in   hierarchical   architecture .   Then   the   obtained   effective   image   representation   is   passed   to   a   linear   classifier   which   is   suitable   for   large   databases   for   object   categorization .   We   have   demonstrated   that   the   proposed   method   is   robust   to   image   variations   and   has   low   sample   complexity . ' ,   ' title ' :   ' Object   categorization   based   on   hierarchical   learning ' } 
{ ' abstract ' :   ' We   have   previously   proposed   a   howling   canceller   which   cancels   howling   by   using   a   cascade   notch   filter   designed   from   a   distance   between   a   loudspeaker   and   a   microphone .   This   method   utilizes   a   pilot   signal   to   estimate   the   distance .   In   this   paper ,   we   introduce   two   methods   into   the   distance - based   howling   canceller   to   improve   speech   quality .   The   first   one   is   an   adaptive   cascade   notch   filter   which   adaptively   adjusts   the   nulls   to   eliminate   howling   and   to   keep   speech   components .   The   second   one   is   a   silent   pilot   signal   whose   frequencies   exist   in   the   ultrasonic   band ,   and   it   is   inaudible   while   on   transmission .   We   implement   the   proposed   howling   canceller   on   a   DSP   to   evaluate   its   capability .   The   experimental   results   show   that   the   proposed   howling   canceller   improves   speech   quality   in   comparison   to   the   conventional   one . ' ,   ' title ' :   ' A   High   Speech   Quality   Distance - Based   Howling   Canceller   with   Adaptive   Cascade   Notch   Filter   and   Silent   Pilot   Signal ' } 
{ ' abstract ' :   ' Purpose   –   This   paper   aims   to   look   at   how   varying   terminology   is   used   on   school   library   web   sites   and   how   that   compares   to   student   preferences . Design / methodology / approach   –   Provides   research   conduced   by   surveying   practicing   school   librarians   and   k ‐ 12   students . Findings   –   Terminology   varies   greatly   on   school   library   web   sites .   Further ,   students   prefer   common   language   use . Practical   implications   –   Practicing   librarians   may   consider   revising   their   web   sites   in   order   to   make   them   more   accessible   for   their   students . Originality / value   –   This   paper   provides   original   research   into   school   library   web   sites ,   an   area   that   is   lacking . ' ,   ' title ' :   ' School   library   web   site   terminology ' } 
{ ' abstract ' :   ' Recently ,   numerous   multireceiver   identity - based   encryption   or   identity - based   broadcast   encryption   schemes   have   been   introduced   with   bilinear   pairing   and   probabilistic   map - to - point   MTP   function .   As   the   bilinear   pairing   and   MTP   functions   are   expensive   operations ,   any   cryptographic   schemes   based   on   these   operations   experience   high   computational   burden .   The   certificateless   public   key   cryptography   sidesteps   the   private   key   escrow   problem   occurring   in   identity - based   cryptosystem   and   certificate   management   troubles   of   certificate   authority - based   public   key   cryptography   CA - PKC .   We   observed   that   certificateless   multireceiver   encryption   CL - MRE   scheme   without   pairing   and   MTP   hash   function   has   not   yet   been   considered   in   the   literature .   In   this   paper ,   we   proposed   a   bilinear   pairing   and   MTP   hash - function - free   CL - MRE   scheme   with   chosen   ciphertext   attack   resilience .   The   detailed   analyses   provide   evidence   that   our   scheme   achieves   forward   secrecy ,   backward   secrecy ,   and   low   computation   costs   than   others .   The   scheme   also   provides   confidentiality   of   the   message   and   receiver   anonymity   in   the   random   oracle   model   with   the   hardness   of   computational   Diffie - Hellman   problem .   Copyright   ©   2014   John   Wiley   &   Sons ,   Ltd . ' ,   ' title ' :   ' Anonymous   and   provably   secure   certificateless   multireceiver   encryption   without   bilinear   pairing ' } 
{ ' abstract ' :   ' We   study   the   problem   of   approximating   one - dimensional   nonintegrable   codistributions   by   integrable   ones   and   apply   the   resulting   approximations   to   approximate   feedback   linearization   of   single - input   systems .   The   approach   derived   in   this   paper   allows   a   linearizable   nonlinear   system   to   be   found   that   is   close   to   the   given   system   in   a   least - squares   ( L2 )   sense .   A   linearly   controllable   single - input   affine   nonlinear   system   is   feedback   linearizable   if   and   only   if   its   characteristic   distribution   is   involutive   ( hence   integrable )   or ,   equivalently ,   any   characteristic   one - form   ( a   one - form   that   annihilates   the   characteristic   distribution )   is   integrable .   We   study   the   problem   of   finding   ( least - squares   approximate )   integrating   factors   that   make   a   fixed   characteristic   one - form   close   to   being   exact   in   anL2   sense .   A   given   one - form   can   be   decomposed   into   exact   and   inexact   parts   using   the   Hodge   decomposition .   We   derive   an   upper   bound   on   the   size   of   the   inexact   part   of   a   scaled   characteristic   one - form   and   show   that   a   least - squares   integrating   factor   provides   the   minimum   value   for   this   upper   bound .   We   also   consider   higher - order   approximate   integrating   factors   that   scale   a   nonintegrable   one - form   in   a   way   that   the   scaled   form   is   closer   to   being   integrable   inL2   together   with   some   derivatives   and   derive   similar   bounds   for   the   inexact   part .   This   allows   a   linearizable   nonlinear   system   that   is   close   to   the   given   system   in   a   least - squares   ( L2 )   sense   together   with   some   derivatives   to   be   found .   The   Sobolev   embedding   techniques   allow   us   to   obtain   an   upper   bound   on   the   uniform   ( L ∞ )   distance   between   the   nonlinear   system   and   its   linearizable   approximation . ' ,   ' title ' :   ' Least - squares   integration   of   one - dimensional   codistributions   with   application   to   approximate   feedback   linearization ' } 
{ ' abstract ' :   ' Latent   sector   errors   in   disk   drives   affect   only   a   few   data   sectors .   They   occur   silently   and   are   detected   only   when   the   affected   area   is   accessed   again .   If   a   latent   error   is   detected   while   the   storage   system   is   operating   under   reduced   redundancy ,   i . e . ,   during   a   RAID   rebuild ,   then   data   loss   may   occur .   Various   features   such   as   scrubbing   and   intra - disk   data   redundancy   are   proposed   to   detect   and / or   recover   from   latent   errors   and   avoid   data   loss .   While   such   features   enhance   data   availability   in   the   storage   system ,   their   execution   may   cause   performance   degradation .   In   this   paper ,   we   evaluate   the   effectiveness   of   scrubbing   and   intra - disk   data   redundancy   in   improving   data   availability   while   the   overall   goal   is   to   maintain   user   performance   within   predefined   bounds .   We   show   that   by   treating   them   as   low   priority   background   activities   and   scheduling   them   efficiently   during   idle   times ,   these   features   remain   performance - wise   transparent   to   the   storage   system   user   while   still   improving   data   reliability .   Detailed   trace - driven   simulations   show   that   the   mean   time   to   data   loss   ( MTTDL )   improves   by   up   to   5   orders   of   magnitude   if   these   features   are   implemented   independently .   By   scheduling   concurrently   both   scrubbing   and   intra - disk   parity   updates   during   idle   times   in   disk   drives ,   MTTDL   improves   by   as   much   as   8   orders   of   magnitude . ' ,   ' title ' :   ' Enhancing   data   availability   in   disk   drives   through   background   activities ' } 
{ ' abstract ' :   ' Financial   crisis   forecasting   has   been   a   long - standing   challenge   that   often   involves   couplings   between   indicators   of   multiple   markets .   Such   couplings   include   implicit   relations   that   might   not   be   effectively   detected   from   raw   market   observations .   However ,   most   methods   for   crisis   forecasting   rely   directly   on   market   observations   and   might   not   detect   the   hidden   interactions   between   markets .   To   this   end ,   the   authors   explore   coupled   market   state   analysis   ( CMSA ) ,   assuming   that   the   observations   of   markets   are   governed   by   a   collection   of   intra -   and   intercoupled   hidden   market   states .   Accordingly ,   they   built   a   forecaster   based   on   these   coupled   market   states   instead   of   observations . ' ,   ' title ' :   ' Financial   Crisis   Forecasting   via   Coupled   Market   State   Analysis ' } 
{ ' abstract ' :   ' In   this   paper ,   an   “ intelligent ”   isolated   intersection   control   system   was   developed .   The   developed   “ intelligent ”   system   makes   “ real   time ”   decisions   as   to   whether   to   extend   ( and   how   much )   current   green   time .   The   model   developed   is   based   on   the   combination   of   the   dynamic   programming   and   neural   networks .   Many   tests   show   that   the   outcome   ( the   extension   of   the   green   time )   of   the   proposed   neural   network   is   nearly   equal   to   the   best   solution .   Practically   negligible   CPU   times   were   achieved ,   and   were   thus   absolutely   acceptable   for   the   “ real   time ”   application   of   the   developed   algorithm . ' ,   ' title ' :   ' Dynamic   programming — neural   network   real - time   traffic   adaptive   signal   control   algorithm ' } 
{ ' abstract ' :   ' This   issue   features   expanded   versions   of   articles   selected   from   the   2014   AAAI   Conference   on   Innovative   Applications   of   Artificial   Intelligence   held   in   Quebec   City ,   Canada .   We   present   a   selection   of   four   articles   describing   deployed   applications   plus   two   more   articles   that   discuss   work   on   emerging   applications . ' ,   ' title ' :   ' Introduction   to   the   Special   Issue   on   Innovative   Applications   of   Artificial   Intelligence   2014 ' } 
{ ' abstract ' :   ' Although   frequently   used   in   fractal   compression   quadrant - based   classification   exhibits   a   significant   defect   which   has   not   been   described   in   the   literature .   We   give   an   efficient   solution   to   this   problem   by   controlling   the   class   structure   based   on   an   adaptive   threshold .   This   makes   this   classification   technique   a   very   efficient   and   competitive   one   also   for   block   matching   motion   compensation   algorithms   in   video   coding . ' ,   ' title ' :   ' Resolving   a   defect   in   quadrant - based   classification   for   fast   block - matching ' } 
{ ' abstract ' :   ' Where   there   are   infinitely   many   possible   basic   states   of   the   world ,   a   standard   probability   function   must   assign   zero   probability   to   each   state   –   since   any   finite   probability   would   sum   to   over   one .   This   generates   problems   for   any   decision   theory   that   appeals   to   expected   utility   or   related   notions .   For   it   leads   to   the   view   that   a   situation   in   which   one   wins   a   million   dollars   if   any   of   a   thousand   of   the   equally   probable   states   is   realized   has   an   expected   value   of   zero   ( since   each   such   state   has   probability   zero ) .   But   such   a   situation   dominates   the   situation   in   which   one   wins   nothing   no   matter   what   ( which   also   has   an   expected   value   of   zero ) ,   and   so   surely   is   more   desirable .   I   formulate   and   defend   some   principles   for   evaluating   options   where   standard   probability   functions   cannot   strictly   represent   probability   –   and   in   particular   for   where   there   is   an   infinitely   spread ,   uniform   distribution   of   probability .   The   principles   appeal   to   standard   probability   functions ,   but   overcome   at   least   some   of   their   limitations   in   such   cases . ' ,   ' title ' :   ' Standard   decision   theory   corrected ' } 
{ ' abstract ' :   ' Backed   by   the   European   Commission ,   a   consortium   of   partners   from   European   industry ,   financial   institutions ,   and   academia   has   embarked   on   a   research   project   to   develop   the   fundamentals   of   secure   electronic   commerce .   The   goal   of   the   9 - million   ECU   project ,   SEMPER   ( Secure   Electronic   Marketplace   for   Europe ) ,   is   to   provide   the   first   open   and   comprehensive   solutions   for   secure   commerce   over   the   Internet   and   other   public   information   networks .   We   describe   the   objectives   and   summarise   the   initial   architecture   of   SEMPER .   A   wide   range   of   businesses   are   rapidly   moving   to   explore   the   huge   potential   of   net -   worked   information   systems ,   especially   with   the   Internet - based   WWW   ( World - wide   Web ) .   The   Internet ,   which   already   connects   more   than   3   million   computers   and   a   sub -   stantially   larger   number   of   users ,   is   growing   at   a   breathtaking   pace   with   thousands   of   newcomers   every   day .   Although   the   Internet   has   its   roots   in   academia   and   is   still   domi -   nated   by   free - of - charge   information ,   dramatic   changes   are   expected   in   the   near   future .   For   instance ,   the   WWW   will   be   used   for   a   wide   variety   of   electronic   commerce   such   as   on - line   trade   or   delivery   of   advanced   multimedia   information   services .   The   evolution   of   broadband   networks   and   " information   highways "   will   intensify   this   trend .   The   need   for   secure   transactions   in   this   new   business   environment ,   which   involves   networks   available   to   the   general   public ,   has   triggered   a   number   of   related   efforts .   These   initial   developments   are   based   almost   exclusively   in   the   US   and   most   of   them   are   limited   to   proprietary ,   or   otherwise   closed   solutions ,   involving   only   electronic   payment   issues .   In   contrast ,   SEMPER   is   directed   towards   a   comprehensive   solution   for   secure   electronic   commerce ,   considering   legal ,   commercial ,   social ,   and   technical   requirements   as   well   as   different   options   for   an   electronic   marketplace . ' ,   ' title ' :   ' Development   of   a   Secure   Electronic   Marketplace   for   Europe ' } 
{ ' abstract ' :   ' Through   the   use   of   a   global   geometric   symmetry ,   detection   ellipses   are   proposed   in   this   paper .   Based   on   the   geometric   symmetry ,   the   proposed   method   first   locates   candidates   of   ellipses   centers .   In   the   meantime ,   according   to   these   candidate   centers ,   all   feature   points   in   an   input   image   are   grouped   into   several   subimages .   Then ,   for   each   subimage ,   by   using   geometric   properties   again ,   all   ellipses   are   extracted .   The   method   significantly   reduces   the   time   required   to   evaluate   all   possible   parameters   without   using   edge   direction   information .   Experimental   results   are   given   to   show   the   correctness   and   effectiveness   of   the   proposed   method . ' ,   ' title ' :   ' Detection   ellipses   by   finding   lines   of   symmetry   in   the   images   via   an   hough   transform   applied   to   straight   lines ' } 
{ ' abstract ' :   ' Automatic   crawling   of   Rich   Internet   Applications   ( RIAs )   is   a   challenge   because   client - side   code   modifies   the   client   dynamically ,   fetch -   ing   server - side   data   asynchronously .   Most   existing   solutions   model   RIAs   as   state   machines   with   DOMs   as   states   and   JavaScript   events   execution   as   transitions .   This   approach   fails   when   used   with   " real - life " ,   complex   RIAs ,   because   the   size   of   the   produced   model   is   much   too   large   to   be   practical .   In   this   paper ,   we   propose   a   new   method   to   crawl   AJAX - based   RIAs   in   an   efficient   manner   by   detecting   " components " ,   which   are   areas   of   the   DOM   that   are   independent   from   each   other ,   and   by   crawling   each   component   separately .   This   leads   to   a   dramatic   reduction   of   the   required   state   space   for   the   model ,   without   loss   of   content   coverage .   Our   method   does   not   require   prior   knowledge   of   the   RIA   nor   predefined   definition   of   components .   Instead ,   we   infer   the   components   by   observing   the   be -   havior   of   the   RIA   during   crawling .   Our   experimental   results   show   that   our   method   can   index   quickly   and   completely   industrial   RIAs   that   are   simply   out   of   reach   for   traditional   methods . ' ,   ' title ' :   ' Indexing   Rich   Internet   Applications   Using   Components - Based   Crawling ' } 
{ ' abstract ' :   ' One   important   aspect   of   constructing   an   overlay   network   is   how   to   exploit   network   locality   in   the   underlying   network .   In   this   paper ,   we   propose   a   scalable   protocol   for   constructing   an   overlay   network   that   takes   account   of   locality   of   network   hosts .   The   constructed   overlay   network   can   significantly   decrease   the   communication   cost   between   end - hosts .   Our   simulation   results   show   that   the   average   distance   between   a   pair   of   hosts   in   the   constructed   overlay   network   is   only   about   11%   of   the   one   in   a   traditional ,   randomly   connected   overlay   network .   Furthermore ,   our   proposed   overlay   considered   to   be   more   scalable   than   tree - based   or   mesh - based   overlays . ' ,   ' title ' :   ' Measurement - based   construction   of   locality - aware   overlay   networks ' } 
{ ' abstract ' :   ' This   paper   presents   a   low   cost ,   flexible   and   customizable   delay   measurement   system   developed   to   assess   the   performance   of   the   VTPE - hBEB   protocol .   The   proposed   system   can   be   used   to   evaluate   other   communication   protocols   as   well   as   to   measure   the   delay   between   two   repetitive   events . ' ,   ' title ' :   ' Delay   measurement   system   for   real - time   serial   data   streams ' } 
{ ' abstract ' :   " Service   robots   have   become   increasingly   important   subjects   in   our   lives .   However ,   they   are   still   facing   problems   like   adaptability   to   their   users .   While   major   work   has   focused   on   intelligent   service   robots ,   the   proposed   approaches   were   mostly   user   independent .   Our   work   is   part   of   the   FUI - RoboPopuli   project ,   which   concentrates   on   endowing   entertainment   companion   robots   with   adaptive   and   social   behaviour .   In   particular ,   we   are   interested   in   robots   that   are   able   to   learn   and   plan   so   that   they   adapt   and   personalize   their   behaviour   according   to   their   users .   Markov   Decision   Processes   ( MDPs )   are   largely   used   for   adaptive   robots   applications .   However ,   one   challenging   point   is   reducing   the   sample   complexity   required   to   learn   an   MDP   model ,   including   the   reward   function .   In   this   article ,   we   present   our   contribution   regarding   the   representation   and   the   learning   of   the   reward   function   through   analysing   interaction   traces   ( i . e .   the   interaction   history   between   the   robot   and   their   users ,   including   users '   feedback ) .   Our   approach   permits   to   generalise   the   learned   rewards   so   that   when   new   users   are   introduced ,   the   robot   may   quickly   adapt   using   what   it   learned   from   previous   experiences   with   other   users .   We   propose ,   in   this   article ,   two   algorithms   to   learn   the   reward   function .   The   first   is   direct   and   certain ,   the   robot   applies   with   a   user   what   it   learned   during   interaction   with   same   kind   of   users   ( i . e .   users   with   similar   profiles ) .   The   second   algorithm   generalises   what   it   learns   to   be   applied   to   all   kinds   of   users .   Through   simulation ,   we   show   that   the   generalised   algorithm   converges   to   an   optimal   reward   function   with   less   than   half   the   samples   needed   by   the   direct   algorithm . " ,   ' title ' :   " Adaptive   and   Personalised   Robots   -   Learning   from   Users '   Feedback " } 
{ ' abstract ' :   " Researches   of   sensor   networks   collecting   patients '   data   with   computerized   triage   tags ,   called   Triage   Network ,   are   attracting   attention .   The   listening   power   used   in   triage   tags   is   the   major   factor   of   lots   of   energy   consumption ,   and   consumption   of   energy   increases   when   sensor   nodes   always   communicate   with   other   nodes   in   active   state .   Hence ,   we   suppose   that   sensor   nodes   are   put   to   sleep   periodically   to   avoid   running   out   of   battery .   However ,   some   nodes   have   mobility   and   nodes   secede   from   the   network   according   to   patients   conditions   in   Triage   Network .   The   paths   are   failed   and   it   is   needed   to   reconstruct   paths   when   these   forwarding   nodes   move   or   secede   from   network .   Therefore ,   data   arrival   ratio   decreases   and   consumption   of   battery   increases   due   to   reconstruction   of   other   paths .   In   this   paper ,   we   propose   a   data   collection   method   using   two   types   of   forwarding   nodes ,   Stable   Nodes   and   Energy   Efficient   Nodes .   This   method   uses   two   types   of   forwarding   nodes   according   to   priority   of   data   and   avoids   loss   of   high   priority   data ,   improves   the   data   arrival   ratio   and   saves   the   energy   consumption .   We   evaluate   the   proposed   method   and   show   its   effectiveness   using   computer   simulations . " ,   ' title ' :   ' Data   collection   method   using   two   types   of   forwarding   nodes   for   energy   saving   in   triage   network ' } 
{ ' abstract ' :   ' This   paper   introduces   Golay - paired   Hadamard   matrices   for   fast   compressed   sensing   of   sparse   signals   in   the   time   or   spectral   domain .   These   sampling   operators   feature   low - memory   requirement ,   hardware - friendly   implementation   and   fast   computation   in   reconstruction .   We   show   that   they   require   a   nearly   optimal   number   of   measurements   for   faithful   reconstruction   of   a   sparse   signal   in   the   time   or   frequency   domain .   Simulation   results   demonstrate   that   the   proposed   sensing   matrices   offer   a   reconstruction   performance   similar   to   that   of   fully   random   matrices . ' ,   ' title ' :   ' Golay   meets   Hadamard :   Golay - paired   Hadamard   matrices   for   fast   compressed   sensing ' } 
{ ' abstract ' :   ' In   this   technical   note ,   the   problem   of   finite - time   output   regulation   control   for   a   class   of   disturbed   system   under   mismatching   condition   is   investigated   via   a   composite   control   design   manner .   The   composite   controller   is   developed   by   using   a   finite   time   control   technique   and   a   finite   time   disturbance   observer   ( FTDO ) .   A   key   idea   is   to   design   virtual   control   laws   based   on   estimation   values   of   the   disturbances   and   the   ith   ( 1 ≤ i ≤ n - 1   where   n   is   the   order   of   the   system )   order   derivative   of   disturbances .   Finite   time   stability   analysis   for   the   augmented   system   is   presented   by   means   of   Lyapunov   stability   theorems ,   which   shows   that   the   system   output   is   regulated   to   zero   in   finite   time   even   in   the   presence   of   mismatched   disturbances .   A   motion   control   application   demonstrates   the   effectiveness   and   attractive   properties   of   the   proposed   method . ' ,   ' title ' :   ' Continuous   Finite - Time   Output   Regulation   for   Disturbed   Systems   Under   Mismatching   Condition ' } 
{ ' abstract ' :   ' In   this   paper   we   propose   an   approach   for   enhanced   data   protection   in   the   cloud ,   based   upon   accountability   governance .   Specifically ,   the   relationships   between   accountability ,   risk   and   trust   are   analyzed   in   order   to   suggest   characteristics   and   means   to   address   data   governance   issues   involved   when   organizations   or   individuals   adopt   cloud   computing .   This   analysis   takes   into   account   insights   from   a   variety   of   stakeholders   within   cloud   ecosystems   obtained   by   running   an   elicitation   workshop . ' ,   ' title ' :   ' Accountability ,   Risk ,   and   Trust   in   Cloud   Services :   Towards   an   Accountability - Based   Approach   to   Risk   and   Trust   Governance ' } 
{ ' abstract ' :   ' Xue   et   al .   recently   proposed   an   innovative   mutual   authentication   and   key   agreement   scheme   for   wireless   sensor   networks   based   on   temporal   credential   using   smart   cards .   However ,   in   this   paper   we   demonstrate   that   their   scheme   is   vulnerable   to   password   guessing   attacks ,   node   capture   attacks   and   denial - of - service   attacks .   Furthermore   we   show   that   their   scheme   has   some   inconsistencies   which   make   it   less   secure   and   more   computationally   costly   than   originally   presented . ' ,   ' title ' :   ' Notes   on   A   Temporal - Credential - Based   Mutual   Authentication   and   Key   Agreement   Scheme   for   Wireless   Sensor   Networks ' } 
{ ' abstract ' :   ' Persistent   Scatterer   Interferometry   ( PSI )   has   been   widely   used   for   landslide   studies   in   recent   years .   This   paper   investigated   the   spatial   patterns   of   PSI   point   targets   and   landslide   occurrences   in   the   Arno   River   basin   in   Central   Italy .   The   main   purpose   is   to   analyze   whether   spatial   patterns   of   Persistent   Scatterers   ( PS )   can   be   recognized   as   indicators   of   landslide   occurrences   throughout   the   whole   basin .   The   bivariate   K - function   was   employed   to   assess   spatial   relationships   between   PS   and   landslides .   The   PSI   point   targets   were   acquired   from   almost   4   years   ( from   March   2003   to   January   2007 )   of   RADARSAT - 1   images .   The   landslide   inventory   was   collected   from   15   years   ( from     1992 – 2007 )   of   surveying   and   mapping   data ,   mainly   including   remote   sensing   data ,   topographic   maps   and   field   investigations .   The   proposed   approach   is   able   to   assess   spatial   patterns   between   a   variety   of   PS   and   landslides ,   in   particular ,   to   understand   if   PSI   point   targets   are   spatially   clustered   ( spatial   attraction )   or   randomly   distributed   ( spatial   independency )   on   various   types   of   landslides   across   the   basin .   Additionally ,   the   degree   and   scale   distances   of   PS   clustering   on   a   variety   of   landslides   can   be   characterized .   The   results   rejected   the   null   hypothesis   that   PSI   point   targets   appear   to   cluster   similarly   on   four   types   of   landslides   ( slides ,   flows ,   falls   and   creeps )   in   the   Arno   River   basin .   Significant   influence   of   PS   velocities   and   acquisition   orbits   can   be   noticed   on   detecting   landslides   with   different   states   of   activities .   Despite   that   the   assessment   may   be   influenced   by   the   quality   of   landslide   inventory   and   Synthetic   Aperture   Radar   ( SAR )   images ,   the   proposed   approach   is   expected   to   provide   guidelines   for   studies   trying   to   detect   and   investigate   landslide   occurrences   at   a   regional   scale   through   spatial   statistical   analysis   of   PS ,   for   which   an   advanced   understanding   of   the   impact   of   scale   distances   on   landslide   clustering   is   fundamentally   needed . ' ,   ' title ' :   ' Investigating   Spatial   Patterns   of   Persistent   Scatterer   Interferometry   Point   Targets   and   Landslide   Occurrences   in   the   Arno   River   Basin ' } 
{ ' abstract ' :   ' This   article   describes   a   middleware   used   in   display   cluster   of   real   time   visual   simulation   system .   This   middleware   which   based   on   TCP / IP   protocol   provides   the   communication   infrastructure   for   visual   simulation   system .   It   provides   unified   process   logic   and   interfaces   for   various   status   and   frame   data   and   the   packing / unpacking   functions   of   simulation   data   without   concerning   the   details   of   the   data .   We   found   two   classes   of   display   synchronization   problems   and   provided   the   resolution   of   them .   The   middleware   provides   a   group   of   APIs   which   hide   the   details   of   data   packing / unpacking ,   processing   and   transmission   and   meets   the   requirement   of   flexibility ,   efficiency   and   extensibility .   This   middleware   has   been   successfully   implemented   to   the   display   cluster   of   several   tower   simulation   system . ' ,   ' title ' :   ' The   Research   of   High   Level   Data   Communication   Middleware   of   Display   Cluster   Used   in   Real   Time   Simulation   Environment ' } 
{ ' abstract ' :   ' The   scattering   parameters   are   fundamental   in   the   characterization   of   electrical   devices   at   high   frequencies .   They   are   particularly   useful   for   analyzing   multiport   high - frequency   and   microwave   networks .   However ,   they   are   not   adequately   presented   in   most ,   if   not   all ,   microwave   engineering   books .   This   paper   identifies   two   common   deficiencies   in   the   way   scattering   parameters   are   being   presented   in   these   books .   It   provides   additional   information   that   should   supplement   those   books   or   book   chapters   on   scattering   parameters . ' ,   ' title ' :   ' Deficiencies   in   the   way   scattering   parameters   are   taught ' } 
{ ' abstract ' :   ' We   study   the   reliability   maximization   problem   in   WDM   networks   with   random   link   failures .   Reliability   in   these   networks   is   defined   as   the   probability   that   the   logical   network   is   connected ,   and   it   is   determined   by   the   underlying   lightpath   routing   and   the   link   failure   probability .   We   show   that   in   general   the   optimal   lightpath   routing   depends   on   the   link   failure   probability ,   and   characterize   the   properties   of   lightpath   routings   that   maximize   the   reliability   in   different   failure   probability   regimes .   In   particular ,   we   show   that   in   the   low   failure   probability   regime ,   maximizing   the   ` ` cross - layer "   min   cut   of   the   ( layered )   network   maximizes   reliability ,   whereas   in   the   high   failure   probability   regime ,   minimizing   the   spanning   tree   of   the   network   maximizes   reliability .   Motivated   by   these   results ,   we   develop   lightpath   routing   algorithms   for   reliability   maximization . ' ,   ' title ' :   ' Maximizing   Reliability   in   WDM   Networks   through   Lightpath   Routing ' } 
{ ' abstract ' :   ' The   slope   of   the   active   distances   is   an   important   parameter   when   investigating   the   error - correcting   capability   of   convolutional   codes   and   the   distance   behavior   of   concatenated   convolutional   codes .   The   slope   of   the   active   distances   is   equal   to   the   minimum   average   weight   cycle   in   the   state - transition   diagram   of   the   encoder .   A   general   upper   bound   on   the   slope   depending   on   the   free   distance   of   the   convolutional   code   and   new   upper   bounds   on   the   slope   of   special   classes   of   binary   convolutional   codes   are   derived .   Moreover ,   a   search   technique ,   resulting   in   new   tables   of   rate   R = 1 / 2   and   rate   R = 1 / 3   convolutional   encoders   with   high   memories   and   large   active   distance - slopes   is   presented .   Furthermore ,   we   show   that   convolutional   codes   with   large   slopes   can   be   used   to   obtain   new   tailbiting   block   codes   with   large   minimum   distances .   Tables   of   rate   R = 1 / 2   and   rate   R = 1 / 3   tailbiting   codes   with   larger   minimum   distances   than   the   best   previously   known   quasi - cyclic   codes   are   given .   Two   new   tailbiting   codes   also   have   larger   minimum   distances   than   the   best   previously   known   binary   linear   block   codes   with   same   size   and   length .   One   of   them   is   also   superior   in   terms   of   minimum   distance   to   any   previously   known   binary   nonlinear   block   code   with   the   same   set   of   parameters . ' ,   ' title ' :   ' Tailbiting   codes   obtained   via   convolutional   codes   with   large   active   distance - slopes ' } 
{ ' abstract ' :   ' MIMO   wireless   technology   is   required   to   increase   the   data   rates   for   a   broad   range   of   applications ,   including   low   cost   mobile   devices .   In   this   paper   we   present   a   very   low   area   reconfigurable   MIMO   detector   which   achieves   a   high   throughput   of   103Mbps   and   uses   27   Kilo   Gates   when   implemented   in   a   commercial   180nm   CMOS   process .   The   low   area   is   achieved   by   the   proposed   in - place   architecture .   This   architecture   implements   the   K - best   algorithm   and   reduces   area   4 - fold   compared   to   the   widely   used   multi - stage   architecture ,   while   provides   reconfigurability   in   terms   of   antenna   configuration   during   real - time   operation . ' ,   ' title ' :   ' A   low - area   flexible   MIMO   detector   for   WiFi / WiMAX   standards ' } 
{ ' abstract ' :   ' Because   human   cognition   is   creative   and   socially   situated ,   knowledge   accumulates ,   diffuses ,   and   gets   applied   in   new   contexts ,   generating   cultural   analogs   of   phenomena   observed   in   population   genetics   such   as   adaptation   and   drift .   It   is   therefore   commonly   thought   that   elements   of   culture   evolve   through   natural   selection .   However ,   natural   selection   was   proposed   to   explain   how   change   accumulates   despite   lack   of   inheritance   of   acquired   traits ,   as   occurs   with   template - mediated   replication .   It   cannot   accommodate   a   process   with   significant   retention   of   acquired   or   horizontally   ( e . g .   socially )   transmitted   traits .   Moreover ,   elements   of   culture   cannot   be   treated   as   discrete   lineages   because   they   constantly   interact   and   influence   one   another .   It   is   proposed   that   what   evolves   through   culture   is   the   mind ;   ideas   and   artifacts   are   merely   reflections   of   its   current   evolved   state .   Interacting   minds   transform   ( in   part )   through   a   non - Darwinian   autopoietic   process   similar   to   that   by   which   early   life   evolved ,   involving   not   survival   of   the   fittest   but   actualization   of   their   potential . ' ,   ' title ' :   ' The   cultural   evolution   of   socially   situated   cognition ' } 
{ ' abstract ' :   ' Event   Extraction   is   a   complex   and   interesting   topic   in   Information   Extraction   that   includes   event   extraction   methods   from   free   text   or   web   data .   The   result   of   event   extraction   systems   can   be   used   in   several   fields   such   as   risk   analysis   systems ,   online   monitoring   systems   or   decide   support   tools .   In   this   paper ,   we   introduce   a   method   that   combines   lexico   - -   semantic   and   machine   learning   to   extract   event   from   Vietnamese   news .   Furthermore ,   we   concentrate   to   describe   event   online   monitoring   system   named   VnLoc   based   on   the   method   that   was   proposed   above   to   extract   event   in   Vietnamese   language .   Besides ,   in   experiment   phase ,   we   have   evaluated   this   method   based   on   precision ,   recall   and   F1   measure .   At   this   time   of   experiment ,   we   on   investigated   on   three   types   of   event :   FIRE ,   CRIME   and   TRANSPORT   ACCIDENT . ' ,   ' title ' :   ' VnLoc :   A   Real   - -   Time   News   Event   Extraction   Framework   for   Vietnamese ' } 
{ ' abstract ' :   ' Reliability   analysis   using   error   probabilities   for   combinational   logic   circuits   has   been   investigated   widely   in   the   literature .   Reliability   analysis   for   sequential   logic   circuits   using   these   methods   would   be   inaccurate   because   of   existence   of   loops   in   their   architecture .   In   this   paper   a   new   method   based   on   conversion   of   sequential   circuit   to   combinational   one   and   applying   an   iterative   reliability   analysis   is   developed .   A   Monte   Carlo   method - based   reliability   analysis   is   introduced   for   sequential   circuits ,   which   is   used   for   first   method   validation .   Experimental   results   demonstrate   good   accuracy   of   the   method . ' ,   ' title ' :   ' SEQUENTIAL   LOGIC   CIRCUITS   RELIABILITY   ANALYSIS ' } 
{ ' abstract ' :   ' According   to   the   Journey   to   Crime   theory ,   offenders   have   a   directionality   preference ,   in   the   form   of   an   activity   path ,   when   they   are   moving   about   in   their   environment   in   search   for   criminal   activities .   Using   clustering   techniques ,   this   theory   is   tested   using   crime   data   for   the   Province   of   British   Columbia ,   Canada .   The   activities   of   57 , 962   offenders   who   were   either   charged ,   chargeable ,   or   for   whom   charges   were   recommended   were   analyzed   by   mapping   their   offense   locations   with   respect   to   their   home   locations   to   determine   directionality .   Once   directionality   was   established ,   a   unique   clustering   technique ,   based   on   K - Means   clustering   and   modified   for   angles ,   was   applied   to   find   the   number   of   activity   paths   for   each   offender .   Although   the   number   of   activity   paths   varies   from   individual   to   individual ,   the   aggregate   pattern   was   very   consistent   with   theory .   It   was   found   that   people   only   have   a   few   activity   paths ,   even   if   they   are   highly   prolific   offenders . ' ,   ' title ' :   ' How   Many   Ways   Do   Offenders   Travel   - -   Evaluating   the   Activity   Paths   of   Offenders ' } 
{ ' abstract ' :   ' Pulse   Coupled   Neural   Network ( PCNN )   is   widely   used   in   the   field   of   image   processing ,   but   it   is   a   difficult   task   to   define   the   relative   parameters   properly   in   the   research   of   the   applications   of   PCNN .   So   far   the   determination   of   parameters   of   its   model   needs   a   lot   of   experiments .   To   deal   with   the   above   problem ,   a   document   segmentation   based   on   the   improved   PCNN   is   proposed .   It   uses   the   maximum   entropy   function   as   the   fitness   function   of   bacterial   foraging   optimization   algorithm ,   adopts   bacterial   foraging   optimization   algorithm   to   search   the   optimal   parameters ,   and   eliminates   the   trouble   of   manually   set   the   experiment   parameters .   Experimental   results   show   that   the   proposed   algorithm   can   effectively   complete   document   segmentation .   And   result   of   the   segmentation   is   better   than   the   contrast   algorithms .   ©   ( 2014 )   COPYRIGHT   Society   of   Photo - Optical   Instrumentation   Engineers   ( SPIE ) .   Downloading   of   the   abstract   is   permitted   for   personal   use   only . ' ,   ' title ' :   ' PCNN   document   segmentation   method   based   on   bacterial   foraging   optimization   algorithm ' } 
{ ' abstract ' :   ' Undirected   graphical   models   encode   in   a   graph   G   the   dependency   structure   of   a   random   vector   Y .   In   many   applications ,   it   is   of   interest   to   model   Y   given   another   random   vector   X   as   input .   We   refer   to   the   problem   of   estimating   the   graph   G ( x )   of   Y   conditioned   on   X   =   x   as   " graph - valued   regression " .   In   this   paper ,   we   propose   a   semiparametric   method   for   estimating   G ( x )   that   builds   a   tree   on   the   X   space   just   as   in   CART   ( classification   and   regression   trees ) ,   but   at   each   leaf   of   the   tree   estimates   a   graph .   We   call   the   method   " Graph - optimized   CART " ,   or   Go - CART .   We   study   the   theoretical   properties   of   Go - CART   using   dyadic   partitioning   trees ,   establishing   oracle   inequalities   on   risk   minimization   and   tree   partition   consistency .   We   also   demonstrate   the   application   of   Go - CART   to   a   meteorological   dataset ,   showing   how   graph - valued   regression   can   provide   a   useful   tool   for   analyzing   complex   data . ' ,   ' title ' :   ' Graph - Valued   Regression ' } 
{ ' abstract ' :   ' Over   the   last   two   decades ,   doubts   have   been   expressed   about   the   adequacy   of   materialism   as   the   correct   framework   for   explaining   phenomenal   consciousness   ( the   experience   of   saturated   greenness   one   has   when   looking   at   a   lush   lawn ,   for   example ) .   This   paper   reconstructs   a   generic   form   of   the   various   arguments   that   have   been   used   to   defend   the   view   of   the   materialistically   inexplicable   nature   of   consciousness   ( MINC ) .   This   reconstruction   reveals   that   the   arguments   turn   on   an   impoverished   notion   of   explanation .   By   discussing   some   examples   from   the   history   of   science ,   the   paper   shows   that   a   reasonable   notion   of   explanation   has   to   be   wider   than   the   one   utilized   in   the   argument   for   MINC ,   which   opens   the   possibility   for   the   materialistic   explicability   of   consciousness .   The   author   ends   the   paper   by   raising   a   question   about   the   very   intelligibility   of   the   project   of   trying   to   explain   the   so - called   nature   of   consciousness   as   opposed   to   the   regularities   characteristic   of   the   relation   between   states   of   consciousness   and   ... ' ,   ' title ' :   ' On   explaining   phenomenal   consciousness ' } 
{ ' abstract ' :   ' Successful   replication   within   an   infected   host   and   successful   transmission   between   hosts   are   key   to   the   continued   spread   of   most   pathogens .   Competing   selection   pressures   exerted   at   these   different   scales   can   lead   to   evolutionary   trade - offs   between   the   determinants   of   fitness   within   and   between   hosts .   Here ,   we   examine   such   a   trade - off   in   the   context   of   influenza   A   viruses   and   the   differential   pressures   exerted   by   temperature - dependent   virus   persistence .   For   a   panel   of   avian   influenza   A   virus   strains ,   we   find   evidence   for   a   trade - off   between   the   persistence   at   high   versus   low   temperatures .   Combining   a   within - host   model   of   influenza   infection   dynamics   with   a   between - host   transmission   model ,   we   study   how   such   a   trade - off   affects   virus   fitness   on   the   host   population   level .   We   show   that   conclusions   regarding   overall   fitness   are   affected   by   the   type   of   link   assumed   between   the   within -   and   between - host   levels   and   the   main   route   of   transmission   ( direct   or   environmental ) .   The   relative   importance   of   virulence   and   immune   response   mediated   virus   clearance   are   also   found   to   influence   the   fitness   impacts   of   virus   persistence   at   low   versus   high   temperatures .   Based   on   our   results ,   we   predict   that   if   transmission   occurs   mainly   directly   and   scales   linearly   with   virus   load ,   and   virulence   or   immune   responses   are   negligible ,   the   evolutionary   pressure   for   influenza   viruses   to   evolve   toward   good   persistence   at   high   within - host   temperatures   dominates .   For   all   other   scenarios ,   influenza   viruses   with   good   environmental   persistence   at   low   temperatures   seem   to   be   favored . ' ,   ' title ' :   ' A   Multi - scale   Analysis   of   Influenza   A   Virus   Fitness   Trade - offs   due   to   Temperature - dependent   Virus   Persistence ' } 
{ ' abstract ' :   ' Peer - to - Peer   ( P2P )   networks   are   largely   used   for   file - sharing   and   hence   must   provide   efficient   mechanisms   for   searching   the   files   stored   at   various   nodes .   The   existing   structuredP2P   overlays   support   only   ” exact - match ”   look - up   which   is   hardly   sufficient   in   a   file   sharing   network .   This   paper   addresses   the   problem   of   keyword - based   search   in   structured   P2P   networks .   We   propose   a   new   keyword - based   searching   algorithm   which   can   be   implemented   on   top   of   any   structured   P2P   overlay .   We   demonstrate   that   the   proposed   algorithm   achieves   very   good   searching   results   as   it   requires   the   minimum   number   of   messages   to   be   sent   in   order   to   find   all   the   references   to   files   containing   at   least   the   given   set   of   keywords . ' ,   ' title ' :   ' A   Keyword   Search   Algorithm   for   Structured   Peer - to - Peer   Networks ' } 
{ ' abstract ' :   ' In   this   paper ,   we   propose   an   adaptive   power   allocation   method   for   hybrid   relay   systems   that   employ   the   amplify - and - forward   and   decode - and - forward   protocols   simultaneously .   The   total   transmission   power   is   analytically   allocated   to   a   source   and   two   selected   relays   by   the   proposed   power   allocation   criterion   to   maximize   the   overall   received   signal - to - noise   ratio   at   the   destination .   Simulation   results   show   that   the   proposed   scheme   achieves   better   performance   than   that   of   conventional   cooperative   schemes   or   hybrid   systems   with   equal   power   allocation . ' ,   ' title ' :   ' Adaptive   relay   selection   and   power   allocation   for   hybrid   relay   systems ' } 
{ ' abstract ' :   ' The   unitary   rotation   of   square - pixellated   images   is   based   on   the   finite   su ( 2 ) - oscillator   model ,   which   describes   systems   whose   values   for   position ,   momentum   and   energy ,   are   discrete   and   finite .   In   a   two - dimensional   position   space ,   this   allows   the   construction   of   angular   momentum   states ,   orthonormal   and   complete ,   for   which   rotations   are   defined   as   multiplication   by   phases   that   carry   the   rotation   angle .   The   decomposition   of   a   digital   square   images   in   terms   of   these   angular   momentum   states   determines   a   unitary   ( hence   invertible )   rotation   of   the   image ,   whose   kernel   can   be   computed   as   a   four - dimensional   array   of   real   numbers . ' ,   ' title ' :   ' Unitary   rotation   of   square - pixellated   images ' } 
{ ' abstract ' :   ' As   more   mobile   storage   devices   are   used   in   consumer   electronics ,   possibility   of   user   confidential   data   leakage   increases .   To   make   things   worse ,   data   of   deleted   file   in   mobile   storage   such   as   USB   drives   can   be   easily   recovered   and ,   thus ,   can   be   vulnerable   to   data   leakage .   To   prevent   this   type   of   data   leakage ,   efficient   secure   deletion   techniques   are   required   and   we   present   two   secure   deletion   techniques ,   namely   block   cleaning   and   zero   overwriting ,   for   flash   memory   storage .   Also ,   we   propose   cost   and   benefit   models   of   both   techniques .   The   models   imply   an   existence   of   an   efficient   adaptive   hybrid   secure   deletion   scheme   that   applies   one   of   the   techniques   based   on   their   costs   and   benefits   at   given   data   arrangements .   Experimental   results   measured   on   an   embedded   board   show   that   the   adaptive   hybrid   scheme   deletes   data   securely   and   efficiently   for   various   data   patterns   on   flash   memory   storage . ' ,   ' title ' :   ' Models   and   Design   of   an   Adaptive   Hybrid   Scheme   for   Secure   Deletion   of   Data   in   Consumer   Electronics ' } 
{ ' abstract ' :   ' In   heterogeneous   and   dynamic   environments ,   efficient   execution   of   parallel   computations   can   require   mappings   of   tasks   to   processors   whose   performance   is   both   irregular   ( because   of   heterogeneity )   and   time - varying   ( because   of   dynamicity ) .   While   adaptive   domain   decomposition   techniques   have   been   used   to   address   heterogeneous   resource   capabilities ,   temporal   variations   in   those   capabilities   have   seldom   been   considered .   We   propose   a   conservative   scheduling   policy   that   uses   information   about   expected   future   variance   in   resource   capabilities   to   produce   more   efficient   data   mapping   decisions .   We   first   present   techniques ,   based   on   time   series   predictors   that   we   developed   in   previous   work ,   for   predicting   CPU   load   at   some   future   time   point ,   average   CPU   load   for   some   future   time   interval ,   and   variation   of   CPU   load   over   some   future   time   interval .   We   then   present   a   family   of   stochastic   scheduling   algorithms   that   exploit   such   predictions   of   future   availability   and   variability   when   making   data   mapping   decisions .   Finally ,   we   describe   experiments   in   which   we   apply   our   techniques   to   an   astrophysics   application .   The   results   of   these   experiments   demonstrate   that   conservative   scheduling   can   produce   execution   times   that   are   both   significantly   faster   and   less   variable   than   other   techniques . ' ,   ' title ' :   ' Conservative   Scheduling :   Using   Predicted   Variance   to   Improve   Scheduling   Decisions   in   Dynamic   Environments ' } 
{ ' abstract ' :   ' We   consider   a   class   of   restless   multi - armed   bandit   problems   that   arises   in   multi - channel   opportunistic   communications ,   where   channels   are   modeled   as   independent   and   stochastically   identical   Gilbert - Elliot   channels   and   channel   state   observations   are   subject   to   errors .   We   show   that   the   myopic   channel   selection   policy   has   a   semi - universal   structure   that   obviates   the   need   to   know   the   Markovian   transition   probabilities   of   the   channel   states .   Based   on   this   structure ,   we   establish   closed - form   lower   and   upper   bounds   on   the   steady - state   throughput   achieved   by   the   myopic   policy .   Furthermore ,   we   characterize   the   approximation   factor   of   the   myopic   policy   to   bound   its   worst - case   performance   loss   with   respect   to   the   optimal   performance . ' ,   ' title ' :   ' On   the   myopic   policy   for   a   class   of   restless   bandit   problems   with   applications   in   dynamic   multichannel   access ' } 
{ ' abstract ' :   ' We   show   that   the   optimum   length - / spl   nu /   guard   sequence   for   block   transmission   over   a   linear   Gaussian - noise   dispersive   channel   with   memory   / spl   nu /   is   a   linear   combination   of   the   N   information   symbols   of   the   block .   A   closed - form   expression   for   the   optimum   guard   sequence   is   derived   subject   to   a   total   average   energy   constraint   on   the   information   and   guard   symbols .   The   achievable   channel   block   throughput   with   the   optimum   guard   sequence   is   compared   with   that   achievable   with   two   common   guard   sequence   types ,   namely   zero   stuffing   and   cyclic   prefix . ' ,   ' title ' :   ' Guard   sequence   optimization   for   block   transmission   over   linear   frequency - selective   channels ' } 
{ ' abstract ' :   " A   modular   program   analysis   considers   components   independently   and   provides   a   succinct   summary   for   each   component ,   which   is   used   when   checking   the   rest   of   the   system .   Consider   a   system   consisting   of   a   library   and   a   client .   A   temporal   summary ,   or     interface   ,   of   the   library   specifies   legal   sequences   of   library   calls .   The   interface   is     safe     if   no   call   sequence   violates   the   library ' s   internal   invariants ;   the   interface   is     permissive     if   it   contains   every   such   sequence .   Modular   program   analysis   requires     full     interfaces ,   which   are   both   safe   and   permissive :   the   client   does   not   cause   errors   in   the   library   if   and   only   if   it   makes   only   sequences   of   library   calls   that   are   allowed   by   the   full   interface   of   the   library . Previous   interface - based   methods   have   focused   on   safe   interfaces ,   which   may   be   too   restrictive   and   thus   reject   good   clients .   We   present   an   algorithm   for   automatically   synthesizing   software   interfaces   that   are   both   safe   and   permissive .   The   algorithm   generates   interfaces   as   graphs   whose   vertices   are   labeled   with   predicates   over   the   library ' s   internal   state ,   and   whose   edges   are   labeled   with   library   calls .   The   interface   state   is   refined   incrementally   until   the   full   interface   is   constructed .   In   other   words ,   the   algorithm   automatically   synthesizes   a   typestate   system   for   the   library ,   against   which   any   client   can   be   checked   for   compatibility .   We   present   an   implementation   of   the   algorithm   which   is   based   on   the   BLAST   model   checker ,   and   we   evaluate   some   case   studies . " ,   ' title ' :   ' Permissive   interfaces ' } 
{ ' abstract ' :   ' In   this   paper ,   we   propose   a   new   method   for   the   motion   planning   problem   of   rigid   object   dexterous   manipulation   with   a   robotic   multi - fingered   hand ,   under   quasi - static   movement   assumption .   This   method   computes   both   object   and   finger   trajectories   as   well   as   the   finger   relocation   sequence .   Its   specificity   is   to   use   a   special   structuring   of   the   research   space   that   allows   to   search   for   paths   directly   in   the   particular   subspace   GS   n     which   is   the   subspace   of   all   the   grasps   that   can   be   achieved   with   n   grasping   fingers .   The   solving   of   the   dexterous   manipulation   planning   problem   is   based   upon   the   exploration   of   this   subspace .   The   proposed   approach   captures   the   connectivity   of   GS   n     in   a   graph   structure .   The   answer   of   the   manipulation   planning   query   is   then   given   by   searching   a   path   in   the   computed   graph .   Simulation   experiments   were   conducted   for   different   dexterous   manipulation   task   examples   to   validate   the   proposed   method . ' ,   ' title ' :   ' Dexterous   manipulation   planning   using   probabilistic   roadmaps   in   continuous   grasp   subspaces ' } 
{ ' abstract ' :   ' This   paper   presents   an   experimental   evaluation   of   different   line   extraction   algorithms   applied   to   2D   laser   scans   for   indoor   environments .   Six   popular   algorithms   in   mobile   robotics   and   computer   vision   are   selected   and   tested .   Real   scan   data   collected   from   two   office   environments   by   using   different   platforms   are   used   in   the   experiments   in   order   to   evaluate   the   algorithms .   Several   comparison   criteria   are   proposed   and   discussed   to   highlight   the   advantages   and   drawbacks   of   each   algorithm ,   including   speed ,   complexity ,   correctness   and   precision .   The   results   of   the   algorithms   are   compared   with   ground   truth   using   standard   statistical   methods .   An   extended   case   study   is   performed   to   further   evaluate   the   algorithms   in   a   SLAM   application . ' ,   ' title ' :   ' A   comparison   of   line   extraction   algorithms   using   2D   range   data   for   indoor   mobile   robotics ' } 
{ ' abstract ' :   ' This   study   investigates   the   use   of   force - stiffness   feedback ,   i . e . ,   a   combination   of   force   offset   and   extra   spring   load ,   in   UAV   tele - operation   with   transmission   time   delay .   The   goal   was   to   further   increase   the   level   of   safety   of   tele - operation   with   a   reduction   in   operator   workload   with   respect   to   force   feedback ,   i . e . ,   using   force   offset   alone .   A   theoretical   analysis   is   given   of   using   force - stiffness   feedback   to   improve   collision   avoidance .   Wave   variables   are   included   to   reduce   time   delay   effects .   An   experiment   was   conducted   to   investigate   the   effects   of   force - stiffness   feedback   on   safety   of   operation ,   operator   performance ,   control   activity ,   and   workload .   Results   indicate   that   force - stiffness   feedback   improves   the   haptic   interface   with   respect   to   force   feedback   alone .   Safety   of   tele - operation   increases   without   increasing   operator   workload   with   respect   to   force   feedback . ' ,   ' title ' :   ' Haptic   interface   in   UAV   tele - operation   using   force - stiffness   feedback ' } 
{ ' abstract ' :   ' Due   to   the   spread   of   the   internet   and   the   ever   increasing   number   of   web   applications ,   the   issue   of   compatibility   across   browsers   has   become   very   important .   This   compatibility   issue   is   also   referred   as   Cross   Browser   Inconsistency   ( XBI )   wherein   same   website   looks   or   behaves   differently   in   different   web   browsers .   In   this   paper   our   aim   is   to   address   this   issue   of   compatibility   and   propose   an   automated   approach   of   detecting   XBIs .   Cross   Browser   Inconsistencies   can   either   be   in   the   content ,   structure   or   behavior   of   the   webpage .   In   order   to   get   a   grasp   of   the   above   mentioned   types   of   inconsistencies ,   we   surveyed   some   random   websites   and   analyzed   them   in   different   browsers .   We   also   studied   the   basic   working   of   browser ,   in   order   to   establish   its   connection   with   the   occurrences   of   XBIs .   Each   browser   has   its   own   rendering   mechanisms ,   which   sometimes   differs   from   standards .   Hence ,   the   execution   of   these   websites   is   different   in   different   browsers .   Finally   we   have   proposed   an   automated   approach   for   XBI   detection . ' ,   ' title ' :   ' An   Automated   Approach   for   Cross - Browser   Inconsistency   ( XBI )   Detection ' } 
{ ' abstract ' :   ' We   present   a   formal   framework   that   combines   high - level   representation   and   causality - based   reasoning   with   low - level   geometric   reasoning   and   motion   planning .   The   frame - work   features   bilateral   interaction   between   task   and   motion   planning ,   and   embeds   geometric   reasoning   in   causal   reasoning ,   thanks   to   several   advantages   inherited   from   its   underlying   components .   In   particular ,   our   choice   of   using   a   causality - based   high - level   formalism   for   describing   action   domains   allows   us   to   represent   ramifications   and   state / transition   constraints ,   and   embed   in   such   formal   domain   descriptions   externally   defined   functions   implemented   in   some   programming   language   ( e . g . ,   C++ ) .   Moreover ,   given   such   a   domain   description ,   the   causal   reasoner   based   on   this   formalism   ( i . e . ,   the   Causal   Calculator )   allows   us   to   compute   optimal   solutions   ( e . g . ,   shortest   plans )   for   elaborate   planning / prediction   problems   with   temporal   constraints .   Utilizing   these   features   of   high - level   representation   and   reasoning ,   we   can   combine   causal   reasoning ,   motion   planning   and   geometric   planning   to   find   feasible   kinematic   solutions   to   task - level   problems .   In   our   framework ,   the   causal   reasoner   guides   the   motion   planner   by   finding   an   optimal   task - plan ;   if   there   is   no   feasible   kinematic   solution   for   that   task - plan   then   the   motion   planner   guides   the   causal   reasoner   by   modifying   the   planning   problem   with   new   temporal   constraints .   Furthermore ,   while   computing   a   task - plan ,   the   causal   reasoner   takes   into   account   geometric   models   and   kinematic   relations   by   means   of   external   predicates   implemented   for   geometric   reasoning   ( e . g . ,   to   check   some   collisions ) ;   in   that   sense   the   geometric   reasoner   guides   the   causal   reasoner   to   find   feasible   kinematic   solutions .   We   illustrate   an   application   of   this   framework   to   robotic   manipulation ,   with   two   pantograph   robots   on   a   complex   assembly   task   that   requires   concurrent   execution   of   actions .   A   short   video   of   this   application   accompanies   the   paper . ' ,   ' title ' :   ' Combining   high - level   causal   reasoning   with   low - level   geometric   reasoning   and   motion   planning   for   robotic   manipulation ' } 
{ ' abstract ' :   ' This   paper   presents   a   novel   template   matching   method   to   detect   and   track   pedestrians   for   people   counting   in   real - time .   Firstly ,   a   novel   background   subtraction   method   is   proposed   for   extracting   all   foreground   objects   from   background .   Then ,   a   shadow   elimination   method   is   used   to   remove   unwanted   shadow   from   the   background .   In   order   to   identify   pedestrians   from   non - pedestrian   objects ,   this   paper   proposed   a   novel   grid - based   template   matching   scheme   to   robustly   verify   each   pedestrian .   Usually ,   a   pedestrian   will   have   different   appearances   at   different   positions .   The   grid - based   approach   can   effectively   reduce   the   perspective   effects   into   a   minimum   since   it   uses   different   templates   to   record   the   appearance   changes   at   each   grid .   When   more   templates   are   used ,   the   detection   process   will   become   more   inefficient .   To   speed   up   its   efficiency ,   an   integral   image   is   used   to   filter   out   all   impossible   candidates   in   advance .   Lastly ,   a   tracking   method   is   applied   to   tracking   the   direction   of   each   moving   pedestrian   so   that   the   real   number   of   passing   people   per   direction   can   be   counted   more   accurately .   Experimental   results   have   proved   that   the   proposed   method   is   robust ,   accurate ,   and   powerful   in   people   counting . ' ,   ' title ' :   ' Grid - based   Template   Matching   for   People   Counting ' } 
{ ' abstract ' :   ' A   tomographic   image   reconstruction   algorithm   that   we   have   been   studying   requires   the   nth - order   Hankel   transform   for   the   nth   function   in   a   series ,   where   n   varies   over   a   set   of   integers .   Unfortunately ,   most   previously   proposed   algorithms   have   either   dealt   with   only   zeroth - order   transforms   or   cannot   be   applied   conveniently   to   our   problem .   We   propose   an   algorithm   for   computing   general   integer - order   Hankel   transforms .   The   algorithm   takes   samples   of   equally   spaced   input   functions   and   gives   equally   spaced   samples   of   the   transforms . ' ,   ' title ' :   ' An   algorithm   for   computing   general   integer - order   Hankel   transforms ' } 
{ ' abstract ' :   ' In   this   paper ,   we   present   a   real - time   approach   that   allows   tracking   deformable   structures   in   3D   ultrasound   sequences .   Our   method   consists   in   obtaining   the   target   displacements   by   combining   robust   dense   motion   estimation   and   mechanical   model   simulation .   We   perform   evaluation   of   our   method   through   simulated   data ,   phantom   data ,   and   real - data .   Results   demonstrate   that   this   novel   approach   has   the   advantage   of   providing   correct   motion   estimation   regarding   different   ultrasound   shortcomings   including   speckle   noise ,   large   shadows   and   ultrasound   gain   variation .   Furthermore ,   we   show   the   good   performance   of   our   method   with   respect   to   state - of - the - art   techniques   by   testing   on   the   3D   databases   provided   by   MICCAI   CLUST ’ 14   and   CLUST ’ 15   challenges . ' ,   ' title ' :   ' Real - time   target   tracking   of   soft   tissues   in   3D   ultrasound   images   based   on   robust   visual   information   and   mechanical   simulation ' } 
{ ' abstract ' :   ' For   two   given   graphs   G1G1   and   G2G2 ,   the   Ramsey   number   R ( G1 , G2 ) R ( G1 , G2 )   is   the   smallest   integer   NN   such   that   for   any   graph   of   order   NN ,   either   GG   contains   a   copy   of   G1G1   or   its   complement   contains   a   copy   of   G2G2 .   Let   CmCm   be   a   cycle   of   length   mm   and   K1 , nK1 , n   a   star   of   order   n + 1n + 1 .   Parsons   ( 1975 )   shows   that   R ( C4 , K1 , n ) ≤ n + ⌊ n − 1 ⌋ + 2   and   if   nn   is   the   square   of   a   prime   power ,   then   the   equality   holds .   In   this   paper ,   by   discussing   the   properties   of   polarity   graphs   whose   vertices   are   points   in   the   projective   planes   over   Galois   fields ,   we   prove   that   R ( C4 , K1 , q2 − t ) = q2 + q − ( t − 1 ) R ( C4 , K1 , q2 − t ) = q2 + q − ( t − 1 )   if   qq   is   an   odd   prime   power ,   1 ≤ t ≤ 2 ⌈ q4 ⌉   and   t ≠ 2 ⌈ q4 ⌉ − 1 ,   which   extends   a   result   on   R ( C4 , K1 , q2 − t ) R ( C4 , K1 , q2 − t )   obtained   by   Parsons   ( 1976 ) . ' ,   ' title ' :   ' Polarity   graphs   and   Ramsey   numbers   for   C   4   versus   stars ' } 
{ ' abstract ' :   ' This   paper   deals   with   the   problem   of   assuring   strict   QoS   guarantees   for   the   end   to   end   connections   that   originate   from   Ethernet   access   network .   It   shows   that   despite   high   link   capacities   in   some   cases   Ethernet   network   might   be   the   reason   of   QoS   deterioration .   The   primary   reason   is   the   lack   of   appropriate   QoS   differentiation   and   traffic   isolation   mechanisms .   The   shared   buffers   and   priority   schedulers   available   in   most   of   Ethernet   switches   appear   to   be   not   sufficient   to   guarantee   strict   QoS .   For   these   cases   new   solution   is   proposed   which   relies   on   additional   traffic   control   mechanisms   available   in   other   network   elements .   Only   additional   mechanism   supporting   typical   functionality   of   Ethernet   switch   can   provide   strict   QoS   guarantees   what   was   verified   in   simulations   studies . ' ,   ' title ' :   ' On   assuring   QoS   in   Ethernet   access   network ' } 
{ ' abstract ' :   ' The   federal   Medicare   regulations   reimburse   hospitals   on   a   pro   rata   share   of   the   hospital \ ' s   cost .   Hence ,   to   meet   its   financial   requirements ,   a   hospital   is   forced   to   shift   more   of   the   financial   burdens   onto   its   private   patients .   This   procedure   has   contributed   to   double   digit   inflation   in   hospital   prices   and   to   proposed   federal   regulation   to   control   the   rate   of   increase   in   hospital   revenues .   In   this   regulatory   environment ,   we   develop   nonlinear   programming   pricing   and   cost   allocation   models   to   aid   hospital   administrators   in   meeting   their   profit   maximizing   and   profit   satisficing   goals .   The   model   enables   administrators   to   explore   tactical   issues   such   as :   i   studying   the   relationship   between   a   voluntary   or   legislated   cap   on   a   hospital \ ' s   total   revenues   and   the   hospital \ ' s   profitability ,   ii   identifying   those   departments   within   the   hospital   that   are   the   most   attractive   candidates   for   cost   reduction   or   cost   containment   efforts ,   and   iii   isolating   those   services   that   should   be   singled   out   by   the   hospital   manager   for   renegotiation   of   the   prospective   or   " customary   and   reasonable "   cap .   Finally ,   the   modeling   approach   is   helpful   in   explaining   the   departmental   cross   subsidies   observed   in   practice ,   and   can   be   of   aid   to   federal   administrators   in   assessing   the   impacts   of   proposed   changes   in   the   Medicare   reimbursement   formula . ' ,   ' title ' :   ' Hospital   Profit   Planning   under   Medicare   Reimbursement ' } 
{ ' abstract ' :   ' We   present   a   ( 4   +   epsilon )   approximation   algorithm   for   weighted   graph   matching   which   applies   in   the   semistreaming ,   sliding   window ,   and   MapReduce   models ;   this   single   algorithm   improves   the   previous   best   algorithm   in   each   model .   The   algorithm   operates   by   reducing   the   maximum - weight   matching   problem   to   a   polylog   number   of   copies   of   the   maximum - cardinality   matching   problem .   The   algorithm   also   extends   to   provide   approximation   guarantees   for   the   more   general   problem   of   finding   weighted   independent   sets   in   p - systems   ( which   include   intersections   of   p   matroids   and   p - bounded   hypergraph   matching ) . ' ,   ' title ' :   ' Improved   Streaming   Algorithms   for   Weighted   Matching ,   via   Unweighted   Matching ' } 
{ ' abstract ' :   ' This   paper   presents   a   novel   approach   to   efficiently   solve   parameter - dependent   ( PD )   linear   matrix   inequality   ( LMI )   problems   for ,   amongst   others ,   linear   parameter - varying   ( LPV )   control   design .   Typically ,   stability   and   performance   is   guaranteed   by   finding   a   PD   Lyapunov   function   such   that   a   PD   LMI   is   feasible   on   a   parameter   domain .   To   solve   the   resulting   semi - infinite   problems ,   we   propose   a   novel   LMI   relaxation   technique   relying   on   B - spline   basis   functions .   This   technique   provides   less   conservative   solutions   and / or   a   reduced   numerical   burden   compared   to   existing   approaches .   Moreover ,   an   elegant   generalization   of   worst - case   optimization   to   the   optimization   of   any   signal   norm   is   obtained   by   expressing   performance   bounds   as   a   function   of   the   system   parameters .   This   generalization   yields   better   performance   bounds   in   a   large   part   of   the   parameter   domain .   Numerical   comparisons   with   the   current   state - of - the - art   demonstrate   the   generality   and   effectiveness   of   our   approach . ' ,   ' title ' :   ' Control   of   linear   parameter - varying   systems   using   B - splines ' } 
{ ' abstract ' :   ' There   is   a   growing   interest   in   simulating   natural   phenomena   in   computer   graphics   applications .   Animating   natural   scenes   in   real   time   is   one   of   the   most   challenging   problems   due   to   the   inherent   complexity   of   their   structure ,   formed   by   millions   of   geometric   entities ,   and   the   interactions   that   happen   within .   An   example   of   natural   scenario   that   is   needed   for   games   or   simulation   programs   are   forests .   Forests   are   difficult   to   render   because   the   huge   amount   of   geometric   entities   and   the   large   amount   of   detail   to   be   represented .   Moreover ,   the   interactions   between   the   objects   ( grass ,   leaves )   and   external   forces   such   as   wind   are   complex   to   model .   In   this   paper   we   concentrate   in   the   rendering   of   falling   leaves   at   low   cost .   We   present   a   technique   that   exploits   graphics   hardware   in   order   to   render   thousands   of   leaves   with   different   falling   paths   in   real   time   and   low   memory   requirements . ' ,   ' title ' :   ' Rendering   falling   leaves   on   graphics   hardware ' } 
{ ' abstract ' :   ' We   previously   presented   DriverDB ,   a   database   that   incorporates   ∼ 6000   cases   of   exome - seq   data ,   in   addition   to   annotation   databases   and   published   bioinformatics   algorithms   dedicated   to   driver   gene / mutation   identification .   The   database   provides   two   points   of   view ,   ‘ Cancer ’   and   ‘ Gene ’ ,   to   help   researchers   visualize   the   relationships   between   cancers   and   driver   genes / mutations .   In   the   updated   DriverDBv2   database   ( http : / / ngs . ym . edu . tw / driverdb )   presented   herein ,   we   incorporated   > 9500   cancer - related   RNA - seq   datasets   and   > 7000   more   exome - seq   datasets   from   The   Cancer   Genome   Atlas   ( TCGA ) ,   International   Cancer   Genome   Consortium   ( ICGC ) ,   and   published   papers .   Seven   additional   computational   algorithms   ( meaning   that   the   updated   database   contains   15   in   total ) ,   which   were   developed   for   driver   gene   identification ,   are   incorporated   into   our   analysis   pipeline ,   and   the   results   are   provided   in   the   ‘ Cancer ’   section .   Furthermore ,   there   are   two   main   new   features ,   ‘ Expression ’   and   ‘ Hotspot ’ ,   in   the   ‘ Gene ’   section .   ‘ Expression ’   displays   two   expression   profiles   of   a   gene   in   terms   of   sample   types   and   mutation   types ,   respectively .   ‘ Hotspot ’   indicates   the   hotspot   mutation   regions   of   a   gene   according   to   the   results   provided   by   four   bioinformatics   tools .   A   new   function ,   ‘ Gene   Set ’ ,   allows   users   to   investigate   the   relationships   among   mutations ,   expression   levels   and   clinical   data   for   a   set   of   genes ,   a   specific   dataset   and   clinical   features . ' ,   ' title ' :   ' DriverDBv2 :   a   database   for   human   cancer   driver   gene   research ' } 
{ ' abstract ' :   ' Thousands   of   deep   and   wide   pipelines   working   concurrently   make   GPGPU   high   power   consuming   parts .   Energy - efficiency   techniques   employ   voltage   overscaling   that   increases   timing   sensitivity   to   variations   and   hence   aggravating   the   energy   use   issues .   This   paper   proposes   a   method   to   increase   spatiotemporal   reuse   of   computational   effort   by   a   combination   of   compilation   and   micro - architectural   design .   An   associative   memristive   memory   ( AMM )   module   is   integrated   with   the   floating   point   units   ( FPUs ) .   Together ,   we   enable   fine - grained   partitioning   of   values   and   find   high - frequency   sets   of   values   for   the   FPUs   by   searching   the   space   of   possible   inputs ,   with   the   help   of   application - specific   profile   feedback .   For   every   kernel   execution ,   the   compiler   pre - stores   these   high - frequent   sets   of   values   in   AMM   modules   - -   representing   partial   functionality   of   the   associated   FPU - -   that   are   concurrently   evaluated   over   two   clock   cycles .   Our   simulation   results   show   high   hit   rates   with   32 - entry   AMM   modules   that   enable   36%   reduction   in   average   energy   use   by   the   kernel   codes .   Compared   to   voltage   overscaling ,   this   technique   enhances   robustness   against   timing   errors   with   39%   average   energy   saving . ' ,   ' title ' :   ' Energy - Efficient   GPGPU   Architectures   via   Collaborative   Compilation   and   Memristive   Memory - Based   Computing ' } 
{ ' abstract ' :   ' Quasi - cyclic   codes   are   renowned   for   their   structural   design   and   low - complexity   shift   register   encoding .   However ,   existing   design   techniques   based   on   difference   families   have   limited   code   size   options   due   to   algebraic   constraints .   We   introduce   in   this   paper   a   notation   of   extended   difference   family   ( EDF )   and   provide   a   systematic   code   design   based   on   EDFs   with   a   high   degree   of   flexibility   in   code   size .   Short / medium - length   codes   of   high   rate   ( / spl   ges /   0.9 )   can   be   easily   constructed . ' ,   ' title ' :   ' Quasi - cyclic   codes   from   extended   difference   families ' } 
{ ' abstract ' :   ' Lexical   cohesion   arises   from   a   chain   of   lexical   items   that   establish   links   between   sentences   in   a   text .   In   this   paper   we   propose   three   different   models   to   capture   lexical   cohesion   for   document - level   machine   translation :   ( a )   a   direct   reward   model   where   translation   hypotheses   are   rewarded   whenever   lexical   cohesion   devices   occur   in   them ,   ( b )   a   conditional   probability   model   where   the   appropriateness   of   using   lexical   cohesion   devices   is   measured ,   and   ( c )   a   mutual   information   trigger   model   where   a   lexical   cohesion   relation   is   considered   as   a   trigger   pair   and   the   strength   of   the   association   between   the   trigger   and   the   triggered   item   is   estimated   by   mutual   information .   We   integrate   the   three   models   into   hierarchical   phrase - based   machine   translation   and   evaluate   their   effectiveness   on   the   NIST   Chinese - English   translation   tasks   with   large - scale   training   data .   Experiment   results   show   that   all   three   models   can   achieve   substantial   improvements   over   the   baseline   and   that   the   mutual   information   trigger   model   performs   better   than   the   others . ' ,   ' title ' :   ' Modeling   lexical   cohesion   for   document - level   machine   translation ' } 
{ ' abstract ' :   ' This   paper   presents   a   lightweight   sketching   system   that   enables   interactive   illustration   of   complex   fluid   systems .   Users   can   sketch   on   a   2.5 - dimensional   ( 2.5 D )   canvas   to   design   the   shapes   and   connections   of   a   fluid   circuit .   These   input   sketches   are   automatically   analyzed   and   abstracted   into   a   hydraulic   graph ,   and   a   new   hybrid   fluid   model   is   used   in   the   background   to   enhance   the   illustrations .   The   system   provides   rich   simple   operations   for   users   to   edit   the   fluid   system   incrementally ,   and   the   new   internal   flow   patterns   can   be   simulated   in   real   time .   Our   system   is   used   to   illustrate   various   fluid   systems   in   medicine ,   biology ,   and   engineering .   We   asked   professional   medical   doctors   to   try   our   system   and   obtained   positive   feedback   from   them . ' ,   ' title ' :   ' Sketch - based   Dynamic   Illustration   of   Fluid   Systems ' } 
{ ' abstract ' :   ' We   present   an   improved   zone   content   classification   method   and   its   performance   evaluation .   We   added   two   new   features   to   the   feature   vector   from   one   previously   published   method   ( Sivaramakrishnan   et   al . ,   1995 ) .   We   assumed   different   independence   relationships   in   two   zone   sets .   We   used   an   optimized   binary   decision   tree   to   estimate   the   maximum   zone   content   class   probability   in   one   set   while   using   the   Viterbi   algorithm   to   find   the   optimal   solution   for   a   zone   sequence   in   the   other   set .   The   training ,   pruning   and   testing   data   set   for   the   algorithm   include   1 , 600   images   drawn   from   the   UWCDROM   III   document   image   database .   The   classifier   is   able   to   classify   each   given   scientific   and   technical   document   zone   into   one   of   the   nine   classes ,   2   text   classes   ( of   font   size   4   -   18pt   and   font   size   19   -   32   pt ) ,   math ,   table ,   halftone ,   map / drawing ,   ruling ,   logo ,   and   others .   Compared   with   our   previous   work   ( Wang   et   al . ,   2000 ) ,   it   raised   the   accuracy   rate   to   98.52%   from   97.53%   and   reduced   the   mean   false   alarm   rate   to   0.53%   from   1.26% . ' ,   ' title ' :   ' Zone   content   classification   and   its   performance   evaluation ' } 
{ ' abstract ' :   ' Big   Data   applications   require   real - time   processing   of   complex   computations   on   streaming   and   static   information .   Applications   such   as   the   diagnosis   of   power   generating   turbines   require   the   integration   of   high   velocity   streaming   and   large   volume   of   static   data   from   multiple   sources .   In   this   paper   we   study   various   optimisations   related   to   efficiently   processing   of   streaming   and   static   information .   We   introduce   novel   indexing   structures   for   stream   processing ,   a   query - planner   component   that   decides   when   their   creation   is   beneficial ,   and   we   examine   precomputed   summarisations   on   archived   measurements   to   accelerate   streaming   and   static   information   processing .   To   put   our   ideas   into   practise ,   we   have   developed   Exa   Stream ,   a   data   stream   management   system   that   is   scalable ,   has   declarative   semantics ,   supports   user   defined   functions ,   and   allows   efficient   execution   of   complex   analytical   queries   on   streaming   and   static   data .   Our   work   is   accompanied   by   an   empirical   evaluation   of   our   optimisation   techniques . ' ,   ' title ' :   ' Real   time   processing   of   streaming   and   static   information ' } 
{ ' abstract ' :   " In   the   last   ten   years ,   speech   recognition   has   evolved   from   a   science   fiction   dream   to   a   widespread   input   method   for   mobile   devices .   In   this   talk ,   I   will   describe   how   speech   recognition   works ,   the   problems   we   have   solved   and   the   challenges   that   remain .   I   will   touch   upon   some   of   Google ' s   main   efforts   in   language   and   pronunciation   modeling ,   and   describe   how   the   adoption   of   neural   networks   for   acoustic   modeling   marked   the   beginning   of   a   technology   revolution   in   the   field ,   with   approaches   such   as   Long   Short   Term   Memory   models   and   Connectionist   Temporal   Classification .   I   will   also   share   my   learnings   on   how   Machine   Learning   and   Human   Knowledge   can   be   harmoniously   combined   to   build   state - of - the - art   technology   that   helps   and   delights   users   across   the   world . " ,   ' title ' :   ' Learnings   and   innovations   in   speech   recognition ' } 
{ ' abstract ' :   ' Nowadays ,   the   explosive   growth   and   variety   of   information   available   on   the   Web   frequently   overwhelms   users   and   leads   users   to   make   poor   decisions .   Consequently ,   recommender   systems   have   become   more   and   more   important   to   assist   people   to   make   decisions   faster .   Among   all   related   techniques ,   collaborative   filtering   approach   is   currently   one   of   the   effective   and   widely   used   techniques   to   build   recommender   systems .   However ,   there   are   major   challenges   like   data   sparsity   and   scalability .   Meanwhile   it   is   hard   to   integrate   demographic   statistical   information   ( Age ,   gender   and   occupation   etc . )   to   collaborative   filtering   model .   Unfortunately ,   it   is   significant   to   take   account   into   these   information ,   especially   user   occupation   when   making   recommendation .   As   we   all   know ,   people   with   different   occupations   may   have   totally   different   tastes .   It   has   been   proved   that   restricted   Boltzmann   machines ( RBM )   model   can   infer   lower - dimensional   representations   automatically   and   is   potential   in   handling   large   and   sparse   dataset .   In   this   paper ,   we   propose   an   improved   User   Occupation   aware   Conditional   Restricted   Boltzmann   Machine   Frame ( UO - CRBMF )   model ,   which   employs   an   improved   RBM   and   takes   full   use   of   user   occupation   information   by   adding   a   conditional   layer   with   user   occupation   information .   Experimental   studies   on   the   standard   benchmark   datasets   of   MovieLens   100k   and   MovieLens   1M   have   shown   its   potential   and   advantages   beyond   baseline   methods . ' ,   ' title ' :   ' User   Occupation   Aware   Conditional   Restricted   Boltzmann   Machine   Based   Recommendation ' } 
{ ' abstract ' :   ' Microservices   complement   approaches   like   DevOps   and   continuous   delivery   in   terms   of   software   architecture .   Along   with   this   architectural   style ,   several   important   deployment   technologies ,   such   as   container - based   virtualization   and   container   orchestration   solutions ,   have   emerged .   These   technologies   allow   to   efficiently   exploit   cloud   platforms ,   providing   a   high   degree   of   scalability ,   availability ,   and   portability   for   microservices .# R ## N ## R ## N # Despite   the   obvious   importance   of   a   sufficient   level   of   performance ,   there   is   still   a   lack   of   performance   engineering   approaches   explicitly   taking   into   account   the   particularities   of   microservices .   In   this   paper ,   we   argue   why   new   solutions   to   performance   engineering   for   microservices   are   needed .   Furthermore ,   we   identify   open   issues   and   outline   possible   research   directions   with   regard   to   performance - aware   testing ,   monitoring ,   and   modeling   of   microservices . ' ,   ' title ' :   ' Performance   Engineering   for   Microservices :   Research   Challenges   and   Directions ' } 
{ ' abstract ' :   ' Intelligent   agents ,   such   as   robots ,   have   to   serve   a   multitude   of   autonomous   functions .   Examples   are ,   e . g . ,   collision   avoidance ,   navigation   and   route   planning ,   active   sensing   of   its   environment ,   or   the   interaction   and   non - verbal   communication   with   people   in   the   extended   reach   space .   Here ,   we   focus   on   the   recognition   of   the   action   of   a   human   agent   based   on   a   biologically   inspired   visual   architecture   of   analyzing   articulated   movements .   The   proposed   processing   architecture   builds   upon   coarsely   segregated   streams   of   sensory   processing   along   different   pathways   which   separately   process   form   and   motion   information   ( Layher   et   al . ,   2014 ) .   Action   recognition   is   performed   in   an   event - based   scheme   by   identifying   representations   of   characteristic   pose   configurations   ( key   poses )   in   an   image   sequence .   In   line   with   perceptual   studies ,   key   poses   are   selected   unsupervised   utilizing   a   feature   driven   criterion   which   combines   extrema   in   the   motion   energy   with   the   horizontal   and   the   vertical   extendedness   of   a   body   shape .   Per   class   representations   of   key   pose   frames   are   learned   using   a   deep   convolutional   neural   network   consisting   of   15   convolutional   layers .   The   network   is   trained   using   the   energy - efficient   deep   neuromorphic   networks   ( Eedn )   framework   ( Esser   et   al . ,   2016 ) ,   which   realizes   the   mapping   of   the   trained   synaptic   weights   onto   the   IBM   Neurosynaptic   System   platform   ( Merolla   et   al . ,   2014 ) .   After   the   mapping ,   the   trained   network   achieves   real - time   capabilities   for   processing   input   streams   and   classify   input   images   at   about   1 , 000   frames   per   second   while   the   computational   stages   only   consume   about   70   mW   of   energy   ( without   spike   transduction ) .   Particularly   regarding   mobile   robotic   systems ,   a   low   energy   profile   might   be   crucial   in   a   variety   application   scenarios .   Cross - validation   results   are   reported   for   two   different   datasets   and   compared   to   state - of - the - art   action   recognition   approaches .   The   results   demonstrate ,   that   ( I )   the   presented   approach   is   on   par   with   other   key   pose   based   methods   described   in   the   literature ,   which   select   key   pose   frames   by   optimizing   classification   accuracy ,   ( II )   compared   to   the   training   on   the   full   set   of   frames ,   representations   trained   on   key   pose   frames   result   in   a   higher   confidence   in   class   assignments ,   and   ( III )   key   pose   representations   show   promising   generalization   capabilities   in   a   cross - dataset   evaluation . ' ,   ' title ' :   ' Real - Time   Biologically   Inspired   Action   Recognition   from   Key   Poses   Using   a   Neuromorphic   Architecture ' } 
{ ' abstract ' :   ' Contents   carried   in   an   image   are   valuable   information   sources   for   many   scientific   and   engineering   applications .   However ,   if   the   image   is   captured   under   low   illumination   conditions   a   large   portion   of   the   image   appears   dark   and   this   heavily   degrades   the   image   quality .   In   order   to   solve   this   problem ,   a   restoration   algorithm   is   developed   here   that   transforms   the   low   input   brightness   to   a   higher   value   using   a   logarithmic   mapping   function .   The   mapping   is   further   refined   by   a   linear   weighting   with   the   input   to   reduce   the   un - necessary   amplification   at   regions   with   high   brightness .   Moreover ,   fine   details   in   the   image   are   preserved   by   applying   the   Retinex   principle   to   extract   and   then   re - insert   object   edges .   Results   from   experiments   using   low   and   normal   illumination   images   have   shown   satisfactory   performances   with   regard   to   the   improvement   in   information   contents   and   the   mitigation   of   viewing   artifacts . ' ,   ' title ' :   ' Logarithmic   profile   mapping   and   Retinex   edge   preserving   for   restoration   of   low   illumination   images ' } 
{ ' abstract ' :   ' We   propose   a   principled   approach   for   the   problem   of   aligning   multiple   partially   overlapping   networks .   The   objective   is   to   map   multiple   graphs   into   a   single   graph   while   preserving   vertex   and   edge   similarities .   The   problem   is   inspired   by   the   task   of   integrating   partial   views   of   a   family   tree   ( genealogical   network )   into   one   unified   network ,   but   it   also   has   applications ,   for   example ,   in   social   and   biological   networks .   Our   approach ,   called   Flan ,   introduces   the   idea   of   generalizing   the   facility   location   problem   by   adding   a   non - linear   term   to   capture   edge   similarities   and   to   infer   the   underlying   entity   network .   The   problem   is   solved   using   an   alternating   optimization   procedure   with   a   Lagrangian   relaxation .   Flan   has   the   advantage   of   being   able   to   leverage   prior   information   on   the   number   of   entities ,   so   that   when   this   information   is   available ,   Flan   is   shown   to   work   robustly   without   the   need   to   use   any   ground   truth   data   for   fine - tuning   method   parameters .   Additionally ,   we   present   three   multiple - network   extensions   to   an   existing   state - of - the - art   pairwise   alignment   method   called   Natalie .   Extensive   experiments   on   synthetic ,   as   well   as   real - world   datasets   on   social   networks   and   genealogical   networks ,   attest   to   the   effectiveness   of   the   proposed   approaches   which   clearly   outperform   a   popular   multiple   network   alignment   method   called   IsoRankN . ' ,   ' title ' :   ' Lagrangian   relaxations   for   multiple   network   alignment ' } 
{ ' abstract ' :   ' Heterogeneous   ultra - dense   networks   enable   ultra - high   data   rates   and   ultra - low   latency   through   the   use   of   dense   sub - 6   GHz   and   millimeter   wave   ( mmWave )   small   cells   with   different   antenna   configurations .   Existing   work   has   widely   studied   spectral   and   energy   efficiency   in   such   networks   and   shown   that   high   spectral   and   energy   efficiency   can   be   achieved .   This   article   investigates   the   benefits   of   heterogeneous   ultra - dense   network   architecture   from   the   perspectives   of   three   promising   technologies ,   i . e . ,   physical   layer   security ,   caching ,   and   wireless   energy   harvesting ,   and   provides   enthusiastic   outlook   towards   application   of   these   technologies   in   heterogeneous   ultra - dense   networks .   Based   on   the   rationale   of   each   technology ,   opportunities   and   challenges   are   identified   to   advance   the   research   in   this   emerging   network . ' ,   ' title ' :   ' A   New   Look   at   Physical   Layer   Security ,   Caching ,   and   Wireless   Energy   Harvesting   for   Heterogeneous   Ultra - dense   Networks ' } 
{ ' abstract ' :   ' We   consider   the   problem   of   joint   modeling   of   videos   and   their   corresponding   textual   descriptions   ( e . g .   sentences   or   phrases ) .   Our   approach   consists   of   three   components :   the   video   representation ,   the   textual   representation ,   and   a   joint   model   that   links   videos   and   text .   Our   video   representation   uses   the   state - of - the - art   deep   3D   ConvNet   to   capture   the   semantic   information   in   the   video .   Our   textual   representation   uses   the   recent   advancement   in   learning   word   and   sentence   vectors   from   large   text   corpus .   The   joint   model   is   learned   to   score   the   correct   ( video ,   text )   pairs   higher   than   the   incorrect   ones .   We   demonstrate   our   approach   in   several   applications :   1 )   retrieving   sentences   given   a   video ;   2 )   retrieving   videos   given   a   sentence ;   3 )   zero - shot   action   recognition   in   videos . ' ,   ' title ' :   ' Beyond   verbs :   Understanding   actions   in   videos   with   text ' } 
{ ' abstract ' :   ' This   paper   presents   a   multi - agent   model   for   simulating   attitude   formation   and   change   based   on   perception   and   communication   in   the   context   of   stabilization   operations .   The   originality   of   our   model   comes   from   ( 1 )   attitude   computation   that   evaluates   information   as   part   of   a   history   relative   to   the   individual   ( 2 )   a   notion   of   co - responsibility   for   attitude   attribution .   We   present   a   military   scenario   of   French   operations   in   Afghanistan   along   with   polls   results   about   the   opinion   of   citizen   toward   present   Forces .   Based   on   these   field   data ,   we   calibrate   the   model   and   show   the   resulting   attitude   dynamics .   We   study   the   sensibility   of   the   model   to   the   co - responsibility   factor . ' ,   ' title ' :   ' From   Field   Data   to   Attitude   Formation ' } 
{ ' abstract ' :   ' This   paper   proposes   two   low - complexity   iterative   algorithms   to   compute   the   capacity   of   a   single - user   multiple - input   multiple - output   channel   with   per - antenna   power   constraint .   The   first   method   results   from   manipulating   the   optimality   conditions   of   the   considered   problem   and   applying   fixed - point   iteration .   In   the   second   approach ,   we   transform   the   considered   problem   into   a   minimax   optimization   program   using   the   well - known   MAC -   BC   duality ,   and   then   solve   it   by   a   novel   alternating   optimization   method .   In   both   proposed   iterative   methods ,   each   iteration   involves   an   optimization   problem   which   can   be   efficiently   solved   by   the   water - filling   algorithm .   The   proposed   iterative   methods   are   provably   convergent .   Complexity   analysis   and   extensive   numerical   experiments   are   carried   out   to   demonstrate   the   superior   performance   of   the   proposed   algorithms   over   an   existing   approach   known   as   the   mode - dropping   algorithm . ' ,   ' title ' :   ' Low - complexity   Approaches   for   MIMO   Capacity   with   Per - antenna   Power   Constraint ' } 
{ ' abstract ' :   ' Inventory - Aware   Pathfinding   is   concerned   with   finding   paths   while   taking   into   account   that   picking   up   items ,   e . g . ,   keys ,   allow   the   character   to   unlock   blocked   pathways ,   e . g . ,   locked   doors .   In   this   work   we   present   a   pruning   method   and   a   preprocessing   method   that   can   improve   significantly   the   scalability   of   such   approaches .   We   apply   our   methods   to   the   recent   approach   of   Inventory - Driven   Jump - Point   Search   ( InvJPS ) .   First ,   we   introduce   InvJPS +   that   allows   to   prune   large   parts   of   the   search   space   by   favoring   short   detours   to   pick   up   items ,   offering   a   trade - off   between   efficiency   and   optimality .   Second ,   we   propose   a   preprocessing   step   that   allows   to   decide   on   runtime   which   items ,   e . g . ,   keys ,   are   worth   using   thus   pruning   potentially   unnecessary   items   before   the   search   starts .   We   show   results   for   combinations   of   the   pruning   and   preprocessing   methods   illustrating   the   best   choices   over   various   scenarios . ' ,   ' title ' :   ' Pruning   and   preprocessing   methods   for   inventory - aware   pathfinding ' } 
{ ' abstract ' :   ' This   paper   proposes   a   method   for   proper   names   extraction   from   Myanmar   text   by   using   latent   Dirichlet   allocation   ( LDA ) .   Our   method   aims   to   extract   proper   names   that   provide   important   information   on   the   contents   of   Myanmar   text .   Our   method   consists   of   two   steps .   In   the   first   step ,   we   extract   topic   words   from   Myanmar   news   articles   by   using   LDA .   In   the   second   step ,   we   make   a   post - processing ,   because   the   resulting   topic   words   contain   some   noisy   words .   Our   post - processing ,   first   of   all ,   eliminates   the   topic   words   whose   prefixes   are   Myanmar   digits   and   suffixes   are   noun   and   verb   particles .   We   then   remove   the   duplicate   words   and   discard   the   topic   words   that   are   contained   in   the   existing   dictionary .   Consequently ,   we   obtain   the   words   as   candidate   of   proper   names ,   namely   personal   names ,   geographical   names ,   unique   object   names ,   organization   names ,   single   event   names ,   and   so   on .   The   evaluation   is   performed   both   from   the   subjective   and   quantitative   perspectives .   From   the   subjective   perspective ,   we   compare   the   accuracy   of   proper   names   extracted   by   our   method   with   those   extracted   by   latent   semantic   indexing   ( LSI )   and   rule - based   method .   It   is   shown   that   both   LS ]   and   our   method   can   improve   the   accuracy   of   those   obtained   by   rule - based   method .   However ,   our   method   can   provide   more   interesting   proper   names   than   LSI .   From   the   quantitative   perspective ,   we   use   the   extracted   proper   names   as   additional   features   in   K - means   clustering .   The   experimental   results   show   that   the   document   clusters   given   by   our   method   are   better   than   those   given   by   LSI   and   rule - based   method   in   precision ,   recall   and   F - score . ' ,   ' title ' :   ' Extraction   of   proper   names   from   myanmar   text   using   latent   dirichlet   allocation ' } 
{ ' abstract ' :   ' Large   scale   assessment   of   aboveground   biomass   ( AGB )   in   tropical   forests   is   often   limited   by   the   saturation   of   remote   sensing   signals   at   high   AGB   values .   Fourier   Transform   Textural   Ordination   ( FOTO )   performs   well   in   quantifying   canopy   texture   from   very   high - resolution   ( VHR )   imagery ,   from   which   stand   structure   parameters   can   be   retrieved   with   no   saturation   effect   for   AGB   values   up   to   650   Mg · ha − 1 .   The   method   is   robust   when   tested   on   wet   evergreen   forests   but   is   more   demanding   when   applied   across   different   forest   types   characterized   by   varying   structures   and   allometries .   The   present   study   focuses   on   a   gradient   of   forest   types   ranging   from   dry   deciduous   to   wet   evergreen   forests   in   the   Western   Ghats   ( WG )   of   India ,   where   we   applied   FOTO   to   Cartosat - 1a   images   with   2.5   m   resolution .   Based   on   21   1 - ha   ground   control   forest   plots ,   we   calibrated   independent   texture – AGB   models   for   the   dry   and   wet   zone   forests   in   the   area ,   as   delineated   from   the   distribution   of   NDVI   values   computed   from   LISS - 4   multispectral   images .   This   stratification   largely   improved   the   relationship   between   texture - derived   and   field - derived   AGB   estimates ,   which   exhibited   a   R2   of   0.82   for   a   mean   rRMSE   of   ca .   17% .   By   inverting   the   texture – AGB   models ,   we   finally   mapped   AGB   predictions   at   1.6 - ha   resolution   over   a   heterogeneous   landscape   of   ca .   1500   km2   in   the   WG ,   with   a   mean   relative   per - pixel   propagated   error   < 20%   for   wet   zone   forests ,   i . e . ,   below   the   recommended   IPCC   criteria   for   Monitoring ,   Reporting   and   Verification   ( MRV )   methods .   The   method   proved   to   perform   well   in   predicting   high - resolution   AGB   values   over   heterogeneous   tropical   landscape   encompassing   diversified   forest   types ,   and   thus   presents   a   promising   option   for   affordable   regional   monitoring   systems   of   greenhouse   gas   ( GhG )   emissions   related   to   forest   degradation . ' ,   ' title ' :   ' Inverting   Aboveground   Biomass – Canopy   Texture   Relationships   in   a   Landscape   of   Forest   Mosaic   in   the   Western   Ghats   of   India   Using   Very   High   Resolution   Cartosat   Imagery ' } 
{ ' abstract ' :   ' Self - driving   vehicle   technologies   are   progressing   rapidly   and   are   expected   to   play   a   significant   role   in   the   future   of   transportation .   One   of   the   main   challenges   for   self - driving   vehicles   on   public   roads   is   the   safe   cooperation   and   collaboration   among   multiple   vehicles   using   sensor - based   perception   and   inter - vehicle   communications .   When   self - driving   vehicles   try   to   occupy   the   same   spatial   area   simultaneously ,   they   might   collide   with   one   another ,   might   become   deadlocked ,   or   might   slam   on   the   brakes   making   it   uncomfortable   or   unsafe   for   passengers   in   a   self - driving   vehicle .   In   this   paper ,   we   study   how   a   self - driving   vehicle   can   safely   navigate   merge   points ,   where   two   lanes   with   different   priorities   meet .   We   present   a   safe   protocol   for   merge   points   named   Autonomous   Vehicle   Protocol   for   Merge   Points ,   where   self - driving   vehicles   use   both   vehicular   communications   and   their   own   perception   systems   for   cooperating   with   other   self - driving   and / or   human - driven   vehicles .   Our   simulation   results   show   that   our   traffic   protocol   has   higher   traffic   throughput ,   compared   to   simple   traffic   protocols ,   while   ensuring   safety . ' ,   ' title ' :   ' A   merging   protocol   for   self - driving   vehicles ' } 
{ ' abstract ' :   ' System   Portfolio   Selection   ( SPS )   problem   is   equivalent   to   multi - objective   optimization   problem ,   with   multi - function   requirements   incommensurable .   In   the   paper ,   the   SPS   problem   is   re - specified   with   a   more   practical   formulation ,   comparing   to   general   portfolio   problem .   Then ,   both   feasible   and   non - inferior   solution   is   re - defined   considering   characteristics   of   SPS   problem ,   specifically ,   four   rules   of   system   function   combinations   are   proposed   according   to   practical   cases .   Then ,   the   instability   of   system   performance   is   involved   in   SPS   problem ,   and   the   robust   theory   is   employed   to   solving   the   uncertainty   of   system   function   values   with   definition   of   robust   non - inferior   solution .   Next ,   the   paper   proposes   an   immediately   updating   algorithm   to   solve   the   problem   of   solution   space   exponentially   growing .   Finally ,   a   case   study   is   used   to   demonstrate   the   usefulness   and   effectiveness   of   the   proposed   approaches .   It   shows   that   the   approach   can   provide   an   efficient   guidance   for   decision - makers   in   the   process   of   making   a   SPS . ' ,   ' title ' :   ' Robust   system   portfolio   selection   with   multi - function   requirements   and   system   instability ' } 
{ ' abstract ' :   ' This   study   explores   the   impact   of   high - photovoltaic   ( PV )   penetration   on   the   inter - area   oscillation   modes   of   large - scale   power   grids .   A   series   of   dynamic   models   with   various   PV   penetration   levels   are   developed   based   on   a   detailed   model   representing   the   U . S .   Eastern   Interconnection   ( EI ) .   Transient   simulations   are   performed   to   investigate   the   change   of   inter - area   oscillation   modes   with   PV   penetration .   The   impact   of   PV   control   strategies   and   parameter   settings   on   inter - area   oscillations   is   studied .   This   paper   finds   that   as   PV   increases ,   the   damping   of   the   dominant   oscillation   mode   decreases   monotonically .   It   is   also   observed   that   the   mode   shape   varies   with   the   PV   control   strategy   and   new   oscillation   modes   may   emerge   under   inappropriate   parameter   settings   in   PV   plant   controls . ' ,   ' title ' :   ' Impact   of   High   PV   Penetration   on   the   Inter - Area   Oscillations   in   the   U . S .   Eastern   Interconnection ' } 
{ ' abstract ' :   ' The   objective   of   this   research   is   to   compare   the   effectiveness   of   different   tracking   devices   underwater .   There   have   been   few   works   in   aquatic   virtual   reality   ( VR )   —   i . e . ,   VR   systems   that   can   be   used   in   a   real   underwater   environment .   Moreover ,   the   works   that   have   been   done   have   noted   limitations   on   tracking   accuracy .   Our   initial   test   results   suggest   that   inertial   measurement   units   work   well   underwater   for   orientation   tracking   but   a   different   approach   is   needed   for   position   tracking .   Towards   this   goal ,   we   have   waterproofed   and   evaluated   several   consumer   tracking   systems   intended   for   gaming   to   determine   the   most   effective   approaches .   First ,   we   informally   tested   infrared   systems   and   fiducial   marker   based   systems ,   which   demonstrated   significant   limitations   of   optical   approaches .   Next ,   we   quantitatively   compared   inertial   measurement   units   ( IMU )   and   a   magnetic   tracking   system   both   above   water   ( as   a   baseline )   and   underwater .   By   comparing   the   devices   rotation   data ,   we   have   discovered   that   the   magnetic   tracking   system   implemented   by   the   Razer   Hydra   is   more   accurate   underwater   as   compared   to   a   phone - based   IMU .   This   suggests   that   magnetic   tracking   systems   should   be   further   explored   for   underwater   VR   applications . ' ,   ' title ' :   ' Towards   usable   underwater   virtual   reality   systems ' } 
{ ' abstract ' :   ' A   faulty   network   GG   is   under   the   conditional   fault   model ,   i . e . , \ xa0every   fault - free   vertex   of   GG   is   incident   to   at   least   two   fault - free   edges .   Let   FFvFFv   and   FFeFFe   be   the   set   of   faulty   vertices   and   faulty   edges   in   FQnFQn ,   respectively .   In   this   paper ,   we   consider   FQnFQn   under   the   conditional   fault   model   and   prove   that   if   | FFv | + | FFe | ≤ 2n − 4 | FFv | + | FFe | ≤ 2n − 4   and   n ≥ 3n ≥ 3 ,   then   FQn − FFv − FFeFQn − FFv − FFe   contains   a   fault - free   cycle   of   every   even   length   from   4   to   2n − 2 | FFv | 2n − 2 | FFv | ;   if   | FFv | + | FFe | ≤ 2n − 5 | FFv | + | FFe | ≤ 2n − 5   and   n ≥ 4n ≥ 4   is   even ,   then   FQn − FFv − FFeFQn − FFv − FFe   contains   a   fault - free   cycle   of   every   odd   length   from   n + 1n + 1   to   2n − 2 | FFv | − 12n − 2 | FFv | − 1 . ' ,   ' title ' :   ' Cycles   embedding   in   folded   hypercubes   under   the   conditional   fault   model ' } 
{ ' abstract ' :   ' Companies   have   invested   considerable   resources   in   the   implementation   of   enterprise   resource   planning   ( ERP )   systems .   The   results   initially   expected   have   rarely   been   reached .   The   optimisation   ( or   efficient   use )   of   such   information   systems   is   nowadays   becoming   a   major   factor   for   firms   striving   to   reach   their   performance   objectives .   After   presenting   a   synthesis   of   several   studies   on   ERP   projects ,   we   build   on   the   findings   of   a   French   investigation   into   the   assessment   and   optimisation   of   ERP   performance .   A   classification   of   company   positions   regarding   their   ERP   use ,   based   on   both   software   maturity   and   strategic   deployment   directions ,   and   an   improvement   process   are   proposed .   Industrial   cases   allow   validation   of   this   approach . ' ,   ' title ' :   ' A   classification   for   better   use   of   ERP   systems ' } 
{ ' abstract ' :   ' This   paper   presents   a   time - domain   biosensor   array   that   uses   a   capacitor - less   current - mode   analog - to - time   converter   ( CMATC )   and   logarithmic   cyclic   time - attenuation - based   TDC   with   discharging   acceleration .   Combining   the   exponential   function   of   the   CMATC   and   logarithmic   function   of   the   proposed   TDC   offers   linear   input - output   characteristics .   The   time - domain   property   enables   bio - imaging   at   a   high   spatial   resolution   and   large   scale   while   maintaining   scalability .   Measurement   results   with   a   0.25 - μ m   test   chip   successfully   demonstrated   linear   input - output   characteristics . ' ,   ' title ' :   ' A   scalable   time - domain   biosensor   array   using   logarithmic   cyclic   time - attenuation - based   TDC   for   high - resolution   and   large - scale   bio - imaging ' } 
{ ' abstract ' :   ' Compared   to   current   mobile   networks ,   next - generation   mobile   networks   are   expected   to   support   higher   numbers   of   simultaneously   connected   devices   and   to   achieve   higher   system   spectrum   efficiency   and   lower   power   consumption .   To   achieve   these   goals ,   we   study   the   multi - sharing   device - to - device   ( D2D )   communication ,   which   allows   any   cellular   user   equipment   to   share   its   radio   resource   with   multiple   D2D   devices .   We   jointly   consider   resource   block   reuse   and   power   control   and   then   develop   the   MISS   algorithm .   Simulation   results   show   that   MISS   performs   very   well   in   terms   of   transmission   power   consumption ,   system   throughput ,   and   the   number   of   permitted   D2D   devices . ' ,   ' title ' :   ' Joint   Resource   Block   Reuse   and   Power   Control   for   Multi - Sharing   Device - to - Device   Communication ' } 
{ ' abstract ' :   ' This   paper   is   concerned   with   event - triggered   H ∞ H ∞   filtering   for   delayed   neural   networks   via   sampled   data .   A   novel   event - triggered   scheme   is   proposed ,   which   can   lead   to   a   significant   reduction   of   the   information   communication   burden   in   the   network ;   the   feature   of   this   scheme   is   that   whether   or   not   the   sampled   data   should   be   transmitted   is   determined   by   the   current   sampled   data   and   the   error   between   the   current   sampled   data   and   the   latest   transmitted   data .   By   constructing   a   proper   Lyapunov – Krasovskii   functional ,   utilizing   the   reciprocally   convex   combination   technique   and   Jensen ’ s   inequality   sufficient   conditions   are   derived   to   ensure   that   the   resultant   filtering   error   system   is   asymptotically   stable .   Based   on   the   derived   H ∞ H ∞   performance   analysis   results ,   the   H ∞ H ∞   filter   design   is   formulated   in   terms   of   Linear   Matrix   Inequalities   ( LMIs ) .   Finally ,   the   proposed   stability   conditions   are   demonstrated   with   numerical   example . ' ,   ' title ' :   ' Event - triggered   H   ∞   filtering   for   delayed   neural   networks   via   sampled - data ' } 
{ ' abstract ' :   ' For   the   double   integrator   with   matched   Lipschitz   disturbances   we   propose   a   continuous   homogeneous   controller   providing   finite - time   stability   of   the   origin .   The   disturbance   is   compensated   exactly   in   finite   time   using   a   discontinuous   function   through   an   integral   action .   Since   the   controller   is   dynamic ,   the   closed   loop   is   a   third   order   system   that   achieves   a   third   order   sliding   mode   in   the   steady   state .   The   stability   and   robustness   properties   of   the   controller   are   proven   using   a   smooth   and   homogeneous   strict   Lyapunov   function   ( LF ) .   In   a   first   stage ,   the   gains   of   the   controller   and   the   LF   are   designed   using   a   method   based   on   Polya ’ s   Theorem .   In   a   second   stage   the   controller ’ s   gains   are   adjusted   through   a   sum   of   squares   representation   of   the   LF . ' ,   ' title ' :   ' Design   of   Continuous   Twisting   Algorithm ' } 
{ ' abstract ' :   ' Big   data   is   now   rapidly   expanding   into   various   domains   such   as   banking ,   insurance   and   e - commerce .   Data   analysis   and   related   studies   have   attracted   more   attentions .   In   health   insurance ,   abuse   of   diagnosis   is   one   of   the   key   fraud   problems ,   which   damages   the   interests   of   insured   people .   To   address   this   issue ,   numbers   of   studies   have   focused   on   this   topic .   This   paper   develops   a   healthcare   fraud   detection   approach   based   on   the   trustworthiness   of   doctors   to   distinguish   fraud   cases   from   normal   records .   Compared   to   conventional   methods ,   our   approach   can   detect   healthcare   fraud   in   a   good   accuracy   by   only   little   feature   information   from   healthcare   data   without   the   violation   of   privacy .   This   approach   combines   a   weighted   HITS   algorithm   with   a   frequent   pattern   mining   algorithm   to   calculate   a   rational   treatment   model   of   a   certain   disease .   In   addition ,   this   paper   also   introduces   the   copy   precision   behavior   in   the   treatment   sequences   of   patients ,   which   is   a   critical   metric   to   learn   the   trustworthiness   of   doctors .   The   numerical   validation   with   a   healthcare   dataset   demonstrates   that   healthcare   fraud   by   misdiagnosis   in   healthcare   treatments   can   be   successfully   detected   by   employing   the   developed   fraud   detection   approach . ' ,   ' title ' :   ' Healthcare   Fraud   Detection   Based   on   Trustworthiness   of   Doctors ' } 
{ ' abstract ' :   ' In   this   paper   we   study   data   collection   in   an   energy   renewable   sensor   network   for   scenarios   such   as   traffic   monitoring   on   busy   highways ,   where   sensors   are   deployed   along   a   predefined   path   ( the   highway )   and   a   mobile   sink   travels   along   the   path   to   collect   data   from   one - hop   sensors   periodically .   As   sensors   are   powered   by   renewable   energy   sources ,   time - varying   characteristics   of   ambient   energy   sources   poses   great   challenges   in   the   design   of   efficient   routing   protocols   for   data   collection   in   such   networks .   In   this   paper   we   first   formulate   a   novel   data   collection   maximization   problem   by   adopting   multi - rate   data   transmissions   and   performing   transmission   time   slot   scheduling ,   and   show   that   the   problem   is   NP - hard .   We   then   devise   an   offline   algorithm   with   a   provable   approximation   ratio   for   the   problem   by   exploiting   the   combinatorial   property   of   the   problem ,   assuming   that   the   harvested   energy   at   each   node   is   given   and   link   communications   in   the   network   are   reliable .   We   also   extend   the   proposed   algorithm   by   minor   modifications   to   a   general   case   of   the   problem   where   the   harvested   energy   at   each   sensor   is   not   known   in   advance   and   link   communications   are   not   reliable .   We   thirdly   develop   a   fast ,   scalable   online   distributed   algorithm   for   the   problem   in   realistic   sensor   networks   in   which   neither   the   global   knowledge   of   the   network   topology   nor   sensor   profiles   such   as   sensor   locations   and   their   harvested   energy   profiles   is   given .   Furthermore ,   we   also   consider   a   special   case   of   the   problem   where   each   node   has   only   a   fixed   transmission   power ,   for   which   we   propose   an   exact   solution   to   the   problem .   We   finally   conduct   extensive   experiments   by   simulations   to   evaluate   the   performance   of   the   proposed   algorithms .   Experimental   results   demonstrate   that   the   proposed   algorithms   are   efficient   and   the   solutions   obtained   are   fractional   of   the   optimum . ' ,   ' title ' :   ' Data   Collection   Maximization   in   Renewable   Sensor   Networks   via   Time - Slot   Scheduling ' } 
{ ' abstract ' :   ' An   increasing   number   of   businesses   are   migrating   their   IT   operations   to   the   cloud .   Likewise   there   is   an   increased   emphasis   on   data   analytics   based   on   multiple   datasets   and   sources   to   derive   information   not   derivable   when   a   dataset   is   mined   in   isolation .   While   ensuring   security   of   data   and   computation   outsourced   to   a   third   party   cloud   service   provider   is   in   itself   challenging ,   supporting   mash - ups   and   analytics   of   data   from   different   parties   hosted   across   different   services   is   even   more   so .   In   this   paper   we   propose   a   cloud - based   service   allowing   multiple   parties   to   perform   secure   multi - party   secure   sum   computation   using   their   clouds   as   delegates .   Our   scheme   provides   data   privacy   both   from   the   delegates   as   well   as   from   the   other   data   owners   under   a   lazy - and - curious   adversary   ( semi - honest )   model .   We   then   describe   how   such   a   secure   sum   primitive   may   be   used   in   various   collaborative ,   cloud - based   distributed   data   mining   tasks   ( classification ,   association   rule   mining   and   clustering ) .   We   implement   a   prototype   and   benchmark   the   service ,   both   as   a   stand - alone   secure   sum   service ,   and   as   a   building   block   for   more   complex   analytics .   The   results   suggest   reasonable   overhead   and   demonstrate   the   practicality   of   carrying   out   privacy   preserved   distributed   analytics   despite   migrating   ( encrypted )   data   to   pos -   sibly   different   and   untrusted   ( semi - honest )   cloud   services . ' ,   ' title ' :   ' Delegated   Secure   Sum   Service   for   Distributed   Data   Mining   in   Multi - Cloud   Settings ' } 
{ ' abstract ' :   ' This   paper   fundamentally   investigates   the   performance   of   evolutionary   multiobjective   optimization   ( EMO )   algorithms   for   computationally   hard   0 - 1   combinatorial   optimization ,   where   a   strict   theoretical   analysis   is   generally   out   of   reach   due   to   the   high   complexity   of   the   underlying   problem .   Based   on   the   examination   of   problem   features   from   a   multiobjective   perspective ,   we   improve   the   understanding   of   the   efficiency   of   a   simple   dominance - based   EMO   algorithm   with   unbounded   archive   for   multiobjective   NK - landscapes   with   correlated   objective   values .   More   particularly ,   we   adopt   a   statistical   approach ,   based   on   simple   and   multiple   linear   regression   analysis ,   to   enquire   the   expected   running   time   of   global   SEMO   with   restart   for   identifying   a   ( 1 + e ) - approximation   of   the   Pareto   set   for   small - size   enumerable   instances .   Our   analysis   provides   further   insights   on   the   EMO   search   behavior   and   on   the   most   important   features   that   characterize   the   difficulty   of   an   instance   for   this   class   of   problems   and   algorithms . ' ,   ' title ' :   ' A   feature - based   performance   analysis   in   evolutionary   multiobjective   optimization ' } 
{ ' abstract ' :   ' Functional   biological   sequences ,   which   typically   come   in   families ,   have   retained   some   level   of   similarity   and   function   during   evolution .   Finding   consensus   regions ,   alignment   of   sequences ,   and   identifying   the   relationship   between   a   sequence   and   a   family   allow   inferences   about   the   function   of   the   sequences .   Profile   hidden   Markov   models   ( HMMs )   are   generally   used   to   identify   those   relationships .   A   profile   HMM   can   be   trained   on   unaligned   members   of   the   family   using   conventional   algorithms   such   as   Baum - Welch ,   Viterbi ,   and   their   modifications .   The   overall   quality   of   the   alignment   depends   on   the   quality   of   the   trained   model .   Unfortunately ,   the   conventional   training   algorithms   converge   to   suboptimal   models   most   of   the   time .   This   work   proposes   a   training   algorithm   that   early   identifies   many   imperfect   models .   The   method   is   based   on   the   Simulated   Annealing   approach   widely   used   in   discrete   optimization   problems .   The   training   algorithm   is   implemented   as   a   component   in   HMMER .   The   performance   of   the   algorithm   is   discussed   on   protein   sequence   data . ' ,   ' title ' :   ' Simulated   annealing   algorithm   with   biased   neighborhood   distribution   for   training   profile   models ' } 
{ ' abstract ' :   ' The   Canny   algorithm   is   a   well   known   edge   detector   that   is   widely   used   in   the   previous   processing   stages   in   several   algorithms   related   to   computer   vision .   An   alternative ,   the   LIP - Canny   algorithm ,   is   based   on   a   robust   mathematical   model   closer   to   the   human   vision   system ,   obtaining   better   results   in   terms   of   edge   detection .   In   this   work   we   describe   LIP - Canny   algorithm   under   the   perspective   from   its   parallelization   and   optimization   by   using   the   NVIDIA   CUDA   framework .   Furthermore ,   we   present   comparative   results   between   an   implementation   of   this   algorithm   using   NVIDIA   CUDA   and   the   analogue   using   a   C / C++   approach . ' ,   ' title ' :   ' Parallelizing   and   optimizing   LIP - canny   using   NVIDIA   CUDA ' } 
{ ' abstract ' :   ' This   paper   presents   an   efficient   Bayesian   blind   multiuser   receiver   for   long   code   multipath   CDMA   systems .   The   proposed   receiver   employs   the   adaptive   sampling   method   for   the   Bayesian   inference   procedure   to   estimate   the   data   symbols   and   multipath   parameters .   Compared   to   the   other   reported   Bayesian   Monte   Carlo   receivers   for   long   code   multipath   CDMA   systems ,   the   proposed   one   achieves   a   faster   convergence   and   a   lower   computational   complexity   to   attain   comparable   performance .   Simulation   results   are   presented   to   demonstrate   the   effectiveness   of   the   proposed   Bayesian   blind   multiuser   receiver . ' ,   ' title ' :   ' Blind   Multiuser   Detection   for   Long   Code   Multipath   DS - CDMA   Systems   with   Bayesian   MC   Techniques ' } 
{ ' abstract ' :   ' Spreadsheets   are   by   far   the   most   prominent   example   of   end - user   programs   of   ample   size   and   substantial   structural   complexity .   In   addition ,   spreadsheets   are   usually   not   tested   very   rigorously   and   thus   comprise   faults .   Locating   faults   is   a   hard   task   due   to   the   size   and   the   structure ,   which   is   usually   not   directly   visible   to   the   user ,   i . e . ,   the   functions   are   hidden   behind   the   cells   and   only   the   computed   values   are   presented .   Hence ,   there   is   a   strong   need   for   debugging   support .   In   this   paper ,   we   adapt   three   program - debugging   approaches   that   have   been   designed   for   more   traditional   procedural   or   object - oriented   programming   languages .   These   techniques   are   Spectrum - based   Fault   Localization ,   Spectrum - Enhanced   Dynamic   Slicing ,   and   Constraint - based   Debugging .   Beside   the   theoretical   foundations ,   we   present   a   more   sophisticated   empirical   evaluation   including   a   comparison   of   these   approaches .   The   empirical   evaluation   shows   that   Sfl   ( Spectrum - based   Fault   Localization )   and   Sendys   ( Spectrum   ENhanced   Dynamic   Slicing )   are   the   most   promising   techniques . ' ,   ' title ' :   ' On   the   empirical   evaluation   of   fault   localization   techniques   for   spreadsheets ' } 
{ ' abstract ' :   ' This   work   provides   elements   to   highlight   the   reliability   challenges   related   to   the   technology   scaling   and   the   BTI   variability .   Through   main   milestones   including   device   reliability   scaling   model   ( for   both   mean   and   spread ) ,   a   discussion   on   the   physical   origin   of   BTI   variability   and   a   digital   IP   failure   rate   analytical   model ,   the   evolution   of   digital   IP   failure   rates   along   the   ITRS   scaling   roadmap   is   assessed .   and   an   analysis   of   the   ITRS   roadmap   on   digital   IP   failure   rates .   This   study   offers   new   perspectives   towards   product   hardening   and   qualification   with   respect   to   both   fresh   and   BTI - related   local   variability ,   especially   in   context   where   Adaptive   Voltage   Scaling   ( AVS )   is   used   to   compensate   for   process   centerings . ' ,   ' title ' :   ' From   BTI   variability   to   product   failure   rate :   A   technology   scaling   perspective ' } 
{ ' abstract ' :   ' In   this   paper   we   discuss   the   problem   of   calculating   the   reachable   states   of   a   dynamical   system   defined   by   ordinary   differential   equations   or   inclusions .   We   present   a   prototype   system   for   approximating   this   set   and   demonstrate   some   experimental   results . ' ,   ' title ' :   ' Reachability   Analysis   via   Face   Lifting ' } 
{ ' abstract ' :   ' By   introducing   the   new   concepts   of   fuzzy     β   - covering   and   fuzzy     β   - neighborhood ,   we   define   two   new   types   of   fuzzy   covering   rough   set   models   which   can   be   regarded   as   bridges   linking   covering   rough   set   theory   and   fuzzy   rough   set   theory .   We   show   the   properties   of   the   two   models ,   and   reveal   the   relationships   between   the   two   models   and   some   others .   Moreover ,   we   present   the   matrix   representations   of   the   newly   defined   lower   and   upper   approximation   operators   so   that   the   calculation   of   lower   and   upper   approximations   of   subsets   can   be   converted   into   operations   on   matrices .   Finally ,   we   generalize   the   models   and   their   matrix   representations   to     L   - fuzzy   covering   rough   sets   which   are   defined   over   fuzzy   lattices . ' ,   ' title ' :   ' Two   fuzzy   covering   rough   set   models   and   their   generalizations   over   fuzzy   lattices ' } 
{ ' abstract ' :   ' Mobile   applications   are   becoming   complex   software   systems   that   must   be   developed   quickly   and   evolve   regularly   to   fit   new   user   requirements   and   execution   contexts .   However ,   addressing   these   constraints   may   result   in   poor   design   choices ,   known   as   antipatterns ,   which   may   degrade   software   quality   and   performance .   Thus ,   the   automatic   detection   of   antipatterns   is   an   important   activity   that   eases   the   future   maintenance   and   evolution   tasks .   Moreover ,   it   helps   developers   to   refactor   their   applications   and   thus ,   to   improve   their   quality .   While   antipatterns   are   well - known   in   object - oriented   applications ,   their   study   in   mobile   applications   is   still   in   their   infancy .   In   this   paper ,   we   presents   a   tooled   approach ,   called   P   aprika   ,   to   analyze   Android   applications   and   to   detect   object - oriented   and   Android - specific   antipatterns   from   binaries   of   applications . ' ,   ' title ' :   ' An   approach   to   detect   Android   antipatterns ' } 
{ ' abstract ' :   ' In   this   paper   we   present   a   new   method   for   object   categorization .   Firstly   an   image   representation   is   obtained   by   the   proposed   hierarchical   learning   method   consisting   of   alternating   between   local   coding   and   maximum   pooling   operations ,   where   the   local   coding   operation   induces   discrimination   while   the   image   descriptor   and   maximum   pooling   operation   induces   invariance   in   hierarchical   architecture .   Then   the   obtained   effective   image   representation   is   passed   to   a   linear   classifier   which   is   suitable   for   large   databases   for   object   categorization .   We   have   demonstrated   that   the   proposed   method   is   robust   to   image   variations   and   has   low   sample   complexity . ' ,   ' title ' :   ' Object   categorization   based   on   hierarchical   learning ' } 
{ ' abstract ' :   ' We   have   previously   proposed   a   howling   canceller   which   cancels   howling   by   using   a   cascade   notch   filter   designed   from   a   distance   between   a   loudspeaker   and   a   microphone .   This   method   utilizes   a   pilot   signal   to   estimate   the   distance .   In   this   paper ,   we   introduce   two   methods   into   the   distance - based   howling   canceller   to   improve   speech   quality .   The   first   one   is   an   adaptive   cascade   notch   filter   which   adaptively   adjusts   the   nulls   to   eliminate   howling   and   to   keep   speech   components .   The   second   one   is   a   silent   pilot   signal   whose   frequencies   exist   in   the   ultrasonic   band ,   and   it   is   inaudible   while   on   transmission .   We   implement   the   proposed   howling   canceller   on   a   DSP   to   evaluate   its   capability .   The   experimental   results   show   that   the   proposed   howling   canceller   improves   speech   quality   in   comparison   to   the   conventional   one . ' ,   ' title ' :   ' A   High   Speech   Quality   Distance - Based   Howling   Canceller   with   Adaptive   Cascade   Notch   Filter   and   Silent   Pilot   Signal ' } 
{ ' abstract ' :   ' Purpose   –   This   paper   aims   to   look   at   how   varying   terminology   is   used   on   school   library   web   sites   and   how   that   compares   to   student   preferences . Design / methodology / approach   –   Provides   research   conduced   by   surveying   practicing   school   librarians   and   k ‐ 12   students . Findings   –   Terminology   varies   greatly   on   school   library   web   sites .   Further ,   students   prefer   common   language   use . Practical   implications   –   Practicing   librarians   may   consider   revising   their   web   sites   in   order   to   make   them   more   accessible   for   their   students . Originality / value   –   This   paper   provides   original   research   into   school   library   web   sites ,   an   area   that   is   lacking . ' ,   ' title ' :   ' School   library   web   site   terminology ' } 
{ ' abstract ' :   ' Recently ,   numerous   multireceiver   identity - based   encryption   or   identity - based   broadcast   encryption   schemes   have   been   introduced   with   bilinear   pairing   and   probabilistic   map - to - point   MTP   function .   As   the   bilinear   pairing   and   MTP   functions   are   expensive   operations ,   any   cryptographic   schemes   based   on   these   operations   experience   high   computational   burden .   The   certificateless   public   key   cryptography   sidesteps   the   private   key   escrow   problem   occurring   in   identity - based   cryptosystem   and   certificate   management   troubles   of   certificate   authority - based   public   key   cryptography   CA - PKC .   We   observed   that   certificateless   multireceiver   encryption   CL - MRE   scheme   without   pairing   and   MTP   hash   function   has   not   yet   been   considered   in   the   literature .   In   this   paper ,   we   proposed   a   bilinear   pairing   and   MTP   hash - function - free   CL - MRE   scheme   with   chosen   ciphertext   attack   resilience .   The   detailed   analyses   provide   evidence   that   our   scheme   achieves   forward   secrecy ,   backward   secrecy ,   and   low   computation   costs   than   others .   The   scheme   also   provides   confidentiality   of   the   message   and   receiver   anonymity   in   the   random   oracle   model   with   the   hardness   of   computational   Diffie - Hellman   problem .   Copyright   ©   2014   John   Wiley   &   Sons ,   Ltd . ' ,   ' title ' :   ' Anonymous   and   provably   secure   certificateless   multireceiver   encryption   without   bilinear   pairing ' } 
{ ' abstract ' :   ' We   study   the   problem   of   approximating   one - dimensional   nonintegrable   codistributions   by   integrable   ones   and   apply   the   resulting   approximations   to   approximate   feedback   linearization   of   single - input   systems .   The   approach   derived   in   this   paper   allows   a   linearizable   nonlinear   system   to   be   found   that   is   close   to   the   given   system   in   a   least - squares   ( L2 )   sense .   A   linearly   controllable   single - input   affine   nonlinear   system   is   feedback   linearizable   if   and   only   if   its   characteristic   distribution   is   involutive   ( hence   integrable )   or ,   equivalently ,   any   characteristic   one - form   ( a   one - form   that   annihilates   the   characteristic   distribution )   is   integrable .   We   study   the   problem   of   finding   ( least - squares   approximate )   integrating   factors   that   make   a   fixed   characteristic   one - form   close   to   being   exact   in   anL2   sense .   A   given   one - form   can   be   decomposed   into   exact   and   inexact   parts   using   the   Hodge   decomposition .   We   derive   an   upper   bound   on   the   size   of   the   inexact   part   of   a   scaled   characteristic   one - form   and   show   that   a   least - squares   integrating   factor   provides   the   minimum   value   for   this   upper   bound .   We   also   consider   higher - order   approximate   integrating   factors   that   scale   a   nonintegrable   one - form   in   a   way   that   the   scaled   form   is   closer   to   being   integrable   inL2   together   with   some   derivatives   and   derive   similar   bounds   for   the   inexact   part .   This   allows   a   linearizable   nonlinear   system   that   is   close   to   the   given   system   in   a   least - squares   ( L2 )   sense   together   with   some   derivatives   to   be   found .   The   Sobolev   embedding   techniques   allow   us   to   obtain   an   upper   bound   on   the   uniform   ( L ∞ )   distance   between   the   nonlinear   system   and   its   linearizable   approximation . ' ,   ' title ' :   ' Least - squares   integration   of   one - dimensional   codistributions   with   application   to   approximate   feedback   linearization ' } 
{ ' abstract ' :   ' Latent   sector   errors   in   disk   drives   affect   only   a   few   data   sectors .   They   occur   silently   and   are   detected   only   when   the   affected   area   is   accessed   again .   If   a   latent   error   is   detected   while   the   storage   system   is   operating   under   reduced   redundancy ,   i . e . ,   during   a   RAID   rebuild ,   then   data   loss   may   occur .   Various   features   such   as   scrubbing   and   intra - disk   data   redundancy   are   proposed   to   detect   and / or   recover   from   latent   errors   and   avoid   data   loss .   While   such   features   enhance   data   availability   in   the   storage   system ,   their   execution   may   cause   performance   degradation .   In   this   paper ,   we   evaluate   the   effectiveness   of   scrubbing   and   intra - disk   data   redundancy   in   improving   data   availability   while   the   overall   goal   is   to   maintain   user   performance   within   predefined   bounds .   We   show   that   by   treating   them   as   low   priority   background   activities   and   scheduling   them   efficiently   during   idle   times ,   these   features   remain   performance - wise   transparent   to   the   storage   system   user   while   still   improving   data   reliability .   Detailed   trace - driven   simulations   show   that   the   mean   time   to   data   loss   ( MTTDL )   improves   by   up   to   5   orders   of   magnitude   if   these   features   are   implemented   independently .   By   scheduling   concurrently   both   scrubbing   and   intra - disk   parity   updates   during   idle   times   in   disk   drives ,   MTTDL   improves   by   as   much   as   8   orders   of   magnitude . ' ,   ' title ' :   ' Enhancing   data   availability   in   disk   drives   through   background   activities ' } 
{ ' abstract ' :   ' Financial   crisis   forecasting   has   been   a   long - standing   challenge   that   often   involves   couplings   between   indicators   of   multiple   markets .   Such   couplings   include   implicit   relations   that   might   not   be   effectively   detected   from   raw   market   observations .   However ,   most   methods   for   crisis   forecasting   rely   directly   on   market   observations   and   might   not   detect   the   hidden   interactions   between   markets .   To   this   end ,   the   authors   explore   coupled   market   state   analysis   ( CMSA ) ,   assuming   that   the   observations   of   markets   are   governed   by   a   collection   of   intra -   and   intercoupled   hidden   market   states .   Accordingly ,   they   built   a   forecaster   based   on   these   coupled   market   states   instead   of   observations . ' ,   ' title ' :   ' Financial   Crisis   Forecasting   via   Coupled   Market   State   Analysis ' } 
{ ' abstract ' :   ' In   this   paper ,   an   “ intelligent ”   isolated   intersection   control   system   was   developed .   The   developed   “ intelligent ”   system   makes   “ real   time ”   decisions   as   to   whether   to   extend   ( and   how   much )   current   green   time .   The   model   developed   is   based   on   the   combination   of   the   dynamic   programming   and   neural   networks .   Many   tests   show   that   the   outcome   ( the   extension   of   the   green   time )   of   the   proposed   neural   network   is   nearly   equal   to   the   best   solution .   Practically   negligible   CPU   times   were   achieved ,   and   were   thus   absolutely   acceptable   for   the   “ real   time ”   application   of   the   developed   algorithm . ' ,   ' title ' :   ' Dynamic   programming — neural   network   real - time   traffic   adaptive   signal   control   algorithm ' } 
{ ' abstract ' :   ' This   issue   features   expanded   versions   of   articles   selected   from   the   2014   AAAI   Conference   on   Innovative   Applications   of   Artificial   Intelligence   held   in   Quebec   City ,   Canada .   We   present   a   selection   of   four   articles   describing   deployed   applications   plus   two   more   articles   that   discuss   work   on   emerging   applications . ' ,   ' title ' :   ' Introduction   to   the   Special   Issue   on   Innovative   Applications   of   Artificial   Intelligence   2014 ' } 
{ ' abstract ' :   ' Although   frequently   used   in   fractal   compression   quadrant - based   classification   exhibits   a   significant   defect   which   has   not   been   described   in   the   literature .   We   give   an   efficient   solution   to   this   problem   by   controlling   the   class   structure   based   on   an   adaptive   threshold .   This   makes   this   classification   technique   a   very   efficient   and   competitive   one   also   for   block   matching   motion   compensation   algorithms   in   video   coding . ' ,   ' title ' :   ' Resolving   a   defect   in   quadrant - based   classification   for   fast   block - matching ' } 
{ ' abstract ' :   ' Where   there   are   infinitely   many   possible   basic   states   of   the   world ,   a   standard   probability   function   must   assign   zero   probability   to   each   state   –   since   any   finite   probability   would   sum   to   over   one .   This   generates   problems   for   any   decision   theory   that   appeals   to   expected   utility   or   related   notions .   For   it   leads   to   the   view   that   a   situation   in   which   one   wins   a   million   dollars   if   any   of   a   thousand   of   the   equally   probable   states   is   realized   has   an   expected   value   of   zero   ( since   each   such   state   has   probability   zero ) .   But   such   a   situation   dominates   the   situation   in   which   one   wins   nothing   no   matter   what   ( which   also   has   an   expected   value   of   zero ) ,   and   so   surely   is   more   desirable .   I   formulate   and   defend   some   principles   for   evaluating   options   where   standard   probability   functions   cannot   strictly   represent   probability   –   and   in   particular   for   where   there   is   an   infinitely   spread ,   uniform   distribution   of   probability .   The   principles   appeal   to   standard   probability   functions ,   but   overcome   at   least   some   of   their   limitations   in   such   cases . ' ,   ' title ' :   ' Standard   decision   theory   corrected ' } 
{ ' abstract ' :   ' Backed   by   the   European   Commission ,   a   consortium   of   partners   from   European   industry ,   financial   institutions ,   and   academia   has   embarked   on   a   research   project   to   develop   the   fundamentals   of   secure   electronic   commerce .   The   goal   of   the   9 - million   ECU   project ,   SEMPER   ( Secure   Electronic   Marketplace   for   Europe ) ,   is   to   provide   the   first   open   and   comprehensive   solutions   for   secure   commerce   over   the   Internet   and   other   public   information   networks .   We   describe   the   objectives   and   summarise   the   initial   architecture   of   SEMPER .   A   wide   range   of   businesses   are   rapidly   moving   to   explore   the   huge   potential   of   net -   worked   information   systems ,   especially   with   the   Internet - based   WWW   ( World - wide   Web ) .   The   Internet ,   which   already   connects   more   than   3   million   computers   and   a   sub -   stantially   larger   number   of   users ,   is   growing   at   a   breathtaking   pace   with   thousands   of   newcomers   every   day .   Although   the   Internet   has   its   roots   in   academia   and   is   still   domi -   nated   by   free - of - charge   information ,   dramatic   changes   are   expected   in   the   near   future .   For   instance ,   the   WWW   will   be   used   for   a   wide   variety   of   electronic   commerce   such   as   on - line   trade   or   delivery   of   advanced   multimedia   information   services .   The   evolution   of   broadband   networks   and   " information   highways "   will   intensify   this   trend .   The   need   for   secure   transactions   in   this   new   business   environment ,   which   involves   networks   available   to   the   general   public ,   has   triggered   a   number   of   related   efforts .   These   initial   developments   are   based   almost   exclusively   in   the   US   and   most   of   them   are   limited   to   proprietary ,   or   otherwise   closed   solutions ,   involving   only   electronic   payment   issues .   In   contrast ,   SEMPER   is   directed   towards   a   comprehensive   solution   for   secure   electronic   commerce ,   considering   legal ,   commercial ,   social ,   and   technical   requirements   as   well   as   different   options   for   an   electronic   marketplace . ' ,   ' title ' :   ' Development   of   a   Secure   Electronic   Marketplace   for   Europe ' } 
{ ' abstract ' :   ' Through   the   use   of   a   global   geometric   symmetry ,   detection   ellipses   are   proposed   in   this   paper .   Based   on   the   geometric   symmetry ,   the   proposed   method   first   locates   candidates   of   ellipses   centers .   In   the   meantime ,   according   to   these   candidate   centers ,   all   feature   points   in   an   input   image   are   grouped   into   several   subimages .   Then ,   for   each   subimage ,   by   using   geometric   properties   again ,   all   ellipses   are   extracted .   The   method   significantly   reduces   the   time   required   to   evaluate   all   possible   parameters   without   using   edge   direction   information .   Experimental   results   are   given   to   show   the   correctness   and   effectiveness   of   the   proposed   method . ' ,   ' title ' :   ' Detection   ellipses   by   finding   lines   of   symmetry   in   the   images   via   an   hough   transform   applied   to   straight   lines ' } 
{ ' abstract ' :   ' Automatic   crawling   of   Rich   Internet   Applications   ( RIAs )   is   a   challenge   because   client - side   code   modifies   the   client   dynamically ,   fetch -   ing   server - side   data   asynchronously .   Most   existing   solutions   model   RIAs   as   state   machines   with   DOMs   as   states   and   JavaScript   events   execution   as   transitions .   This   approach   fails   when   used   with   " real - life " ,   complex   RIAs ,   because   the   size   of   the   produced   model   is   much   too   large   to   be   practical .   In   this   paper ,   we   propose   a   new   method   to   crawl   AJAX - based   RIAs   in   an   efficient   manner   by   detecting   " components " ,   which   are   areas   of   the   DOM   that   are   independent   from   each   other ,   and   by   crawling   each   component   separately .   This   leads   to   a   dramatic   reduction   of   the   required   state   space   for   the   model ,   without   loss   of   content   coverage .   Our   method   does   not   require   prior   knowledge   of   the   RIA   nor   predefined   definition   of   components .   Instead ,   we   infer   the   components   by   observing   the   be -   havior   of   the   RIA   during   crawling .   Our   experimental   results   show   that   our   method   can   index   quickly   and   completely   industrial   RIAs   that   are   simply   out   of   reach   for   traditional   methods . ' ,   ' title ' :   ' Indexing   Rich   Internet   Applications   Using   Components - Based   Crawling ' } 
{ ' abstract ' :   ' One   important   aspect   of   constructing   an   overlay   network   is   how   to   exploit   network   locality   in   the   underlying   network .   In   this   paper ,   we   propose   a   scalable   protocol   for   constructing   an   overlay   network   that   takes   account   of   locality   of   network   hosts .   The   constructed   overlay   network   can   significantly   decrease   the   communication   cost   between   end - hosts .   Our   simulation   results   show   that   the   average   distance   between   a   pair   of   hosts   in   the   constructed   overlay   network   is   only   about   11%   of   the   one   in   a   traditional ,   randomly   connected   overlay   network .   Furthermore ,   our   proposed   overlay   considered   to   be   more   scalable   than   tree - based   or   mesh - based   overlays . ' ,   ' title ' :   ' Measurement - based   construction   of   locality - aware   overlay   networks ' } 
{ ' abstract ' :   ' This   paper   presents   a   low   cost ,   flexible   and   customizable   delay   measurement   system   developed   to   assess   the   performance   of   the   VTPE - hBEB   protocol .   The   proposed   system   can   be   used   to   evaluate   other   communication   protocols   as   well   as   to   measure   the   delay   between   two   repetitive   events . ' ,   ' title ' :   ' Delay   measurement   system   for   real - time   serial   data   streams ' } 
{ ' abstract ' :   " Service   robots   have   become   increasingly   important   subjects   in   our   lives .   However ,   they   are   still   facing   problems   like   adaptability   to   their   users .   While   major   work   has   focused   on   intelligent   service   robots ,   the   proposed   approaches   were   mostly   user   independent .   Our   work   is   part   of   the   FUI - RoboPopuli   project ,   which   concentrates   on   endowing   entertainment   companion   robots   with   adaptive   and   social   behaviour .   In   particular ,   we   are   interested   in   robots   that   are   able   to   learn   and   plan   so   that   they   adapt   and   personalize   their   behaviour   according   to   their   users .   Markov   Decision   Processes   ( MDPs )   are   largely   used   for   adaptive   robots   applications .   However ,   one   challenging   point   is   reducing   the   sample   complexity   required   to   learn   an   MDP   model ,   including   the   reward   function .   In   this   article ,   we   present   our   contribution   regarding   the   representation   and   the   learning   of   the   reward   function   through   analysing   interaction   traces   ( i . e .   the   interaction   history   between   the   robot   and   their   users ,   including   users '   feedback ) .   Our   approach   permits   to   generalise   the   learned   rewards   so   that   when   new   users   are   introduced ,   the   robot   may   quickly   adapt   using   what   it   learned   from   previous   experiences   with   other   users .   We   propose ,   in   this   article ,   two   algorithms   to   learn   the   reward   function .   The   first   is   direct   and   certain ,   the   robot   applies   with   a   user   what   it   learned   during   interaction   with   same   kind   of   users   ( i . e .   users   with   similar   profiles ) .   The   second   algorithm   generalises   what   it   learns   to   be   applied   to   all   kinds   of   users .   Through   simulation ,   we   show   that   the   generalised   algorithm   converges   to   an   optimal   reward   function   with   less   than   half   the   samples   needed   by   the   direct   algorithm . " ,   ' title ' :   " Adaptive   and   Personalised   Robots   -   Learning   from   Users '   Feedback " } 
{ ' abstract ' :   " Researches   of   sensor   networks   collecting   patients '   data   with   computerized   triage   tags ,   called   Triage   Network ,   are   attracting   attention .   The   listening   power   used   in   triage   tags   is   the   major   factor   of   lots   of   energy   consumption ,   and   consumption   of   energy   increases   when   sensor   nodes   always   communicate   with   other   nodes   in   active   state .   Hence ,   we   suppose   that   sensor   nodes   are   put   to   sleep   periodically   to   avoid   running   out   of   battery .   However ,   some   nodes   have   mobility   and   nodes   secede   from   the   network   according   to   patients   conditions   in   Triage   Network .   The   paths   are   failed   and   it   is   needed   to   reconstruct   paths   when   these   forwarding   nodes   move   or   secede   from   network .   Therefore ,   data   arrival   ratio   decreases   and   consumption   of   battery   increases   due   to   reconstruction   of   other   paths .   In   this   paper ,   we   propose   a   data   collection   method   using   two   types   of   forwarding   nodes ,   Stable   Nodes   and   Energy   Efficient   Nodes .   This   method   uses   two   types   of   forwarding   nodes   according   to   priority   of   data   and   avoids   loss   of   high   priority   data ,   improves   the   data   arrival   ratio   and   saves   the   energy   consumption .   We   evaluate   the   proposed   method   and   show   its   effectiveness   using   computer   simulations . " ,   ' title ' :   ' Data   collection   method   using   two   types   of   forwarding   nodes   for   energy   saving   in   triage   network ' } 
{ ' abstract ' :   ' This   paper   introduces   Golay - paired   Hadamard   matrices   for   fast   compressed   sensing   of   sparse   signals   in   the   time   or   spectral   domain .   These   sampling   operators   feature   low - memory   requirement ,   hardware - friendly   implementation   and   fast   computation   in   reconstruction .   We   show   that   they   require   a   nearly   optimal   number   of   measurements   for   faithful   reconstruction   of   a   sparse   signal   in   the   time   or   frequency   domain .   Simulation   results   demonstrate   that   the   proposed   sensing   matrices   offer   a   reconstruction   performance   similar   to   that   of   fully   random   matrices . ' ,   ' title ' :   ' Golay   meets   Hadamard :   Golay - paired   Hadamard   matrices   for   fast   compressed   sensing ' } 
{ ' abstract ' :   ' In   this   technical   note ,   the   problem   of   finite - time   output   regulation   control   for   a   class   of   disturbed   system   under   mismatching   condition   is   investigated   via   a   composite   control   design   manner .   The   composite   controller   is   developed   by   using   a   finite   time   control   technique   and   a   finite   time   disturbance   observer   ( FTDO ) .   A   key   idea   is   to   design   virtual   control   laws   based   on   estimation   values   of   the   disturbances   and   the   ith   ( 1 ≤ i ≤ n - 1   where   n   is   the   order   of   the   system )   order   derivative   of   disturbances .   Finite   time   stability   analysis   for   the   augmented   system   is   presented   by   means   of   Lyapunov   stability   theorems ,   which   shows   that   the   system   output   is   regulated   to   zero   in   finite   time   even   in   the   presence   of   mismatched   disturbances .   A   motion   control   application   demonstrates   the   effectiveness   and   attractive   properties   of   the   proposed   method . ' ,   ' title ' :   ' Continuous   Finite - Time   Output   Regulation   for   Disturbed   Systems   Under   Mismatching   Condition ' } 
{ ' abstract ' :   ' In   this   paper   we   propose   an   approach   for   enhanced   data   protection   in   the   cloud ,   based   upon   accountability   governance .   Specifically ,   the   relationships   between   accountability ,   risk   and   trust   are   analyzed   in   order   to   suggest   characteristics   and   means   to   address   data   governance   issues   involved   when   organizations   or   individuals   adopt   cloud   computing .   This   analysis   takes   into   account   insights   from   a   variety   of   stakeholders   within   cloud   ecosystems   obtained   by   running   an   elicitation   workshop . ' ,   ' title ' :   ' Accountability ,   Risk ,   and   Trust   in   Cloud   Services :   Towards   an   Accountability - Based   Approach   to   Risk   and   Trust   Governance ' } 
{ ' abstract ' :   ' Xue   et   al .   recently   proposed   an   innovative   mutual   authentication   and   key   agreement   scheme   for   wireless   sensor   networks   based   on   temporal   credential   using   smart   cards .   However ,   in   this   paper   we   demonstrate   that   their   scheme   is   vulnerable   to   password   guessing   attacks ,   node   capture   attacks   and   denial - of - service   attacks .   Furthermore   we   show   that   their   scheme   has   some   inconsistencies   which   make   it   less   secure   and   more   computationally   costly   than   originally   presented . ' ,   ' title ' :   ' Notes   on   A   Temporal - Credential - Based   Mutual   Authentication   and   Key   Agreement   Scheme   for   Wireless   Sensor   Networks ' } 
{ ' abstract ' :   ' Persistent   Scatterer   Interferometry   ( PSI )   has   been   widely   used   for   landslide   studies   in   recent   years .   This   paper   investigated   the   spatial   patterns   of   PSI   point   targets   and   landslide   occurrences   in   the   Arno   River   basin   in   Central   Italy .   The   main   purpose   is   to   analyze   whether   spatial   patterns   of   Persistent   Scatterers   ( PS )   can   be   recognized   as   indicators   of   landslide   occurrences   throughout   the   whole   basin .   The   bivariate   K - function   was   employed   to   assess   spatial   relationships   between   PS   and   landslides .   The   PSI   point   targets   were   acquired   from   almost   4   years   ( from   March   2003   to   January   2007 )   of   RADARSAT - 1   images .   The   landslide   inventory   was   collected   from   15   years   ( from     1992 – 2007 )   of   surveying   and   mapping   data ,   mainly   including   remote   sensing   data ,   topographic   maps   and   field   investigations .   The   proposed   approach   is   able   to   assess   spatial   patterns   between   a   variety   of   PS   and   landslides ,   in   particular ,   to   understand   if   PSI   point   targets   are   spatially   clustered   ( spatial   attraction )   or   randomly   distributed   ( spatial   independency )   on   various   types   of   landslides   across   the   basin .   Additionally ,   the   degree   and   scale   distances   of   PS   clustering   on   a   variety   of   landslides   can   be   characterized .   The   results   rejected   the   null   hypothesis   that   PSI   point   targets   appear   to   cluster   similarly   on   four   types   of   landslides   ( slides ,   flows ,   falls   and   creeps )   in   the   Arno   River   basin .   Significant   influence   of   PS   velocities   and   acquisition   orbits   can   be   noticed   on   detecting   landslides   with   different   states   of   activities .   Despite   that   the   assessment   may   be   influenced   by   the   quality   of   landslide   inventory   and   Synthetic   Aperture   Radar   ( SAR )   images ,   the   proposed   approach   is   expected   to   provide   guidelines   for   studies   trying   to   detect   and   investigate   landslide   occurrences   at   a   regional   scale   through   spatial   statistical   analysis   of   PS ,   for   which   an   advanced   understanding   of   the   impact   of   scale   distances   on   landslide   clustering   is   fundamentally   needed . ' ,   ' title ' :   ' Investigating   Spatial   Patterns   of   Persistent   Scatterer   Interferometry   Point   Targets   and   Landslide   Occurrences   in   the   Arno   River   Basin ' } 
{ ' abstract ' :   ' This   article   describes   a   middleware   used   in   display   cluster   of   real   time   visual   simulation   system .   This   middleware   which   based   on   TCP / IP   protocol   provides   the   communication   infrastructure   for   visual   simulation   system .   It   provides   unified   process   logic   and   interfaces   for   various   status   and   frame   data   and   the   packing / unpacking   functions   of   simulation   data   without   concerning   the   details   of   the   data .   We   found   two   classes   of   display   synchronization   problems   and   provided   the   resolution   of   them .   The   middleware   provides   a   group   of   APIs   which   hide   the   details   of   data   packing / unpacking ,   processing   and   transmission   and   meets   the   requirement   of   flexibility ,   efficiency   and   extensibility .   This   middleware   has   been   successfully   implemented   to   the   display   cluster   of   several   tower   simulation   system . ' ,   ' title ' :   ' The   Research   of   High   Level   Data   Communication   Middleware   of   Display   Cluster   Used   in   Real   Time   Simulation   Environment ' } 
{ ' abstract ' :   ' The   scattering   parameters   are   fundamental   in   the   characterization   of   electrical   devices   at   high   frequencies .   They   are   particularly   useful   for   analyzing   multiport   high - frequency   and   microwave   networks .   However ,   they   are   not   adequately   presented   in   most ,   if   not   all ,   microwave   engineering   books .   This   paper   identifies   two   common   deficiencies   in   the   way   scattering   parameters   are   being   presented   in   these   books .   It   provides   additional   information   that   should   supplement   those   books   or   book   chapters   on   scattering   parameters . ' ,   ' title ' :   ' Deficiencies   in   the   way   scattering   parameters   are   taught ' } 
{ ' abstract ' :   ' We   study   the   reliability   maximization   problem   in   WDM   networks   with   random   link   failures .   Reliability   in   these   networks   is   defined   as   the   probability   that   the   logical   network   is   connected ,   and   it   is   determined   by   the   underlying   lightpath   routing   and   the   link   failure   probability .   We   show   that   in   general   the   optimal   lightpath   routing   depends   on   the   link   failure   probability ,   and   characterize   the   properties   of   lightpath   routings   that   maximize   the   reliability   in   different   failure   probability   regimes .   In   particular ,   we   show   that   in   the   low   failure   probability   regime ,   maximizing   the   ` ` cross - layer "   min   cut   of   the   ( layered )   network   maximizes   reliability ,   whereas   in   the   high   failure   probability   regime ,   minimizing   the   spanning   tree   of   the   network   maximizes   reliability .   Motivated   by   these   results ,   we   develop   lightpath   routing   algorithms   for   reliability   maximization . ' ,   ' title ' :   ' Maximizing   Reliability   in   WDM   Networks   through   Lightpath   Routing ' } 
{ ' abstract ' :   ' The   slope   of   the   active   distances   is   an   important   parameter   when   investigating   the   error - correcting   capability   of   convolutional   codes   and   the   distance   behavior   of   concatenated   convolutional   codes .   The   slope   of   the   active   distances   is   equal   to   the   minimum   average   weight   cycle   in   the   state - transition   diagram   of   the   encoder .   A   general   upper   bound   on   the   slope   depending   on   the   free   distance   of   the   convolutional   code   and   new   upper   bounds   on   the   slope   of   special   classes   of   binary   convolutional   codes   are   derived .   Moreover ,   a   search   technique ,   resulting   in   new   tables   of   rate   R = 1 / 2   and   rate   R = 1 / 3   convolutional   encoders   with   high   memories   and   large   active   distance - slopes   is   presented .   Furthermore ,   we   show   that   convolutional   codes   with   large   slopes   can   be   used   to   obtain   new   tailbiting   block   codes   with   large   minimum   distances .   Tables   of   rate   R = 1 / 2   and   rate   R = 1 / 3   tailbiting   codes   with   larger   minimum   distances   than   the   best   previously   known   quasi - cyclic   codes   are   given .   Two   new   tailbiting   codes   also   have   larger   minimum   distances   than   the   best   previously   known   binary   linear   block   codes   with   same   size   and   length .   One   of   them   is   also   superior   in   terms   of   minimum   distance   to   any   previously   known   binary   nonlinear   block   code   with   the   same   set   of   parameters . ' ,   ' title ' :   ' Tailbiting   codes   obtained   via   convolutional   codes   with   large   active   distance - slopes ' } 
{ ' abstract ' :   ' MIMO   wireless   technology   is   required   to   increase   the   data   rates   for   a   broad   range   of   applications ,   including   low   cost   mobile   devices .   In   this   paper   we   present   a   very   low   area   reconfigurable   MIMO   detector   which   achieves   a   high   throughput   of   103Mbps   and   uses   27   Kilo   Gates   when   implemented   in   a   commercial   180nm   CMOS   process .   The   low   area   is   achieved   by   the   proposed   in - place   architecture .   This   architecture   implements   the   K - best   algorithm   and   reduces   area   4 - fold   compared   to   the   widely   used   multi - stage   architecture ,   while   provides   reconfigurability   in   terms   of   antenna   configuration   during   real - time   operation . ' ,   ' title ' :   ' A   low - area   flexible   MIMO   detector   for   WiFi / WiMAX   standards ' } 
{ ' abstract ' :   ' Because   human   cognition   is   creative   and   socially   situated ,   knowledge   accumulates ,   diffuses ,   and   gets   applied   in   new   contexts ,   generating   cultural   analogs   of   phenomena   observed   in   population   genetics   such   as   adaptation   and   drift .   It   is   therefore   commonly   thought   that   elements   of   culture   evolve   through   natural   selection .   However ,   natural   selection   was   proposed   to   explain   how   change   accumulates   despite   lack   of   inheritance   of   acquired   traits ,   as   occurs   with   template - mediated   replication .   It   cannot   accommodate   a   process   with   significant   retention   of   acquired   or   horizontally   ( e . g .   socially )   transmitted   traits .   Moreover ,   elements   of   culture   cannot   be   treated   as   discrete   lineages   because   they   constantly   interact   and   influence   one   another .   It   is   proposed   that   what   evolves   through   culture   is   the   mind ;   ideas   and   artifacts   are   merely   reflections   of   its   current   evolved   state .   Interacting   minds   transform   ( in   part )   through   a   non - Darwinian   autopoietic   process   similar   to   that   by   which   early   life   evolved ,   involving   not   survival   of   the   fittest   but   actualization   of   their   potential . ' ,   ' title ' :   ' The   cultural   evolution   of   socially   situated   cognition ' } 
{ ' abstract ' :   ' Event   Extraction   is   a   complex   and   interesting   topic   in   Information   Extraction   that   includes   event   extraction   methods   from   free   text   or   web   data .   The   result   of   event   extraction   systems   can   be   used   in   several   fields   such   as   risk   analysis   systems ,   online   monitoring   systems   or   decide   support   tools .   In   this   paper ,   we   introduce   a   method   that   combines   lexico   - -   semantic   and   machine   learning   to   extract   event   from   Vietnamese   news .   Furthermore ,   we   concentrate   to   describe   event   online   monitoring   system   named   VnLoc   based   on   the   method   that   was   proposed   above   to   extract   event   in   Vietnamese   language .   Besides ,   in   experiment   phase ,   we   have   evaluated   this   method   based   on   precision ,   recall   and   F1   measure .   At   this   time   of   experiment ,   we   on   investigated   on   three   types   of   event :   FIRE ,   CRIME   and   TRANSPORT   ACCIDENT . ' ,   ' title ' :   ' VnLoc :   A   Real   - -   Time   News   Event   Extraction   Framework   for   Vietnamese ' } 
{ ' abstract ' :   ' Reliability   analysis   using   error   probabilities   for   combinational   logic   circuits   has   been   investigated   widely   in   the   literature .   Reliability   analysis   for   sequential   logic   circuits   using   these   methods   would   be   inaccurate   because   of   existence   of   loops   in   their   architecture .   In   this   paper   a   new   method   based   on   conversion   of   sequential   circuit   to   combinational   one   and   applying   an   iterative   reliability   analysis   is   developed .   A   Monte   Carlo   method - based   reliability   analysis   is   introduced   for   sequential   circuits ,   which   is   used   for   first   method   validation .   Experimental   results   demonstrate   good   accuracy   of   the   method . ' ,   ' title ' :   ' SEQUENTIAL   LOGIC   CIRCUITS   RELIABILITY   ANALYSIS ' } 
{ ' abstract ' :   ' According   to   the   Journey   to   Crime   theory ,   offenders   have   a   directionality   preference ,   in   the   form   of   an   activity   path ,   when   they   are   moving   about   in   their   environment   in   search   for   criminal   activities .   Using   clustering   techniques ,   this   theory   is   tested   using   crime   data   for   the   Province   of   British   Columbia ,   Canada .   The   activities   of   57 , 962   offenders   who   were   either   charged ,   chargeable ,   or   for   whom   charges   were   recommended   were   analyzed   by   mapping   their   offense   locations   with   respect   to   their   home   locations   to   determine   directionality .   Once   directionality   was   established ,   a   unique   clustering   technique ,   based   on   K - Means   clustering   and   modified   for   angles ,   was   applied   to   find   the   number   of   activity   paths   for   each   offender .   Although   the   number   of   activity   paths   varies   from   individual   to   individual ,   the   aggregate   pattern   was   very   consistent   with   theory .   It   was   found   that   people   only   have   a   few   activity   paths ,   even   if   they   are   highly   prolific   offenders . ' ,   ' title ' :   ' How   Many   Ways   Do   Offenders   Travel   - -   Evaluating   the   Activity   Paths   of   Offenders ' } 
{ ' abstract ' :   ' Pulse   Coupled   Neural   Network ( PCNN )   is   widely   used   in   the   field   of   image   processing ,   but   it   is   a   difficult   task   to   define   the   relative   parameters   properly   in   the   research   of   the   applications   of   PCNN .   So   far   the   determination   of   parameters   of   its   model   needs   a   lot   of   experiments .   To   deal   with   the   above   problem ,   a   document   segmentation   based   on   the   improved   PCNN   is   proposed .   It   uses   the   maximum   entropy   function   as   the   fitness   function   of   bacterial   foraging   optimization   algorithm ,   adopts   bacterial   foraging   optimization   algorithm   to   search   the   optimal   parameters ,   and   eliminates   the   trouble   of   manually   set   the   experiment   parameters .   Experimental   results   show   that   the   proposed   algorithm   can   effectively   complete   document   segmentation .   And   result   of   the   segmentation   is   better   than   the   contrast   algorithms .   ©   ( 2014 )   COPYRIGHT   Society   of   Photo - Optical   Instrumentation   Engineers   ( SPIE ) .   Downloading   of   the   abstract   is   permitted   for   personal   use   only . ' ,   ' title ' :   ' PCNN   document   segmentation   method   based   on   bacterial   foraging   optimization   algorithm ' } 
{ ' abstract ' :   ' Undirected   graphical   models   encode   in   a   graph   G   the   dependency   structure   of   a   random   vector   Y .   In   many   applications ,   it   is   of   interest   to   model   Y   given   another   random   vector   X   as   input .   We   refer   to   the   problem   of   estimating   the   graph   G ( x )   of   Y   conditioned   on   X   =   x   as   " graph - valued   regression " .   In   this   paper ,   we   propose   a   semiparametric   method   for   estimating   G ( x )   that   builds   a   tree   on   the   X   space   just   as   in   CART   ( classification   and   regression   trees ) ,   but   at   each   leaf   of   the   tree   estimates   a   graph .   We   call   the   method   " Graph - optimized   CART " ,   or   Go - CART .   We   study   the   theoretical   properties   of   Go - CART   using   dyadic   partitioning   trees ,   establishing   oracle   inequalities   on   risk   minimization   and   tree   partition   consistency .   We   also   demonstrate   the   application   of   Go - CART   to   a   meteorological   dataset ,   showing   how   graph - valued   regression   can   provide   a   useful   tool   for   analyzing   complex   data . ' ,   ' title ' :   ' Graph - Valued   Regression ' } 
{ ' abstract ' :   ' Over   the   last   two   decades ,   doubts   have   been   expressed   about   the   adequacy   of   materialism   as   the   correct   framework   for   explaining   phenomenal   consciousness   ( the   experience   of   saturated   greenness   one   has   when   looking   at   a   lush   lawn ,   for   example ) .   This   paper   reconstructs   a   generic   form   of   the   various   arguments   that   have   been   used   to   defend   the   view   of   the   materialistically   inexplicable   nature   of   consciousness   ( MINC ) .   This   reconstruction   reveals   that   the   arguments   turn   on   an   impoverished   notion   of   explanation .   By   discussing   some   examples   from   the   history   of   science ,   the   paper   shows   that   a   reasonable   notion   of   explanation   has   to   be   wider   than   the   one   utilized   in   the   argument   for   MINC ,   which   opens   the   possibility   for   the   materialistic   explicability   of   consciousness .   The   author   ends   the   paper   by   raising   a   question   about   the   very   intelligibility   of   the   project   of   trying   to   explain   the   so - called   nature   of   consciousness   as   opposed   to   the   regularities   characteristic   of   the   relation   between   states   of   consciousness   and   ... ' ,   ' title ' :   ' On   explaining   phenomenal   consciousness ' } 
{ ' abstract ' :   ' Successful   replication   within   an   infected   host   and   successful   transmission   between   hosts   are   key   to   the   continued   spread   of   most   pathogens .   Competing   selection   pressures   exerted   at   these   different   scales   can   lead   to   evolutionary   trade - offs   between   the   determinants   of   fitness   within   and   between   hosts .   Here ,   we   examine   such   a   trade - off   in   the   context   of   influenza   A   viruses   and   the   differential   pressures   exerted   by   temperature - dependent   virus   persistence .   For   a   panel   of   avian   influenza   A   virus   strains ,   we   find   evidence   for   a   trade - off   between   the   persistence   at   high   versus   low   temperatures .   Combining   a   within - host   model   of   influenza   infection   dynamics   with   a   between - host   transmission   model ,   we   study   how   such   a   trade - off   affects   virus   fitness   on   the   host   population   level .   We   show   that   conclusions   regarding   overall   fitness   are   affected   by   the   type   of   link   assumed   between   the   within -   and   between - host   levels   and   the   main   route   of   transmission   ( direct   or   environmental ) .   The   relative   importance   of   virulence   and   immune   response   mediated   virus   clearance   are   also   found   to   influence   the   fitness   impacts   of   virus   persistence   at   low   versus   high   temperatures .   Based   on   our   results ,   we   predict   that   if   transmission   occurs   mainly   directly   and   scales   linearly   with   virus   load ,   and   virulence   or   immune   responses   are   negligible ,   the   evolutionary   pressure   for   influenza   viruses   to   evolve   toward   good   persistence   at   high   within - host   temperatures   dominates .   For   all   other   scenarios ,   influenza   viruses   with   good   environmental   persistence   at   low   temperatures   seem   to   be   favored . ' ,   ' title ' :   ' A   Multi - scale   Analysis   of   Influenza   A   Virus   Fitness   Trade - offs   due   to   Temperature - dependent   Virus   Persistence ' } 
{ ' abstract ' :   ' Peer - to - Peer   ( P2P )   networks   are   largely   used   for   file - sharing   and   hence   must   provide   efficient   mechanisms   for   searching   the   files   stored   at   various   nodes .   The   existing   structuredP2P   overlays   support   only   ” exact - match ”   look - up   which   is   hardly   sufficient   in   a   file   sharing   network .   This   paper   addresses   the   problem   of   keyword - based   search   in   structured   P2P   networks .   We   propose   a   new   keyword - based   searching   algorithm   which   can   be   implemented   on   top   of   any   structured   P2P   overlay .   We   demonstrate   that   the   proposed   algorithm   achieves   very   good   searching   results   as   it   requires   the   minimum   number   of   messages   to   be   sent   in   order   to   find   all   the   references   to   files   containing   at   least   the   given   set   of   keywords . ' ,   ' title ' :   ' A   Keyword   Search   Algorithm   for   Structured   Peer - to - Peer   Networks ' } 
{ ' abstract ' :   ' In   this   paper ,   we   propose   an   adaptive   power   allocation   method   for   hybrid   relay   systems   that   employ   the   amplify - and - forward   and   decode - and - forward   protocols   simultaneously .   The   total   transmission   power   is   analytically   allocated   to   a   source   and   two   selected   relays   by   the   proposed   power   allocation   criterion   to   maximize   the   overall   received   signal - to - noise   ratio   at   the   destination .   Simulation   results   show   that   the   proposed   scheme   achieves   better   performance   than   that   of   conventional   cooperative   schemes   or   hybrid   systems   with   equal   power   allocation . ' ,   ' title ' :   ' Adaptive   relay   selection   and   power   allocation   for   hybrid   relay   systems ' } 
{ ' abstract ' :   ' The   unitary   rotation   of   square - pixellated   images   is   based   on   the   finite   su ( 2 ) - oscillator   model ,   which   describes   systems   whose   values   for   position ,   momentum   and   energy ,   are   discrete   and   finite .   In   a   two - dimensional   position   space ,   this   allows   the   construction   of   angular   momentum   states ,   orthonormal   and   complete ,   for   which   rotations   are   defined   as   multiplication   by   phases   that   carry   the   rotation   angle .   The   decomposition   of   a   digital   square   images   in   terms   of   these   angular   momentum   states   determines   a   unitary   ( hence   invertible )   rotation   of   the   image ,   whose   kernel   can   be   computed   as   a   four - dimensional   array   of   real   numbers . ' ,   ' title ' :   ' Unitary   rotation   of   square - pixellated   images ' } 
{ ' abstract ' :   ' As   more   mobile   storage   devices   are   used   in   consumer   electronics ,   possibility   of   user   confidential   data   leakage   increases .   To   make   things   worse ,   data   of   deleted   file   in   mobile   storage   such   as   USB   drives   can   be   easily   recovered   and ,   thus ,   can   be   vulnerable   to   data   leakage .   To   prevent   this   type   of   data   leakage ,   efficient   secure   deletion   techniques   are   required   and   we   present   two   secure   deletion   techniques ,   namely   block   cleaning   and   zero   overwriting ,   for   flash   memory   storage .   Also ,   we   propose   cost   and   benefit   models   of   both   techniques .   The   models   imply   an   existence   of   an   efficient   adaptive   hybrid   secure   deletion   scheme   that   applies   one   of   the   techniques   based   on   their   costs   and   benefits   at   given   data   arrangements .   Experimental   results   measured   on   an   embedded   board   show   that   the   adaptive   hybrid   scheme   deletes   data   securely   and   efficiently   for   various   data   patterns   on   flash   memory   storage . ' ,   ' title ' :   ' Models   and   Design   of   an   Adaptive   Hybrid   Scheme   for   Secure   Deletion   of   Data   in   Consumer   Electronics ' } 
{ ' abstract ' :   ' In   heterogeneous   and   dynamic   environments ,   efficient   execution   of   parallel   computations   can   require   mappings   of   tasks   to   processors   whose   performance   is   both   irregular   ( because   of   heterogeneity )   and   time - varying   ( because   of   dynamicity ) .   While   adaptive   domain   decomposition   techniques   have   been   used   to   address   heterogeneous   resource   capabilities ,   temporal   variations   in   those   capabilities   have   seldom   been   considered .   We   propose   a   conservative   scheduling   policy   that   uses   information   about   expected   future   variance   in   resource   capabilities   to   produce   more   efficient   data   mapping   decisions .   We   first   present   techniques ,   based   on   time   series   predictors   that   we   developed   in   previous   work ,   for   predicting   CPU   load   at   some   future   time   point ,   average   CPU   load   for   some   future   time   interval ,   and   variation   of   CPU   load   over   some   future   time   interval .   We   then   present   a   family   of   stochastic   scheduling   algorithms   that   exploit   such   predictions   of   future   availability   and   variability   when   making   data   mapping   decisions .   Finally ,   we   describe   experiments   in   which   we   apply   our   techniques   to   an   astrophysics   application .   The   results   of   these   experiments   demonstrate   that   conservative   scheduling   can   produce   execution   times   that   are   both   significantly   faster   and   less   variable   than   other   techniques . ' ,   ' title ' :   ' Conservative   Scheduling :   Using   Predicted   Variance   to   Improve   Scheduling   Decisions   in   Dynamic   Environments ' } 
{ ' abstract ' :   ' We   consider   a   class   of   restless   multi - armed   bandit   problems   that   arises   in   multi - channel   opportunistic   communications ,   where   channels   are   modeled   as   independent   and   stochastically   identical   Gilbert - Elliot   channels   and   channel   state   observations   are   subject   to   errors .   We   show   that   the   myopic   channel   selection   policy   has   a   semi - universal   structure   that   obviates   the   need   to   know   the   Markovian   transition   probabilities   of   the   channel   states .   Based   on   this   structure ,   we   establish   closed - form   lower   and   upper   bounds   on   the   steady - state   throughput   achieved   by   the   myopic   policy .   Furthermore ,   we   characterize   the   approximation   factor   of   the   myopic   policy   to   bound   its   worst - case   performance   loss   with   respect   to   the   optimal   performance . ' ,   ' title ' :   ' On   the   myopic   policy   for   a   class   of   restless   bandit   problems   with   applications   in   dynamic   multichannel   access ' } 
{ ' abstract ' :   ' We   show   that   the   optimum   length - / spl   nu /   guard   sequence   for   block   transmission   over   a   linear   Gaussian - noise   dispersive   channel   with   memory   / spl   nu /   is   a   linear   combination   of   the   N   information   symbols   of   the   block .   A   closed - form   expression   for   the   optimum   guard   sequence   is   derived   subject   to   a   total   average   energy   constraint   on   the   information   and   guard   symbols .   The   achievable   channel   block   throughput   with   the   optimum   guard   sequence   is   compared   with   that   achievable   with   two   common   guard   sequence   types ,   namely   zero   stuffing   and   cyclic   prefix . ' ,   ' title ' :   ' Guard   sequence   optimization   for   block   transmission   over   linear   frequency - selective   channels ' } 
{ ' abstract ' :   " A   modular   program   analysis   considers   components   independently   and   provides   a   succinct   summary   for   each   component ,   which   is   used   when   checking   the   rest   of   the   system .   Consider   a   system   consisting   of   a   library   and   a   client .   A   temporal   summary ,   or     interface   ,   of   the   library   specifies   legal   sequences   of   library   calls .   The   interface   is     safe     if   no   call   sequence   violates   the   library ' s   internal   invariants ;   the   interface   is     permissive     if   it   contains   every   such   sequence .   Modular   program   analysis   requires     full     interfaces ,   which   are   both   safe   and   permissive :   the   client   does   not   cause   errors   in   the   library   if   and   only   if   it   makes   only   sequences   of   library   calls   that   are   allowed   by   the   full   interface   of   the   library . Previous   interface - based   methods   have   focused   on   safe   interfaces ,   which   may   be   too   restrictive   and   thus   reject   good   clients .   We   present   an   algorithm   for   automatically   synthesizing   software   interfaces   that   are   both   safe   and   permissive .   The   algorithm   generates   interfaces   as   graphs   whose   vertices   are   labeled   with   predicates   over   the   library ' s   internal   state ,   and   whose   edges   are   labeled   with   library   calls .   The   interface   state   is   refined   incrementally   until   the   full   interface   is   constructed .   In   other   words ,   the   algorithm   automatically   synthesizes   a   typestate   system   for   the   library ,   against   which   any   client   can   be   checked   for   compatibility .   We   present   an   implementation   of   the   algorithm   which   is   based   on   the   BLAST   model   checker ,   and   we   evaluate   some   case   studies . " ,   ' title ' :   ' Permissive   interfaces ' } 
{ ' abstract ' :   ' In   this   paper ,   we   propose   a   new   method   for   the   motion   planning   problem   of   rigid   object   dexterous   manipulation   with   a   robotic   multi - fingered   hand ,   under   quasi - static   movement   assumption .   This   method   computes   both   object   and   finger   trajectories   as   well   as   the   finger   relocation   sequence .   Its   specificity   is   to   use   a   special   structuring   of   the   research   space   that   allows   to   search   for   paths   directly   in   the   particular   subspace   GS   n     which   is   the   subspace   of   all   the   grasps   that   can   be   achieved   with   n   grasping   fingers .   The   solving   of   the   dexterous   manipulation   planning   problem   is   based   upon   the   exploration   of   this   subspace .   The   proposed   approach   captures   the   connectivity   of   GS   n     in   a   graph   structure .   The   answer   of   the   manipulation   planning   query   is   then   given   by   searching   a   path   in   the   computed   graph .   Simulation   experiments   were   conducted   for   different   dexterous   manipulation   task   examples   to   validate   the   proposed   method . ' ,   ' title ' :   ' Dexterous   manipulation   planning   using   probabilistic   roadmaps   in   continuous   grasp   subspaces ' } 
{ ' abstract ' :   ' This   paper   presents   an   experimental   evaluation   of   different   line   extraction   algorithms   applied   to   2D   laser   scans   for   indoor   environments .   Six   popular   algorithms   in   mobile   robotics   and   computer   vision   are   selected   and   tested .   Real   scan   data   collected   from   two   office   environments   by   using   different   platforms   are   used   in   the   experiments   in   order   to   evaluate   the   algorithms .   Several   comparison   criteria   are   proposed   and   discussed   to   highlight   the   advantages   and   drawbacks   of   each   algorithm ,   including   speed ,   complexity ,   correctness   and   precision .   The   results   of   the   algorithms   are   compared   with   ground   truth   using   standard   statistical   methods .   An   extended   case   study   is   performed   to   further   evaluate   the   algorithms   in   a   SLAM   application . ' ,   ' title ' :   ' A   comparison   of   line   extraction   algorithms   using   2D   range   data   for   indoor   mobile   robotics ' } 
{ ' abstract ' :   ' This   study   investigates   the   use   of   force - stiffness   feedback ,   i . e . ,   a   combination   of   force   offset   and   extra   spring   load ,   in   UAV   tele - operation   with   transmission   time   delay .   The   goal   was   to   further   increase   the   level   of   safety   of   tele - operation   with   a   reduction   in   operator   workload   with   respect   to   force   feedback ,   i . e . ,   using   force   offset   alone .   A   theoretical   analysis   is   given   of   using   force - stiffness   feedback   to   improve   collision   avoidance .   Wave   variables   are   included   to   reduce   time   delay   effects .   An   experiment   was   conducted   to   investigate   the   effects   of   force - stiffness   feedback   on   safety   of   operation ,   operator   performance ,   control   activity ,   and   workload .   Results   indicate   that   force - stiffness   feedback   improves   the   haptic   interface   with   respect   to   force   feedback   alone .   Safety   of   tele - operation   increases   without   increasing   operator   workload   with   respect   to   force   feedback . ' ,   ' title ' :   ' Haptic   interface   in   UAV   tele - operation   using   force - stiffness   feedback ' } 
{ ' abstract ' :   ' Due   to   the   spread   of   the   internet   and   the   ever   increasing   number   of   web   applications ,   the   issue   of   compatibility   across   browsers   has   become   very   important .   This   compatibility   issue   is   also   referred   as   Cross   Browser   Inconsistency   ( XBI )   wherein   same   website   looks   or   behaves   differently   in   different   web   browsers .   In   this   paper   our   aim   is   to   address   this   issue   of   compatibility   and   propose   an   automated   approach   of   detecting   XBIs .   Cross   Browser   Inconsistencies   can   either   be   in   the   content ,   structure   or   behavior   of   the   webpage .   In   order   to   get   a   grasp   of   the   above   mentioned   types   of   inconsistencies ,   we   surveyed   some   random   websites   and   analyzed   them   in   different   browsers .   We   also   studied   the   basic   working   of   browser ,   in   order   to   establish   its   connection   with   the   occurrences   of   XBIs .   Each   browser   has   its   own   rendering   mechanisms ,   which   sometimes   differs   from   standards .   Hence ,   the   execution   of   these   websites   is   different   in   different   browsers .   Finally   we   have   proposed   an   automated   approach   for   XBI   detection . ' ,   ' title ' :   ' An   Automated   Approach   for   Cross - Browser   Inconsistency   ( XBI )   Detection ' } 
{ ' abstract ' :   ' We   present   a   formal   framework   that   combines   high - level   representation   and   causality - based   reasoning   with   low - level   geometric   reasoning   and   motion   planning .   The   frame - work   features   bilateral   interaction   between   task   and   motion   planning ,   and   embeds   geometric   reasoning   in   causal   reasoning ,   thanks   to   several   advantages   inherited   from   its   underlying   components .   In   particular ,   our   choice   of   using   a   causality - based   high - level   formalism   for   describing   action   domains   allows   us   to   represent   ramifications   and   state / transition   constraints ,   and   embed   in   such   formal   domain   descriptions   externally   defined   functions   implemented   in   some   programming   language   ( e . g . ,   C++ ) .   Moreover ,   given   such   a   domain   description ,   the   causal   reasoner   based   on   this   formalism   ( i . e . ,   the   Causal   Calculator )   allows   us   to   compute   optimal   solutions   ( e . g . ,   shortest   plans )   for   elaborate   planning / prediction   problems   with   temporal   constraints .   Utilizing   these   features   of   high - level   representation   and   reasoning ,   we   can   combine   causal   reasoning ,   motion   planning   and   geometric   planning   to   find   feasible   kinematic   solutions   to   task - level   problems .   In   our   framework ,   the   causal   reasoner   guides   the   motion   planner   by   finding   an   optimal   task - plan ;   if   there   is   no   feasible   kinematic   solution   for   that   task - plan   then   the   motion   planner   guides   the   causal   reasoner   by   modifying   the   planning   problem   with   new   temporal   constraints .   Furthermore ,   while   computing   a   task - plan ,   the   causal   reasoner   takes   into   account   geometric   models   and   kinematic   relations   by   means   of   external   predicates   implemented   for   geometric   reasoning   ( e . g . ,   to   check   some   collisions ) ;   in   that   sense   the   geometric   reasoner   guides   the   causal   reasoner   to   find   feasible   kinematic   solutions .   We   illustrate   an   application   of   this   framework   to   robotic   manipulation ,   with   two   pantograph   robots   on   a   complex   assembly   task   that   requires   concurrent   execution   of   actions .   A   short   video   of   this   application   accompanies   the   paper . ' ,   ' title ' :   ' Combining   high - level   causal   reasoning   with   low - level   geometric   reasoning   and   motion   planning   for   robotic   manipulation ' } 
{ ' abstract ' :   ' This   paper   presents   a   novel   template   matching   method   to   detect   and   track   pedestrians   for   people   counting   in   real - time .   Firstly ,   a   novel   background   subtraction   method   is   proposed   for   extracting   all   foreground   objects   from   background .   Then ,   a   shadow   elimination   method   is   used   to   remove   unwanted   shadow   from   the   background .   In   order   to   identify   pedestrians   from   non - pedestrian   objects ,   this   paper   proposed   a   novel   grid - based   template   matching   scheme   to   robustly   verify   each   pedestrian .   Usually ,   a   pedestrian   will   have   different   appearances   at   different   positions .   The   grid - based   approach   can   effectively   reduce   the   perspective   effects   into   a   minimum   since   it   uses   different   templates   to   record   the   appearance   changes   at   each   grid .   When   more   templates   are   used ,   the   detection   process   will   become   more   inefficient .   To   speed   up   its   efficiency ,   an   integral   image   is   used   to   filter   out   all   impossible   candidates   in   advance .   Lastly ,   a   tracking   method   is   applied   to   tracking   the   direction   of   each   moving   pedestrian   so   that   the   real   number   of   passing   people   per   direction   can   be   counted   more   accurately .   Experimental   results   have   proved   that   the   proposed   method   is   robust ,   accurate ,   and   powerful   in   people   counting . ' ,   ' title ' :   ' Grid - based   Template   Matching   for   People   Counting ' } 
{ ' abstract ' :   ' A   tomographic   image   reconstruction   algorithm   that   we   have   been   studying   requires   the   nth - order   Hankel   transform   for   the   nth   function   in   a   series ,   where   n   varies   over   a   set   of   integers .   Unfortunately ,   most   previously   proposed   algorithms   have   either   dealt   with   only   zeroth - order   transforms   or   cannot   be   applied   conveniently   to   our   problem .   We   propose   an   algorithm   for   computing   general   integer - order   Hankel   transforms .   The   algorithm   takes   samples   of   equally   spaced   input   functions   and   gives   equally   spaced   samples   of   the   transforms . ' ,   ' title ' :   ' An   algorithm   for   computing   general   integer - order   Hankel   transforms ' } 
{ ' abstract ' :   ' In   this   paper ,   we   present   a   real - time   approach   that   allows   tracking   deformable   structures   in   3D   ultrasound   sequences .   Our   method   consists   in   obtaining   the   target   displacements   by   combining   robust   dense   motion   estimation   and   mechanical   model   simulation .   We   perform   evaluation   of   our   method   through   simulated   data ,   phantom   data ,   and   real - data .   Results   demonstrate   that   this   novel   approach   has   the   advantage   of   providing   correct   motion   estimation   regarding   different   ultrasound   shortcomings   including   speckle   noise ,   large   shadows   and   ultrasound   gain   variation .   Furthermore ,   we   show   the   good   performance   of   our   method   with   respect   to   state - of - the - art   techniques   by   testing   on   the   3D   databases   provided   by   MICCAI   CLUST ’ 14   and   CLUST ’ 15   challenges . ' ,   ' title ' :   ' Real - time   target   tracking   of   soft   tissues   in   3D   ultrasound   images   based   on   robust   visual   information   and   mechanical   simulation ' } 
{ ' abstract ' :   ' For   two   given   graphs   G1G1   and   G2G2 ,   the   Ramsey   number   R ( G1 , G2 ) R ( G1 , G2 )   is   the   smallest   integer   NN   such   that   for   any   graph   of   order   NN ,   either   GG   contains   a   copy   of   G1G1   or   its   complement   contains   a   copy   of   G2G2 .   Let   CmCm   be   a   cycle   of   length   mm   and   K1 , nK1 , n   a   star   of   order   n + 1n + 1 .   Parsons   ( 1975 )   shows   that   R ( C4 , K1 , n ) ≤ n + ⌊ n − 1 ⌋ + 2   and   if   nn   is   the   square   of   a   prime   power ,   then   the   equality   holds .   In   this   paper ,   by   discussing   the   properties   of   polarity   graphs   whose   vertices   are   points   in   the   projective   planes   over   Galois   fields ,   we   prove   that   R ( C4 , K1 , q2 − t ) = q2 + q − ( t − 1 ) R ( C4 , K1 , q2 − t ) = q2 + q − ( t − 1 )   if   qq   is   an   odd   prime   power ,   1 ≤ t ≤ 2 ⌈ q4 ⌉   and   t ≠ 2 ⌈ q4 ⌉ − 1 ,   which   extends   a   result   on   R ( C4 , K1 , q2 − t ) R ( C4 , K1 , q2 − t )   obtained   by   Parsons   ( 1976 ) . ' ,   ' title ' :   ' Polarity   graphs   and   Ramsey   numbers   for   C   4   versus   stars ' } 
{ ' abstract ' :   ' This   paper   deals   with   the   problem   of   assuring   strict   QoS   guarantees   for   the   end   to   end   connections   that   originate   from   Ethernet   access   network .   It   shows   that   despite   high   link   capacities   in   some   cases   Ethernet   network   might   be   the   reason   of   QoS   deterioration .   The   primary   reason   is   the   lack   of   appropriate   QoS   differentiation   and   traffic   isolation   mechanisms .   The   shared   buffers   and   priority   schedulers   available   in   most   of   Ethernet   switches   appear   to   be   not   sufficient   to   guarantee   strict   QoS .   For   these   cases   new   solution   is   proposed   which   relies   on   additional   traffic   control   mechanisms   available   in   other   network   elements .   Only   additional   mechanism   supporting   typical   functionality   of   Ethernet   switch   can   provide   strict   QoS   guarantees   what   was   verified   in   simulations   studies . ' ,   ' title ' :   ' On   assuring   QoS   in   Ethernet   access   network ' } 
{ ' abstract ' :   ' The   federal   Medicare   regulations   reimburse   hospitals   on   a   pro   rata   share   of   the   hospital \ ' s   cost .   Hence ,   to   meet   its   financial   requirements ,   a   hospital   is   forced   to   shift   more   of   the   financial   burdens   onto   its   private   patients .   This   procedure   has   contributed   to   double   digit   inflation   in   hospital   prices   and   to   proposed   federal   regulation   to   control   the   rate   of   increase   in   hospital   revenues .   In   this   regulatory   environment ,   we   develop   nonlinear   programming   pricing   and   cost   allocation   models   to   aid   hospital   administrators   in   meeting   their   profit   maximizing   and   profit   satisficing   goals .   The   model   enables   administrators   to   explore   tactical   issues   such   as :   i   studying   the   relationship   between   a   voluntary   or   legislated   cap   on   a   hospital \ ' s   total   revenues   and   the   hospital \ ' s   profitability ,   ii   identifying   those   departments   within   the   hospital   that   are   the   most   attractive   candidates   for   cost   reduction   or   cost   containment   efforts ,   and   iii   isolating   those   services   that   should   be   singled   out   by   the   hospital   manager   for   renegotiation   of   the   prospective   or   " customary   and   reasonable "   cap .   Finally ,   the   modeling   approach   is   helpful   in   explaining   the   departmental   cross   subsidies   observed   in   practice ,   and   can   be   of   aid   to   federal   administrators   in   assessing   the   impacts   of   proposed   changes   in   the   Medicare   reimbursement   formula . ' ,   ' title ' :   ' Hospital   Profit   Planning   under   Medicare   Reimbursement ' } 
{ ' abstract ' :   ' We   present   a   ( 4   +   epsilon )   approximation   algorithm   for   weighted   graph   matching   which   applies   in   the   semistreaming ,   sliding   window ,   and   MapReduce   models ;   this   single   algorithm   improves   the   previous   best   algorithm   in   each   model .   The   algorithm   operates   by   reducing   the   maximum - weight   matching   problem   to   a   polylog   number   of   copies   of   the   maximum - cardinality   matching   problem .   The   algorithm   also   extends   to   provide   approximation   guarantees   for   the   more   general   problem   of   finding   weighted   independent   sets   in   p - systems   ( which   include   intersections   of   p   matroids   and   p - bounded   hypergraph   matching ) . ' ,   ' title ' :   ' Improved   Streaming   Algorithms   for   Weighted   Matching ,   via   Unweighted   Matching ' } 
{ ' abstract ' :   ' This   paper   presents   a   novel   approach   to   efficiently   solve   parameter - dependent   ( PD )   linear   matrix   inequality   ( LMI )   problems   for ,   amongst   others ,   linear   parameter - varying   ( LPV )   control   design .   Typically ,   stability   and   performance   is   guaranteed   by   finding   a   PD   Lyapunov   function   such   that   a   PD   LMI   is   feasible   on   a   parameter   domain .   To   solve   the   resulting   semi - infinite   problems ,   we   propose   a   novel   LMI   relaxation   technique   relying   on   B - spline   basis   functions .   This   technique   provides   less   conservative   solutions   and / or   a   reduced   numerical   burden   compared   to   existing   approaches .   Moreover ,   an   elegant   generalization   of   worst - case   optimization   to   the   optimization   of   any   signal   norm   is   obtained   by   expressing   performance   bounds   as   a   function   of   the   system   parameters .   This   generalization   yields   better   performance   bounds   in   a   large   part   of   the   parameter   domain .   Numerical   comparisons   with   the   current   state - of - the - art   demonstrate   the   generality   and   effectiveness   of   our   approach . ' ,   ' title ' :   ' Control   of   linear   parameter - varying   systems   using   B - splines ' } 
{ ' abstract ' :   ' There   is   a   growing   interest   in   simulating   natural   phenomena   in   computer   graphics   applications .   Animating   natural   scenes   in   real   time   is   one   of   the   most   challenging   problems   due   to   the   inherent   complexity   of   their   structure ,   formed   by   millions   of   geometric   entities ,   and   the   interactions   that   happen   within .   An   example   of   natural   scenario   that   is   needed   for   games   or   simulation   programs   are   forests .   Forests   are   difficult   to   render   because   the   huge   amount   of   geometric   entities   and   the   large   amount   of   detail   to   be   represented .   Moreover ,   the   interactions   between   the   objects   ( grass ,   leaves )   and   external   forces   such   as   wind   are   complex   to   model .   In   this   paper   we   concentrate   in   the   rendering   of   falling   leaves   at   low   cost .   We   present   a   technique   that   exploits   graphics   hardware   in   order   to   render   thousands   of   leaves   with   different   falling   paths   in   real   time   and   low   memory   requirements . ' ,   ' title ' :   ' Rendering   falling   leaves   on   graphics   hardware ' } 
{ ' abstract ' :   ' We   previously   presented   DriverDB ,   a   database   that   incorporates   ∼ 6000   cases   of   exome - seq   data ,   in   addition   to   annotation   databases   and   published   bioinformatics   algorithms   dedicated   to   driver   gene / mutation   identification .   The   database   provides   two   points   of   view ,   ‘ Cancer ’   and   ‘ Gene ’ ,   to   help   researchers   visualize   the   relationships   between   cancers   and   driver   genes / mutations .   In   the   updated   DriverDBv2   database   ( http : / / ngs . ym . edu . tw / driverdb )   presented   herein ,   we   incorporated   > 9500   cancer - related   RNA - seq   datasets   and   > 7000   more   exome - seq   datasets   from   The   Cancer   Genome   Atlas   ( TCGA ) ,   International   Cancer   Genome   Consortium   ( ICGC ) ,   and   published   papers .   Seven   additional   computational   algorithms   ( meaning   that   the   updated   database   contains   15   in   total ) ,   which   were   developed   for   driver   gene   identification ,   are   incorporated   into   our   analysis   pipeline ,   and   the   results   are   provided   in   the   ‘ Cancer ’   section .   Furthermore ,   there   are   two   main   new   features ,   ‘ Expression ’   and   ‘ Hotspot ’ ,   in   the   ‘ Gene ’   section .   ‘ Expression ’   displays   two   expression   profiles   of   a   gene   in   terms   of   sample   types   and   mutation   types ,   respectively .   ‘ Hotspot ’   indicates   the   hotspot   mutation   regions   of   a   gene   according   to   the   results   provided   by   four   bioinformatics   tools .   A   new   function ,   ‘ Gene   Set ’ ,   allows   users   to   investigate   the   relationships   among   mutations ,   expression   levels   and   clinical   data   for   a   set   of   genes ,   a   specific   dataset   and   clinical   features . ' ,   ' title ' :   ' DriverDBv2 :   a   database   for   human   cancer   driver   gene   research ' } 
{ ' abstract ' :   ' Thousands   of   deep   and   wide   pipelines   working   concurrently   make   GPGPU   high   power   consuming   parts .   Energy - efficiency   techniques   employ   voltage   overscaling   that   increases   timing   sensitivity   to   variations   and   hence   aggravating   the   energy   use   issues .   This   paper   proposes   a   method   to   increase   spatiotemporal   reuse   of   computational   effort   by   a   combination   of   compilation   and   micro - architectural   design .   An   associative   memristive   memory   ( AMM )   module   is   integrated   with   the   floating   point   units   ( FPUs ) .   Together ,   we   enable   fine - grained   partitioning   of   values   and   find   high - frequency   sets   of   values   for   the   FPUs   by   searching   the   space   of   possible   inputs ,   with   the   help   of   application - specific   profile   feedback .   For   every   kernel   execution ,   the   compiler   pre - stores   these   high - frequent   sets   of   values   in   AMM   modules   - -   representing   partial   functionality   of   the   associated   FPU - -   that   are   concurrently   evaluated   over   two   clock   cycles .   Our   simulation   results   show   high   hit   rates   with   32 - entry   AMM   modules   that   enable   36%   reduction   in   average   energy   use   by   the   kernel   codes .   Compared   to   voltage   overscaling ,   this   technique   enhances   robustness   against   timing   errors   with   39%   average   energy   saving . ' ,   ' title ' :   ' Energy - Efficient   GPGPU   Architectures   via   Collaborative   Compilation   and   Memristive   Memory - Based   Computing ' } 
{ ' abstract ' :   ' Quasi - cyclic   codes   are   renowned   for   their   structural   design   and   low - complexity   shift   register   encoding .   However ,   existing   design   techniques   based   on   difference   families   have   limited   code   size   options   due   to   algebraic   constraints .   We   introduce   in   this   paper   a   notation   of   extended   difference   family   ( EDF )   and   provide   a   systematic   code   design   based   on   EDFs   with   a   high   degree   of   flexibility   in   code   size .   Short / medium - length   codes   of   high   rate   ( / spl   ges /   0.9 )   can   be   easily   constructed . ' ,   ' title ' :   ' Quasi - cyclic   codes   from   extended   difference   families ' } 
{ ' abstract ' :   ' Lexical   cohesion   arises   from   a   chain   of   lexical   items   that   establish   links   between   sentences   in   a   text .   In   this   paper   we   propose   three   different   models   to   capture   lexical   cohesion   for   document - level   machine   translation :   ( a )   a   direct   reward   model   where   translation   hypotheses   are   rewarded   whenever   lexical   cohesion   devices   occur   in   them ,   ( b )   a   conditional   probability   model   where   the   appropriateness   of   using   lexical   cohesion   devices   is   measured ,   and   ( c )   a   mutual   information   trigger   model   where   a   lexical   cohesion   relation   is   considered   as   a   trigger   pair   and   the   strength   of   the   association   between   the   trigger   and   the   triggered   item   is   estimated   by   mutual   information .   We   integrate   the   three   models   into   hierarchical   phrase - based   machine   translation   and   evaluate   their   effectiveness   on   the   NIST   Chinese - English   translation   tasks   with   large - scale   training   data .   Experiment   results   show   that   all   three   models   can   achieve   substantial   improvements   over   the   baseline   and   that   the   mutual   information   trigger   model   performs   better   than   the   others . ' ,   ' title ' :   ' Modeling   lexical   cohesion   for   document - level   machine   translation ' } 
{ ' abstract ' :   ' This   paper   presents   a   lightweight   sketching   system   that   enables   interactive   illustration   of   complex   fluid   systems .   Users   can   sketch   on   a   2.5 - dimensional   ( 2.5 D )   canvas   to   design   the   shapes   and   connections   of   a   fluid   circuit .   These   input   sketches   are   automatically   analyzed   and   abstracted   into   a   hydraulic   graph ,   and   a   new   hybrid   fluid   model   is   used   in   the   background   to   enhance   the   illustrations .   The   system   provides   rich   simple   operations   for   users   to   edit   the   fluid   system   incrementally ,   and   the   new   internal   flow   patterns   can   be   simulated   in   real   time .   Our   system   is   used   to   illustrate   various   fluid   systems   in   medicine ,   biology ,   and   engineering .   We   asked   professional   medical   doctors   to   try   our   system   and   obtained   positive   feedback   from   them . ' ,   ' title ' :   ' Sketch - based   Dynamic   Illustration   of   Fluid   Systems ' } 
{ ' abstract ' :   ' We   present   an   improved   zone   content   classification   method   and   its   performance   evaluation .   We   added   two   new   features   to   the   feature   vector   from   one   previously   published   method   ( Sivaramakrishnan   et   al . ,   1995 ) .   We   assumed   different   independence   relationships   in   two   zone   sets .   We   used   an   optimized   binary   decision   tree   to   estimate   the   maximum   zone   content   class   probability   in   one   set   while   using   the   Viterbi   algorithm   to   find   the   optimal   solution   for   a   zone   sequence   in   the   other   set .   The   training ,   pruning   and   testing   data   set   for   the   algorithm   include   1 , 600   images   drawn   from   the   UWCDROM   III   document   image   database .   The   classifier   is   able   to   classify   each   given   scientific   and   technical   document   zone   into   one   of   the   nine   classes ,   2   text   classes   ( of   font   size   4   -   18pt   and   font   size   19   -   32   pt ) ,   math ,   table ,   halftone ,   map / drawing ,   ruling ,   logo ,   and   others .   Compared   with   our   previous   work   ( Wang   et   al . ,   2000 ) ,   it   raised   the   accuracy   rate   to   98.52%   from   97.53%   and   reduced   the   mean   false   alarm   rate   to   0.53%   from   1.26% . ' ,   ' title ' :   ' Zone   content   classification   and   its   performance   evaluation ' } 
{ ' abstract ' :   ' Big   Data   applications   require   real - time   processing   of   complex   computations   on   streaming   and   static   information .   Applications   such   as   the   diagnosis   of   power   generating   turbines   require   the   integration   of   high   velocity   streaming   and   large   volume   of   static   data   from   multiple   sources .   In   this   paper   we   study   various   optimisations   related   to   efficiently   processing   of   streaming   and   static   information .   We   introduce   novel   indexing   structures   for   stream   processing ,   a   query - planner   component   that   decides   when   their   creation   is   beneficial ,   and   we   examine   precomputed   summarisations   on   archived   measurements   to   accelerate   streaming   and   static   information   processing .   To   put   our   ideas   into   practise ,   we   have   developed   Exa   Stream ,   a   data   stream   management   system   that   is   scalable ,   has   declarative   semantics ,   supports   user   defined   functions ,   and   allows   efficient   execution   of   complex   analytical   queries   on   streaming   and   static   data .   Our   work   is   accompanied   by   an   empirical   evaluation   of   our   optimisation   techniques . ' ,   ' title ' :   ' Real   time   processing   of   streaming   and   static   information ' } 
{ ' abstract ' :   " In   the   last   ten   years ,   speech   recognition   has   evolved   from   a   science   fiction   dream   to   a   widespread   input   method   for   mobile   devices .   In   this   talk ,   I   will   describe   how   speech   recognition   works ,   the   problems   we   have   solved   and   the   challenges   that   remain .   I   will   touch   upon   some   of   Google ' s   main   efforts   in   language   and   pronunciation   modeling ,   and   describe   how   the   adoption   of   neural   networks   for   acoustic   modeling   marked   the   beginning   of   a   technology   revolution   in   the   field ,   with   approaches   such   as   Long   Short   Term   Memory   models   and   Connectionist   Temporal   Classification .   I   will   also   share   my   learnings   on   how   Machine   Learning   and   Human   Knowledge   can   be   harmoniously   combined   to   build   state - of - the - art   technology   that   helps   and   delights   users   across   the   world . " ,   ' title ' :   ' Learnings   and   innovations   in   speech   recognition ' } 
{ ' abstract ' :   ' Nowadays ,   the   explosive   growth   and   variety   of   information   available   on   the   Web   frequently   overwhelms   users   and   leads   users   to   make   poor   decisions .   Consequently ,   recommender   systems   have   become   more   and   more   important   to   assist   people   to   make   decisions   faster .   Among   all   related   techniques ,   collaborative   filtering   approach   is   currently   one   of   the   effective   and   widely   used   techniques   to   build   recommender   systems .   However ,   there   are   major   challenges   like   data   sparsity   and   scalability .   Meanwhile   it   is   hard   to   integrate   demographic   statistical   information   ( Age ,   gender   and   occupation   etc . )   to   collaborative   filtering   model .   Unfortunately ,   it   is   significant   to   take   account   into   these   information ,   especially   user   occupation   when   making   recommendation .   As   we   all   know ,   people   with   different   occupations   may   have   totally   different   tastes .   It   has   been   proved   that   restricted   Boltzmann   machines ( RBM )   model   can   infer   lower - dimensional   representations   automatically   and   is   potential   in   handling   large   and   sparse   dataset .   In   this   paper ,   we   propose   an   improved   User   Occupation   aware   Conditional   Restricted   Boltzmann   Machine   Frame ( UO - CRBMF )   model ,   which   employs   an   improved   RBM   and   takes   full   use   of   user   occupation   information   by   adding   a   conditional   layer   with   user   occupation   information .   Experimental   studies   on   the   standard   benchmark   datasets   of   MovieLens   100k   and   MovieLens   1M   have   shown   its   potential   and   advantages   beyond   baseline   methods . ' ,   ' title ' :   ' User   Occupation   Aware   Conditional   Restricted   Boltzmann   Machine   Based   Recommendation ' } 
{ ' abstract ' :   ' Microservices   complement   approaches   like   DevOps   and   continuous   delivery   in   terms   of   software   architecture .   Along   with   this   architectural   style ,   several   important   deployment   technologies ,   such   as   container - based   virtualization   and   container   orchestration   solutions ,   have   emerged .   These   technologies   allow   to   efficiently   exploit   cloud   platforms ,   providing   a   high   degree   of   scalability ,   availability ,   and   portability   for   microservices .# R ## N ## R ## N # Despite   the   obvious   importance   of   a   sufficient   level   of   performance ,   there   is   still   a   lack   of   performance   engineering   approaches   explicitly   taking   into   account   the   particularities   of   microservices .   In   this   paper ,   we   argue   why   new   solutions   to   performance   engineering   for   microservices   are   needed .   Furthermore ,   we   identify   open   issues   and   outline   possible   research   directions   with   regard   to   performance - aware   testing ,   monitoring ,   and   modeling   of   microservices . ' ,   ' title ' :   ' Performance   Engineering   for   Microservices :   Research   Challenges   and   Directions ' } 
{ ' abstract ' :   ' Intelligent   agents ,   such   as   robots ,   have   to   serve   a   multitude   of   autonomous   functions .   Examples   are ,   e . g . ,   collision   avoidance ,   navigation   and   route   planning ,   active   sensing   of   its   environment ,   or   the   interaction   and   non - verbal   communication   with   people   in   the   extended   reach   space .   Here ,   we   focus   on   the   recognition   of   the   action   of   a   human   agent   based   on   a   biologically   inspired   visual   architecture   of   analyzing   articulated   movements .   The   proposed   processing   architecture   builds   upon   coarsely   segregated   streams   of   sensory   processing   along   different   pathways   which   separately   process   form   and   motion   information   ( Layher   et   al . ,   2014 ) .   Action   recognition   is   performed   in   an   event - based   scheme   by   identifying   representations   of   characteristic   pose   configurations   ( key   poses )   in   an   image   sequence .   In   line   with   perceptual   studies ,   key   poses   are   selected   unsupervised   utilizing   a   feature   driven   criterion   which   combines   extrema   in   the   motion   energy   with   the   horizontal   and   the   vertical   extendedness   of   a   body   shape .   Per   class   representations   of   key   pose   frames   are   learned   using   a   deep   convolutional   neural   network   consisting   of   15   convolutional   layers .   The   network   is   trained   using   the   energy - efficient   deep   neuromorphic   networks   ( Eedn )   framework   ( Esser   et   al . ,   2016 ) ,   which   realizes   the   mapping   of   the   trained   synaptic   weights   onto   the   IBM   Neurosynaptic   System   platform   ( Merolla   et   al . ,   2014 ) .   After   the   mapping ,   the   trained   network   achieves   real - time   capabilities   for   processing   input   streams   and   classify   input   images   at   about   1 , 000   frames   per   second   while   the   computational   stages   only   consume   about   70   mW   of   energy   ( without   spike   transduction ) .   Particularly   regarding   mobile   robotic   systems ,   a   low   energy   profile   might   be   crucial   in   a   variety   application   scenarios .   Cross - validation   results   are   reported   for   two   different   datasets   and   compared   to   state - of - the - art   action   recognition   approaches .   The   results   demonstrate ,   that   ( I )   the   presented   approach   is   on   par   with   other   key   pose   based   methods   described   in   the   literature ,   which   select   key   pose   frames   by   optimizing   classification   accuracy ,   ( II )   compared   to   the   training   on   the   full   set   of   frames ,   representations   trained   on   key   pose   frames   result   in   a   higher   confidence   in   class   assignments ,   and   ( III )   key   pose   representations   show   promising   generalization   capabilities   in   a   cross - dataset   evaluation . ' ,   ' title ' :   ' Real - Time   Biologically   Inspired   Action   Recognition   from   Key   Poses   Using   a   Neuromorphic   Architecture ' } 
{ ' abstract ' :   ' Contents   carried   in   an   image   are   valuable   information   sources   for   many   scientific   and   engineering   applications .   However ,   if   the   image   is   captured   under   low   illumination   conditions   a   large   portion   of   the   image   appears   dark   and   this   heavily   degrades   the   image   quality .   In   order   to   solve   this   problem ,   a   restoration   algorithm   is   developed   here   that   transforms   the   low   input   brightness   to   a   higher   value   using   a   logarithmic   mapping   function .   The   mapping   is   further   refined   by   a   linear   weighting   with   the   input   to   reduce   the   un - necessary   amplification   at   regions   with   high   brightness .   Moreover ,   fine   details   in   the   image   are   preserved   by   applying   the   Retinex   principle   to   extract   and   then   re - insert   object   edges .   Results   from   experiments   using   low   and   normal   illumination   images   have   shown   satisfactory   performances   with   regard   to   the   improvement   in   information   contents   and   the   mitigation   of   viewing   artifacts . ' ,   ' title ' :   ' Logarithmic   profile   mapping   and   Retinex   edge   preserving   for   restoration   of   low   illumination   images ' } 
{ ' abstract ' :   ' We   propose   a   principled   approach   for   the   problem   of   aligning   multiple   partially   overlapping   networks .   The   objective   is   to   map   multiple   graphs   into   a   single   graph   while   preserving   vertex   and   edge   similarities .   The   problem   is   inspired   by   the   task   of   integrating   partial   views   of   a   family   tree   ( genealogical   network )   into   one   unified   network ,   but   it   also   has   applications ,   for   example ,   in   social   and   biological   networks .   Our   approach ,   called   Flan ,   introduces   the   idea   of   generalizing   the   facility   location   problem   by   adding   a   non - linear   term   to   capture   edge   similarities   and   to   infer   the   underlying   entity   network .   The   problem   is   solved   using   an   alternating   optimization   procedure   with   a   Lagrangian   relaxation .   Flan   has   the   advantage   of   being   able   to   leverage   prior   information   on   the   number   of   entities ,   so   that   when   this   information   is   available ,   Flan   is   shown   to   work   robustly   without   the   need   to   use   any   ground   truth   data   for   fine - tuning   method   parameters .   Additionally ,   we   present   three   multiple - network   extensions   to   an   existing   state - of - the - art   pairwise   alignment   method   called   Natalie .   Extensive   experiments   on   synthetic ,   as   well   as   real - world   datasets   on   social   networks   and   genealogical   networks ,   attest   to   the   effectiveness   of   the   proposed   approaches   which   clearly   outperform   a   popular   multiple   network   alignment   method   called   IsoRankN . ' ,   ' title ' :   ' Lagrangian   relaxations   for   multiple   network   alignment ' } 
{ ' abstract ' :   ' Heterogeneous   ultra - dense   networks   enable   ultra - high   data   rates   and   ultra - low   latency   through   the   use   of   dense   sub - 6   GHz   and   millimeter   wave   ( mmWave )   small   cells   with   different   antenna   configurations .   Existing   work   has   widely   studied   spectral   and   energy   efficiency   in   such   networks   and   shown   that   high   spectral   and   energy   efficiency   can   be   achieved .   This   article   investigates   the   benefits   of   heterogeneous   ultra - dense   network   architecture   from   the   perspectives   of   three   promising   technologies ,   i . e . ,   physical   layer   security ,   caching ,   and   wireless   energy   harvesting ,   and   provides   enthusiastic   outlook   towards   application   of   these   technologies   in   heterogeneous   ultra - dense   networks .   Based   on   the   rationale   of   each   technology ,   opportunities   and   challenges   are   identified   to   advance   the   research   in   this   emerging   network . ' ,   ' title ' :   ' A   New   Look   at   Physical   Layer   Security ,   Caching ,   and   Wireless   Energy   Harvesting   for   Heterogeneous   Ultra - dense   Networks ' } 
{ ' abstract ' :   ' We   consider   the   problem   of   joint   modeling   of   videos   and   their   corresponding   textual   descriptions   ( e . g .   sentences   or   phrases ) .   Our   approach   consists   of   three   components :   the   video   representation ,   the   textual   representation ,   and   a   joint   model   that   links   videos   and   text .   Our   video   representation   uses   the   state - of - the - art   deep   3D   ConvNet   to   capture   the   semantic   information   in   the   video .   Our   textual   representation   uses   the   recent   advancement   in   learning   word   and   sentence   vectors   from   large   text   corpus .   The   joint   model   is   learned   to   score   the   correct   ( video ,   text )   pairs   higher   than   the   incorrect   ones .   We   demonstrate   our   approach   in   several   applications :   1 )   retrieving   sentences   given   a   video ;   2 )   retrieving   videos   given   a   sentence ;   3 )   zero - shot   action   recognition   in   videos . ' ,   ' title ' :   ' Beyond   verbs :   Understanding   actions   in   videos   with   text ' } 
{ ' abstract ' :   ' This   paper   presents   a   multi - agent   model   for   simulating   attitude   formation   and   change   based   on   perception   and   communication   in   the   context   of   stabilization   operations .   The   originality   of   our   model   comes   from   ( 1 )   attitude   computation   that   evaluates   information   as   part   of   a   history   relative   to   the   individual   ( 2 )   a   notion   of   co - responsibility   for   attitude   attribution .   We   present   a   military   scenario   of   French   operations   in   Afghanistan   along   with   polls   results   about   the   opinion   of   citizen   toward   present   Forces .   Based   on   these   field   data ,   we   calibrate   the   model   and   show   the   resulting   attitude   dynamics .   We   study   the   sensibility   of   the   model   to   the   co - responsibility   factor . ' ,   ' title ' :   ' From   Field   Data   to   Attitude   Formation ' } 
{ ' abstract ' :   ' This   paper   proposes   two   low - complexity   iterative   algorithms   to   compute   the   capacity   of   a   single - user   multiple - input   multiple - output   channel   with   per - antenna   power   constraint .   The   first   method   results   from   manipulating   the   optimality   conditions   of   the   considered   problem   and   applying   fixed - point   iteration .   In   the   second   approach ,   we   transform   the   considered   problem   into   a   minimax   optimization   program   using   the   well - known   MAC -   BC   duality ,   and   then   solve   it   by   a   novel   alternating   optimization   method .   In   both   proposed   iterative   methods ,   each   iteration   involves   an   optimization   problem   which   can   be   efficiently   solved   by   the   water - filling   algorithm .   The   proposed   iterative   methods   are   provably   convergent .   Complexity   analysis   and   extensive   numerical   experiments   are   carried   out   to   demonstrate   the   superior   performance   of   the   proposed   algorithms   over   an   existing   approach   known   as   the   mode - dropping   algorithm . ' ,   ' title ' :   ' Low - complexity   Approaches   for   MIMO   Capacity   with   Per - antenna   Power   Constraint ' } 
{ ' abstract ' :   ' Inventory - Aware   Pathfinding   is   concerned   with   finding   paths   while   taking   into   account   that   picking   up   items ,   e . g . ,   keys ,   allow   the   character   to   unlock   blocked   pathways ,   e . g . ,   locked   doors .   In   this   work   we   present   a   pruning   method   and   a   preprocessing   method   that   can   improve   significantly   the   scalability   of   such   approaches .   We   apply   our   methods   to   the   recent   approach   of   Inventory - Driven   Jump - Point   Search   ( InvJPS ) .   First ,   we   introduce   InvJPS +   that   allows   to   prune   large   parts   of   the   search   space   by   favoring   short   detours   to   pick   up   items ,   offering   a   trade - off   between   efficiency   and   optimality .   Second ,   we   propose   a   preprocessing   step   that   allows   to   decide   on   runtime   which   items ,   e . g . ,   keys ,   are   worth   using   thus   pruning   potentially   unnecessary   items   before   the   search   starts .   We   show   results   for   combinations   of   the   pruning   and   preprocessing   methods   illustrating   the   best   choices   over   various   scenarios . ' ,   ' title ' :   ' Pruning   and   preprocessing   methods   for   inventory - aware   pathfinding ' } 
{ ' abstract ' :   ' This   paper   proposes   a   method   for   proper   names   extraction   from   Myanmar   text   by   using   latent   Dirichlet   allocation   ( LDA ) .   Our   method   aims   to   extract   proper   names   that   provide   important   information   on   the   contents   of   Myanmar   text .   Our   method   consists   of   two   steps .   In   the   first   step ,   we   extract   topic   words   from   Myanmar   news   articles   by   using   LDA .   In   the   second   step ,   we   make   a   post - processing ,   because   the   resulting   topic   words   contain   some   noisy   words .   Our   post - processing ,   first   of   all ,   eliminates   the   topic   words   whose   prefixes   are   Myanmar   digits   and   suffixes   are   noun   and   verb   particles .   We   then   remove   the   duplicate   words   and   discard   the   topic   words   that   are   contained   in   the   existing   dictionary .   Consequently ,   we   obtain   the   words   as   candidate   of   proper   names ,   namely   personal   names ,   geographical   names ,   unique   object   names ,   organization   names ,   single   event   names ,   and   so   on .   The   evaluation   is   performed   both   from   the   subjective   and   quantitative   perspectives .   From   the   subjective   perspective ,   we   compare   the   accuracy   of   proper   names   extracted   by   our   method   with   those   extracted   by   latent   semantic   indexing   ( LSI )   and   rule - based   method .   It   is   shown   that   both   LS ]   and   our   method   can   improve   the   accuracy   of   those   obtained   by   rule - based   method .   However ,   our   method   can   provide   more   interesting   proper   names   than   LSI .   From   the   quantitative   perspective ,   we   use   the   extracted   proper   names   as   additional   features   in   K - means   clustering .   The   experimental   results   show   that   the   document   clusters   given   by   our   method   are   better   than   those   given   by   LSI   and   rule - based   method   in   precision ,   recall   and   F - score . ' ,   ' title ' :   ' Extraction   of   proper   names   from   myanmar   text   using   latent   dirichlet   allocation ' } 
{ ' abstract ' :   ' Large   scale   assessment   of   aboveground   biomass   ( AGB )   in   tropical   forests   is   often   limited   by   the   saturation   of   remote   sensing   signals   at   high   AGB   values .   Fourier   Transform   Textural   Ordination   ( FOTO )   performs   well   in   quantifying   canopy   texture   from   very   high - resolution   ( VHR )   imagery ,   from   which   stand   structure   parameters   can   be   retrieved   with   no   saturation   effect   for   AGB   values   up   to   650   Mg · ha − 1 .   The   method   is   robust   when   tested   on   wet   evergreen   forests   but   is   more   demanding   when   applied   across   different   forest   types   characterized   by   varying   structures   and   allometries .   The   present   study   focuses   on   a   gradient   of   forest   types   ranging   from   dry   deciduous   to   wet   evergreen   forests   in   the   Western   Ghats   ( WG )   of   India ,   where   we   applied   FOTO   to   Cartosat - 1a   images   with   2.5   m   resolution .   Based   on   21   1 - ha   ground   control   forest   plots ,   we   calibrated   independent   texture – AGB   models   for   the   dry   and   wet   zone   forests   in   the   area ,   as   delineated   from   the   distribution   of   NDVI   values   computed   from   LISS - 4   multispectral   images .   This   stratification   largely   improved   the   relationship   between   texture - derived   and   field - derived   AGB   estimates ,   which   exhibited   a   R2   of   0.82   for   a   mean   rRMSE   of   ca .   17% .   By   inverting   the   texture – AGB   models ,   we   finally   mapped   AGB   predictions   at   1.6 - ha   resolution   over   a   heterogeneous   landscape   of   ca .   1500   km2   in   the   WG ,   with   a   mean   relative   per - pixel   propagated   error   < 20%   for   wet   zone   forests ,   i . e . ,   below   the   recommended   IPCC   criteria   for   Monitoring ,   Reporting   and   Verification   ( MRV )   methods .   The   method   proved   to   perform   well   in   predicting   high - resolution   AGB   values   over   heterogeneous   tropical   landscape   encompassing   diversified   forest   types ,   and   thus   presents   a   promising   option   for   affordable   regional   monitoring   systems   of   greenhouse   gas   ( GhG )   emissions   related   to   forest   degradation . ' ,   ' title ' :   ' Inverting   Aboveground   Biomass – Canopy   Texture   Relationships   in   a   Landscape   of   Forest   Mosaic   in   the   Western   Ghats   of   India   Using   Very   High   Resolution   Cartosat   Imagery ' } 
{ ' abstract ' :   ' Self - driving   vehicle   technologies   are   progressing   rapidly   and   are   expected   to   play   a   significant   role   in   the   future   of   transportation .   One   of   the   main   challenges   for   self - driving   vehicles   on   public   roads   is   the   safe   cooperation   and   collaboration   among   multiple   vehicles   using   sensor - based   perception   and   inter - vehicle   communications .   When   self - driving   vehicles   try   to   occupy   the   same   spatial   area   simultaneously ,   they   might   collide   with   one   another ,   might   become   deadlocked ,   or   might   slam   on   the   brakes   making   it   uncomfortable   or   unsafe   for   passengers   in   a   self - driving   vehicle .   In   this   paper ,   we   study   how   a   self - driving   vehicle   can   safely   navigate   merge   points ,   where   two   lanes   with   different   priorities   meet .   We   present   a   safe   protocol   for   merge   points   named   Autonomous   Vehicle   Protocol   for   Merge   Points ,   where   self - driving   vehicles   use   both   vehicular   communications   and   their   own   perception   systems   for   cooperating   with   other   self - driving   and / or   human - driven   vehicles .   Our   simulation   results   show   that   our   traffic   protocol   has   higher   traffic   throughput ,   compared   to   simple   traffic   protocols ,   while   ensuring   safety . ' ,   ' title ' :   ' A   merging   protocol   for   self - driving   vehicles ' } 
{ ' abstract ' :   ' System   Portfolio   Selection   ( SPS )   problem   is   equivalent   to   multi - objective   optimization   problem ,   with   multi - function   requirements   incommensurable .   In   the   paper ,   the   SPS   problem   is   re - specified   with   a   more   practical   formulation ,   comparing   to   general   portfolio   problem .   Then ,   both   feasible   and   non - inferior   solution   is   re - defined   considering   characteristics   of   SPS   problem ,   specifically ,   four   rules   of   system   function   combinations   are   proposed   according   to   practical   cases .   Then ,   the   instability   of   system   performance   is   involved   in   SPS   problem ,   and   the   robust   theory   is   employed   to   solving   the   uncertainty   of   system   function   values   with   definition   of   robust   non - inferior   solution .   Next ,   the   paper   proposes   an   immediately   updating   algorithm   to   solve   the   problem   of   solution   space   exponentially   growing .   Finally ,   a   case   study   is   used   to   demonstrate   the   usefulness   and   effectiveness   of   the   proposed   approaches .   It   shows   that   the   approach   can   provide   an   efficient   guidance   for   decision - makers   in   the   process   of   making   a   SPS . ' ,   ' title ' :   ' Robust   system   portfolio   selection   with   multi - function   requirements   and   system   instability ' } 
{ ' abstract ' :   ' This   study   explores   the   impact   of   high - photovoltaic   ( PV )   penetration   on   the   inter - area   oscillation   modes   of   large - scale   power   grids .   A   series   of   dynamic   models   with   various   PV   penetration   levels   are   developed   based   on   a   detailed   model   representing   the   U . S .   Eastern   Interconnection   ( EI ) .   Transient   simulations   are   performed   to   investigate   the   change   of   inter - area   oscillation   modes   with   PV   penetration .   The   impact   of   PV   control   strategies   and   parameter   settings   on   inter - area   oscillations   is   studied .   This   paper   finds   that   as   PV   increases ,   the   damping   of   the   dominant   oscillation   mode   decreases   monotonically .   It   is   also   observed   that   the   mode   shape   varies   with   the   PV   control   strategy   and   new   oscillation   modes   may   emerge   under   inappropriate   parameter   settings   in   PV   plant   controls . ' ,   ' title ' :   ' Impact   of   High   PV   Penetration   on   the   Inter - Area   Oscillations   in   the   U . S .   Eastern   Interconnection ' } 
{ ' abstract ' :   ' The   objective   of   this   research   is   to   compare   the   effectiveness   of   different   tracking   devices   underwater .   There   have   been   few   works   in   aquatic   virtual   reality   ( VR )   —   i . e . ,   VR   systems   that   can   be   used   in   a   real   underwater   environment .   Moreover ,   the   works   that   have   been   done   have   noted   limitations   on   tracking   accuracy .   Our   initial   test   results   suggest   that   inertial   measurement   units   work   well   underwater   for   orientation   tracking   but   a   different   approach   is   needed   for   position   tracking .   Towards   this   goal ,   we   have   waterproofed   and   evaluated   several   consumer   tracking   systems   intended   for   gaming   to   determine   the   most   effective   approaches .   First ,   we   informally   tested   infrared   systems   and   fiducial   marker   based   systems ,   which   demonstrated   significant   limitations   of   optical   approaches .   Next ,   we   quantitatively   compared   inertial   measurement   units   ( IMU )   and   a   magnetic   tracking   system   both   above   water   ( as   a   baseline )   and   underwater .   By   comparing   the   devices   rotation   data ,   we   have   discovered   that   the   magnetic   tracking   system   implemented   by   the   Razer   Hydra   is   more   accurate   underwater   as   compared   to   a   phone - based   IMU .   This   suggests   that   magnetic   tracking   systems   should   be   further   explored   for   underwater   VR   applications . ' ,   ' title ' :   ' Towards   usable   underwater   virtual   reality   systems ' } 
{ ' abstract ' :   ' A   faulty   network   GG   is   under   the   conditional   fault   model ,   i . e . , \ xa0every   fault - free   vertex   of   GG   is   incident   to   at   least   two   fault - free   edges .   Let   FFvFFv   and   FFeFFe   be   the   set   of   faulty   vertices   and   faulty   edges   in   FQnFQn ,   respectively .   In   this   paper ,   we   consider   FQnFQn   under   the   conditional   fault   model   and   prove   that   if   | FFv | + | FFe | ≤ 2n − 4 | FFv | + | FFe | ≤ 2n − 4   and   n ≥ 3n ≥ 3 ,   then   FQn − FFv − FFeFQn − FFv − FFe   contains   a   fault - free   cycle   of   every   even   length   from   4   to   2n − 2 | FFv | 2n − 2 | FFv | ;   if   | FFv | + | FFe | ≤ 2n − 5 | FFv | + | FFe | ≤ 2n − 5   and   n ≥ 4n ≥ 4   is   even ,   then   FQn − FFv − FFeFQn − FFv − FFe   contains   a   fault - free   cycle   of   every   odd   length   from   n + 1n + 1   to   2n − 2 | FFv | − 12n − 2 | FFv | − 1 . ' ,   ' title ' :   ' Cycles   embedding   in   folded   hypercubes   under   the   conditional   fault   model ' } 
{ ' abstract ' :   ' Companies   have   invested   considerable   resources   in   the   implementation   of   enterprise   resource   planning   ( ERP )   systems .   The   results   initially   expected   have   rarely   been   reached .   The   optimisation   ( or   efficient   use )   of   such   information   systems   is   nowadays   becoming   a   major   factor   for   firms   striving   to   reach   their   performance   objectives .   After   presenting   a   synthesis   of   several   studies   on   ERP   projects ,   we   build   on   the   findings   of   a   French   investigation   into   the   assessment   and   optimisation   of   ERP   performance .   A   classification   of   company   positions   regarding   their   ERP   use ,   based   on   both   software   maturity   and   strategic   deployment   directions ,   and   an   improvement   process   are   proposed .   Industrial   cases   allow   validation   of   this   approach . ' ,   ' title ' :   ' A   classification   for   better   use   of   ERP   systems ' } 
{ ' abstract ' :   ' This   paper   presents   a   time - domain   biosensor   array   that   uses   a   capacitor - less   current - mode   analog - to - time   converter   ( CMATC )   and   logarithmic   cyclic   time - attenuation - based   TDC   with   discharging   acceleration .   Combining   the   exponential   function   of   the   CMATC   and   logarithmic   function   of   the   proposed   TDC   offers   linear   input - output   characteristics .   The   time - domain   property   enables   bio - imaging   at   a   high   spatial   resolution   and   large   scale   while   maintaining   scalability .   Measurement   results   with   a   0.25 - μ m   test   chip   successfully   demonstrated   linear   input - output   characteristics . ' ,   ' title ' :   ' A   scalable   time - domain   biosensor   array   using   logarithmic   cyclic   time - attenuation - based   TDC   for   high - resolution   and   large - scale   bio - imaging ' } 
{ ' abstract ' :   ' Compared   to   current   mobile   networks ,   next - generation   mobile   networks   are   expected   to   support   higher   numbers   of   simultaneously   connected   devices   and   to   achieve   higher   system   spectrum   efficiency   and   lower   power   consumption .   To   achieve   these   goals ,   we   study   the   multi - sharing   device - to - device   ( D2D )   communication ,   which   allows   any   cellular   user   equipment   to   share   its   radio   resource   with   multiple   D2D   devices .   We   jointly   consider   resource   block   reuse   and   power   control   and   then   develop   the   MISS   algorithm .   Simulation   results   show   that   MISS   performs   very   well   in   terms   of   transmission   power   consumption ,   system   throughput ,   and   the   number   of   permitted   D2D   devices . ' ,   ' title ' :   ' Joint   Resource   Block   Reuse   and   Power   Control   for   Multi - Sharing   Device - to - Device   Communication ' } 
{ ' abstract ' :   ' This   paper   is   concerned   with   event - triggered   H ∞ H ∞   filtering   for   delayed   neural   networks   via   sampled   data .   A   novel   event - triggered   scheme   is   proposed ,   which   can   lead   to   a   significant   reduction   of   the   information   communication   burden   in   the   network ;   the   feature   of   this   scheme   is   that   whether   or   not   the   sampled   data   should   be   transmitted   is   determined   by   the   current   sampled   data   and   the   error   between   the   current   sampled   data   and   the   latest   transmitted   data .   By   constructing   a   proper   Lyapunov – Krasovskii   functional ,   utilizing   the   reciprocally   convex   combination   technique   and   Jensen ’ s   inequality   sufficient   conditions   are   derived   to   ensure   that   the   resultant   filtering   error   system   is   asymptotically   stable .   Based   on   the   derived   H ∞ H ∞   performance   analysis   results ,   the   H ∞ H ∞   filter   design   is   formulated   in   terms   of   Linear   Matrix   Inequalities   ( LMIs ) .   Finally ,   the   proposed   stability   conditions   are   demonstrated   with   numerical   example . ' ,   ' title ' :   ' Event - triggered   H   ∞   filtering   for   delayed   neural   networks   via   sampled - data ' } 
{ ' abstract ' :   ' For   the   double   integrator   with   matched   Lipschitz   disturbances   we   propose   a   continuous   homogeneous   controller   providing   finite - time   stability   of   the   origin .   The   disturbance   is   compensated   exactly   in   finite   time   using   a   discontinuous   function   through   an   integral   action .   Since   the   controller   is   dynamic ,   the   closed   loop   is   a   third   order   system   that   achieves   a   third   order   sliding   mode   in   the   steady   state .   The   stability   and   robustness   properties   of   the   controller   are   proven   using   a   smooth   and   homogeneous   strict   Lyapunov   function   ( LF ) .   In   a   first   stage ,   the   gains   of   the   controller   and   the   LF   are   designed   using   a   method   based   on   Polya ’ s   Theorem .   In   a   second   stage   the   controller ’ s   gains   are   adjusted   through   a   sum   of   squares   representation   of   the   LF . ' ,   ' title ' :   ' Design   of   Continuous   Twisting   Algorithm ' } 
{ ' abstract ' :   ' Big   data   is   now   rapidly   expanding   into   various   domains   such   as   banking ,   insurance   and   e - commerce .   Data   analysis   and   related   studies   have   attracted   more   attentions .   In   health   insurance ,   abuse   of   diagnosis   is   one   of   the   key   fraud   problems ,   which   damages   the   interests   of   insured   people .   To   address   this   issue ,   numbers   of   studies   have   focused   on   this   topic .   This   paper   develops   a   healthcare   fraud   detection   approach   based   on   the   trustworthiness   of   doctors   to   distinguish   fraud   cases   from   normal   records .   Compared   to   conventional   methods ,   our   approach   can   detect   healthcare   fraud   in   a   good   accuracy   by   only   little   feature   information   from   healthcare   data   without   the   violation   of   privacy .   This   approach   combines   a   weighted   HITS   algorithm   with   a   frequent   pattern   mining   algorithm   to   calculate   a   rational   treatment   model   of   a   certain   disease .   In   addition ,   this   paper   also   introduces   the   copy   precision   behavior   in   the   treatment   sequences   of   patients ,   which   is   a   critical   metric   to   learn   the   trustworthiness   of   doctors .   The   numerical   validation   with   a   healthcare   dataset   demonstrates   that   healthcare   fraud   by   misdiagnosis   in   healthcare   treatments   can   be   successfully   detected   by   employing   the   developed   fraud   detection   approach . ' ,   ' title ' :   ' Healthcare   Fraud   Detection   Based   on   Trustworthiness   of   Doctors ' } 
{ ' abstract ' :   ' In   this   paper   we   study   data   collection   in   an   energy   renewable   sensor   network   for   scenarios   such   as   traffic   monitoring   on   busy   highways ,   where   sensors   are   deployed   along   a   predefined   path   ( the   highway )   and   a   mobile   sink   travels   along   the   path   to   collect   data   from   one - hop   sensors   periodically .   As   sensors   are   powered   by   renewable   energy   sources ,   time - varying   characteristics   of   ambient   energy   sources   poses   great   challenges   in   the   design   of   efficient   routing   protocols   for   data   collection   in   such   networks .   In   this   paper   we   first   formulate   a   novel   data   collection   maximization   problem   by   adopting   multi - rate   data   transmissions   and   performing   transmission   time   slot   scheduling ,   and   show   that   the   problem   is   NP - hard .   We   then   devise   an   offline   algorithm   with   a   provable   approximation   ratio   for   the   problem   by   exploiting   the   combinatorial   property   of   the   problem ,   assuming   that   the   harvested   energy   at   each   node   is   given   and   link   communications   in   the   network   are   reliable .   We   also   extend   the   proposed   algorithm   by   minor   modifications   to   a   general   case   of   the   problem   where   the   harvested   energy   at   each   sensor   is   not   known   in   advance   and   link   communications   are   not   reliable .   We   thirdly   develop   a   fast ,   scalable   online   distributed   algorithm   for   the   problem   in   realistic   sensor   networks   in   which   neither   the   global   knowledge   of   the   network   topology   nor   sensor   profiles   such   as   sensor   locations   and   their   harvested   energy   profiles   is   given .   Furthermore ,   we   also   consider   a   special   case   of   the   problem   where   each   node   has   only   a   fixed   transmission   power ,   for   which   we   propose   an   exact   solution   to   the   problem .   We   finally   conduct   extensive   experiments   by   simulations   to   evaluate   the   performance   of   the   proposed   algorithms .   Experimental   results   demonstrate   that   the   proposed   algorithms   are   efficient   and   the   solutions   obtained   are   fractional   of   the   optimum . ' ,   ' title ' :   ' Data   Collection   Maximization   in   Renewable   Sensor   Networks   via   Time - Slot   Scheduling ' } 
{ ' abstract ' :   ' An   increasing   number   of   businesses   are   migrating   their   IT   operations   to   the   cloud .   Likewise   there   is   an   increased   emphasis   on   data   analytics   based   on   multiple   datasets   and   sources   to   derive   information   not   derivable   when   a   dataset   is   mined   in   isolation .   While   ensuring   security   of   data   and   computation   outsourced   to   a   third   party   cloud   service   provider   is   in   itself   challenging ,   supporting   mash - ups   and   analytics   of   data   from   different   parties   hosted   across   different   services   is   even   more   so .   In   this   paper   we   propose   a   cloud - based   service   allowing   multiple   parties   to   perform   secure   multi - party   secure   sum   computation   using   their   clouds   as   delegates .   Our   scheme   provides   data   privacy   both   from   the   delegates   as   well   as   from   the   other   data   owners   under   a   lazy - and - curious   adversary   ( semi - honest )   model .   We   then   describe   how   such   a   secure   sum   primitive   may   be   used   in   various   collaborative ,   cloud - based   distributed   data   mining   tasks   ( classification ,   association   rule   mining   and   clustering ) .   We   implement   a   prototype   and   benchmark   the   service ,   both   as   a   stand - alone   secure   sum   service ,   and   as   a   building   block   for   more   complex   analytics .   The   results   suggest   reasonable   overhead   and   demonstrate   the   practicality   of   carrying   out   privacy   preserved   distributed   analytics   despite   migrating   ( encrypted )   data   to   pos -   sibly   different   and   untrusted   ( semi - honest )   cloud   services . ' ,   ' title ' :   ' Delegated   Secure   Sum   Service   for   Distributed   Data   Mining   in   Multi - Cloud   Settings ' } 
{ ' abstract ' :   ' This   paper   fundamentally   investigates   the   performance   of   evolutionary   multiobjective   optimization   ( EMO )   algorithms   for   computationally   hard   0 - 1   combinatorial   optimization ,   where   a   strict   theoretical   analysis   is   generally   out   of   reach   due   to   the   high   complexity   of   the   underlying   problem .   Based   on   the   examination   of   problem   features   from   a   multiobjective   perspective ,   we   improve   the   understanding   of   the   efficiency   of   a   simple   dominance - based   EMO   algorithm   with   unbounded   archive   for   multiobjective   NK - landscapes   with   correlated   objective   values .   More   particularly ,   we   adopt   a   statistical   approach ,   based   on   simple   and   multiple   linear   regression   analysis ,   to   enquire   the   expected   running   time   of   global   SEMO   with   restart   for   identifying   a   ( 1 + e ) - approximation   of   the   Pareto   set   for   small - size   enumerable   instances .   Our   analysis   provides   further   insights   on   the   EMO   search   behavior   and   on   the   most   important   features   that   characterize   the   difficulty   of   an   instance   for   this   class   of   problems   and   algorithms . ' ,   ' title ' :   ' A   feature - based   performance   analysis   in   evolutionary   multiobjective   optimization ' } 
{ ' abstract ' :   ' Functional   biological   sequences ,   which   typically   come   in   families ,   have   retained   some   level   of   similarity   and   function   during   evolution .   Finding   consensus   regions ,   alignment   of   sequences ,   and   identifying   the   relationship   between   a   sequence   and   a   family   allow   inferences   about   the   function   of   the   sequences .   Profile   hidden   Markov   models   ( HMMs )   are   generally   used   to   identify   those   relationships .   A   profile   HMM   can   be   trained   on   unaligned   members   of   the   family   using   conventional   algorithms   such   as   Baum - Welch ,   Viterbi ,   and   their   modifications .   The   overall   quality   of   the   alignment   depends   on   the   quality   of   the   trained   model .   Unfortunately ,   the   conventional   training   algorithms   converge   to   suboptimal   models   most   of   the   time .   This   work   proposes   a   training   algorithm   that   early   identifies   many   imperfect   models .   The   method   is   based   on   the   Simulated   Annealing   approach   widely   used   in   discrete   optimization   problems .   The   training   algorithm   is   implemented   as   a   component   in   HMMER .   The   performance   of   the   algorithm   is   discussed   on   protein   sequence   data . ' ,   ' title ' :   ' Simulated   annealing   algorithm   with   biased   neighborhood   distribution   for   training   profile   models ' } 
{ ' abstract ' :   ' The   Canny   algorithm   is   a   well   known   edge   detector   that   is   widely   used   in   the   previous   processing   stages   in   several   algorithms   related   to   computer   vision .   An   alternative ,   the   LIP - Canny   algorithm ,   is   based   on   a   robust   mathematical   model   closer   to   the   human   vision   system ,   obtaining   better   results   in   terms   of   edge   detection .   In   this   work   we   describe   LIP - Canny   algorithm   under   the   perspective   from   its   parallelization   and   optimization   by   using   the   NVIDIA   CUDA   framework .   Furthermore ,   we   present   comparative   results   between   an   implementation   of   this   algorithm   using   NVIDIA   CUDA   and   the   analogue   using   a   C / C++   approach . ' ,   ' title ' :   ' Parallelizing   and   optimizing   LIP - canny   using   NVIDIA   CUDA ' } 
{ ' abstract ' :   ' This   paper   presents   an   efficient   Bayesian   blind   multiuser   receiver   for   long   code   multipath   CDMA   systems .   The   proposed   receiver   employs   the   adaptive   sampling   method   for   the   Bayesian   inference   procedure   to   estimate   the   data   symbols   and   multipath   parameters .   Compared   to   the   other   reported   Bayesian   Monte   Carlo   receivers   for   long   code   multipath   CDMA   systems ,   the   proposed   one   achieves   a   faster   convergence   and   a   lower   computational   complexity   to   attain   comparable   performance .   Simulation   results   are   presented   to   demonstrate   the   effectiveness   of   the   proposed   Bayesian   blind   multiuser   receiver . ' ,   ' title ' :   ' Blind   Multiuser   Detection   for   Long   Code   Multipath   DS - CDMA   Systems   with   Bayesian   MC   Techniques ' } 
{ ' abstract ' :   ' Spreadsheets   are   by   far   the   most   prominent   example   of   end - user   programs   of   ample   size   and   substantial   structural   complexity .   In   addition ,   spreadsheets   are   usually   not   tested   very   rigorously   and   thus   comprise   faults .   Locating   faults   is   a   hard   task   due   to   the   size   and   the   structure ,   which   is   usually   not   directly   visible   to   the   user ,   i . e . ,   the   functions   are   hidden   behind   the   cells   and   only   the   computed   values   are   presented .   Hence ,   there   is   a   strong   need   for   debugging   support .   In   this   paper ,   we   adapt   three   program - debugging   approaches   that   have   been   designed   for   more   traditional   procedural   or   object - oriented   programming   languages .   These   techniques   are   Spectrum - based   Fault   Localization ,   Spectrum - Enhanced   Dynamic   Slicing ,   and   Constraint - based   Debugging .   Beside   the   theoretical   foundations ,   we   present   a   more   sophisticated   empirical   evaluation   including   a   comparison   of   these   approaches .   The   empirical   evaluation   shows   that   Sfl   ( Spectrum - based   Fault   Localization )   and   Sendys   ( Spectrum   ENhanced   Dynamic   Slicing )   are   the   most   promising   techniques . ' ,   ' title ' :   ' On   the   empirical   evaluation   of   fault   localization   techniques   for   spreadsheets ' } 
{ ' abstract ' :   ' This   work   provides   elements   to   highlight   the   reliability   challenges   related   to   the   technology   scaling   and   the   BTI   variability .   Through   main   milestones   including   device   reliability   scaling   model   ( for   both   mean   and   spread ) ,   a   discussion   on   the   physical   origin   of   BTI   variability   and   a   digital   IP   failure   rate   analytical   model ,   the   evolution   of   digital   IP   failure   rates   along   the   ITRS   scaling   roadmap   is   assessed .   and   an   analysis   of   the   ITRS   roadmap   on   digital   IP   failure   rates .   This   study   offers   new   perspectives   towards   product   hardening   and   qualification   with   respect   to   both   fresh   and   BTI - related   local   variability ,   especially   in   context   where   Adaptive   Voltage   Scaling   ( AVS )   is   used   to   compensate   for   process   centerings . ' ,   ' title ' :   ' From   BTI   variability   to   product   failure   rate :   A   technology   scaling   perspective ' } 
{ ' abstract ' :   ' In   this   paper   we   discuss   the   problem   of   calculating   the   reachable   states   of   a   dynamical   system   defined   by   ordinary   differential   equations   or   inclusions .   We   present   a   prototype   system   for   approximating   this   set   and   demonstrate   some   experimental   results . ' ,   ' title ' :   ' Reachability   Analysis   via   Face   Lifting ' } 
{ ' abstract ' :   ' By   introducing   the   new   concepts   of   fuzzy     β   - covering   and   fuzzy     β   - neighborhood ,   we   define   two   new   types   of   fuzzy   covering   rough   set   models   which   can   be   regarded   as   bridges   linking   covering   rough   set   theory   and   fuzzy   rough   set   theory .   We   show   the   properties   of   the   two   models ,   and   reveal   the   relationships   between   the   two   models   and   some   others .   Moreover ,   we   present   the   matrix   representations   of   the   newly   defined   lower   and   upper   approximation   operators   so   that   the   calculation   of   lower   and   upper   approximations   of   subsets   can   be   converted   into   operations   on   matrices .   Finally ,   we   generalize   the   models   and   their   matrix   representations   to     L   - fuzzy   covering   rough   sets   which   are   defined   over   fuzzy   lattices . ' ,   ' title ' :   ' Two   fuzzy   covering   rough   set   models   and   their   generalizations   over   fuzzy   lattices ' } 
{ ' abstract ' :   ' Mobile   applications   are   becoming   complex   software   systems   that   must   be   developed   quickly   and   evolve   regularly   to   fit   new   user   requirements   and   execution   contexts .   However ,   addressing   these   constraints   may   result   in   poor   design   choices ,   known   as   antipatterns ,   which   may   degrade   software   quality   and   performance .   Thus ,   the   automatic   detection   of   antipatterns   is   an   important   activity   that   eases   the   future   maintenance   and   evolution   tasks .   Moreover ,   it   helps   developers   to   refactor   their   applications   and   thus ,   to   improve   their   quality .   While   antipatterns   are   well - known   in   object - oriented   applications ,   their   study   in   mobile   applications   is   still   in   their   infancy .   In   this   paper ,   we   presents   a   tooled   approach ,   called   P   aprika   ,   to   analyze   Android   applications   and   to   detect   object - oriented   and   Android - specific   antipatterns   from   binaries   of   applications . ' ,   ' title ' :   ' An   approach   to   detect   Android   antipatterns ' } 
{ ' abstract ' :   ' In   this   paper   we   present   a   new   method   for   object   categorization .   Firstly   an   image   representation   is   obtained   by   the   proposed   hierarchical   learning   method   consisting   of   alternating   between   local   coding   and   maximum   pooling   operations ,   where   the   local   coding   operation   induces   discrimination   while   the   image   descriptor   and   maximum   pooling   operation   induces   invariance   in   hierarchical   architecture .   Then   the   obtained   effective   image   representation   is   passed   to   a   linear   classifier   which   is   suitable   for   large   databases   for   object   categorization .   We   have   demonstrated   that   the   proposed   method   is   robust   to   image   variations   and   has   low   sample   complexity . ' ,   ' title ' :   ' Object   categorization   based   on   hierarchical   learning ' } 
{ ' abstract ' :   ' We   have   previously   proposed   a   howling   canceller   which   cancels   howling   by   using   a   cascade   notch   filter   designed   from   a   distance   between   a   loudspeaker   and   a   microphone .   This   method   utilizes   a   pilot   signal   to   estimate   the   distance .   In   this   paper ,   we   introduce   two   methods   into   the   distance - based   howling   canceller   to   improve   speech   quality .   The   first   one   is   an   adaptive   cascade   notch   filter   which   adaptively   adjusts   the   nulls   to   eliminate   howling   and   to   keep   speech   components .   The   second   one   is   a   silent   pilot   signal   whose   frequencies   exist   in   the   ultrasonic   band ,   and   it   is   inaudible   while   on   transmission .   We   implement   the   proposed   howling   canceller   on   a   DSP   to   evaluate   its   capability .   The   experimental   results   show   that   the   proposed   howling   canceller   improves   speech   quality   in   comparison   to   the   conventional   one . ' ,   ' title ' :   ' A   High   Speech   Quality   Distance - Based   Howling   Canceller   with   Adaptive   Cascade   Notch   Filter   and   Silent   Pilot   Signal ' } 
{ ' abstract ' :   ' Purpose   –   This   paper   aims   to   look   at   how   varying   terminology   is   used   on   school   library   web   sites   and   how   that   compares   to   student   preferences . Design / methodology / approach   –   Provides   research   conduced   by   surveying   practicing   school   librarians   and   k ‐ 12   students . Findings   –   Terminology   varies   greatly   on   school   library   web   sites .   Further ,   students   prefer   common   language   use . Practical   implications   –   Practicing   librarians   may   consider   revising   their   web   sites   in   order   to   make   them   more   accessible   for   their   students . Originality / value   –   This   paper   provides   original   research   into   school   library   web   sites ,   an   area   that   is   lacking . ' ,   ' title ' :   ' School   library   web   site   terminology ' } 
{ ' abstract ' :   ' Recently ,   numerous   multireceiver   identity - based   encryption   or   identity - based   broadcast   encryption   schemes   have   been   introduced   with   bilinear   pairing   and   probabilistic   map - to - point   MTP   function .   As   the   bilinear   pairing   and   MTP   functions   are   expensive   operations ,   any   cryptographic   schemes   based   on   these   operations   experience   high   computational   burden .   The   certificateless   public   key   cryptography   sidesteps   the   private   key   escrow   problem   occurring   in   identity - based   cryptosystem   and   certificate   management   troubles   of   certificate   authority - based   public   key   cryptography   CA - PKC .   We   observed   that   certificateless   multireceiver   encryption   CL - MRE   scheme   without   pairing   and   MTP   hash   function   has   not   yet   been   considered   in   the   literature .   In   this   paper ,   we   proposed   a   bilinear   pairing   and   MTP   hash - function - free   CL - MRE   scheme   with   chosen   ciphertext   attack   resilience .   The   detailed   analyses   provide   evidence   that   our   scheme   achieves   forward   secrecy ,   backward   secrecy ,   and   low   computation   costs   than   others .   The   scheme   also   provides   confidentiality   of   the   message   and   receiver   anonymity   in   the   random   oracle   model   with   the   hardness   of   computational   Diffie - Hellman   problem .   Copyright   ©   2014   John   Wiley   &   Sons ,   Ltd . ' ,   ' title ' :   ' Anonymous   and   provably   secure   certificateless   multireceiver   encryption   without   bilinear   pairing ' } 
{ ' abstract ' :   ' We   study   the   problem   of   approximating   one - dimensional   nonintegrable   codistributions   by   integrable   ones   and   apply   the   resulting   approximations   to   approximate   feedback   linearization   of   single - input   systems .   The   approach   derived   in   this   paper   allows   a   linearizable   nonlinear   system   to   be   found   that   is   close   to   the   given   system   in   a   least - squares   ( L2 )   sense .   A   linearly   controllable   single - input   affine   nonlinear   system   is   feedback   linearizable   if   and   only   if   its   characteristic   distribution   is   involutive   ( hence   integrable )   or ,   equivalently ,   any   characteristic   one - form   ( a   one - form   that   annihilates   the   characteristic   distribution )   is   integrable .   We   study   the   problem   of   finding   ( least - squares   approximate )   integrating   factors   that   make   a   fixed   characteristic   one - form   close   to   being   exact   in   anL2   sense .   A   given   one - form   can   be   decomposed   into   exact   and   inexact   parts   using   the   Hodge   decomposition .   We   derive   an   upper   bound   on   the   size   of   the   inexact   part   of   a   scaled   characteristic   one - form   and   show   that   a   least - squares   integrating   factor   provides   the   minimum   value   for   this   upper   bound .   We   also   consider   higher - order   approximate   integrating   factors   that   scale   a   nonintegrable   one - form   in   a   way   that   the   scaled   form   is   closer   to   being   integrable   inL2   together   with   some   derivatives   and   derive   similar   bounds   for   the   inexact   part .   This   allows   a   linearizable   nonlinear   system   that   is   close   to   the   given   system   in   a   least - squares   ( L2 )   sense   together   with   some   derivatives   to   be   found .   The   Sobolev   embedding   techniques   allow   us   to   obtain   an   upper   bound   on   the   uniform   ( L ∞ )   distance   between   the   nonlinear   system   and   its   linearizable   approximation . ' ,   ' title ' :   ' Least - squares   integration   of   one - dimensional   codistributions   with   application   to   approximate   feedback   linearization ' } 
{ ' abstract ' :   ' Latent   sector   errors   in   disk   drives   affect   only   a   few   data   sectors .   They   occur   silently   and   are   detected   only   when   the   affected   area   is   accessed   again .   If   a   latent   error   is   detected   while   the   storage   system   is   operating   under   reduced   redundancy ,   i . e . ,   during   a   RAID   rebuild ,   then   data   loss   may   occur .   Various   features   such   as   scrubbing   and   intra - disk   data   redundancy   are   proposed   to   detect   and / or   recover   from   latent   errors   and   avoid   data   loss .   While   such   features   enhance   data   availability   in   the   storage   system ,   their   execution   may   cause   performance   degradation .   In   this   paper ,   we   evaluate   the   effectiveness   of   scrubbing   and   intra - disk   data   redundancy   in   improving   data   availability   while   the   overall   goal   is   to   maintain   user   performance   within   predefined   bounds .   We   show   that   by   treating   them   as   low   priority   background   activities   and   scheduling   them   efficiently   during   idle   times ,   these   features   remain   performance - wise   transparent   to   the   storage   system   user   while   still   improving   data   reliability .   Detailed   trace - driven   simulations   show   that   the   mean   time   to   data   loss   ( MTTDL )   improves   by   up   to   5   orders   of   magnitude   if   these   features   are   implemented   independently .   By   scheduling   concurrently   both   scrubbing   and   intra - disk   parity   updates   during   idle   times   in   disk   drives ,   MTTDL   improves   by   as   much   as   8   orders   of   magnitude . ' ,   ' title ' :   ' Enhancing   data   availability   in   disk   drives   through   background   activities ' } 
{ ' abstract ' :   ' Financial   crisis   forecasting   has   been   a   long - standing   challenge   that   often   involves   couplings   between   indicators   of   multiple   markets .   Such   couplings   include   implicit   relations   that   might   not   be   effectively   detected   from   raw   market   observations .   However ,   most   methods   for   crisis   forecasting   rely   directly   on   market   observations   and   might   not   detect   the   hidden   interactions   between   markets .   To   this   end ,   the   authors   explore   coupled   market   state   analysis   ( CMSA ) ,   assuming   that   the   observations   of   markets   are   governed   by   a   collection   of   intra -   and   intercoupled   hidden   market   states .   Accordingly ,   they   built   a   forecaster   based   on   these   coupled   market   states   instead   of   observations . ' ,   ' title ' :   ' Financial   Crisis   Forecasting   via   Coupled   Market   State   Analysis ' } 
{ ' abstract ' :   ' In   this   paper ,   an   “ intelligent ”   isolated   intersection   control   system   was   developed .   The   developed   “ intelligent ”   system   makes   “ real   time ”   decisions   as   to   whether   to   extend   ( and   how   much )   current   green   time .   The   model   developed   is   based   on   the   combination   of   the   dynamic   programming   and   neural   networks .   Many   tests   show   that   the   outcome   ( the   extension   of   the   green   time )   of   the   proposed   neural   network   is   nearly   equal   to   the   best   solution .   Practically   negligible   CPU   times   were   achieved ,   and   were   thus   absolutely   acceptable   for   the   “ real   time ”   application   of   the   developed   algorithm . ' ,   ' title ' :   ' Dynamic   programming — neural   network   real - time   traffic   adaptive   signal   control   algorithm ' } 
{ ' abstract ' :   ' This   issue   features   expanded   versions   of   articles   selected   from   the   2014   AAAI   Conference   on   Innovative   Applications   of   Artificial   Intelligence   held   in   Quebec   City ,   Canada .   We   present   a   selection   of   four   articles   describing   deployed   applications   plus   two   more   articles   that   discuss   work   on   emerging   applications . ' ,   ' title ' :   ' Introduction   to   the   Special   Issue   on   Innovative   Applications   of   Artificial   Intelligence   2014 ' } 
{ ' abstract ' :   ' Although   frequently   used   in   fractal   compression   quadrant - based   classification   exhibits   a   significant   defect   which   has   not   been   described   in   the   literature .   We   give   an   efficient   solution   to   this   problem   by   controlling   the   class   structure   based   on   an   adaptive   threshold .   This   makes   this   classification   technique   a   very   efficient   and   competitive   one   also   for   block   matching   motion   compensation   algorithms   in   video   coding . ' ,   ' title ' :   ' Resolving   a   defect   in   quadrant - based   classification   for   fast   block - matching ' } 
{ ' abstract ' :   ' Where   there   are   infinitely   many   possible   basic   states   of   the   world ,   a   standard   probability   function   must   assign   zero   probability   to   each   state   –   since   any   finite   probability   would   sum   to   over   one .   This   generates   problems   for   any   decision   theory   that   appeals   to   expected   utility   or   related   notions .   For   it   leads   to   the   view   that   a   situation   in   which   one   wins   a   million   dollars   if   any   of   a   thousand   of   the   equally   probable   states   is   realized   has   an   expected   value   of   zero   ( since   each   such   state   has   probability   zero ) .   But   such   a   situation   dominates   the   situation   in   which   one   wins   nothing   no   matter   what   ( which   also   has   an   expected   value   of   zero ) ,   and   so   surely   is   more   desirable .   I   formulate   and   defend   some   principles   for   evaluating   options   where   standard   probability   functions   cannot   strictly   represent   probability   –   and   in   particular   for   where   there   is   an   infinitely   spread ,   uniform   distribution   of   probability .   The   principles   appeal   to   standard   probability   functions ,   but   overcome   at   least   some   of   their   limitations   in   such   cases . ' ,   ' title ' :   ' Standard   decision   theory   corrected ' } 
{ ' abstract ' :   ' Backed   by   the   European   Commission ,   a   consortium   of   partners   from   European   industry ,   financial   institutions ,   and   academia   has   embarked   on   a   research   project   to   develop   the   fundamentals   of   secure   electronic   commerce .   The   goal   of   the   9 - million   ECU   project ,   SEMPER   ( Secure   Electronic   Marketplace   for   Europe ) ,   is   to   provide   the   first   open   and   comprehensive   solutions   for   secure   commerce   over   the   Internet   and   other   public   information   networks .   We   describe   the   objectives   and   summarise   the   initial   architecture   of   SEMPER .   A   wide   range   of   businesses   are   rapidly   moving   to   explore   the   huge   potential   of   net -   worked   information   systems ,   especially   with   the   Internet - based   WWW   ( World - wide   Web ) .   The   Internet ,   which   already   connects   more   than   3   million   computers   and   a   sub -   stantially   larger   number   of   users ,   is   growing   at   a   breathtaking   pace   with   thousands   of   newcomers   every   day .   Although   the   Internet   has   its   roots   in   academia   and   is   still   domi -   nated   by   free - of - charge   information ,   dramatic   changes   are   expected   in   the   near   future .   For   instance ,   the   WWW   will   be   used   for   a   wide   variety   of   electronic   commerce   such   as   on - line   trade   or   delivery   of   advanced   multimedia   information   services .   The   evolution   of   broadband   networks   and   " information   highways "   will   intensify   this   trend .   The   need   for   secure   transactions   in   this   new   business   environment ,   which   involves   networks   available   to   the   general   public ,   has   triggered   a   number   of   related   efforts .   These   initial   developments   are   based   almost   exclusively   in   the   US   and   most   of   them   are   limited   to   proprietary ,   or   otherwise   closed   solutions ,   involving   only   electronic   payment   issues .   In   contrast ,   SEMPER   is   directed   towards   a   comprehensive   solution   for   secure   electronic   commerce ,   considering   legal ,   commercial ,   social ,   and   technical   requirements   as   well   as   different   options   for   an   electronic   marketplace . ' ,   ' title ' :   ' Development   of   a   Secure   Electronic   Marketplace   for   Europe ' } 
{ ' abstract ' :   ' Through   the   use   of   a   global   geometric   symmetry ,   detection   ellipses   are   proposed   in   this   paper .   Based   on   the   geometric   symmetry ,   the   proposed   method   first   locates   candidates   of   ellipses   centers .   In   the   meantime ,   according   to   these   candidate   centers ,   all   feature   points   in   an   input   image   are   grouped   into   several   subimages .   Then ,   for   each   subimage ,   by   using   geometric   properties   again ,   all   ellipses   are   extracted .   The   method   significantly   reduces   the   time   required   to   evaluate   all   possible   parameters   without   using   edge   direction   information .   Experimental   results   are   given   to   show   the   correctness   and   effectiveness   of   the   proposed   method . ' ,   ' title ' :   ' Detection   ellipses   by   finding   lines   of   symmetry   in   the   images   via   an   hough   transform   applied   to   straight   lines ' } 
{ ' abstract ' :   ' Automatic   crawling   of   Rich   Internet   Applications   ( RIAs )   is   a   challenge   because   client - side   code   modifies   the   client   dynamically ,   fetch -   ing   server - side   data   asynchronously .   Most   existing   solutions   model   RIAs   as   state   machines   with   DOMs   as   states   and   JavaScript   events   execution   as   transitions .   This   approach   fails   when   used   with   " real - life " ,   complex   RIAs ,   because   the   size   of   the   produced   model   is   much   too   large   to   be   practical .   In   this   paper ,   we   propose   a   new   method   to   crawl   AJAX - based   RIAs   in   an   efficient   manner   by   detecting   " components " ,   which   are   areas   of   the   DOM   that   are   independent   from   each   other ,   and   by   crawling   each   component   separately .   This   leads   to   a   dramatic   reduction   of   the   required   state   space   for   the   model ,   without   loss   of   content   coverage .   Our   method   does   not   require   prior   knowledge   of   the   RIA   nor   predefined   definition   of   components .   Instead ,   we   infer   the   components   by   observing   the   be -   havior   of   the   RIA   during   crawling .   Our   experimental   results   show   that   our   method   can   index   quickly   and   completely   industrial   RIAs   that   are   simply   out   of   reach   for   traditional   methods . ' ,   ' title ' :   ' Indexing   Rich   Internet   Applications   Using   Components - Based   Crawling ' } 
{ ' abstract ' :   ' One   important   aspect   of   constructing   an   overlay   network   is   how   to   exploit   network   locality   in   the   underlying   network .   In   this   paper ,   we   propose   a   scalable   protocol   for   constructing   an   overlay   network   that   takes   account   of   locality   of   network   hosts .   The   constructed   overlay   network   can   significantly   decrease   the   communication   cost   between   end - hosts .   Our   simulation   results   show   that   the   average   distance   between   a   pair   of   hosts   in   the   constructed   overlay   network   is   only   about   11%   of   the   one   in   a   traditional ,   randomly   connected   overlay   network .   Furthermore ,   our   proposed   overlay   considered   to   be   more   scalable   than   tree - based   or   mesh - based   overlays . ' ,   ' title ' :   ' Measurement - based   construction   of   locality - aware   overlay   networks ' } 
{ ' abstract ' :   ' This   paper   presents   a   low   cost ,   flexible   and   customizable   delay   measurement   system   developed   to   assess   the   performance   of   the   VTPE - hBEB   protocol .   The   proposed   system   can   be   used   to   evaluate   other   communication   protocols   as   well   as   to   measure   the   delay   between   two   repetitive   events . ' ,   ' title ' :   ' Delay   measurement   system   for   real - time   serial   data   streams ' } 
{ ' abstract ' :   " Service   robots   have   become   increasingly   important   subjects   in   our   lives .   However ,   they   are   still   facing   problems   like   adaptability   to   their   users .   While   major   work   has   focused   on   intelligent   service   robots ,   the   proposed   approaches   were   mostly   user   independent .   Our   work   is   part   of   the   FUI - RoboPopuli   project ,   which   concentrates   on   endowing   entertainment   companion   robots   with   adaptive   and   social   behaviour .   In   particular ,   we   are   interested   in   robots   that   are   able   to   learn   and   plan   so   that   they   adapt   and   personalize   their   behaviour   according   to   their   users .   Markov   Decision   Processes   ( MDPs )   are   largely   used   for   adaptive   robots   applications .   However ,   one   challenging   point   is   reducing   the   sample   complexity   required   to   learn   an   MDP   model ,   including   the   reward   function .   In   this   article ,   we   present   our   contribution   regarding   the   representation   and   the   learning   of   the   reward   function   through   analysing   interaction   traces   ( i . e .   the   interaction   history   between   the   robot   and   their   users ,   including   users '   feedback ) .   Our   approach   permits   to   generalise   the   learned   rewards   so   that   when   new   users   are   introduced ,   the   robot   may   quickly   adapt   using   what   it   learned   from   previous   experiences   with   other   users .   We   propose ,   in   this   article ,   two   algorithms   to   learn   the   reward   function .   The   first   is   direct   and   certain ,   the   robot   applies   with   a   user   what   it   learned   during   interaction   with   same   kind   of   users   ( i . e .   users   with   similar   profiles ) .   The   second   algorithm   generalises   what   it   learns   to   be   applied   to   all   kinds   of   users .   Through   simulation ,   we   show   that   the   generalised   algorithm   converges   to   an   optimal   reward   function   with   less   than   half   the   samples   needed   by   the   direct   algorithm . " ,   ' title ' :   " Adaptive   and   Personalised   Robots   -   Learning   from   Users '   Feedback " } 
{ ' abstract ' :   " Researches   of   sensor   networks   collecting   patients '   data   with   computerized   triage   tags ,   called   Triage   Network ,   are   attracting   attention .   The   listening   power   used   in   triage   tags   is   the   major   factor   of   lots   of   energy   consumption ,   and   consumption   of   energy   increases   when   sensor   nodes   always   communicate   with   other   nodes   in   active   state .   Hence ,   we   suppose   that   sensor   nodes   are   put   to   sleep   periodically   to   avoid   running   out   of   battery .   However ,   some   nodes   have   mobility   and   nodes   secede   from   the   network   according   to   patients   conditions   in   Triage   Network .   The   paths   are   failed   and   it   is   needed   to   reconstruct   paths   when   these   forwarding   nodes   move   or   secede   from   network .   Therefore ,   data   arrival   ratio   decreases   and   consumption   of   battery   increases   due   to   reconstruction   of   other   paths .   In   this   paper ,   we   propose   a   data   collection   method   using   two   types   of   forwarding   nodes ,   Stable   Nodes   and   Energy   Efficient   Nodes .   This   method   uses   two   types   of   forwarding   nodes   according   to   priority   of   data   and   avoids   loss   of   high   priority   data ,   improves   the   data   arrival   ratio   and   saves   the   energy   consumption .   We   evaluate   the   proposed   method   and   show   its   effectiveness   using   computer   simulations . " ,   ' title ' :   ' Data   collection   method   using   two   types   of   forwarding   nodes   for   energy   saving   in   triage   network ' } 
{ ' abstract ' :   ' This   paper   introduces   Golay - paired   Hadamard   matrices   for   fast   compressed   sensing   of   sparse   signals   in   the   time   or   spectral   domain .   These   sampling   operators   feature   low - memory   requirement ,   hardware - friendly   implementation   and   fast   computation   in   reconstruction .   We   show   that   they   require   a   nearly   optimal   number   of   measurements   for   faithful   reconstruction   of   a   sparse   signal   in   the   time   or   frequency   domain .   Simulation   results   demonstrate   that   the   proposed   sensing   matrices   offer   a   reconstruction   performance   similar   to   that   of   fully   random   matrices . ' ,   ' title ' :   ' Golay   meets   Hadamard :   Golay - paired   Hadamard   matrices   for   fast   compressed   sensing ' } 
{ ' abstract ' :   ' In   this   technical   note ,   the   problem   of   finite - time   output   regulation   control   for   a   class   of   disturbed   system   under   mismatching   condition   is   investigated   via   a   composite   control   design   manner .   The   composite   controller   is   developed   by   using   a   finite   time   control   technique   and   a   finite   time   disturbance   observer   ( FTDO ) .   A   key   idea   is   to   design   virtual   control   laws   based   on   estimation   values   of   the   disturbances   and   the   ith   ( 1 ≤ i ≤ n - 1   where   n   is   the   order   of   the   system )   order   derivative   of   disturbances .   Finite   time   stability   analysis   for   the   augmented   system   is   presented   by   means   of   Lyapunov   stability   theorems ,   which   shows   that   the   system   output   is   regulated   to   zero   in   finite   time   even   in   the   presence   of   mismatched   disturbances .   A   motion   control   application   demonstrates   the   effectiveness   and   attractive   properties   of   the   proposed   method . ' ,   ' title ' :   ' Continuous   Finite - Time   Output   Regulation   for   Disturbed   Systems   Under   Mismatching   Condition ' } 
{ ' abstract ' :   ' In   this   paper   we   propose   an   approach   for   enhanced   data   protection   in   the   cloud ,   based   upon   accountability   governance .   Specifically ,   the   relationships   between   accountability ,   risk   and   trust   are   analyzed   in   order   to   suggest   characteristics   and   means   to   address   data   governance   issues   involved   when   organizations   or   individuals   adopt   cloud   computing .   This   analysis   takes   into   account   insights   from   a   variety   of   stakeholders   within   cloud   ecosystems   obtained   by   running   an   elicitation   workshop . ' ,   ' title ' :   ' Accountability ,   Risk ,   and   Trust   in   Cloud   Services :   Towards   an   Accountability - Based   Approach   to   Risk   and   Trust   Governance ' } 
{ ' abstract ' :   ' Xue   et   al .   recently   proposed   an   innovative   mutual   authentication   and   key   agreement   scheme   for   wireless   sensor   networks   based   on   temporal   credential   using   smart   cards .   However ,   in   this   paper   we   demonstrate   that   their   scheme   is   vulnerable   to   password   guessing   attacks ,   node   capture   attacks   and   denial - of - service   attacks .   Furthermore   we   show   that   their   scheme   has   some   inconsistencies   which   make   it   less   secure   and   more   computationally   costly   than   originally   presented . ' ,   ' title ' :   ' Notes   on   A   Temporal - Credential - Based   Mutual   Authentication   and   Key   Agreement   Scheme   for   Wireless   Sensor   Networks ' } 
{ ' abstract ' :   ' Persistent   Scatterer   Interferometry   ( PSI )   has   been   widely   used   for   landslide   studies   in   recent   years .   This   paper   investigated   the   spatial   patterns   of   PSI   point   targets   and   landslide   occurrences   in   the   Arno   River   basin   in   Central   Italy .   The   main   purpose   is   to   analyze   whether   spatial   patterns   of   Persistent   Scatterers   ( PS )   can   be   recognized   as   indicators   of   landslide   occurrences   throughout   the   whole   basin .   The   bivariate   K - function   was   employed   to   assess   spatial   relationships   between   PS   and   landslides .   The   PSI   point   targets   were   acquired   from   almost   4   years   ( from   March   2003   to   January   2007 )   of   RADARSAT - 1   images .   The   landslide   inventory   was   collected   from   15   years   ( from     1992 – 2007 )   of   surveying   and   mapping   data ,   mainly   including   remote   sensing   data ,   topographic   maps   and   field   investigations .   The   proposed   approach   is   able   to   assess   spatial   patterns   between   a   variety   of   PS   and   landslides ,   in   particular ,   to   understand   if   PSI   point   targets   are   spatially   clustered   ( spatial   attraction )   or   randomly   distributed   ( spatial   independency )   on   various   types   of   landslides   across   the   basin .   Additionally ,   the   degree   and   scale   distances   of   PS   clustering   on   a   variety   of   landslides   can   be   characterized .   The   results   rejected   the   null   hypothesis   that   PSI   point   targets   appear   to   cluster   similarly   on   four   types   of   landslides   ( slides ,   flows ,   falls   and   creeps )   in   the   Arno   River   basin .   Significant   influence   of   PS   velocities   and   acquisition   orbits   can   be   noticed   on   detecting   landslides   with   different   states   of   activities .   Despite   that   the   assessment   may   be   influenced   by   the   quality   of   landslide   inventory   and   Synthetic   Aperture   Radar   ( SAR )   images ,   the   proposed   approach   is   expected   to   provide   guidelines   for   studies   trying   to   detect   and   investigate   landslide   occurrences   at   a   regional   scale   through   spatial   statistical   analysis   of   PS ,   for   which   an   advanced   understanding   of   the   impact   of   scale   distances   on   landslide   clustering   is   fundamentally   needed . ' ,   ' title ' :   ' Investigating   Spatial   Patterns   of   Persistent   Scatterer   Interferometry   Point   Targets   and   Landslide   Occurrences   in   the   Arno   River   Basin ' } 
{ ' abstract ' :   ' This   article   describes   a   middleware   used   in   display   cluster   of   real   time   visual   simulation   system .   This   middleware   which   based   on   TCP / IP   protocol   provides   the   communication   infrastructure   for   visual   simulation   system .   It   provides   unified   process   logic   and   interfaces   for   various   status   and   frame   data   and   the   packing / unpacking   functions   of   simulation   data   without   concerning   the   details   of   the   data .   We   found   two   classes   of   display   synchronization   problems   and   provided   the   resolution   of   them .   The   middleware   provides   a   group   of   APIs   which   hide   the   details   of   data   packing / unpacking ,   processing   and   transmission   and   meets   the   requirement   of   flexibility ,   efficiency   and   extensibility .   This   middleware   has   been   successfully   implemented   to   the   display   cluster   of   several   tower   simulation   system . ' ,   ' title ' :   ' The   Research   of   High   Level   Data   Communication   Middleware   of   Display   Cluster   Used   in   Real   Time   Simulation   Environment ' } 
{ ' abstract ' :   ' The   scattering   parameters   are   fundamental   in   the   characterization   of   electrical   devices   at   high   frequencies .   They   are   particularly   useful   for   analyzing   multiport   high - frequency   and   microwave   networks .   However ,   they   are   not   adequately   presented   in   most ,   if   not   all ,   microwave   engineering   books .   This   paper   identifies   two   common   deficiencies   in   the   way   scattering   parameters   are   being   presented   in   these   books .   It   provides   additional   information   that   should   supplement   those   books   or   book   chapters   on   scattering   parameters . ' ,   ' title ' :   ' Deficiencies   in   the   way   scattering   parameters   are   taught ' } 
{ ' abstract ' :   ' We   study   the   reliability   maximization   problem   in   WDM   networks   with   random   link   failures .   Reliability   in   these   networks   is   defined   as   the   probability   that   the   logical   network   is   connected ,   and   it   is   determined   by   the   underlying   lightpath   routing   and   the   link   failure   probability .   We   show   that   in   general   the   optimal   lightpath   routing   depends   on   the   link   failure   probability ,   and   characterize   the   properties   of   lightpath   routings   that   maximize   the   reliability   in   different   failure   probability   regimes .   In   particular ,   we   show   that   in   the   low   failure   probability   regime ,   maximizing   the   ` ` cross - layer "   min   cut   of   the   ( layered )   network   maximizes   reliability ,   whereas   in   the   high   failure   probability   regime ,   minimizing   the   spanning   tree   of   the   network   maximizes   reliability .   Motivated   by   these   results ,   we   develop   lightpath   routing   algorithms   for   reliability   maximization . ' ,   ' title ' :   ' Maximizing   Reliability   in   WDM   Networks   through   Lightpath   Routing ' } 
{ ' abstract ' :   ' The   slope   of   the   active   distances   is   an   important   parameter   when   investigating   the   error - correcting   capability   of   convolutional   codes   and   the   distance   behavior   of   concatenated   convolutional   codes .   The   slope   of   the   active   distances   is   equal   to   the   minimum   average   weight   cycle   in   the   state - transition   diagram   of   the   encoder .   A   general   upper   bound   on   the   slope   depending   on   the   free   distance   of   the   convolutional   code   and   new   upper   bounds   on   the   slope   of   special   classes   of   binary   convolutional   codes   are   derived .   Moreover ,   a   search   technique ,   resulting   in   new   tables   of   rate   R = 1 / 2   and   rate   R = 1 / 3   convolutional   encoders   with   high   memories   and   large   active   distance - slopes   is   presented .   Furthermore ,   we   show   that   convolutional   codes   with   large   slopes   can   be   used   to   obtain   new   tailbiting   block   codes   with   large   minimum   distances .   Tables   of   rate   R = 1 / 2   and   rate   R = 1 / 3   tailbiting   codes   with   larger   minimum   distances   than   the   best   previously   known   quasi - cyclic   codes   are   given .   Two   new   tailbiting   codes   also   have   larger   minimum   distances   than   the   best   previously   known   binary   linear   block   codes   with   same   size   and   length .   One   of   them   is   also   superior   in   terms   of   minimum   distance   to   any   previously   known   binary   nonlinear   block   code   with   the   same   set   of   parameters . ' ,   ' title ' :   ' Tailbiting   codes   obtained   via   convolutional   codes   with   large   active   distance - slopes ' } 
{ ' abstract ' :   ' MIMO   wireless   technology   is   required   to   increase   the   data   rates   for   a   broad   range   of   applications ,   including   low   cost   mobile   devices .   In   this   paper   we   present   a   very   low   area   reconfigurable   MIMO   detector   which   achieves   a   high   throughput   of   103Mbps   and   uses   27   Kilo   Gates   when   implemented   in   a   commercial   180nm   CMOS   process .   The   low   area   is   achieved   by   the   proposed   in - place   architecture .   This   architecture   implements   the   K - best   algorithm   and   reduces   area   4 - fold   compared   to   the   widely   used   multi - stage   architecture ,   while   provides   reconfigurability   in   terms   of   antenna   configuration   during   real - time   operation . ' ,   ' title ' :   ' A   low - area   flexible   MIMO   detector   for   WiFi / WiMAX   standards ' } 
{ ' abstract ' :   ' Because   human   cognition   is   creative   and   socially   situated ,   knowledge   accumulates ,   diffuses ,   and   gets   applied   in   new   contexts ,   generating   cultural   analogs   of   phenomena   observed   in   population   genetics   such   as   adaptation   and   drift .   It   is   therefore   commonly   thought   that   elements   of   culture   evolve   through   natural   selection .   However ,   natural   selection   was   proposed   to   explain   how   change   accumulates   despite   lack   of   inheritance   of   acquired   traits ,   as   occurs   with   template - mediated   replication .   It   cannot   accommodate   a   process   with   significant   retention   of   acquired   or   horizontally   ( e . g .   socially )   transmitted   traits .   Moreover ,   elements   of   culture   cannot   be   treated   as   discrete   lineages   because   they   constantly   interact   and   influence   one   another .   It   is   proposed   that   what   evolves   through   culture   is   the   mind ;   ideas   and   artifacts   are   merely   reflections   of   its   current   evolved   state .   Interacting   minds   transform   ( in   part )   through   a   non - Darwinian   autopoietic   process   similar   to   that   by   which   early   life   evolved ,   involving   not   survival   of   the   fittest   but   actualization   of   their   potential . ' ,   ' title ' :   ' The   cultural   evolution   of   socially   situated   cognition ' } 
{ ' abstract ' :   ' Event   Extraction   is   a   complex   and   interesting   topic   in   Information   Extraction   that   includes   event   extraction   methods   from   free   text   or   web   data .   The   result   of   event   extraction   systems   can   be   used   in   several   fields   such   as   risk   analysis   systems ,   online   monitoring   systems   or   decide   support   tools .   In   this   paper ,   we   introduce   a   method   that   combines   lexico   - -   semantic   and   machine   learning   to   extract   event   from   Vietnamese   news .   Furthermore ,   we   concentrate   to   describe   event   online   monitoring   system   named   VnLoc   based   on   the   method   that   was   proposed   above   to   extract   event   in   Vietnamese   language .   Besides ,   in   experiment   phase ,   we   have   evaluated   this   method   based   on   precision ,   recall   and   F1   measure .   At   this   time   of   experiment ,   we   on   investigated   on   three   types   of   event :   FIRE ,   CRIME   and   TRANSPORT   ACCIDENT . ' ,   ' title ' :   ' VnLoc :   A   Real   - -   Time   News   Event   Extraction   Framework   for   Vietnamese ' } 
{ ' abstract ' :   ' Reliability   analysis   using   error   probabilities   for   combinational   logic   circuits   has   been   investigated   widely   in   the   literature .   Reliability   analysis   for   sequential   logic   circuits   using   these   methods   would   be   inaccurate   because   of   existence   of   loops   in   their   architecture .   In   this   paper   a   new   method   based   on   conversion   of   sequential   circuit   to   combinational   one   and   applying   an   iterative   reliability   analysis   is   developed .   A   Monte   Carlo   method - based   reliability   analysis   is   introduced   for   sequential   circuits ,   which   is   used   for   first   method   validation .   Experimental   results   demonstrate   good   accuracy   of   the   method . ' ,   ' title ' :   ' SEQUENTIAL   LOGIC   CIRCUITS   RELIABILITY   ANALYSIS ' } 
{ ' abstract ' :   ' According   to   the   Journey   to   Crime   theory ,   offenders   have   a   directionality   preference ,   in   the   form   of   an   activity   path ,   when   they   are   moving   about   in   their   environment   in   search   for   criminal   activities .   Using   clustering   techniques ,   this   theory   is   tested   using   crime   data   for   the   Province   of   British   Columbia ,   Canada .   The   activities   of   57 , 962   offenders   who   were   either   charged ,   chargeable ,   or   for   whom   charges   were   recommended   were   analyzed   by   mapping   their   offense   locations   with   respect   to   their   home   locations   to   determine   directionality .   Once   directionality   was   established ,   a   unique   clustering   technique ,   based   on   K - Means   clustering   and   modified   for   angles ,   was   applied   to   find   the   number   of   activity   paths   for   each   offender .   Although   the   number   of   activity   paths   varies   from   individual   to   individual ,   the   aggregate   pattern   was   very   consistent   with   theory .   It   was   found   that   people   only   have   a   few   activity   paths ,   even   if   they   are   highly   prolific   offenders . ' ,   ' title ' :   ' How   Many   Ways   Do   Offenders   Travel   - -   Evaluating   the   Activity   Paths   of   Offenders ' } 
{ ' abstract ' :   ' Pulse   Coupled   Neural   Network ( PCNN )   is   widely   used   in   the   field   of   image   processing ,   but   it   is   a   difficult   task   to   define   the   relative   parameters   properly   in   the   research   of   the   applications   of   PCNN .   So   far   the   determination   of   parameters   of   its   model   needs   a   lot   of   experiments .   To   deal   with   the   above   problem ,   a   document   segmentation   based   on   the   improved   PCNN   is   proposed .   It   uses   the   maximum   entropy   function   as   the   fitness   function   of   bacterial   foraging   optimization   algorithm ,   adopts   bacterial   foraging   optimization   algorithm   to   search   the   optimal   parameters ,   and   eliminates   the   trouble   of   manually   set   the   experiment   parameters .   Experimental   results   show   that   the   proposed   algorithm   can   effectively   complete   document   segmentation .   And   result   of   the   segmentation   is   better   than   the   contrast   algorithms .   ©   ( 2014 )   COPYRIGHT   Society   of   Photo - Optical   Instrumentation   Engineers   ( SPIE ) .   Downloading   of   the   abstract   is   permitted   for   personal   use   only . ' ,   ' title ' :   ' PCNN   document   segmentation   method   based   on   bacterial   foraging   optimization   algorithm ' } 
{ ' abstract ' :   ' Undirected   graphical   models   encode   in   a   graph   G   the   dependency   structure   of   a   random   vector   Y .   In   many   applications ,   it   is   of   interest   to   model   Y   given   another   random   vector   X   as   input .   We   refer   to   the   problem   of   estimating   the   graph   G ( x )   of   Y   conditioned   on   X   =   x   as   " graph - valued   regression " .   In   this   paper ,   we   propose   a   semiparametric   method   for   estimating   G ( x )   that   builds   a   tree   on   the   X   space   just   as   in   CART   ( classification   and   regression   trees ) ,   but   at   each   leaf   of   the   tree   estimates   a   graph .   We   call   the   method   " Graph - optimized   CART " ,   or   Go - CART .   We   study   the   theoretical   properties   of   Go - CART   using   dyadic   partitioning   trees ,   establishing   oracle   inequalities   on   risk   minimization   and   tree   partition   consistency .   We   also   demonstrate   the   application   of   Go - CART   to   a   meteorological   dataset ,   showing   how   graph - valued   regression   can   provide   a   useful   tool   for   analyzing   complex   data . ' ,   ' title ' :   ' Graph - Valued   Regression ' } 
{ ' abstract ' :   ' Over   the   last   two   decades ,   doubts   have   been   expressed   about   the   adequacy   of   materialism   as   the   correct   framework   for   explaining   phenomenal   consciousness   ( the   experience   of   saturated   greenness   one   has   when   looking   at   a   lush   lawn ,   for   example ) .   This   paper   reconstructs   a   generic   form   of   the   various   arguments   that   have   been   used   to   defend   the   view   of   the   materialistically   inexplicable   nature   of   consciousness   ( MINC ) .   This   reconstruction   reveals   that   the   arguments   turn   on   an   impoverished   notion   of   explanation .   By   discussing   some   examples   from   the   history   of   science ,   the   paper   shows   that   a   reasonable   notion   of   explanation   has   to   be   wider   than   the   one   utilized   in   the   argument   for   MINC ,   which   opens   the   possibility   for   the   materialistic   explicability   of   consciousness .   The   author   ends   the   paper   by   raising   a   question   about   the   very   intelligibility   of   the   project   of   trying   to   explain   the   so - called   nature   of   consciousness   as   opposed   to   the   regularities   characteristic   of   the   relation   between   states   of   consciousness   and   ... ' ,   ' title ' :   ' On   explaining   phenomenal   consciousness ' } 
{ ' abstract ' :   ' Successful   replication   within   an   infected   host   and   successful   transmission   between   hosts   are   key   to   the   continued   spread   of   most   pathogens .   Competing   selection   pressures   exerted   at   these   different   scales   can   lead   to   evolutionary   trade - offs   between   the   determinants   of   fitness   within   and   between   hosts .   Here ,   we   examine   such   a   trade - off   in   the   context   of   influenza   A   viruses   and   the   differential   pressures   exerted   by   temperature - dependent   virus   persistence .   For   a   panel   of   avian   influenza   A   virus   strains ,   we   find   evidence   for   a   trade - off   between   the   persistence   at   high   versus   low   temperatures .   Combining   a   within - host   model   of   influenza   infection   dynamics   with   a   between - host   transmission   model ,   we   study   how   such   a   trade - off   affects   virus   fitness   on   the   host   population   level .   We   show   that   conclusions   regarding   overall   fitness   are   affected   by   the   type   of   link   assumed   between   the   within -   and   between - host   levels   and   the   main   route   of   transmission   ( direct   or   environmental ) .   The   relative   importance   of   virulence   and   immune   response   mediated   virus   clearance   are   also   found   to   influence   the   fitness   impacts   of   virus   persistence   at   low   versus   high   temperatures .   Based   on   our   results ,   we   predict   that   if   transmission   occurs   mainly   directly   and   scales   linearly   with   virus   load ,   and   virulence   or   immune   responses   are   negligible ,   the   evolutionary   pressure   for   influenza   viruses   to   evolve   toward   good   persistence   at   high   within - host   temperatures   dominates .   For   all   other   scenarios ,   influenza   viruses   with   good   environmental   persistence   at   low   temperatures   seem   to   be   favored . ' ,   ' title ' :   ' A   Multi - scale   Analysis   of   Influenza   A   Virus   Fitness   Trade - offs   due   to   Temperature - dependent   Virus   Persistence ' } 
{ ' abstract ' :   ' Peer - to - Peer   ( P2P )   networks   are   largely   used   for   file - sharing   and   hence   must   provide   efficient   mechanisms   for   searching   the   files   stored   at   various   nodes .   The   existing   structuredP2P   overlays   support   only   ” exact - match ”   look - up   which   is   hardly   sufficient   in   a   file   sharing   network .   This   paper   addresses   the   problem   of   keyword - based   search   in   structured   P2P   networks .   We   propose   a   new   keyword - based   searching   algorithm   which   can   be   implemented   on   top   of   any   structured   P2P   overlay .   We   demonstrate   that   the   proposed   algorithm   achieves   very   good   searching   results   as   it   requires   the   minimum   number   of   messages   to   be   sent   in   order   to   find   all   the   references   to   files   containing   at   least   the   given   set   of   keywords . ' ,   ' title ' :   ' A   Keyword   Search   Algorithm   for   Structured   Peer - to - Peer   Networks ' } 
{ ' abstract ' :   ' In   this   paper ,   we   propose   an   adaptive   power   allocation   method   for   hybrid   relay   systems   that   employ   the   amplify - and - forward   and   decode - and - forward   protocols   simultaneously .   The   total   transmission   power   is   analytically   allocated   to   a   source   and   two   selected   relays   by   the   proposed   power   allocation   criterion   to   maximize   the   overall   received   signal - to - noise   ratio   at   the   destination .   Simulation   results   show   that   the   proposed   scheme   achieves   better   performance   than   that   of   conventional   cooperative   schemes   or   hybrid   systems   with   equal   power   allocation . ' ,   ' title ' :   ' Adaptive   relay   selection   and   power   allocation   for   hybrid   relay   systems ' } 
{ ' abstract ' :   ' The   unitary   rotation   of   square - pixellated   images   is   based   on   the   finite   su ( 2 ) - oscillator   model ,   which   describes   systems   whose   values   for   position ,   momentum   and   energy ,   are   discrete   and   finite .   In   a   two - dimensional   position   space ,   this   allows   the   construction   of   angular   momentum   states ,   orthonormal   and   complete ,   for   which   rotations   are   defined   as   multiplication   by   phases   that   carry   the   rotation   angle .   The   decomposition   of   a   digital   square   images   in   terms   of   these   angular   momentum   states   determines   a   unitary   ( hence   invertible )   rotation   of   the   image ,   whose   kernel   can   be   computed   as   a   four - dimensional   array   of   real   numbers . ' ,   ' title ' :   ' Unitary   rotation   of   square - pixellated   images ' } 
{ ' abstract ' :   ' As   more   mobile   storage   devices   are   used   in   consumer   electronics ,   possibility   of   user   confidential   data   leakage   increases .   To   make   things   worse ,   data   of   deleted   file   in   mobile   storage   such   as   USB   drives   can   be   easily   recovered   and ,   thus ,   can   be   vulnerable   to   data   leakage .   To   prevent   this   type   of   data   leakage ,   efficient   secure   deletion   techniques   are   required   and   we   present   two   secure   deletion   techniques ,   namely   block   cleaning   and   zero   overwriting ,   for   flash   memory   storage .   Also ,   we   propose   cost   and   benefit   models   of   both   techniques .   The   models   imply   an   existence   of   an   efficient   adaptive   hybrid   secure   deletion   scheme   that   applies   one   of   the   techniques   based   on   their   costs   and   benefits   at   given   data   arrangements .   Experimental   results   measured   on   an   embedded   board   show   that   the   adaptive   hybrid   scheme   deletes   data   securely   and   efficiently   for   various   data   patterns   on   flash   memory   storage . ' ,   ' title ' :   ' Models   and   Design   of   an   Adaptive   Hybrid   Scheme   for   Secure   Deletion   of   Data   in   Consumer   Electronics ' } 
{ ' abstract ' :   ' In   heterogeneous   and   dynamic   environments ,   efficient   execution   of   parallel   computations   can   require   mappings   of   tasks   to   processors   whose   performance   is   both   irregular   ( because   of   heterogeneity )   and   time - varying   ( because   of   dynamicity ) .   While   adaptive   domain   decomposition   techniques   have   been   used   to   address   heterogeneous   resource   capabilities ,   temporal   variations   in   those   capabilities   have   seldom   been   considered .   We   propose   a   conservative   scheduling   policy   that   uses   information   about   expected   future   variance   in   resource   capabilities   to   produce   more   efficient   data   mapping   decisions .   We   first   present   techniques ,   based   on   time   series   predictors   that   we   developed   in   previous   work ,   for   predicting   CPU   load   at   some   future   time   point ,   average   CPU   load   for   some   future   time   interval ,   and   variation   of   CPU   load   over   some   future   time   interval .   We   then   present   a   family   of   stochastic   scheduling   algorithms   that   exploit   such   predictions   of   future   availability   and   variability   when   making   data   mapping   decisions .   Finally ,   we   describe   experiments   in   which   we   apply   our   techniques   to   an   astrophysics   application .   The   results   of   these   experiments   demonstrate   that   conservative   scheduling   can   produce   execution   times   that   are   both   significantly   faster   and   less   variable   than   other   techniques . ' ,   ' title ' :   ' Conservative   Scheduling :   Using   Predicted   Variance   to   Improve   Scheduling   Decisions   in   Dynamic   Environments ' } 
{ ' abstract ' :   ' We   consider   a   class   of   restless   multi - armed   bandit   problems   that   arises   in   multi - channel   opportunistic   communications ,   where   channels   are   modeled   as   independent   and   stochastically   identical   Gilbert - Elliot   channels   and   channel   state   observations   are   subject   to   errors .   We   show   that   the   myopic   channel   selection   policy   has   a   semi - universal   structure   that   obviates   the   need   to   know   the   Markovian   transition   probabilities   of   the   channel   states .   Based   on   this   structure ,   we   establish   closed - form   lower   and   upper   bounds   on   the   steady - state   throughput   achieved   by   the   myopic   policy .   Furthermore ,   we   characterize   the   approximation   factor   of   the   myopic   policy   to   bound   its   worst - case   performance   loss   with   respect   to   the   optimal   performance . ' ,   ' title ' :   ' On   the   myopic   policy   for   a   class   of   restless   bandit   problems   with   applications   in   dynamic   multichannel   access ' } 
{ ' abstract ' :   ' We   show   that   the   optimum   length - / spl   nu /   guard   sequence   for   block   transmission   over   a   linear   Gaussian - noise   dispersive   channel   with   memory   / spl   nu /   is   a   linear   combination   of   the   N   information   symbols   of   the   block .   A   closed - form   expression   for   the   optimum   guard   sequence   is   derived   subject   to   a   total   average   energy   constraint   on   the   information   and   guard   symbols .   The   achievable   channel   block   throughput   with   the   optimum   guard   sequence   is   compared   with   that   achievable   with   two   common   guard   sequence   types ,   namely   zero   stuffing   and   cyclic   prefix . ' ,   ' title ' :   ' Guard   sequence   optimization   for   block   transmission   over   linear   frequency - selective   channels ' } 
{ ' abstract ' :   " A   modular   program   analysis   considers   components   independently   and   provides   a   succinct   summary   for   each   component ,   which   is   used   when   checking   the   rest   of   the   system .   Consider   a   system   consisting   of   a   library   and   a   client .   A   temporal   summary ,   or     interface   ,   of   the   library   specifies   legal   sequences   of   library   calls .   The   interface   is     safe     if   no   call   sequence   violates   the   library ' s   internal   invariants ;   the   interface   is     permissive     if   it   contains   every   such   sequence .   Modular   program   analysis   requires     full     interfaces ,   which   are   both   safe   and   permissive :   the   client   does   not   cause   errors   in   the   library   if   and   only   if   it   makes   only   sequences   of   library   calls   that   are   allowed   by   the   full   interface   of   the   library . Previous   interface - based   methods   have   focused   on   safe   interfaces ,   which   may   be   too   restrictive   and   thus   reject   good   clients .   We   present   an   algorithm   for   automatically   synthesizing   software   interfaces   that   are   both   safe   and   permissive .   The   algorithm   generates   interfaces   as   graphs   whose   vertices   are   labeled   with   predicates   over   the   library ' s   internal   state ,   and   whose   edges   are   labeled   with   library   calls .   The   interface   state   is   refined   incrementally   until   the   full   interface   is   constructed .   In   other   words ,   the   algorithm   automatically   synthesizes   a   typestate   system   for   the   library ,   against   which   any   client   can   be   checked   for   compatibility .   We   present   an   implementation   of   the   algorithm   which   is   based   on   the   BLAST   model   checker ,   and   we   evaluate   some   case   studies . " ,   ' title ' :   ' Permissive   interfaces ' } 
{ ' abstract ' :   ' In   this   paper ,   we   propose   a   new   method   for   the   motion   planning   problem   of   rigid   object   dexterous   manipulation   with   a   robotic   multi - fingered   hand ,   under   quasi - static   movement   assumption .   This   method   computes   both   object   and   finger   trajectories   as   well   as   the   finger   relocation   sequence .   Its   specificity   is   to   use   a   special   structuring   of   the   research   space   that   allows   to   search   for   paths   directly   in   the   particular   subspace   GS   n     which   is   the   subspace   of   all   the   grasps   that   can   be   achieved   with   n   grasping   fingers .   The   solving   of   the   dexterous   manipulation   planning   problem   is   based   upon   the   exploration   of   this   subspace .   The   proposed   approach   captures   the   connectivity   of   GS   n     in   a   graph   structure .   The   answer   of   the   manipulation   planning   query   is   then   given   by   searching   a   path   in   the   computed   graph .   Simulation   experiments   were   conducted   for   different   dexterous   manipulation   task   examples   to   validate   the   proposed   method . ' ,   ' title ' :   ' Dexterous   manipulation   planning   using   probabilistic   roadmaps   in   continuous   grasp   subspaces ' } 
{ ' abstract ' :   ' This   paper   presents   an   experimental   evaluation   of   different   line   extraction   algorithms   applied   to   2D   laser   scans   for   indoor   environments .   Six   popular   algorithms   in   mobile   robotics   and   computer   vision   are   selected   and   tested .   Real   scan   data   collected   from   two   office   environments   by   using   different   platforms   are   used   in   the   experiments   in   order   to   evaluate   the   algorithms .   Several   comparison   criteria   are   proposed   and   discussed   to   highlight   the   advantages   and   drawbacks   of   each   algorithm ,   including   speed ,   complexity ,   correctness   and   precision .   The   results   of   the   algorithms   are   compared   with   ground   truth   using   standard   statistical   methods .   An   extended   case   study   is   performed   to   further   evaluate   the   algorithms   in   a   SLAM   application . ' ,   ' title ' :   ' A   comparison   of   line   extraction   algorithms   using   2D   range   data   for   indoor   mobile   robotics ' } 
{ ' abstract ' :   ' This   study   investigates   the   use   of   force - stiffness   feedback ,   i . e . ,   a   combination   of   force   offset   and   extra   spring   load ,   in   UAV   tele - operation   with   transmission   time   delay .   The   goal   was   to   further   increase   the   level   of   safety   of   tele - operation   with   a   reduction   in   operator   workload   with   respect   to   force   feedback ,   i . e . ,   using   force   offset   alone .   A   theoretical   analysis   is   given   of   using   force - stiffness   feedback   to   improve   collision   avoidance .   Wave   variables   are   included   to   reduce   time   delay   effects .   An   experiment   was   conducted   to   investigate   the   effects   of   force - stiffness   feedback   on   safety   of   operation ,   operator   performance ,   control   activity ,   and   workload .   Results   indicate   that   force - stiffness   feedback   improves   the   haptic   interface   with   respect   to   force   feedback   alone .   Safety   of   tele - operation   increases   without   increasing   operator   workload   with   respect   to   force   feedback . ' ,   ' title ' :   ' Haptic   interface   in   UAV   tele - operation   using   force - stiffness   feedback ' } 
{ ' abstract ' :   ' Due   to   the   spread   of   the   internet   and   the   ever   increasing   number   of   web   applications ,   the   issue   of   compatibility   across   browsers   has   become   very   important .   This   compatibility   issue   is   also   referred   as   Cross   Browser   Inconsistency   ( XBI )   wherein   same   website   looks   or   behaves   differently   in   different   web   browsers .   In   this   paper   our   aim   is   to   address   this   issue   of   compatibility   and   propose   an   automated   approach   of   detecting   XBIs .   Cross   Browser   Inconsistencies   can   either   be   in   the   content ,   structure   or   behavior   of   the   webpage .   In   order   to   get   a   grasp   of   the   above   mentioned   types   of   inconsistencies ,   we   surveyed   some   random   websites   and   analyzed   them   in   different   browsers .   We   also   studied   the   basic   working   of   browser ,   in   order   to   establish   its   connection   with   the   occurrences   of   XBIs .   Each   browser   has   its   own   rendering   mechanisms ,   which   sometimes   differs   from   standards .   Hence ,   the   execution   of   these   websites   is   different   in   different   browsers .   Finally   we   have   proposed   an   automated   approach   for   XBI   detection . ' ,   ' title ' :   ' An   Automated   Approach   for   Cross - Browser   Inconsistency   ( XBI )   Detection ' } 
{ ' abstract ' :   ' We   present   a   formal   framework   that   combines   high - level   representation   and   causality - based   reasoning   with   low - level   geometric   reasoning   and   motion   planning .   The   frame - work   features   bilateral   interaction   between   task   and   motion   planning ,   and   embeds   geometric   reasoning   in   causal   reasoning ,   thanks   to   several   advantages   inherited   from   its   underlying   components .   In   particular ,   our   choice   of   using   a   causality - based   high - level   formalism   for   describing   action   domains   allows   us   to   represent   ramifications   and   state / transition   constraints ,   and   embed   in   such   formal   domain   descriptions   externally   defined   functions   implemented   in   some   programming   language   ( e . g . ,   C++ ) .   Moreover ,   given   such   a   domain   description ,   the   causal   reasoner   based   on   this   formalism   ( i . e . ,   the   Causal   Calculator )   allows   us   to   compute   optimal   solutions   ( e . g . ,   shortest   plans )   for   elaborate   planning / prediction   problems   with   temporal   constraints .   Utilizing   these   features   of   high - level   representation   and   reasoning ,   we   can   combine   causal   reasoning ,   motion   planning   and   geometric   planning   to   find   feasible   kinematic   solutions   to   task - level   problems .   In   our   framework ,   the   causal   reasoner   guides   the   motion   planner   by   finding   an   optimal   task - plan ;   if   there   is   no   feasible   kinematic   solution   for   that   task - plan   then   the   motion   planner   guides   the   causal   reasoner   by   modifying   the   planning   problem   with   new   temporal   constraints .   Furthermore ,   while   computing   a   task - plan ,   the   causal   reasoner   takes   into   account   geometric   models   and   kinematic   relations   by   means   of   external   predicates   implemented   for   geometric   reasoning   ( e . g . ,   to   check   some   collisions ) ;   in   that   sense   the   geometric   reasoner   guides   the   causal   reasoner   to   find   feasible   kinematic   solutions .   We   illustrate   an   application   of   this   framework   to   robotic   manipulation ,   with   two   pantograph   robots   on   a   complex   assembly   task   that   requires   concurrent   execution   of   actions .   A   short   video   of   this   application   accompanies   the   paper . ' ,   ' title ' :   ' Combining   high - level   causal   reasoning   with   low - level   geometric   reasoning   and   motion   planning   for   robotic   manipulation ' } 
{ ' abstract ' :   ' This   paper   presents   a   novel   template   matching   method   to   detect   and   track   pedestrians   for   people   counting   in   real - time .   Firstly ,   a   novel   background   subtraction   method   is   proposed   for   extracting   all   foreground   objects   from   background .   Then ,   a   shadow   elimination   method   is   used   to   remove   unwanted   shadow   from   the   background .   In   order   to   identify   pedestrians   from   non - pedestrian   objects ,   this   paper   proposed   a   novel   grid - based   template   matching   scheme   to   robustly   verify   each   pedestrian .   Usually ,   a   pedestrian   will   have   different   appearances   at   different   positions .   The   grid - based   approach   can   effectively   reduce   the   perspective   effects   into   a   minimum   since   it   uses   different   templates   to   record   the   appearance   changes   at   each   grid .   When   more   templates   are   used ,   the   detection   process   will   become   more   inefficient .   To   speed   up   its   efficiency ,   an   integral   image   is   used   to   filter   out   all   impossible   candidates   in   advance .   Lastly ,   a   tracking   method   is   applied   to   tracking   the   direction   of   each   moving   pedestrian   so   that   the   real   number   of   passing   people   per   direction   can   be   counted   more   accurately .   Experimental   results   have   proved   that   the   proposed   method   is   robust ,   accurate ,   and   powerful   in   people   counting . ' ,   ' title ' :   ' Grid - based   Template   Matching   for   People   Counting ' } 
{ ' abstract ' :   ' A   tomographic   image   reconstruction   algorithm   that   we   have   been   studying   requires   the   nth - order   Hankel   transform   for   the   nth   function   in   a   series ,   where   n   varies   over   a   set   of   integers .   Unfortunately ,   most   previously   proposed   algorithms   have   either   dealt   with   only   zeroth - order   transforms   or   cannot   be   applied   conveniently   to   our   problem .   We   propose   an   algorithm   for   computing   general   integer - order   Hankel   transforms .   The   algorithm   takes   samples   of   equally   spaced   input   functions   and   gives   equally   spaced   samples   of   the   transforms . ' ,   ' title ' :   ' An   algorithm   for   computing   general   integer - order   Hankel   transforms ' } 
{ ' abstract ' :   ' In   this   paper ,   we   present   a   real - time   approach   that   allows   tracking   deformable   structures   in   3D   ultrasound   sequences .   Our   method   consists   in   obtaining   the   target   displacements   by   combining   robust   dense   motion   estimation   and   mechanical   model   simulation .   We   perform   evaluation   of   our   method   through   simulated   data ,   phantom   data ,   and   real - data .   Results   demonstrate   that   this   novel   approach   has   the   advantage   of   providing   correct   motion   estimation   regarding   different   ultrasound   shortcomings   including   speckle   noise ,   large   shadows   and   ultrasound   gain   variation .   Furthermore ,   we   show   the   good   performance   of   our   method   with   respect   to   state - of - the - art   techniques   by   testing   on   the   3D   databases   provided   by   MICCAI   CLUST ’ 14   and   CLUST ’ 15   challenges . ' ,   ' title ' :   ' Real - time   target   tracking   of   soft   tissues   in   3D   ultrasound   images   based   on   robust   visual   information   and   mechanical   simulation ' } 
{ ' abstract ' :   ' For   two   given   graphs   G1G1   and   G2G2 ,   the   Ramsey   number   R ( G1 , G2 ) R ( G1 , G2 )   is   the   smallest   integer   NN   such   that   for   any   graph   of   order   NN ,   either   GG   contains   a   copy   of   G1G1   or   its   complement   contains   a   copy   of   G2G2 .   Let   CmCm   be   a   cycle   of   length   mm   and   K1 , nK1 , n   a   star   of   order   n + 1n + 1 .   Parsons   ( 1975 )   shows   that   R ( C4 , K1 , n ) ≤ n + ⌊ n − 1 ⌋ + 2   and   if   nn   is   the   square   of   a   prime   power ,   then   the   equality   holds .   In   this   paper ,   by   discussing   the   properties   of   polarity   graphs   whose   vertices   are   points   in   the   projective   planes   over   Galois   fields ,   we   prove   that   R ( C4 , K1 , q2 − t ) = q2 + q − ( t − 1 ) R ( C4 , K1 , q2 − t ) = q2 + q − ( t − 1 )   if   qq   is   an   odd   prime   power ,   1 ≤ t ≤ 2 ⌈ q4 ⌉   and   t ≠ 2 ⌈ q4 ⌉ − 1 ,   which   extends   a   result   on   R ( C4 , K1 , q2 − t ) R ( C4 , K1 , q2 − t )   obtained   by   Parsons   ( 1976 ) . ' ,   ' title ' :   ' Polarity   graphs   and   Ramsey   numbers   for   C   4   versus   stars ' } 
{ ' abstract ' :   ' This   paper   deals   with   the   problem   of   assuring   strict   QoS   guarantees   for   the   end   to   end   connections   that   originate   from   Ethernet   access   network .   It   shows   that   despite   high   link   capacities   in   some   cases   Ethernet   network   might   be   the   reason   of   QoS   deterioration .   The   primary   reason   is   the   lack   of   appropriate   QoS   differentiation   and   traffic   isolation   mechanisms .   The   shared   buffers   and   priority   schedulers   available   in   most   of   Ethernet   switches   appear   to   be   not   sufficient   to   guarantee   strict   QoS .   For   these   cases   new   solution   is   proposed   which   relies   on   additional   traffic   control   mechanisms   available   in   other   network   elements .   Only   additional   mechanism   supporting   typical   functionality   of   Ethernet   switch   can   provide   strict   QoS   guarantees   what   was   verified   in   simulations   studies . ' ,   ' title ' :   ' On   assuring   QoS   in   Ethernet   access   network ' } 
{ ' abstract ' :   ' The   federal   Medicare   regulations   reimburse   hospitals   on   a   pro   rata   share   of   the   hospital \ ' s   cost .   Hence ,   to   meet   its   financial   requirements ,   a   hospital   is   forced   to   shift   more   of   the   financial   burdens   onto   its   private   patients .   This   procedure   has   contributed   to   double   digit   inflation   in   hospital   prices   and   to   proposed   federal   regulation   to   control   the   rate   of   increase   in   hospital   revenues .   In   this   regulatory   environment ,   we   develop   nonlinear   programming   pricing   and   cost   allocation   models   to   aid   hospital   administrators   in   meeting   their   profit   maximizing   and   profit   satisficing   goals .   The   model   enables   administrators   to   explore   tactical   issues   such   as :   i   studying   the   relationship   between   a   voluntary   or   legislated   cap   on   a   hospital \ ' s   total   revenues   and   the   hospital \ ' s   profitability ,   ii   identifying   those   departments   within   the   hospital   that   are   the   most   attractive   candidates   for   cost   reduction   or   cost   containment   efforts ,   and   iii   isolating   those   services   that   should   be   singled   out   by   the   hospital   manager   for   renegotiation   of   the   prospective   or   " customary   and   reasonable "   cap .   Finally ,   the   modeling   approach   is   helpful   in   explaining   the   departmental   cross   subsidies   observed   in   practice ,   and   can   be   of   aid   to   federal   administrators   in   assessing   the   impacts   of   proposed   changes   in   the   Medicare   reimbursement   formula . ' ,   ' title ' :   ' Hospital   Profit   Planning   under   Medicare   Reimbursement ' } 
{ ' abstract ' :   ' We   present   a   ( 4   +   epsilon )   approximation   algorithm   for   weighted   graph   matching   which   applies   in   the   semistreaming ,   sliding   window ,   and   MapReduce   models ;   this   single   algorithm   improves   the   previous   best   algorithm   in   each   model .   The   algorithm   operates   by   reducing   the   maximum - weight   matching   problem   to   a   polylog   number   of   copies   of   the   maximum - cardinality   matching   problem .   The   algorithm   also   extends   to   provide   approximation   guarantees   for   the   more   general   problem   of   finding   weighted   independent   sets   in   p - systems   ( which   include   intersections   of   p   matroids   and   p - bounded   hypergraph   matching ) . ' ,   ' title ' :   ' Improved   Streaming   Algorithms   for   Weighted   Matching ,   via   Unweighted   Matching ' } 
{ ' abstract ' :   ' This   paper   presents   a   novel   approach   to   efficiently   solve   parameter - dependent   ( PD )   linear   matrix   inequality   ( LMI )   problems   for ,   amongst   others ,   linear   parameter - varying   ( LPV )   control   design .   Typically ,   stability   and   performance   is   guaranteed   by   finding   a   PD   Lyapunov   function   such   that   a   PD   LMI   is   feasible   on   a   parameter   domain .   To   solve   the   resulting   semi - infinite   problems ,   we   propose   a   novel   LMI   relaxation   technique   relying   on   B - spline   basis   functions .   This   technique   provides   less   conservative   solutions   and / or   a   reduced   numerical   burden   compared   to   existing   approaches .   Moreover ,   an   elegant   generalization   of   worst - case   optimization   to   the   optimization   of   any   signal   norm   is   obtained   by   expressing   performance   bounds   as   a   function   of   the   system   parameters .   This   generalization   yields   better   performance   bounds   in   a   large   part   of   the   parameter   domain .   Numerical   comparisons   with   the   current   state - of - the - art   demonstrate   the   generality   and   effectiveness   of   our   approach . ' ,   ' title ' :   ' Control   of   linear   parameter - varying   systems   using   B - splines ' } 
{ ' abstract ' :   ' There   is   a   growing   interest   in   simulating   natural   phenomena   in   computer   graphics   applications .   Animating   natural   scenes   in   real   time   is   one   of   the   most   challenging   problems   due   to   the   inherent   complexity   of   their   structure ,   formed   by   millions   of   geometric   entities ,   and   the   interactions   that   happen   within .   An   example   of   natural   scenario   that   is   needed   for   games   or   simulation   programs   are   forests .   Forests   are   difficult   to   render   because   the   huge   amount   of   geometric   entities   and   the   large   amount   of   detail   to   be   represented .   Moreover ,   the   interactions   between   the   objects   ( grass ,   leaves )   and   external   forces   such   as   wind   are   complex   to   model .   In   this   paper   we   concentrate   in   the   rendering   of   falling   leaves   at   low   cost .   We   present   a   technique   that   exploits   graphics   hardware   in   order   to   render   thousands   of   leaves   with   different   falling   paths   in   real   time   and   low   memory   requirements . ' ,   ' title ' :   ' Rendering   falling   leaves   on   graphics   hardware ' } 
{ ' abstract ' :   ' We   previously   presented   DriverDB ,   a   database   that   incorporates   ∼ 6000   cases   of   exome - seq   data ,   in   addition   to   annotation   databases   and   published   bioinformatics   algorithms   dedicated   to   driver   gene / mutation   identification .   The   database   provides   two   points   of   view ,   ‘ Cancer ’   and   ‘ Gene ’ ,   to   help   researchers   visualize   the   relationships   between   cancers   and   driver   genes / mutations .   In   the   updated   DriverDBv2   database   ( http : / / ngs . ym . edu . tw / driverdb )   presented   herein ,   we   incorporated   > 9500   cancer - related   RNA - seq   datasets   and   > 7000   more   exome - seq   datasets   from   The   Cancer   Genome   Atlas   ( TCGA ) ,   International   Cancer   Genome   Consortium   ( ICGC ) ,   and   published   papers .   Seven   additional   computational   algorithms   ( meaning   that   the   updated   database   contains   15   in   total ) ,   which   were   developed   for   driver   gene   identification ,   are   incorporated   into   our   analysis   pipeline ,   and   the   results   are   provided   in   the   ‘ Cancer ’   section .   Furthermore ,   there   are   two   main   new   features ,   ‘ Expression ’   and   ‘ Hotspot ’ ,   in   the   ‘ Gene ’   section .   ‘ Expression ’   displays   two   expression   profiles   of   a   gene   in   terms   of   sample   types   and   mutation   types ,   respectively .   ‘ Hotspot ’   indicates   the   hotspot   mutation   regions   of   a   gene   according   to   the   results   provided   by   four   bioinformatics   tools .   A   new   function ,   ‘ Gene   Set ’ ,   allows   users   to   investigate   the   relationships   among   mutations ,   expression   levels   and   clinical   data   for   a   set   of   genes ,   a   specific   dataset   and   clinical   features . ' ,   ' title ' :   ' DriverDBv2 :   a   database   for   human   cancer   driver   gene   research ' } 
{ ' abstract ' :   ' Thousands   of   deep   and   wide   pipelines   working   concurrently   make   GPGPU   high   power   consuming   parts .   Energy - efficiency   techniques   employ   voltage   overscaling   that   increases   timing   sensitivity   to   variations   and   hence   aggravating   the   energy   use   issues .   This   paper   proposes   a   method   to   increase   spatiotemporal   reuse   of   computational   effort   by   a   combination   of   compilation   and   micro - architectural   design .   An   associative   memristive   memory   ( AMM )   module   is   integrated   with   the   floating   point   units   ( FPUs ) .   Together ,   we   enable   fine - grained   partitioning   of   values   and   find   high - frequency   sets   of   values   for   the   FPUs   by   searching   the   space   of   possible   inputs ,   with   the   help   of   application - specific   profile   feedback .   For   every   kernel   execution ,   the   compiler   pre - stores   these   high - frequent   sets   of   values   in   AMM   modules   - -   representing   partial   functionality   of   the   associated   FPU - -   that   are   concurrently   evaluated   over   two   clock   cycles .   Our   simulation   results   show   high   hit   rates   with   32 - entry   AMM   modules   that   enable   36%   reduction   in   average   energy   use   by   the   kernel   codes .   Compared   to   voltage   overscaling ,   this   technique   enhances   robustness   against   timing   errors   with   39%   average   energy   saving . ' ,   ' title ' :   ' Energy - Efficient   GPGPU   Architectures   via   Collaborative   Compilation   and   Memristive   Memory - Based   Computing ' } 
{ ' abstract ' :   ' Quasi - cyclic   codes   are   renowned   for   their   structural   design   and   low - complexity   shift   register   encoding .   However ,   existing   design   techniques   based   on   difference   families   have   limited   code   size   options   due   to   algebraic   constraints .   We   introduce   in   this   paper   a   notation   of   extended   difference   family   ( EDF )   and   provide   a   systematic   code   design   based   on   EDFs   with   a   high   degree   of   flexibility   in   code   size .   Short / medium - length   codes   of   high   rate   ( / spl   ges /   0.9 )   can   be   easily   constructed . ' ,   ' title ' :   ' Quasi - cyclic   codes   from   extended   difference   families ' } 
{ ' abstract ' :   ' Lexical   cohesion   arises   from   a   chain   of   lexical   items   that   establish   links   between   sentences   in   a   text .   In   this   paper   we   propose   three   different   models   to   capture   lexical   cohesion   for   document - level   machine   translation :   ( a )   a   direct   reward   model   where   translation   hypotheses   are   rewarded   whenever   lexical   cohesion   devices   occur   in   them ,   ( b )   a   conditional   probability   model   where   the   appropriateness   of   using   lexical   cohesion   devices   is   measured ,   and   ( c )   a   mutual   information   trigger   model   where   a   lexical   cohesion   relation   is   considered   as   a   trigger   pair   and   the   strength   of   the   association   between   the   trigger   and   the   triggered   item   is   estimated   by   mutual   information .   We   integrate   the   three   models   into   hierarchical   phrase - based   machine   translation   and   evaluate   their   effectiveness   on   the   NIST   Chinese - English   translation   tasks   with   large - scale   training   data .   Experiment   results   show   that   all   three   models   can   achieve   substantial   improvements   over   the   baseline   and   that   the   mutual   information   trigger   model   performs   better   than   the   others . ' ,   ' title ' :   ' Modeling   lexical   cohesion   for   document - level   machine   translation ' } 
{ ' abstract ' :   ' This   paper   presents   a   lightweight   sketching   system   that   enables   interactive   illustration   of   complex   fluid   systems .   Users   can   sketch   on   a   2.5 - dimensional   ( 2.5 D )   canvas   to   design   the   shapes   and   connections   of   a   fluid   circuit .   These   input   sketches   are   automatically   analyzed   and   abstracted   into   a   hydraulic   graph ,   and   a   new   hybrid   fluid   model   is   used   in   the   background   to   enhance   the   illustrations .   The   system   provides   rich   simple   operations   for   users   to   edit   the   fluid   system   incrementally ,   and   the   new   internal   flow   patterns   can   be   simulated   in   real   time .   Our   system   is   used   to   illustrate   various   fluid   systems   in   medicine ,   biology ,   and   engineering .   We   asked   professional   medical   doctors   to   try   our   system   and   obtained   positive   feedback   from   them . ' ,   ' title ' :   ' Sketch - based   Dynamic   Illustration   of   Fluid   Systems ' } 
{ ' abstract ' :   ' We   present   an   improved   zone   content   classification   method   and   its   performance   evaluation .   We   added   two   new   features   to   the   feature   vector   from   one   previously   published   method   ( Sivaramakrishnan   et   al . ,   1995 ) .   We   assumed   different   independence   relationships   in   two   zone   sets .   We   used   an   optimized   binary   decision   tree   to   estimate   the   maximum   zone   content   class   probability   in   one   set   while   using   the   Viterbi   algorithm   to   find   the   optimal   solution   for   a   zone   sequence   in   the   other   set .   The   training ,   pruning   and   testing   data   set   for   the   algorithm   include   1 , 600   images   drawn   from   the   UWCDROM   III   document   image   database .   The   classifier   is   able   to   classify   each   given   scientific   and   technical   document   zone   into   one   of   the   nine   classes ,   2   text   classes   ( of   font   size   4   -   18pt   and   font   size   19   -   32   pt ) ,   math ,   table ,   halftone ,   map / drawing ,   ruling ,   logo ,   and   others .   Compared   with   our   previous   work   ( Wang   et   al . ,   2000 ) ,   it   raised   the   accuracy   rate   to   98.52%   from   97.53%   and   reduced   the   mean   false   alarm   rate   to   0.53%   from   1.26% . ' ,   ' title ' :   ' Zone   content   classification   and   its   performance   evaluation ' } 
{ ' abstract ' :   ' Big   Data   applications   require   real - time   processing   of   complex   computations   on   streaming   and   static   information .   Applications   such   as   the   diagnosis   of   power   generating   turbines   require   the   integration   of   high   velocity   streaming   and   large   volume   of   static   data   from   multiple   sources .   In   this   paper   we   study   various   optimisations   related   to   efficiently   processing   of   streaming   and   static   information .   We   introduce   novel   indexing   structures   for   stream   processing ,   a   query - planner   component   that   decides   when   their   creation   is   beneficial ,   and   we   examine   precomputed   summarisations   on   archived   measurements   to   accelerate   streaming   and   static   information   processing .   To   put   our   ideas   into   practise ,   we   have   developed   Exa   Stream ,   a   data   stream   management   system   that   is   scalable ,   has   declarative   semantics ,   supports   user   defined   functions ,   and   allows   efficient   execution   of   complex   analytical   queries   on   streaming   and   static   data .   Our   work   is   accompanied   by   an   empirical   evaluation   of   our   optimisation   techniques . ' ,   ' title ' :   ' Real   time   processing   of   streaming   and   static   information ' } 
{ ' abstract ' :   " In   the   last   ten   years ,   speech   recognition   has   evolved   from   a   science   fiction   dream   to   a   widespread   input   method   for   mobile   devices .   In   this   talk ,   I   will   describe   how   speech   recognition   works ,   the   problems   we   have   solved   and   the   challenges   that   remain .   I   will   touch   upon   some   of   Google ' s   main   efforts   in   language   and   pronunciation   modeling ,   and   describe   how   the   adoption   of   neural   networks   for   acoustic   modeling   marked   the   beginning   of   a   technology   revolution   in   the   field ,   with   approaches   such   as   Long   Short   Term   Memory   models   and   Connectionist   Temporal   Classification .   I   will   also   share   my   learnings   on   how   Machine   Learning   and   Human   Knowledge   can   be   harmoniously   combined   to   build   state - of - the - art   technology   that   helps   and   delights   users   across   the   world . " ,   ' title ' :   ' Learnings   and   innovations   in   speech   recognition ' } 
{ ' abstract ' :   ' Nowadays ,   the   explosive   growth   and   variety   of   information   available   on   the   Web   frequently   overwhelms   users   and   leads   users   to   make   poor   decisions .   Consequently ,   recommender   systems   have   become   more   and   more   important   to   assist   people   to   make   decisions   faster .   Among   all   related   techniques ,   collaborative   filtering   approach   is   currently   one   of   the   effective   and   widely   used   techniques   to   build   recommender   systems .   However ,   there   are   major   challenges   like   data   sparsity   and   scalability .   Meanwhile   it   is   hard   to   integrate   demographic   statistical   information   ( Age ,   gender   and   occupation   etc . )   to   collaborative   filtering   model .   Unfortunately ,   it   is   significant   to   take   account   into   these   information ,   especially   user   occupation   when   making   recommendation .   As   we   all   know ,   people   with   different   occupations   may   have   totally   different   tastes .   It   has   been   proved   that   restricted   Boltzmann   machines ( RBM )   model   can   infer   lower - dimensional   representations   automatically   and   is   potential   in   handling   large   and   sparse   dataset .   In   this   paper ,   we   propose   an   improved   User   Occupation   aware   Conditional   Restricted   Boltzmann   Machine   Frame ( UO - CRBMF )   model ,   which   employs   an   improved   RBM   and   takes   full   use   of   user   occupation   information   by   adding   a   conditional   layer   with   user   occupation   information .   Experimental   studies   on   the   standard   benchmark   datasets   of   MovieLens   100k   and   MovieLens   1M   have   shown   its   potential   and   advantages   beyond   baseline   methods . ' ,   ' title ' :   ' User   Occupation   Aware   Conditional   Restricted   Boltzmann   Machine   Based   Recommendation ' } 
{ ' abstract ' :   ' Microservices   complement   approaches   like   DevOps   and   continuous   delivery   in   terms   of   software   architecture .   Along   with   this   architectural   style ,   several   important   deployment   technologies ,   such   as   container - based   virtualization   and   container   orchestration   solutions ,   have   emerged .   These   technologies   allow   to   efficiently   exploit   cloud   platforms ,   providing   a   high   degree   of   scalability ,   availability ,   and   portability   for   microservices .# R ## N ## R ## N # Despite   the   obvious   importance   of   a   sufficient   level   of   performance ,   there   is   still   a   lack   of   performance   engineering   approaches   explicitly   taking   into   account   the   particularities   of   microservices .   In   this   paper ,   we   argue   why   new   solutions   to   performance   engineering   for   microservices   are   needed .   Furthermore ,   we   identify   open   issues   and   outline   possible   research   directions   with   regard   to   performance - aware   testing ,   monitoring ,   and   modeling   of   microservices . ' ,   ' title ' :   ' Performance   Engineering   for   Microservices :   Research   Challenges   and   Directions ' } 
{ ' abstract ' :   ' Intelligent   agents ,   such   as   robots ,   have   to   serve   a   multitude   of   autonomous   functions .   Examples   are ,   e . g . ,   collision   avoidance ,   navigation   and   route   planning ,   active   sensing   of   its   environment ,   or   the   interaction   and   non - verbal   communication   with   people   in   the   extended   reach   space .   Here ,   we   focus   on   the   recognition   of   the   action   of   a   human   agent   based   on   a   biologically   inspired   visual   architecture   of   analyzing   articulated   movements .   The   proposed   processing   architecture   builds   upon   coarsely   segregated   streams   of   sensory   processing   along   different   pathways   which   separately   process   form   and   motion   information   ( Layher   et   al . ,   2014 ) .   Action   recognition   is   performed   in   an   event - based   scheme   by   identifying   representations   of   characteristic   pose   configurations   ( key   poses )   in   an   image   sequence .   In   line   with   perceptual   studies ,   key   poses   are   selected   unsupervised   utilizing   a   feature   driven   criterion   which   combines   extrema   in   the   motion   energy   with   the   horizontal   and   the   vertical   extendedness   of   a   body   shape .   Per   class   representations   of   key   pose   frames   are   learned   using   a   deep   convolutional   neural   network   consisting   of   15   convolutional   layers .   The   network   is   trained   using   the   energy - efficient   deep   neuromorphic   networks   ( Eedn )   framework   ( Esser   et   al . ,   2016 ) ,   which   realizes   the   mapping   of   the   trained   synaptic   weights   onto   the   IBM   Neurosynaptic   System   platform   ( Merolla   et   al . ,   2014 ) .   After   the   mapping ,   the   trained   network   achieves   real - time   capabilities   for   processing   input   streams   and   classify   input   images   at   about   1 , 000   frames   per   second   while   the   computational   stages   only   consume   about   70   mW   of   energy   ( without   spike   transduction ) .   Particularly   regarding   mobile   robotic   systems ,   a   low   energy   profile   might   be   crucial   in   a   variety   application   scenarios .   Cross - validation   results   are   reported   for   two   different   datasets   and   compared   to   state - of - the - art   action   recognition   approaches .   The   results   demonstrate ,   that   ( I )   the   presented   approach   is   on   par   with   other   key   pose   based   methods   described   in   the   literature ,   which   select   key   pose   frames   by   optimizing   classification   accuracy ,   ( II )   compared   to   the   training   on   the   full   set   of   frames ,   representations   trained   on   key   pose   frames   result   in   a   higher   confidence   in   class   assignments ,   and   ( III )   key   pose   representations   show   promising   generalization   capabilities   in   a   cross - dataset   evaluation . ' ,   ' title ' :   ' Real - Time   Biologically   Inspired   Action   Recognition   from   Key   Poses   Using   a   Neuromorphic   Architecture ' } 
{ ' abstract ' :   ' Contents   carried   in   an   image   are   valuable   information   sources   for   many   scientific   and   engineering   applications .   However ,   if   the   image   is   captured   under   low   illumination   conditions   a   large   portion   of   the   image   appears   dark   and   this   heavily   degrades   the   image   quality .   In   order   to   solve   this   problem ,   a   restoration   algorithm   is   developed   here   that   transforms   the   low   input   brightness   to   a   higher   value   using   a   logarithmic   mapping   function .   The   mapping   is   further   refined   by   a   linear   weighting   with   the   input   to   reduce   the   un - necessary   amplification   at   regions   with   high   brightness .   Moreover ,   fine   details   in   the   image   are   preserved   by   applying   the   Retinex   principle   to   extract   and   then   re - insert   object   edges .   Results   from   experiments   using   low   and   normal   illumination   images   have   shown   satisfactory   performances   with   regard   to   the   improvement   in   information   contents   and   the   mitigation   of   viewing   artifacts . ' ,   ' title ' :   ' Logarithmic   profile   mapping   and   Retinex   edge   preserving   for   restoration   of   low   illumination   images ' } 
{ ' abstract ' :   ' We   propose   a   principled   approach   for   the   problem   of   aligning   multiple   partially   overlapping   networks .   The   objective   is   to   map   multiple   graphs   into   a   single   graph   while   preserving   vertex   and   edge   similarities .   The   problem   is   inspired   by   the   task   of   integrating   partial   views   of   a   family   tree   ( genealogical   network )   into   one   unified   network ,   but   it   also   has   applications ,   for   example ,   in   social   and   biological   networks .   Our   approach ,   called   Flan ,   introduces   the   idea   of   generalizing   the   facility   location   problem   by   adding   a   non - linear   term   to   capture   edge   similarities   and   to   infer   the   underlying   entity   network .   The   problem   is   solved   using   an   alternating   optimization   procedure   with   a   Lagrangian   relaxation .   Flan   has   the   advantage   of   being   able   to   leverage   prior   information   on   the   number   of   entities ,   so   that   when   this   information   is   available ,   Flan   is   shown   to   work   robustly   without   the   need   to   use   any   ground   truth   data   for   fine - tuning   method   parameters .   Additionally ,   we   present   three   multiple - network   extensions   to   an   existing   state - of - the - art   pairwise   alignment   method   called   Natalie .   Extensive   experiments   on   synthetic ,   as   well   as   real - world   datasets   on   social   networks   and   genealogical   networks ,   attest   to   the   effectiveness   of   the   proposed   approaches   which   clearly   outperform   a   popular   multiple   network   alignment   method   called   IsoRankN . ' ,   ' title ' :   ' Lagrangian   relaxations   for   multiple   network   alignment ' } 
{ ' abstract ' :   ' Heterogeneous   ultra - dense   networks   enable   ultra - high   data   rates   and   ultra - low   latency   through   the   use   of   dense   sub - 6   GHz   and   millimeter   wave   ( mmWave )   small   cells   with   different   antenna   configurations .   Existing   work   has   widely   studied   spectral   and   energy   efficiency   in   such   networks   and   shown   that   high   spectral   and   energy   efficiency   can   be   achieved .   This   article   investigates   the   benefits   of   heterogeneous   ultra - dense   network   architecture   from   the   perspectives   of   three   promising   technologies ,   i . e . ,   physical   layer   security ,   caching ,   and   wireless   energy   harvesting ,   and   provides   enthusiastic   outlook   towards   application   of   these   technologies   in   heterogeneous   ultra - dense   networks .   Based   on   the   rationale   of   each   technology ,   opportunities   and   challenges   are   identified   to   advance   the   research   in   this   emerging   network . ' ,   ' title ' :   ' A   New   Look   at   Physical   Layer   Security ,   Caching ,   and   Wireless   Energy   Harvesting   for   Heterogeneous   Ultra - dense   Networks ' } 
{ ' abstract ' :   ' We   consider   the   problem   of   joint   modeling   of   videos   and   their   corresponding   textual   descriptions   ( e . g .   sentences   or   phrases ) .   Our   approach   consists   of   three   components :   the   video   representation ,   the   textual   representation ,   and   a   joint   model   that   links   videos   and   text .   Our   video   representation   uses   the   state - of - the - art   deep   3D   ConvNet   to   capture   the   semantic   information   in   the   video .   Our   textual   representation   uses   the   recent   advancement   in   learning   word   and   sentence   vectors   from   large   text   corpus .   The   joint   model   is   learned   to   score   the   correct   ( video ,   text )   pairs   higher   than   the   incorrect   ones .   We   demonstrate   our   approach   in   several   applications :   1 )   retrieving   sentences   given   a   video ;   2 )   retrieving   videos   given   a   sentence ;   3 )   zero - shot   action   recognition   in   videos . ' ,   ' title ' :   ' Beyond   verbs :   Understanding   actions   in   videos   with   text ' } 
{ ' abstract ' :   ' This   paper   presents   a   multi - agent   model   for   simulating   attitude   formation   and   change   based   on   perception   and   communication   in   the   context   of   stabilization   operations .   The   originality   of   our   model   comes   from   ( 1 )   attitude   computation   that   evaluates   information   as   part   of   a   history   relative   to   the   individual   ( 2 )   a   notion   of   co - responsibility   for   attitude   attribution .   We   present   a   military   scenario   of   French   operations   in   Afghanistan   along   with   polls   results   about   the   opinion   of   citizen   toward   present   Forces .   Based   on   these   field   data ,   we   calibrate   the   model   and   show   the   resulting   attitude   dynamics .   We   study   the   sensibility   of   the   model   to   the   co - responsibility   factor . ' ,   ' title ' :   ' From   Field   Data   to   Attitude   Formation ' } 
{ ' abstract ' :   ' This   paper   proposes   two   low - complexity   iterative   algorithms   to   compute   the   capacity   of   a   single - user   multiple - input   multiple - output   channel   with   per - antenna   power   constraint .   The   first   method   results   from   manipulating   the   optimality   conditions   of   the   considered   problem   and   applying   fixed - point   iteration .   In   the   second   approach ,   we   transform   the   considered   problem   into   a   minimax   optimization   program   using   the   well - known   MAC -   BC   duality ,   and   then   solve   it   by   a   novel   alternating   optimization   method .   In   both   proposed   iterative   methods ,   each   iteration   involves   an   optimization   problem   which   can   be   efficiently   solved   by   the   water - filling   algorithm .   The   proposed   iterative   methods   are   provably   convergent .   Complexity   analysis   and   extensive   numerical   experiments   are   carried   out   to   demonstrate   the   superior   performance   of   the   proposed   algorithms   over   an   existing   approach   known   as   the   mode - dropping   algorithm . ' ,   ' title ' :   ' Low - complexity   Approaches   for   MIMO   Capacity   with   Per - antenna   Power   Constraint ' } 
{ ' abstract ' :   ' Inventory - Aware   Pathfinding   is   concerned   with   finding   paths   while   taking   into   account   that   picking   up   items ,   e . g . ,   keys ,   allow   the   character   to   unlock   blocked   pathways ,   e . g . ,   locked   doors .   In   this   work   we   present   a   pruning   method   and   a   preprocessing   method   that   can   improve   significantly   the   scalability   of   such   approaches .   We   apply   our   methods   to   the   recent   approach   of   Inventory - Driven   Jump - Point   Search   ( InvJPS ) .   First ,   we   introduce   InvJPS +   that   allows   to   prune   large   parts   of   the   search   space   by   favoring   short   detours   to   pick   up   items ,   offering   a   trade - off   between   efficiency   and   optimality .   Second ,   we   propose   a   preprocessing   step   that   allows   to   decide   on   runtime   which   items ,   e . g . ,   keys ,   are   worth   using   thus   pruning   potentially   unnecessary   items   before   the   search   starts .   We   show   results   for   combinations   of   the   pruning   and   preprocessing   methods   illustrating   the   best   choices   over   various   scenarios . ' ,   ' title ' :   ' Pruning   and   preprocessing   methods   for   inventory - aware   pathfinding ' } 
{ ' abstract ' :   ' This   paper   proposes   a   method   for   proper   names   extraction   from   Myanmar   text   by   using   latent   Dirichlet   allocation   ( LDA ) .   Our   method   aims   to   extract   proper   names   that   provide   important   information   on   the   contents   of   Myanmar   text .   Our   method   consists   of   two   steps .   In   the   first   step ,   we   extract   topic   words   from   Myanmar   news   articles   by   using   LDA .   In   the   second   step ,   we   make   a   post - processing ,   because   the   resulting   topic   words   contain   some   noisy   words .   Our   post - processing ,   first   of   all ,   eliminates   the   topic   words   whose   prefixes   are   Myanmar   digits   and   suffixes   are   noun   and   verb   particles .   We   then   remove   the   duplicate   words   and   discard   the   topic   words   that   are   contained   in   the   existing   dictionary .   Consequently ,   we   obtain   the   words   as   candidate   of   proper   names ,   namely   personal   names ,   geographical   names ,   unique   object   names ,   organization   names ,   single   event   names ,   and   so   on .   The   evaluation   is   performed   both   from   the   subjective   and   quantitative   perspectives .   From   the   subjective   perspective ,   we   compare   the   accuracy   of   proper   names   extracted   by   our   method   with   those   extracted   by   latent   semantic   indexing   ( LSI )   and   rule - based   method .   It   is   shown   that   both   LS ]   and   our   method   can   improve   the   accuracy   of   those   obtained   by   rule - based   method .   However ,   our   method   can   provide   more   interesting   proper   names   than   LSI .   From   the   quantitative   perspective ,   we   use   the   extracted   proper   names   as   additional   features   in   K - means   clustering .   The   experimental   results   show   that   the   document   clusters   given   by   our   method   are   better   than   those   given   by   LSI   and   rule - based   method   in   precision ,   recall   and   F - score . ' ,   ' title ' :   ' Extraction   of   proper   names   from   myanmar   text   using   latent   dirichlet   allocation ' } 
{ ' abstract ' :   ' Large   scale   assessment   of   aboveground   biomass   ( AGB )   in   tropical   forests   is   often   limited   by   the   saturation   of   remote   sensing   signals   at   high   AGB   values .   Fourier   Transform   Textural   Ordination   ( FOTO )   performs   well   in   quantifying   canopy   texture   from   very   high - resolution   ( VHR )   imagery ,   from   which   stand   structure   parameters   can   be   retrieved   with   no   saturation   effect   for   AGB   values   up   to   650   Mg · ha − 1 .   The   method   is   robust   when   tested   on   wet   evergreen   forests   but   is   more   demanding   when   applied   across   different   forest   types   characterized   by   varying   structures   and   allometries .   The   present   study   focuses   on   a   gradient   of   forest   types   ranging   from   dry   deciduous   to   wet   evergreen   forests   in   the   Western   Ghats   ( WG )   of   India ,   where   we   applied   FOTO   to   Cartosat - 1a   images   with   2.5   m   resolution .   Based   on   21   1 - ha   ground   control   forest   plots ,   we   calibrated   independent   texture – AGB   models   for   the   dry   and   wet   zone   forests   in   the   area ,   as   delineated   from   the   distribution   of   NDVI   values   computed   from   LISS - 4   multispectral   images .   This   stratification   largely   improved   the   relationship   between   texture - derived   and   field - derived   AGB   estimates ,   which   exhibited   a   R2   of   0.82   for   a   mean   rRMSE   of   ca .   17% .   By   inverting   the   texture – AGB   models ,   we   finally   mapped   AGB   predictions   at   1.6 - ha   resolution   over   a   heterogeneous   landscape   of   ca .   1500   km2   in   the   WG ,   with   a   mean   relative   per - pixel   propagated   error   < 20%   for   wet   zone   forests ,   i . e . ,   below   the   recommended   IPCC   criteria   for   Monitoring ,   Reporting   and   Verification   ( MRV )   methods .   The   method   proved   to   perform   well   in   predicting   high - resolution   AGB   values   over   heterogeneous   tropical   landscape   encompassing   diversified   forest   types ,   and   thus   presents   a   promising   option   for   affordable   regional   monitoring   systems   of   greenhouse   gas   ( GhG )   emissions   related   to   forest   degradation . ' ,   ' title ' :   ' Inverting   Aboveground   Biomass – Canopy   Texture   Relationships   in   a   Landscape   of   Forest   Mosaic   in   the   Western   Ghats   of   India   Using   Very   High   Resolution   Cartosat   Imagery ' } 
{ ' abstract ' :   ' Self - driving   vehicle   technologies   are   progressing   rapidly   and   are   expected   to   play   a   significant   role   in   the   future   of   transportation .   One   of   the   main   challenges   for   self - driving   vehicles   on   public   roads   is   the   safe   cooperation   and   collaboration   among   multiple   vehicles   using   sensor - based   perception   and   inter - vehicle   communications .   When   self - driving   vehicles   try   to   occupy   the   same   spatial   area   simultaneously ,   they   might   collide   with   one   another ,   might   become   deadlocked ,   or   might   slam   on   the   brakes   making   it   uncomfortable   or   unsafe   for   passengers   in   a   self - driving   vehicle .   In   this   paper ,   we   study   how   a   self - driving   vehicle   can   safely   navigate   merge   points ,   where   two   lanes   with   different   priorities   meet .   We   present   a   safe   protocol   for   merge   points   named   Autonomous   Vehicle   Protocol   for   Merge   Points ,   where   self - driving   vehicles   use   both   vehicular   communications   and   their   own   perception   systems   for   cooperating   with   other   self - driving   and / or   human - driven   vehicles .   Our   simulation   results   show   that   our   traffic   protocol   has   higher   traffic   throughput ,   compared   to   simple   traffic   protocols ,   while   ensuring   safety . ' ,   ' title ' :   ' A   merging   protocol   for   self - driving   vehicles ' } 
{ ' abstract ' :   ' System   Portfolio   Selection   ( SPS )   problem   is   equivalent   to   multi - objective   optimization   problem ,   with   multi - function   requirements   incommensurable .   In   the   paper ,   the   SPS   problem   is   re - specified   with   a   more   practical   formulation ,   comparing   to   general   portfolio   problem .   Then ,   both   feasible   and   non - inferior   solution   is   re - defined   considering   characteristics   of   SPS   problem ,   specifically ,   four   rules   of   system   function   combinations   are   proposed   according   to   practical   cases .   Then ,   the   instability   of   system   performance   is   involved   in   SPS   problem ,   and   the   robust   theory   is   employed   to   solving   the   uncertainty   of   system   function   values   with   definition   of   robust   non - inferior   solution .   Next ,   the   paper   proposes   an   immediately   updating   algorithm   to   solve   the   problem   of   solution   space   exponentially   growing .   Finally ,   a   case   study   is   used   to   demonstrate   the   usefulness   and   effectiveness   of   the   proposed   approaches .   It   shows   that   the   approach   can   provide   an   efficient   guidance   for   decision - makers   in   the   process   of   making   a   SPS . ' ,   ' title ' :   ' Robust   system   portfolio   selection   with   multi - function   requirements   and   system   instability ' } 
{ ' abstract ' :   ' This   study   explores   the   impact   of   high - photovoltaic   ( PV )   penetration   on   the   inter - area   oscillation   modes   of   large - scale   power   grids .   A   series   of   dynamic   models   with   various   PV   penetration   levels   are   developed   based   on   a   detailed   model   representing   the   U . S .   Eastern   Interconnection   ( EI ) .   Transient   simulations   are   performed   to   investigate   the   change   of   inter - area   oscillation   modes   with   PV   penetration .   The   impact   of   PV   control   strategies   and   parameter   settings   on   inter - area   oscillations   is   studied .   This   paper   finds   that   as   PV   increases ,   the   damping   of   the   dominant   oscillation   mode   decreases   monotonically .   It   is   also   observed   that   the   mode   shape   varies   with   the   PV   control   strategy   and   new   oscillation   modes   may   emerge   under   inappropriate   parameter   settings   in   PV   plant   controls . ' ,   ' title ' :   ' Impact   of   High   PV   Penetration   on   the   Inter - Area   Oscillations   in   the   U . S .   Eastern   Interconnection ' } 
{ ' abstract ' :   ' The   objective   of   this   research   is   to   compare   the   effectiveness   of   different   tracking   devices   underwater .   There   have   been   few   works   in   aquatic   virtual   reality   ( VR )   —   i . e . ,   VR   systems   that   can   be   used   in   a   real   underwater   environment .   Moreover ,   the   works   that   have   been   done   have   noted   limitations   on   tracking   accuracy .   Our   initial   test   results   suggest   that   inertial   measurement   units   work   well   underwater   for   orientation   tracking   but   a   different   approach   is   needed   for   position   tracking .   Towards   this   goal ,   we   have   waterproofed   and   evaluated   several   consumer   tracking   systems   intended   for   gaming   to   determine   the   most   effective   approaches .   First ,   we   informally   tested   infrared   systems   and   fiducial   marker   based   systems ,   which   demonstrated   significant   limitations   of   optical   approaches .   Next ,   we   quantitatively   compared   inertial   measurement   units   ( IMU )   and   a   magnetic   tracking   system   both   above   water   ( as   a   baseline )   and   underwater .   By   comparing   the   devices   rotation   data ,   we   have   discovered   that   the   magnetic   tracking   system   implemented   by   the   Razer   Hydra   is   more   accurate   underwater   as   compared   to   a   phone - based   IMU .   This   suggests   that   magnetic   tracking   systems   should   be   further   explored   for   underwater   VR   applications . ' ,   ' title ' :   ' Towards   usable   underwater   virtual   reality   systems ' } 
{ ' abstract ' :   ' A   faulty   network   GG   is   under   the   conditional   fault   model ,   i . e . , \ xa0every   fault - free   vertex   of   GG   is   incident   to   at   least   two   fault - free   edges .   Let   FFvFFv   and   FFeFFe   be   the   set   of   faulty   vertices   and   faulty   edges   in   FQnFQn ,   respectively .   In   this   paper ,   we   consider   FQnFQn   under   the   conditional   fault   model   and   prove   that   if   | FFv | + | FFe | ≤ 2n − 4 | FFv | + | FFe | ≤ 2n − 4   and   n ≥ 3n ≥ 3 ,   then   FQn − FFv − FFeFQn − FFv − FFe   contains   a   fault - free   cycle   of   every   even   length   from   4   to   2n − 2 | FFv | 2n − 2 | FFv | ;   if   | FFv | + | FFe | ≤ 2n − 5 | FFv | + | FFe | ≤ 2n − 5   and   n ≥ 4n ≥ 4   is   even ,   then   FQn − FFv − FFeFQn − FFv − FFe   contains   a   fault - free   cycle   of   every   odd   length   from   n + 1n + 1   to   2n − 2 | FFv | − 12n − 2 | FFv | − 1 . ' ,   ' title ' :   ' Cycles   embedding   in   folded   hypercubes   under   the   conditional   fault   model ' } 
{ ' abstract ' :   ' Companies   have   invested   considerable   resources   in   the   implementation   of   enterprise   resource   planning   ( ERP )   systems .   The   results   initially   expected   have   rarely   been   reached .   The   optimisation   ( or   efficient   use )   of   such   information   systems   is   nowadays   becoming   a   major   factor   for   firms   striving   to   reach   their   performance   objectives .   After   presenting   a   synthesis   of   several   studies   on   ERP   projects ,   we   build   on   the   findings   of   a   French   investigation   into   the   assessment   and   optimisation   of   ERP   performance .   A   classification   of   company   positions   regarding   their   ERP   use ,   based   on   both   software   maturity   and   strategic   deployment   directions ,   and   an   improvement   process   are   proposed .   Industrial   cases   allow   validation   of   this   approach . ' ,   ' title ' :   ' A   classification   for   better   use   of   ERP   systems ' } 
{ ' abstract ' :   ' This   paper   presents   a   time - domain   biosensor   array   that   uses   a   capacitor - less   current - mode   analog - to - time   converter   ( CMATC )   and   logarithmic   cyclic   time - attenuation - based   TDC   with   discharging   acceleration .   Combining   the   exponential   function   of   the   CMATC   and   logarithmic   function   of   the   proposed   TDC   offers   linear   input - output   characteristics .   The   time - domain   property   enables   bio - imaging   at   a   high   spatial   resolution   and   large   scale   while   maintaining   scalability .   Measurement   results   with   a   0.25 - μ m   test   chip   successfully   demonstrated   linear   input - output   characteristics . ' ,   ' title ' :   ' A   scalable   time - domain   biosensor   array   using   logarithmic   cyclic   time - attenuation - based   TDC   for   high - resolution   and   large - scale   bio - imaging ' } 
{ ' abstract ' :   ' Compared   to   current   mobile   networks ,   next - generation   mobile   networks   are   expected   to   support   higher   numbers   of   simultaneously   connected   devices   and   to   achieve   higher   system   spectrum   efficiency   and   lower   power   consumption .   To   achieve   these   goals ,   we   study   the   multi - sharing   device - to - device   ( D2D )   communication ,   which   allows   any   cellular   user   equipment   to   share   its   radio   resource   with   multiple   D2D   devices .   We   jointly   consider   resource   block   reuse   and   power   control   and   then   develop   the   MISS   algorithm .   Simulation   results   show   that   MISS   performs   very   well   in   terms   of   transmission   power   consumption ,   system   throughput ,   and   the   number   of   permitted   D2D   devices . ' ,   ' title ' :   ' Joint   Resource   Block   Reuse   and   Power   Control   for   Multi - Sharing   Device - to - Device   Communication ' } 
{ ' abstract ' :   ' This   paper   is   concerned   with   event - triggered   H ∞ H ∞   filtering   for   delayed   neural   networks   via   sampled   data .   A   novel   event - triggered   scheme   is   proposed ,   which   can   lead   to   a   significant   reduction   of   the   information   communication   burden   in   the   network ;   the   feature   of   this   scheme   is   that   whether   or   not   the   sampled   data   should   be   transmitted   is   determined   by   the   current   sampled   data   and   the   error   between   the   current   sampled   data   and   the   latest   transmitted   data .   By   constructing   a   proper   Lyapunov – Krasovskii   functional ,   utilizing   the   reciprocally   convex   combination   technique   and   Jensen ’ s   inequality   sufficient   conditions   are   derived   to   ensure   that   the   resultant   filtering   error   system   is   asymptotically   stable .   Based   on   the   derived   H ∞ H ∞   performance   analysis   results ,   the   H ∞ H ∞   filter   design   is   formulated   in   terms   of   Linear   Matrix   Inequalities   ( LMIs ) .   Finally ,   the   proposed   stability   conditions   are   demonstrated   with   numerical   example . ' ,   ' title ' :   ' Event - triggered   H   ∞   filtering   for   delayed   neural   networks   via   sampled - data ' } 
{ ' abstract ' :   ' For   the   double   integrator   with   matched   Lipschitz   disturbances   we   propose   a   continuous   homogeneous   controller   providing   finite - time   stability   of   the   origin .   The   disturbance   is   compensated   exactly   in   finite   time   using   a   discontinuous   function   through   an   integral   action .   Since   the   controller   is   dynamic ,   the   closed   loop   is   a   third   order   system   that   achieves   a   third   order   sliding   mode   in   the   steady   state .   The   stability   and   robustness   properties   of   the   controller   are   proven   using   a   smooth   and   homogeneous   strict   Lyapunov   function   ( LF ) .   In   a   first   stage ,   the   gains   of   the   controller   and   the   LF   are   designed   using   a   method   based   on   Polya ’ s   Theorem .   In   a   second   stage   the   controller ’ s   gains   are   adjusted   through   a   sum   of   squares   representation   of   the   LF . ' ,   ' title ' :   ' Design   of   Continuous   Twisting   Algorithm ' } 
{ ' abstract ' :   ' Big   data   is   now   rapidly   expanding   into   various   domains   such   as   banking ,   insurance   and   e - commerce .   Data   analysis   and   related   studies   have   attracted   more   attentions .   In   health   insurance ,   abuse   of   diagnosis   is   one   of   the   key   fraud   problems ,   which   damages   the   interests   of   insured   people .   To   address   this   issue ,   numbers   of   studies   have   focused   on   this   topic .   This   paper   develops   a   healthcare   fraud   detection   approach   based   on   the   trustworthiness   of   doctors   to   distinguish   fraud   cases   from   normal   records .   Compared   to   conventional   methods ,   our   approach   can   detect   healthcare   fraud   in   a   good   accuracy   by   only   little   feature   information   from   healthcare   data   without   the   violation   of   privacy .   This   approach   combines   a   weighted   HITS   algorithm   with   a   frequent   pattern   mining   algorithm   to   calculate   a   rational   treatment   model   of   a   certain   disease .   In   addition ,   this   paper   also   introduces   the   copy   precision   behavior   in   the   treatment   sequences   of   patients ,   which   is   a   critical   metric   to   learn   the   trustworthiness   of   doctors .   The   numerical   validation   with   a   healthcare   dataset   demonstrates   that   healthcare   fraud   by   misdiagnosis   in   healthcare   treatments   can   be   successfully   detected   by   employing   the   developed   fraud   detection   approach . ' ,   ' title ' :   ' Healthcare   Fraud   Detection   Based   on   Trustworthiness   of   Doctors ' } 
{ ' abstract ' :   ' In   this   paper   we   study   data   collection   in   an   energy   renewable   sensor   network   for   scenarios   such   as   traffic   monitoring   on   busy   highways ,   where   sensors   are   deployed   along   a   predefined   path   ( the   highway )   and   a   mobile   sink   travels   along   the   path   to   collect   data   from   one - hop   sensors   periodically .   As   sensors   are   powered   by   renewable   energy   sources ,   time - varying   characteristics   of   ambient   energy   sources   poses   great   challenges   in   the   design   of   efficient   routing   protocols   for   data   collection   in   such   networks .   In   this   paper   we   first   formulate   a   novel   data   collection   maximization   problem   by   adopting   multi - rate   data   transmissions   and   performing   transmission   time   slot   scheduling ,   and   show   that   the   problem   is   NP - hard .   We   then   devise   an   offline   algorithm   with   a   provable   approximation   ratio   for   the   problem   by   exploiting   the   combinatorial   property   of   the   problem ,   assuming   that   the   harvested   energy   at   each   node   is   given   and   link   communications   in   the   network   are   reliable .   We   also   extend   the   proposed   algorithm   by   minor   modifications   to   a   general   case   of   the   problem   where   the   harvested   energy   at   each   sensor   is   not   known   in   advance   and   link   communications   are   not   reliable .   We   thirdly   develop   a   fast ,   scalable   online   distributed   algorithm   for   the   problem   in   realistic   sensor   networks   in   which   neither   the   global   knowledge   of   the   network   topology   nor   sensor   profiles   such   as   sensor   locations   and   their   harvested   energy   profiles   is   given .   Furthermore ,   we   also   consider   a   special   case   of   the   problem   where   each   node   has   only   a   fixed   transmission   power ,   for   which   we   propose   an   exact   solution   to   the   problem .   We   finally   conduct   extensive   experiments   by   simulations   to   evaluate   the   performance   of   the   proposed   algorithms .   Experimental   results   demonstrate   that   the   proposed   algorithms   are   efficient   and   the   solutions   obtained   are   fractional   of   the   optimum . ' ,   ' title ' :   ' Data   Collection   Maximization   in   Renewable   Sensor   Networks   via   Time - Slot   Scheduling ' } 
{ ' abstract ' :   ' An   increasing   number   of   businesses   are   migrating   their   IT   operations   to   the   cloud .   Likewise   there   is   an   increased   emphasis   on   data   analytics   based   on   multiple   datasets   and   sources   to   derive   information   not   derivable   when   a   dataset   is   mined   in   isolation .   While   ensuring   security   of   data   and   computation   outsourced   to   a   third   party   cloud   service   provider   is   in   itself   challenging ,   supporting   mash - ups   and   analytics   of   data   from   different   parties   hosted   across   different   services   is   even   more   so .   In   this   paper   we   propose   a   cloud - based   service   allowing   multiple   parties   to   perform   secure   multi - party   secure   sum   computation   using   their   clouds   as   delegates .   Our   scheme   provides   data   privacy   both   from   the   delegates   as   well   as   from   the   other   data   owners   under   a   lazy - and - curious   adversary   ( semi - honest )   model .   We   then   describe   how   such   a   secure   sum   primitive   may   be   used   in   various   collaborative ,   cloud - based   distributed   data   mining   tasks   ( classification ,   association   rule   mining   and   clustering ) .   We   implement   a   prototype   and   benchmark   the   service ,   both   as   a   stand - alone   secure   sum   service ,   and   as   a   building   block   for   more   complex   analytics .   The   results   suggest   reasonable   overhead   and   demonstrate   the   practicality   of   carrying   out   privacy   preserved   distributed   analytics   despite   migrating   ( encrypted )   data   to   pos -   sibly   different   and   untrusted   ( semi - honest )   cloud   services . ' ,   ' title ' :   ' Delegated   Secure   Sum   Service   for   Distributed   Data   Mining   in   Multi - Cloud   Settings ' } 
{ ' abstract ' :   ' This   paper   fundamentally   investigates   the   performance   of   evolutionary   multiobjective   optimization   ( EMO )   algorithms   for   computationally   hard   0 - 1   combinatorial   optimization ,   where   a   strict   theoretical   analysis   is   generally   out   of   reach   due   to   the   high   complexity   of   the   underlying   problem .   Based   on   the   examination   of   problem   features   from   a   multiobjective   perspective ,   we   improve   the   understanding   of   the   efficiency   of   a   simple   dominance - based   EMO   algorithm   with   unbounded   archive   for   multiobjective   NK - landscapes   with   correlated   objective   values .   More   particularly ,   we   adopt   a   statistical   approach ,   based   on   simple   and   multiple   linear   regression   analysis ,   to   enquire   the   expected   running   time   of   global   SEMO   with   restart   for   identifying   a   ( 1 + e ) - approximation   of   the   Pareto   set   for   small - size   enumerable   instances .   Our   analysis   provides   further   insights   on   the   EMO   search   behavior   and   on   the   most   important   features   that   characterize   the   difficulty   of   an   instance   for   this   class   of   problems   and   algorithms . ' ,   ' title ' :   ' A   feature - based   performance   analysis   in   evolutionary   multiobjective   optimization ' } 
{ ' abstract ' :   ' Functional   biological   sequences ,   which   typically   come   in   families ,   have   retained   some   level   of   similarity   and   function   during   evolution .   Finding   consensus   regions ,   alignment   of   sequences ,   and   identifying   the   relationship   between   a   sequence   and   a   family   allow   inferences   about   the   function   of   the   sequences .   Profile   hidden   Markov   models   ( HMMs )   are   generally   used   to   identify   those   relationships .   A   profile   HMM   can   be   trained   on   unaligned   members   of   the   family   using   conventional   algorithms   such   as   Baum - Welch ,   Viterbi ,   and   their   modifications .   The   overall   quality   of   the   alignment   depends   on   the   quality   of   the   trained   model .   Unfortunately ,   the   conventional   training   algorithms   converge   to   suboptimal   models   most   of   the   time .   This   work   proposes   a   training   algorithm   that   early   identifies   many   imperfect   models .   The   method   is   based   on   the   Simulated   Annealing   approach   widely   used   in   discrete   optimization   problems .   The   training   algorithm   is   implemented   as   a   component   in   HMMER .   The   performance   of   the   algorithm   is   discussed   on   protein   sequence   data . ' ,   ' title ' :   ' Simulated   annealing   algorithm   with   biased   neighborhood   distribution   for   training   profile   models ' } 
{ ' abstract ' :   ' The   Canny   algorithm   is   a   well   known   edge   detector   that   is   widely   used   in   the   previous   processing   stages   in   several   algorithms   related   to   computer   vision .   An   alternative ,   the   LIP - Canny   algorithm ,   is   based   on   a   robust   mathematical   model   closer   to   the   human   vision   system ,   obtaining   better   results   in   terms   of   edge   detection .   In   this   work   we   describe   LIP - Canny   algorithm   under   the   perspective   from   its   parallelization   and   optimization   by   using   the   NVIDIA   CUDA   framework .   Furthermore ,   we   present   comparative   results   between   an   implementation   of   this   algorithm   using   NVIDIA   CUDA   and   the   analogue   using   a   C / C++   approach . ' ,   ' title ' :   ' Parallelizing   and   optimizing   LIP - canny   using   NVIDIA   CUDA ' } 
{ ' abstract ' :   ' This   paper   presents   an   efficient   Bayesian   blind   multiuser   receiver   for   long   code   multipath   CDMA   systems .   The   proposed   receiver   employs   the   adaptive   sampling   method   for   the   Bayesian   inference   procedure   to   estimate   the   data   symbols   and   multipath   parameters .   Compared   to   the   other   reported   Bayesian   Monte   Carlo   receivers   for   long   code   multipath   CDMA   systems ,   the   proposed   one   achieves   a   faster   convergence   and   a   lower   computational   complexity   to   attain   comparable   performance .   Simulation   results   are   presented   to   demonstrate   the   effectiveness   of   the   proposed   Bayesian   blind   multiuser   receiver . ' ,   ' title ' :   ' Blind   Multiuser   Detection   for   Long   Code   Multipath   DS - CDMA   Systems   with   Bayesian   MC   Techniques ' } 
{ ' abstract ' :   ' Spreadsheets   are   by   far   the   most   prominent   example   of   end - user   programs   of   ample   size   and   substantial   structural   complexity .   In   addition ,   spreadsheets   are   usually   not   tested   very   rigorously   and   thus   comprise   faults .   Locating   faults   is   a   hard   task   due   to   the   size   and   the   structure ,   which   is   usually   not   directly   visible   to   the   user ,   i . e . ,   the   functions   are   hidden   behind   the   cells   and   only   the   computed   values   are   presented .   Hence ,   there   is   a   strong   need   for   debugging   support .   In   this   paper ,   we   adapt   three   program - debugging   approaches   that   have   been   designed   for   more   traditional   procedural   or   object - oriented   programming   languages .   These   techniques   are   Spectrum - based   Fault   Localization ,   Spectrum - Enhanced   Dynamic   Slicing ,   and   Constraint - based   Debugging .   Beside   the   theoretical   foundations ,   we   present   a   more   sophisticated   empirical   evaluation   including   a   comparison   of   these   approaches .   The   empirical   evaluation   shows   that   Sfl   ( Spectrum - based   Fault   Localization )   and   Sendys   ( Spectrum   ENhanced   Dynamic   Slicing )   are   the   most   promising   techniques . ' ,   ' title ' :   ' On   the   empirical   evaluation   of   fault   localization   techniques   for   spreadsheets ' } 
{ ' abstract ' :   ' This   work   provides   elements   to   highlight   the   reliability   challenges   related   to   the   technology   scaling   and   the   BTI   variability .   Through   main   milestones   including   device   reliability   scaling   model   ( for   both   mean   and   spread ) ,   a   discussion   on   the   physical   origin   of   BTI   variability   and   a   digital   IP   failure   rate   analytical   model ,   the   evolution   of   digital   IP   failure   rates   along   the   ITRS   scaling   roadmap   is   assessed .   and   an   analysis   of   the   ITRS   roadmap   on   digital   IP   failure   rates .   This   study   offers   new   perspectives   towards   product   hardening   and   qualification   with   respect   to   both   fresh   and   BTI - related   local   variability ,   especially   in   context   where   Adaptive   Voltage   Scaling   ( AVS )   is   used   to   compensate   for   process   centerings . ' ,   ' title ' :   ' From   BTI   variability   to   product   failure   rate :   A   technology   scaling   perspective ' } 
{ ' abstract ' :   ' In   this   paper   we   discuss   the   problem   of   calculating   the   reachable   states   of   a   dynamical   system   defined   by   ordinary   differential   equations   or   inclusions .   We   present   a   prototype   system   for   approximating   this   set   and   demonstrate   some   experimental   results . ' ,   ' title ' :   ' Reachability   Analysis   via   Face   Lifting ' } 
{ ' abstract ' :   ' By   introducing   the   new   concepts   of   fuzzy     β   - covering   and   fuzzy     β   - neighborhood ,   we   define   two   new   types   of   fuzzy   covering   rough   set   models   which   can   be   regarded   as   bridges   linking   covering   rough   set   theory   and   fuzzy   rough   set   theory .   We   show   the   properties   of   the   two   models ,   and   reveal   the   relationships   between   the   two   models   and   some   others .   Moreover ,   we   present   the   matrix   representations   of   the   newly   defined   lower   and   upper   approximation   operators   so   that   the   calculation   of   lower   and   upper   approximations   of   subsets   can   be   converted   into   operations   on   matrices .   Finally ,   we   generalize   the   models   and   their   matrix   representations   to     L   - fuzzy   covering   rough   sets   which   are   defined   over   fuzzy   lattices . ' ,   ' title ' :   ' Two   fuzzy   covering   rough   set   models   and   their   generalizations   over   fuzzy   lattices ' } 
{ ' abstract ' :   ' Mobile   applications   are   becoming   complex   software   systems   that   must   be   developed   quickly   and   evolve   regularly   to   fit   new   user   requirements   and   execution   contexts .   However ,   addressing   these   constraints   may   result   in   poor   design   choices ,   known   as   antipatterns ,   which   may   degrade   software   quality   and   performance .   Thus ,   the   automatic   detection   of   antipatterns   is   an   important   activity   that   eases   the   future   maintenance   and   evolution   tasks .   Moreover ,   it   helps   developers   to   refactor   their   applications   and   thus ,   to   improve   their   quality .   While   antipatterns   are   well - known   in   object - oriented   applications ,   their   study   in   mobile   applications   is   still   in   their   infancy .   In   this   paper ,   we   presents   a   tooled   approach ,   called   P   aprika   ,   to   analyze   Android   applications   and   to   detect   object - oriented   and   Android - specific   antipatterns   from   binaries   of   applications . ' ,   ' title ' :   ' An   approach   to   detect   Android   antipatterns ' } 
{ ' abstract ' :   ' In   this   paper   we   present   a   new   method   for   object   categorization .   Firstly   an   image   representation   is   obtained   by   the   proposed   hierarchical   learning   method   consisting   of   alternating   between   local   coding   and   maximum   pooling   operations ,   where   the   local   coding   operation   induces   discrimination   while   the   image   descriptor   and   maximum   pooling   operation   induces   invariance   in   hierarchical   architecture .   Then   the   obtained   effective   image   representation   is   passed   to   a   linear   classifier   which   is   suitable   for   large   databases   for   object   categorization .   We   have   demonstrated   that   the   proposed   method   is   robust   to   image   variations   and   has   low   sample   complexity . ' ,   ' title ' :   ' Object   categorization   based   on   hierarchical   learning ' } 
{ ' abstract ' :   ' We   have   previously   proposed   a   howling   canceller   which   cancels   howling   by   using   a   cascade   notch   filter   designed   from   a   distance   between   a   loudspeaker   and   a   microphone .   This   method   utilizes   a   pilot   signal   to   estimate   the   distance .   In   this   paper ,   we   introduce   two   methods   into   the   distance - based   howling   canceller   to   improve   speech   quality .   The   first   one   is   an   adaptive   cascade   notch   filter   which   adaptively   adjusts   the   nulls   to   eliminate   howling   and   to   keep   speech   components .   The   second   one   is   a   silent   pilot   signal   whose   frequencies   exist   in   the   ultrasonic   band ,   and   it   is   inaudible   while   on   transmission .   We   implement   the   proposed   howling   canceller   on   a   DSP   to   evaluate   its   capability .   The   experimental   results   show   that   the   proposed   howling   canceller   improves   speech   quality   in   comparison   to   the   conventional   one . ' ,   ' title ' :   ' A   High   Speech   Quality   Distance - Based   Howling   Canceller   with   Adaptive   Cascade   Notch   Filter   and   Silent   Pilot   Signal ' } 
{ ' abstract ' :   ' Purpose   –   This   paper   aims   to   look   at   how   varying   terminology   is   used   on   school   library   web   sites   and   how   that   compares   to   student   preferences . Design / methodology / approach   –   Provides   research   conduced   by   surveying   practicing   school   librarians   and   k ‐ 12   students . Findings   –   Terminology   varies   greatly   on   school   library   web   sites .   Further ,   students   prefer   common   language   use . Practical   implications   –   Practicing   librarians   may   consider   revising   their   web   sites   in   order   to   make   them   more   accessible   for   their   students . Originality / value   –   This   paper   provides   original   research   into   school   library   web   sites ,   an   area   that   is   lacking . ' ,   ' title ' :   ' School   library   web   site   terminology ' } 
{ ' abstract ' :   ' Recently ,   numerous   multireceiver   identity - based   encryption   or   identity - based   broadcast   encryption   schemes   have   been   introduced   with   bilinear   pairing   and   probabilistic   map - to - point   MTP   function .   As   the   bilinear   pairing   and   MTP   functions   are   expensive   operations ,   any   cryptographic   schemes   based   on   these   operations   experience   high   computational   burden .   The   certificateless   public   key   cryptography   sidesteps   the   private   key   escrow   problem   occurring   in   identity - based   cryptosystem   and   certificate   management   troubles   of   certificate   authority - based   public   key   cryptography   CA - PKC .   We   observed   that   certificateless   multireceiver   encryption   CL - MRE   scheme   without   pairing   and   MTP   hash   function   has   not   yet   been   considered   in   the   literature .   In   this   paper ,   we   proposed   a   bilinear   pairing   and   MTP   hash - function - free   CL - MRE   scheme   with   chosen   ciphertext   attack   resilience .   The   detailed   analyses   provide   evidence   that   our   scheme   achieves   forward   secrecy ,   backward   secrecy ,   and   low   computation   costs   than   others .   The   scheme   also   provides   confidentiality   of   the   message   and   receiver   anonymity   in   the   random   oracle   model   with   the   hardness   of   computational   Diffie - Hellman   problem .   Copyright   ©   2014   John   Wiley   &   Sons ,   Ltd . ' ,   ' title ' :   ' Anonymous   and   provably   secure   certificateless   multireceiver   encryption   without   bilinear   pairing ' } 
{ ' abstract ' :   ' We   study   the   problem   of   approximating   one - dimensional   nonintegrable   codistributions   by   integrable   ones   and   apply   the   resulting   approximations   to   approximate   feedback   linearization   of   single - input   systems .   The   approach   derived   in   this   paper   allows   a   linearizable   nonlinear   system   to   be   found   that   is   close   to   the   given   system   in   a   least - squares   ( L2 )   sense .   A   linearly   controllable   single - input   affine   nonlinear   system   is   feedback   linearizable   if   and   only   if   its   characteristic   distribution   is   involutive   ( hence   integrable )   or ,   equivalently ,   any   characteristic   one - form   ( a   one - form   that   annihilates   the   characteristic   distribution )   is   integrable .   We   study   the   problem   of   finding   ( least - squares   approximate )   integrating   factors   that   make   a   fixed   characteristic   one - form   close   to   being   exact   in   anL2   sense .   A   given   one - form   can   be   decomposed   into   exact   and   inexact   parts   using   the   Hodge   decomposition .   We   derive   an   upper   bound   on   the   size   of   the   inexact   part   of   a   scaled   characteristic   one - form   and   show   that   a   least - squares   integrating   factor   provides   the   minimum   value   for   this   upper   bound .   We   also   consider   higher - order   approximate   integrating   factors   that   scale   a   nonintegrable   one - form   in   a   way   that   the   scaled   form   is   closer   to   being   integrable   inL2   together   with   some   derivatives   and   derive   similar   bounds   for   the   inexact   part .   This   allows   a   linearizable   nonlinear   system   that   is   close   to   the   given   system   in   a   least - squares   ( L2 )   sense   together   with   some   derivatives   to   be   found .   The   Sobolev   embedding   techniques   allow   us   to   obtain   an   upper   bound   on   the   uniform   ( L ∞ )   distance   between   the   nonlinear   system   and   its   linearizable   approximation . ' ,   ' title ' :   ' Least - squares   integration   of   one - dimensional   codistributions   with   application   to   approximate   feedback   linearization ' } 
{ ' abstract ' :   ' Latent   sector   errors   in   disk   drives   affect   only   a   few   data   sectors .   They   occur   silently   and   are   detected   only   when   the   affected   area   is   accessed   again .   If   a   latent   error   is   detected   while   the   storage   system   is   operating   under   reduced   redundancy ,   i . e . ,   during   a   RAID   rebuild ,   then   data   loss   may   occur .   Various   features   such   as   scrubbing   and   intra - disk   data   redundancy   are   proposed   to   detect   and / or   recover   from   latent   errors   and   avoid   data   loss .   While   such   features   enhance   data   availability   in   the   storage   system ,   their   execution   may   cause   performance   degradation .   In   this   paper ,   we   evaluate   the   effectiveness   of   scrubbing   and   intra - disk   data   redundancy   in   improving   data   availability   while   the   overall   goal   is   to   maintain   user   performance   within   predefined   bounds .   We   show   that   by   treating   them   as   low   priority   background   activities   and   scheduling   them   efficiently   during   idle   times ,   these   features   remain   performance - wise   transparent   to   the   storage   system   user   while   still   improving   data   reliability .   Detailed   trace - driven   simulations   show   that   the   mean   time   to   data   loss   ( MTTDL )   improves   by   up   to   5   orders   of   magnitude   if   these   features   are   implemented   independently .   By   scheduling   concurrently   both   scrubbing   and   intra - disk   parity   updates   during   idle   times   in   disk   drives ,   MTTDL   improves   by   as   much   as   8   orders   of   magnitude . ' ,   ' title ' :   ' Enhancing   data   availability   in   disk   drives   through   background   activities ' } 
{ ' abstract ' :   ' Financial   crisis   forecasting   has   been   a   long - standing   challenge   that   often   involves   couplings   between   indicators   of   multiple   markets .   Such   couplings   include   implicit   relations   that   might   not   be   effectively   detected   from   raw   market   observations .   However ,   most   methods   for   crisis   forecasting   rely   directly   on   market   observations   and   might   not   detect   the   hidden   interactions   between   markets .   To   this   end ,   the   authors   explore   coupled   market   state   analysis   ( CMSA ) ,   assuming   that   the   observations   of   markets   are   governed   by   a   collection   of   intra -   and   intercoupled   hidden   market   states .   Accordingly ,   they   built   a   forecaster   based   on   these   coupled   market   states   instead   of   observations . ' ,   ' title ' :   ' Financial   Crisis   Forecasting   via   Coupled   Market   State   Analysis ' } 
{ ' abstract ' :   ' In   this   paper ,   an   “ intelligent ”   isolated   intersection   control   system   was   developed .   The   developed   “ intelligent ”   system   makes   “ real   time ”   decisions   as   to   whether   to   extend   ( and   how   much )   current   green   time .   The   model   developed   is   based   on   the   combination   of   the   dynamic   programming   and   neural   networks .   Many   tests   show   that   the   outcome   ( the   extension   of   the   green   time )   of   the   proposed   neural   network   is   nearly   equal   to   the   best   solution .   Practically   negligible   CPU   times   were   achieved ,   and   were   thus   absolutely   acceptable   for   the   “ real   time ”   application   of   the   developed   algorithm . ' ,   ' title ' :   ' Dynamic   programming — neural   network   real - time   traffic   adaptive   signal   control   algorithm ' } 
{ ' abstract ' :   ' This   issue   features   expanded   versions   of   articles   selected   from   the   2014   AAAI   Conference   on   Innovative   Applications   of   Artificial   Intelligence   held   in   Quebec   City ,   Canada .   We   present   a   selection   of   four   articles   describing   deployed   applications   plus   two   more   articles   that   discuss   work   on   emerging   applications . ' ,   ' title ' :   ' Introduction   to   the   Special   Issue   on   Innovative   Applications   of   Artificial   Intelligence   2014 ' } 
{ ' abstract ' :   ' Although   frequently   used   in   fractal   compression   quadrant - based   classification   exhibits   a   significant   defect   which   has   not   been   described   in   the   literature .   We   give   an   efficient   solution   to   this   problem   by   controlling   the   class   structure   based   on   an   adaptive   threshold .   This   makes   this   classification   technique   a   very   efficient   and   competitive   one   also   for   block   matching   motion   compensation   algorithms   in   video   coding . ' ,   ' title ' :   ' Resolving   a   defect   in   quadrant - based   classification   for   fast   block - matching ' } 
{ ' abstract ' :   ' Where   there   are   infinitely   many   possible   basic   states   of   the   world ,   a   standard   probability   function   must   assign   zero   probability   to   each   state   –   since   any   finite   probability   would   sum   to   over   one .   This   generates   problems   for   any   decision   theory   that   appeals   to   expected   utility   or   related   notions .   For   it   leads   to   the   view   that   a   situation   in   which   one   wins   a   million   dollars   if   any   of   a   thousand   of   the   equally   probable   states   is   realized   has   an   expected   value   of   zero   ( since   each   such   state   has   probability   zero ) .   But   such   a   situation   dominates   the   situation   in   which   one   wins   nothing   no   matter   what   ( which   also   has   an   expected   value   of   zero ) ,   and   so   surely   is   more   desirable .   I   formulate   and   defend   some   principles   for   evaluating   options   where   standard   probability   functions   cannot   strictly   represent   probability   –   and   in   particular   for   where   there   is   an   infinitely   spread ,   uniform   distribution   of   probability .   The   principles   appeal   to   standard   probability   functions ,   but   overcome   at   least   some   of   their   limitations   in   such   cases . ' ,   ' title ' :   ' Standard   decision   theory   corrected ' } 
{ ' abstract ' :   ' Backed   by   the   European   Commission ,   a   consortium   of   partners   from   European   industry ,   financial   institutions ,   and   academia   has   embarked   on   a   research   project   to   develop   the   fundamentals   of   secure   electronic   commerce .   The   goal   of   the   9 - million   ECU   project ,   SEMPER   ( Secure   Electronic   Marketplace   for   Europe ) ,   is   to   provide   the   first   open   and   comprehensive   solutions   for   secure   commerce   over   the   Internet   and   other   public   information   networks .   We   describe   the   objectives   and   summarise   the   initial   architecture   of   SEMPER .   A   wide   range   of   businesses   are   rapidly   moving   to   explore   the   huge   potential   of   net -   worked   information   systems ,   especially   with   the   Internet - based   WWW   ( World - wide   Web ) .   The   Internet ,   which   already   connects   more   than   3   million   computers   and   a   sub -   stantially   larger   number   of   users ,   is   growing   at   a   breathtaking   pace   with   thousands   of   newcomers   every   day .   Although   the   Internet   has   its   roots   in   academia   and   is   still   domi -   nated   by   free - of - charge   information ,   dramatic   changes   are   expected   in   the   near   future .   For   instance ,   the   WWW   will   be   used   for   a   wide   variety   of   electronic   commerce   such   as   on - line   trade   or   delivery   of   advanced   multimedia   information   services .   The   evolution   of   broadband   networks   and   " information   highways "   will   intensify   this   trend .   The   need   for   secure   transactions   in   this   new   business   environment ,   which   involves   networks   available   to   the   general   public ,   has   triggered   a   number   of   related   efforts .   These   initial   developments   are   based   almost   exclusively   in   the   US   and   most   of   them   are   limited   to   proprietary ,   or   otherwise   closed   solutions ,   involving   only   electronic   payment   issues .   In   contrast ,   SEMPER   is   directed   towards   a   comprehensive   solution   for   secure   electronic   commerce ,   considering   legal ,   commercial ,   social ,   and   technical   requirements   as   well   as   different   options   for   an   electronic   marketplace . ' ,   ' title ' :   ' Development   of   a   Secure   Electronic   Marketplace   for   Europe ' } 
{ ' abstract ' :   ' Through   the   use   of   a   global   geometric   symmetry ,   detection   ellipses   are   proposed   in   this   paper .   Based   on   the   geometric   symmetry ,   the   proposed   method   first   locates   candidates   of   ellipses   centers .   In   the   meantime ,   according   to   these   candidate   centers ,   all   feature   points   in   an   input   image   are   grouped   into   several   subimages .   Then ,   for   each   subimage ,   by   using   geometric   properties   again ,   all   ellipses   are   extracted .   The   method   significantly   reduces   the   time   required   to   evaluate   all   possible   parameters   without   using   edge   direction   information .   Experimental   results   are   given   to   show   the   correctness   and   effectiveness   of   the   proposed   method . ' ,   ' title ' :   ' Detection   ellipses   by   finding   lines   of   symmetry   in   the   images   via   an   hough   transform   applied   to   straight   lines ' } 
{ ' abstract ' :   ' Automatic   crawling   of   Rich   Internet   Applications   ( RIAs )   is   a   challenge   because   client - side   code   modifies   the   client   dynamically ,   fetch -   ing   server - side   data   asynchronously .   Most   existing   solutions   model   RIAs   as   state   machines   with   DOMs   as   states   and   JavaScript   events   execution   as   transitions .   This   approach   fails   when   used   with   " real - life " ,   complex   RIAs ,   because   the   size   of   the   produced   model   is   much   too   large   to   be   practical .   In   this   paper ,   we   propose   a   new   method   to   crawl   AJAX - based   RIAs   in   an   efficient   manner   by   detecting   " components " ,   which   are   areas   of   the   DOM   that   are   independent   from   each   other ,   and   by   crawling   each   component   separately .   This   leads   to   a   dramatic   reduction   of   the   required   state   space   for   the   model ,   without   loss   of   content   coverage .   Our   method   does   not   require   prior   knowledge   of   the   RIA   nor   predefined   definition   of   components .   Instead ,   we   infer   the   components   by   observing   the   be -   havior   of   the   RIA   during   crawling .   Our   experimental   results   show   that   our   method   can   index   quickly   and   completely   industrial   RIAs   that   are   simply   out   of   reach   for   traditional   methods . ' ,   ' title ' :   ' Indexing   Rich   Internet   Applications   Using   Components - Based   Crawling ' } 
{ ' abstract ' :   ' One   important   aspect   of   constructing   an   overlay   network   is   how   to   exploit   network   locality   in   the   underlying   network .   In   this   paper ,   we   propose   a   scalable   protocol   for   constructing   an   overlay   network   that   takes   account   of   locality   of   network   hosts .   The   constructed   overlay   network   can   significantly   decrease   the   communication   cost   between   end - hosts .   Our   simulation   results   show   that   the   average   distance   between   a   pair   of   hosts   in   the   constructed   overlay   network   is   only   about   11%   of   the   one   in   a   traditional ,   randomly   connected   overlay   network .   Furthermore ,   our   proposed   overlay   considered   to   be   more   scalable   than   tree - based   or   mesh - based   overlays . ' ,   ' title ' :   ' Measurement - based   construction   of   locality - aware   overlay   networks ' } 
{ ' abstract ' :   ' This   paper   presents   a   low   cost ,   flexible   and   customizable   delay   measurement   system   developed   to   assess   the   performance   of   the   VTPE - hBEB   protocol .   The   proposed   system   can   be   used   to   evaluate   other   communication   protocols   as   well   as   to   measure   the   delay   between   two   repetitive   events . ' ,   ' title ' :   ' Delay   measurement   system   for   real - time   serial   data   streams ' } 
{ ' abstract ' :   " Service   robots   have   become   increasingly   important   subjects   in   our   lives .   However ,   they   are   still   facing   problems   like   adaptability   to   their   users .   While   major   work   has   focused   on   intelligent   service   robots ,   the   proposed   approaches   were   mostly   user   independent .   Our   work   is   part   of   the   FUI - RoboPopuli   project ,   which   concentrates   on   endowing   entertainment   companion   robots   with   adaptive   and   social   behaviour .   In   particular ,   we   are   interested   in   robots   that   are   able   to   learn   and   plan   so   that   they   adapt   and   personalize   their   behaviour   according   to   their   users .   Markov   Decision   Processes   ( MDPs )   are   largely   used   for   adaptive   robots   applications .   However ,   one   challenging   point   is   reducing   the   sample   complexity   required   to   learn   an   MDP   model ,   including   the   reward   function .   In   this   article ,   we   present   our   contribution   regarding   the   representation   and   the   learning   of   the   reward   function   through   analysing   interaction   traces   ( i . e .   the   interaction   history   between   the   robot   and   their   users ,   including   users '   feedback ) .   Our   approach   permits   to   generalise   the   learned   rewards   so   that   when   new   users   are   introduced ,   the   robot   may   quickly   adapt   using   what   it   learned   from   previous   experiences   with   other   users .   We   propose ,   in   this   article ,   two   algorithms   to   learn   the   reward   function .   The   first   is   direct   and   certain ,   the   robot   applies   with   a   user   what   it   learned   during   interaction   with   same   kind   of   users   ( i . e .   users   with   similar   profiles ) .   The   second   algorithm   generalises   what   it   learns   to   be   applied   to   all   kinds   of   users .   Through   simulation ,   we   show   that   the   generalised   algorithm   converges   to   an   optimal   reward   function   with   less   than   half   the   samples   needed   by   the   direct   algorithm . " ,   ' title ' :   " Adaptive   and   Personalised   Robots   -   Learning   from   Users '   Feedback " } 
{ ' abstract ' :   " Researches   of   sensor   networks   collecting   patients '   data   with   computerized   triage   tags ,   called   Triage   Network ,   are   attracting   attention .   The   listening   power   used   in   triage   tags   is   the   major   factor   of   lots   of   energy   consumption ,   and   consumption   of   energy   increases   when   sensor   nodes   always   communicate   with   other   nodes   in   active   state .   Hence ,   we   suppose   that   sensor   nodes   are   put   to   sleep   periodically   to   avoid   running   out   of   battery .   However ,   some   nodes   have   mobility   and   nodes   secede   from   the   network   according   to   patients   conditions   in   Triage   Network .   The   paths   are   failed   and   it   is   needed   to   reconstruct   paths   when   these   forwarding   nodes   move   or   secede   from   network .   Therefore ,   data   arrival   ratio   decreases   and   consumption   of   battery   increases   due   to   reconstruction   of   other   paths .   In   this   paper ,   we   propose   a   data   collection   method   using   two   types   of   forwarding   nodes ,   Stable   Nodes   and   Energy   Efficient   Nodes .   This   method   uses   two   types   of   forwarding   nodes   according   to   priority   of   data   and   avoids   loss   of   high   priority   data ,   improves   the   data   arrival   ratio   and   saves   the   energy   consumption .   We   evaluate   the   proposed   method   and   show   its   effectiveness   using   computer   simulations . " ,   ' title ' :   ' Data   collection   method   using   two   types   of   forwarding   nodes   for   energy   saving   in   triage   network ' } 
{ ' abstract ' :   ' This   paper   introduces   Golay - paired   Hadamard   matrices   for   fast   compressed   sensing   of   sparse   signals   in   the   time   or   spectral   domain .   These   sampling   operators   feature   low - memory   requirement ,   hardware - friendly   implementation   and   fast   computation   in   reconstruction .   We   show   that   they   require   a   nearly   optimal   number   of   measurements   for   faithful   reconstruction   of   a   sparse   signal   in   the   time   or   frequency   domain .   Simulation   results   demonstrate   that   the   proposed   sensing   matrices   offer   a   reconstruction   performance   similar   to   that   of   fully   random   matrices . ' ,   ' title ' :   ' Golay   meets   Hadamard :   Golay - paired   Hadamard   matrices   for   fast   compressed   sensing ' } 
{ ' abstract ' :   ' In   this   technical   note ,   the   problem   of   finite - time   output   regulation   control   for   a   class   of   disturbed   system   under   mismatching   condition   is   investigated   via   a   composite   control   design   manner .   The   composite   controller   is   developed   by   using   a   finite   time   control   technique   and   a   finite   time   disturbance   observer   ( FTDO ) .   A   key   idea   is   to   design   virtual   control   laws   based   on   estimation   values   of   the   disturbances   and   the   ith   ( 1 ≤ i ≤ n - 1   where   n   is   the   order   of   the   system )   order   derivative   of   disturbances .   Finite   time   stability   analysis   for   the   augmented   system   is   presented   by   means   of   Lyapunov   stability   theorems ,   which   shows   that   the   system   output   is   regulated   to   zero   in   finite   time   even   in   the   presence   of   mismatched   disturbances .   A   motion   control   application   demonstrates   the   effectiveness   and   attractive   properties   of   the   proposed   method . ' ,   ' title ' :   ' Continuous   Finite - Time   Output   Regulation   for   Disturbed   Systems   Under   Mismatching   Condition ' } 
{ ' abstract ' :   ' In   this   paper   we   propose   an   approach   for   enhanced   data   protection   in   the   cloud ,   based   upon   accountability   governance .   Specifically ,   the   relationships   between   accountability ,   risk   and   trust   are   analyzed   in   order   to   suggest   characteristics   and   means   to   address   data   governance   issues   involved   when   organizations   or   individuals   adopt   cloud   computing .   This   analysis   takes   into   account   insights   from   a   variety   of   stakeholders   within   cloud   ecosystems   obtained   by   running   an   elicitation   workshop . ' ,   ' title ' :   ' Accountability ,   Risk ,   and   Trust   in   Cloud   Services :   Towards   an   Accountability - Based   Approach   to   Risk   and   Trust   Governance ' } 
{ ' abstract ' :   ' Xue   et   al .   recently   proposed   an   innovative   mutual   authentication   and   key   agreement   scheme   for   wireless   sensor   networks   based   on   temporal   credential   using   smart   cards .   However ,   in   this   paper   we   demonstrate   that   their   scheme   is   vulnerable   to   password   guessing   attacks ,   node   capture   attacks   and   denial - of - service   attacks .   Furthermore   we   show   that   their   scheme   has   some   inconsistencies   which   make   it   less   secure   and   more   computationally   costly   than   originally   presented . ' ,   ' title ' :   ' Notes   on   A   Temporal - Credential - Based   Mutual   Authentication   and   Key   Agreement   Scheme   for   Wireless   Sensor   Networks ' } 
{ ' abstract ' :   ' Persistent   Scatterer   Interferometry   ( PSI )   has   been   widely   used   for   landslide   studies   in   recent   years .   This   paper   investigated   the   spatial   patterns   of   PSI   point   targets   and   landslide   occurrences   in   the   Arno   River   basin   in   Central   Italy .   The   main   purpose   is   to   analyze   whether   spatial   patterns   of   Persistent   Scatterers   ( PS )   can   be   recognized   as   indicators   of   landslide   occurrences   throughout   the   whole   basin .   The   bivariate   K - function   was   employed   to   assess   spatial   relationships   between   PS   and   landslides .   The   PSI   point   targets   were   acquired   from   almost   4   years   ( from   March   2003   to   January   2007 )   of   RADARSAT - 1   images .   The   landslide   inventory   was   collected   from   15   years   ( from     1992 – 2007 )   of   surveying   and   mapping   data ,   mainly   including   remote   sensing   data ,   topographic   maps   and   field   investigations .   The   proposed   approach   is   able   to   assess   spatial   patterns   between   a   variety   of   PS   and   landslides ,   in   particular ,   to   understand   if   PSI   point   targets   are   spatially   clustered   ( spatial   attraction )   or   randomly   distributed   ( spatial   independency )   on   various   types   of   landslides   across   the   basin .   Additionally ,   the   degree   and   scale   distances   of   PS   clustering   on   a   variety   of   landslides   can   be   characterized .   The   results   rejected   the   null   hypothesis   that   PSI   point   targets   appear   to   cluster   similarly   on   four   types   of   landslides   ( slides ,   flows ,   falls   and   creeps )   in   the   Arno   River   basin .   Significant   influence   of   PS   velocities   and   acquisition   orbits   can   be   noticed   on   detecting   landslides   with   different   states   of   activities .   Despite   that   the   assessment   may   be   influenced   by   the   quality   of   landslide   inventory   and   Synthetic   Aperture   Radar   ( SAR )   images ,   the   proposed   approach   is   expected   to   provide   guidelines   for   studies   trying   to   detect   and   investigate   landslide   occurrences   at   a   regional   scale   through   spatial   statistical   analysis   of   PS ,   for   which   an   advanced   understanding   of   the   impact   of   scale   distances   on   landslide   clustering   is   fundamentally   needed . ' ,   ' title ' :   ' Investigating   Spatial   Patterns   of   Persistent   Scatterer   Interferometry   Point   Targets   and   Landslide   Occurrences   in   the   Arno   River   Basin ' } 
{ ' abstract ' :   ' This   article   describes   a   middleware   used   in   display   cluster   of   real   time   visual   simulation   system .   This   middleware   which   based   on   TCP / IP   protocol   provides   the   communication   infrastructure   for   visual   simulation   system .   It   provides   unified   process   logic   and   interfaces   for   various   status   and   frame   data   and   the   packing / unpacking   functions   of   simulation   data   without   concerning   the   details   of   the   data .   We   found   two   classes   of   display   synchronization   problems   and   provided   the   resolution   of   them .   The   middleware   provides   a   group   of   APIs   which   hide   the   details   of   data   packing / unpacking ,   processing   and   transmission   and   meets   the   requirement   of   flexibility ,   efficiency   and   extensibility .   This   middleware   has   been   successfully   implemented   to   the   display   cluster   of   several   tower   simulation   system . ' ,   ' title ' :   ' The   Research   of   High   Level   Data   Communication   Middleware   of   Display   Cluster   Used   in   Real   Time   Simulation   Environment ' } 
{ ' abstract ' :   ' The   scattering   parameters   are   fundamental   in   the   characterization   of   electrical   devices   at   high   frequencies .   They   are   particularly   useful   for   analyzing   multiport   high - frequency   and   microwave   networks .   However ,   they   are   not   adequately   presented   in   most ,   if   not   all ,   microwave   engineering   books .   This   paper   identifies   two   common   deficiencies   in   the   way   scattering   parameters   are   being   presented   in   these   books .   It   provides   additional   information   that   should   supplement   those   books   or   book   chapters   on   scattering   parameters . ' ,   ' title ' :   ' Deficiencies   in   the   way   scattering   parameters   are   taught ' } 
{ ' abstract ' :   ' We   study   the   reliability   maximization   problem   in   WDM   networks   with   random   link   failures .   Reliability   in   these   networks   is   defined   as   the   probability   that   the   logical   network   is   connected ,   and   it   is   determined   by   the   underlying   lightpath   routing   and   the   link   failure   probability .   We   show   that   in   general   the   optimal   lightpath   routing   depends   on   the   link   failure   probability ,   and   characterize   the   properties   of   lightpath   routings   that   maximize   the   reliability   in   different   failure   probability   regimes .   In   particular ,   we   show   that   in   the   low   failure   probability   regime ,   maximizing   the   ` ` cross - layer "   min   cut   of   the   ( layered )   network   maximizes   reliability ,   whereas   in   the   high   failure   probability   regime ,   minimizing   the   spanning   tree   of   the   network   maximizes   reliability .   Motivated   by   these   results ,   we   develop   lightpath   routing   algorithms   for   reliability   maximization . ' ,   ' title ' :   ' Maximizing   Reliability   in   WDM   Networks   through   Lightpath   Routing ' } 
{ ' abstract ' :   ' The   slope   of   the   active   distances   is   an   important   parameter   when   investigating   the   error - correcting   capability   of   convolutional   codes   and   the   distance   behavior   of   concatenated   convolutional   codes .   The   slope   of   the   active   distances   is   equal   to   the   minimum   average   weight   cycle   in   the   state - transition   diagram   of   the   encoder .   A   general   upper   bound   on   the   slope   depending   on   the   free   distance   of   the   convolutional   code   and   new   upper   bounds   on   the   slope   of   special   classes   of   binary   convolutional   codes   are   derived .   Moreover ,   a   search   technique ,   resulting   in   new   tables   of   rate   R = 1 / 2   and   rate   R = 1 / 3   convolutional   encoders   with   high   memories   and   large   active   distance - slopes   is   presented .   Furthermore ,   we   show   that   convolutional   codes   with   large   slopes   can   be   used   to   obtain   new   tailbiting   block   codes   with   large   minimum   distances .   Tables   of   rate   R = 1 / 2   and   rate   R = 1 / 3   tailbiting   codes   with   larger   minimum   distances   than   the   best   previously   known   quasi - cyclic   codes   are   given .   Two   new   tailbiting   codes   also   have   larger   minimum   distances   than   the   best   previously   known   binary   linear   block   codes   with   same   size   and   length .   One   of   them   is   also   superior   in   terms   of   minimum   distance   to   any   previously   known   binary   nonlinear   block   code   with   the   same   set   of   parameters . ' ,   ' title ' :   ' Tailbiting   codes   obtained   via   convolutional   codes   with   large   active   distance - slopes ' } 
{ ' abstract ' :   ' MIMO   wireless   technology   is   required   to   increase   the   data   rates   for   a   broad   range   of   applications ,   including   low   cost   mobile   devices .   In   this   paper   we   present   a   very   low   area   reconfigurable   MIMO   detector   which   achieves   a   high   throughput   of   103Mbps   and   uses   27   Kilo   Gates   when   implemented   in   a   commercial   180nm   CMOS   process .   The   low   area   is   achieved   by   the   proposed   in - place   architecture .   This   architecture   implements   the   K - best   algorithm   and   reduces   area   4 - fold   compared   to   the   widely   used   multi - stage   architecture ,   while   provides   reconfigurability   in   terms   of   antenna   configuration   during   real - time   operation . ' ,   ' title ' :   ' A   low - area   flexible   MIMO   detector   for   WiFi / WiMAX   standards ' } 
{ ' abstract ' :   ' Because   human   cognition   is   creative   and   socially   situated ,   knowledge   accumulates ,   diffuses ,   and   gets   applied   in   new   contexts ,   generating   cultural   analogs   of   phenomena   observed   in   population   genetics   such   as   adaptation   and   drift .   It   is   therefore   commonly   thought   that   elements   of   culture   evolve   through   natural   selection .   However ,   natural   selection   was   proposed   to   explain   how   change   accumulates   despite   lack   of   inheritance   of   acquired   traits ,   as   occurs   with   template - mediated   replication .   It   cannot   accommodate   a   process   with   significant   retention   of   acquired   or   horizontally   ( e . g .   socially )   transmitted   traits .   Moreover ,   elements   of   culture   cannot   be   treated   as   discrete   lineages   because   they   constantly   interact   and   influence   one   another .   It   is   proposed   that   what   evolves   through   culture   is   the   mind ;   ideas   and   artifacts   are   merely   reflections   of   its   current   evolved   state .   Interacting   minds   transform   ( in   part )   through   a   non - Darwinian   autopoietic   process   similar   to   that   by   which   early   life   evolved ,   involving   not   survival   of   the   fittest   but   actualization   of   their   potential . ' ,   ' title ' :   ' The   cultural   evolution   of   socially   situated   cognition ' } 
{ ' abstract ' :   ' Event   Extraction   is   a   complex   and   interesting   topic   in   Information   Extraction   that   includes   event   extraction   methods   from   free   text   or   web   data .   The   result   of   event   extraction   systems   can   be   used   in   several   fields   such   as   risk   analysis   systems ,   online   monitoring   systems   or   decide   support   tools .   In   this   paper ,   we   introduce   a   method   that   combines   lexico   - -   semantic   and   machine   learning   to   extract   event   from   Vietnamese   news .   Furthermore ,   we   concentrate   to   describe   event   online   monitoring   system   named   VnLoc   based   on   the   method   that   was   proposed   above   to   extract   event   in   Vietnamese   language .   Besides ,   in   experiment   phase ,   we   have   evaluated   this   method   based   on   precision ,   recall   and   F1   measure .   At   this   time   of   experiment ,   we   on   investigated   on   three   types   of   event :   FIRE ,   CRIME   and   TRANSPORT   ACCIDENT . ' ,   ' title ' :   ' VnLoc :   A   Real   - -   Time   News   Event   Extraction   Framework   for   Vietnamese ' } 
{ ' abstract ' :   ' Reliability   analysis   using   error   probabilities   for   combinational   logic   circuits   has   been   investigated   widely   in   the   literature .   Reliability   analysis   for   sequential   logic   circuits   using   these   methods   would   be   inaccurate   because   of   existence   of   loops   in   their   architecture .   In   this   paper   a   new   method   based   on   conversion   of   sequential   circuit   to   combinational   one   and   applying   an   iterative   reliability   analysis   is   developed .   A   Monte   Carlo   method - based   reliability   analysis   is   introduced   for   sequential   circuits ,   which   is   used   for   first   method   validation .   Experimental   results   demonstrate   good   accuracy   of   the   method . ' ,   ' title ' :   ' SEQUENTIAL   LOGIC   CIRCUITS   RELIABILITY   ANALYSIS ' } 
{ ' abstract ' :   ' According   to   the   Journey   to   Crime   theory ,   offenders   have   a   directionality   preference ,   in   the   form   of   an   activity   path ,   when   they   are   moving   about   in   their   environment   in   search   for   criminal   activities .   Using   clustering   techniques ,   this   theory   is   tested   using   crime   data   for   the   Province   of   British   Columbia ,   Canada .   The   activities   of   57 , 962   offenders   who   were   either   charged ,   chargeable ,   or   for   whom   charges   were   recommended   were   analyzed   by   mapping   their   offense   locations   with   respect   to   their   home   locations   to   determine   directionality .   Once   directionality   was   established ,   a   unique   clustering   technique ,   based   on   K - Means   clustering   and   modified   for   angles ,   was   applied   to   find   the   number   of   activity   paths   for   each   offender .   Although   the   number   of   activity   paths   varies   from   individual   to   individual ,   the   aggregate   pattern   was   very   consistent   with   theory .   It   was   found   that   people   only   have   a   few   activity   paths ,   even   if   they   are   highly   prolific   offenders . ' ,   ' title ' :   ' How   Many   Ways   Do   Offenders   Travel   - -   Evaluating   the   Activity   Paths   of   Offenders ' } 
{ ' abstract ' :   ' Pulse   Coupled   Neural   Network ( PCNN )   is   widely   used   in   the   field   of   image   processing ,   but   it   is   a   difficult   task   to   define   the   relative   parameters   properly   in   the   research   of   the   applications   of   PCNN .   So   far   the   determination   of   parameters   of   its   model   needs   a   lot   of   experiments .   To   deal   with   the   above   problem ,   a   document   segmentation   based   on   the   improved   PCNN   is   proposed .   It   uses   the   maximum   entropy   function   as   the   fitness   function   of   bacterial   foraging   optimization   algorithm ,   adopts   bacterial   foraging   optimization   algorithm   to   search   the   optimal   parameters ,   and   eliminates   the   trouble   of   manually   set   the   experiment   parameters .   Experimental   results   show   that   the   proposed   algorithm   can   effectively   complete   document   segmentation .   And   result   of   the   segmentation   is   better   than   the   contrast   algorithms .   ©   ( 2014 )   COPYRIGHT   Society   of   Photo - Optical   Instrumentation   Engineers   ( SPIE ) .   Downloading   of   the   abstract   is   permitted   for   personal   use   only . ' ,   ' title ' :   ' PCNN   document   segmentation   method   based   on   bacterial   foraging   optimization   algorithm ' } 
{ ' abstract ' :   ' Undirected   graphical   models   encode   in   a   graph   G   the   dependency   structure   of   a   random   vector   Y .   In   many   applications ,   it   is   of   interest   to   model   Y   given   another   random   vector   X   as   input .   We   refer   to   the   problem   of   estimating   the   graph   G ( x )   of   Y   conditioned   on   X   =   x   as   " graph - valued   regression " .   In   this   paper ,   we   propose   a   semiparametric   method   for   estimating   G ( x )   that   builds   a   tree   on   the   X   space   just   as   in   CART   ( classification   and   regression   trees ) ,   but   at   each   leaf   of   the   tree   estimates   a   graph .   We   call   the   method   " Graph - optimized   CART " ,   or   Go - CART .   We   study   the   theoretical   properties   of   Go - CART   using   dyadic   partitioning   trees ,   establishing   oracle   inequalities   on   risk   minimization   and   tree   partition   consistency .   We   also   demonstrate   the   application   of   Go - CART   to   a   meteorological   dataset ,   showing   how   graph - valued   regression   can   provide   a   useful   tool   for   analyzing   complex   data . ' ,   ' title ' :   ' Graph - Valued   Regression ' } 
{ ' abstract ' :   ' Over   the   last   two   decades ,   doubts   have   been   expressed   about   the   adequacy   of   materialism   as   the   correct   framework   for   explaining   phenomenal   consciousness   ( the   experience   of   saturated   greenness   one   has   when   looking   at   a   lush   lawn ,   for   example ) .   This   paper   reconstructs   a   generic   form   of   the   various   arguments   that   have   been   used   to   defend   the   view   of   the   materialistically   inexplicable   nature   of   consciousness   ( MINC ) .   This   reconstruction   reveals   that   the   arguments   turn   on   an   impoverished   notion   of   explanation .   By   discussing   some   examples   from   the   history   of   science ,   the   paper   shows   that   a   reasonable   notion   of   explanation   has   to   be   wider   than   the   one   utilized   in   the   argument   for   MINC ,   which   opens   the   possibility   for   the   materialistic   explicability   of   consciousness .   The   author   ends   the   paper   by   raising   a   question   about   the   very   intelligibility   of   the   project   of   trying   to   explain   the   so - called   nature   of   consciousness   as   opposed   to   the   regularities   characteristic   of   the   relation   between   states   of   consciousness   and   ... ' ,   ' title ' :   ' On   explaining   phenomenal   consciousness ' } 
{ ' abstract ' :   ' Successful   replication   within   an   infected   host   and   successful   transmission   between   hosts   are   key   to   the   continued   spread   of   most   pathogens .   Competing   selection   pressures   exerted   at   these   different   scales   can   lead   to   evolutionary   trade - offs   between   the   determinants   of   fitness   within   and   between   hosts .   Here ,   we   examine   such   a   trade - off   in   the   context   of   influenza   A   viruses   and   the   differential   pressures   exerted   by   temperature - dependent   virus   persistence .   For   a   panel   of   avian   influenza   A   virus   strains ,   we   find   evidence   for   a   trade - off   between   the   persistence   at   high   versus   low   temperatures .   Combining   a   within - host   model   of   influenza   infection   dynamics   with   a   between - host   transmission   model ,   we   study   how   such   a   trade - off   affects   virus   fitness   on   the   host   population   level .   We   show   that   conclusions   regarding   overall   fitness   are   affected   by   the   type   of   link   assumed   between   the   within -   and   between - host   levels   and   the   main   route   of   transmission   ( direct   or   environmental ) .   The   relative   importance   of   virulence   and   immune   response   mediated   virus   clearance   are   also   found   to   influence   the   fitness   impacts   of   virus   persistence   at   low   versus   high   temperatures .   Based   on   our   results ,   we   predict   that   if   transmission   occurs   mainly   directly   and   scales   linearly   with   virus   load ,   and   virulence   or   immune   responses   are   negligible ,   the   evolutionary   pressure   for   influenza   viruses   to   evolve   toward   good   persistence   at   high   within - host   temperatures   dominates .   For   all   other   scenarios ,   influenza   viruses   with   good   environmental   persistence   at   low   temperatures   seem   to   be   favored . ' ,   ' title ' :   ' A   Multi - scale   Analysis   of   Influenza   A   Virus   Fitness   Trade - offs   due   to   Temperature - dependent   Virus   Persistence ' } 
{ ' abstract ' :   ' Peer - to - Peer   ( P2P )   networks   are   largely   used   for   file - sharing   and   hence   must   provide   efficient   mechanisms   for   searching   the   files   stored   at   various   nodes .   The   existing   structuredP2P   overlays   support   only   ” exact - match ”   look - up   which   is   hardly   sufficient   in   a   file   sharing   network .   This   paper   addresses   the   problem   of   keyword - based   search   in   structured   P2P   networks .   We   propose   a   new   keyword - based   searching   algorithm   which   can   be   implemented   on   top   of   any   structured   P2P   overlay .   We   demonstrate   that   the   proposed   algorithm   achieves   very   good   searching   results   as   it   requires   the   minimum   number   of   messages   to   be   sent   in   order   to   find   all   the   references   to   files   containing   at   least   the   given   set   of   keywords . ' ,   ' title ' :   ' A   Keyword   Search   Algorithm   for   Structured   Peer - to - Peer   Networks ' } 
{ ' abstract ' :   ' In   this   paper ,   we   propose   an   adaptive   power   allocation   method   for   hybrid   relay   systems   that   employ   the   amplify - and - forward   and   decode - and - forward   protocols   simultaneously .   The   total   transmission   power   is   analytically   allocated   to   a   source   and   two   selected   relays   by   the   proposed   power   allocation   criterion   to   maximize   the   overall   received   signal - to - noise   ratio   at   the   destination .   Simulation   results   show   that   the   proposed   scheme   achieves   better   performance   than   that   of   conventional   cooperative   schemes   or   hybrid   systems   with   equal   power   allocation . ' ,   ' title ' :   ' Adaptive   relay   selection   and   power   allocation   for   hybrid   relay   systems ' } 
{ ' abstract ' :   ' The   unitary   rotation   of   square - pixellated   images   is   based   on   the   finite   su ( 2 ) - oscillator   model ,   which   describes   systems   whose   values   for   position ,   momentum   and   energy ,   are   discrete   and   finite .   In   a   two - dimensional   position   space ,   this   allows   the   construction   of   angular   momentum   states ,   orthonormal   and   complete ,   for   which   rotations   are   defined   as   multiplication   by   phases   that   carry   the   rotation   angle .   The   decomposition   of   a   digital   square   images   in   terms   of   these   angular   momentum   states   determines   a   unitary   ( hence   invertible )   rotation   of   the   image ,   whose   kernel   can   be   computed   as   a   four - dimensional   array   of   real   numbers . ' ,   ' title ' :   ' Unitary   rotation   of   square - pixellated   images ' } 
{ ' abstract ' :   ' As   more   mobile   storage   devices   are   used   in   consumer   electronics ,   possibility   of   user   confidential   data   leakage   increases .   To   make   things   worse ,   data   of   deleted   file   in   mobile   storage   such   as   USB   drives   can   be   easily   recovered   and ,   thus ,   can   be   vulnerable   to   data   leakage .   To   prevent   this   type   of   data   leakage ,   efficient   secure   deletion   techniques   are   required   and   we   present   two   secure   deletion   techniques ,   namely   block   cleaning   and   zero   overwriting ,   for   flash   memory   storage .   Also ,   we   propose   cost   and   benefit   models   of   both   techniques .   The   models   imply   an   existence   of   an   efficient   adaptive   hybrid   secure   deletion   scheme   that   applies   one   of   the   techniques   based   on   their   costs   and   benefits   at   given   data   arrangements .   Experimental   results   measured   on   an   embedded   board   show   that   the   adaptive   hybrid   scheme   deletes   data   securely   and   efficiently   for   various   data   patterns   on   flash   memory   storage . ' ,   ' title ' :   ' Models   and   Design   of   an   Adaptive   Hybrid   Scheme   for   Secure   Deletion   of   Data   in   Consumer   Electronics ' } 
{ ' abstract ' :   ' In   heterogeneous   and   dynamic   environments ,   efficient   execution   of   parallel   computations   can   require   mappings   of   tasks   to   processors   whose   performance   is   both   irregular   ( because   of   heterogeneity )   and   time - varying   ( because   of   dynamicity ) .   While   adaptive   domain   decomposition   techniques   have   been   used   to   address   heterogeneous   resource   capabilities ,   temporal   variations   in   those   capabilities   have   seldom   been   considered .   We   propose   a   conservative   scheduling   policy   that   uses   information   about   expected   future   variance   in   resource   capabilities   to   produce   more   efficient   data   mapping   decisions .   We   first   present   techniques ,   based   on   time   series   predictors   that   we   developed   in   previous   work ,   for   predicting   CPU   load   at   some   future   time   point ,   average   CPU   load   for   some   future   time   interval ,   and   variation   of   CPU   load   over   some   future   time   interval .   We   then   present   a   family   of   stochastic   scheduling   algorithms   that   exploit   such   predictions   of   future   availability   and   variability   when   making   data   mapping   decisions .   Finally ,   we   describe   experiments   in   which   we   apply   our   techniques   to   an   astrophysics   application .   The   results   of   these   experiments   demonstrate   that   conservative   scheduling   can   produce   execution   times   that   are   both   significantly   faster   and   less   variable   than   other   techniques . ' ,   ' title ' :   ' Conservative   Scheduling :   Using   Predicted   Variance   to   Improve   Scheduling   Decisions   in   Dynamic   Environments ' } 
{ ' abstract ' :   ' We   consider   a   class   of   restless   multi - armed   bandit   problems   that   arises   in   multi - channel   opportunistic   communications ,   where   channels   are   modeled   as   independent   and   stochastically   identical   Gilbert - Elliot   channels   and   channel   state   observations   are   subject   to   errors .   We   show   that   the   myopic   channel   selection   policy   has   a   semi - universal   structure   that   obviates   the   need   to   know   the   Markovian   transition   probabilities   of   the   channel   states .   Based   on   this   structure ,   we   establish   closed - form   lower   and   upper   bounds   on   the   steady - state   throughput   achieved   by   the   myopic   policy .   Furthermore ,   we   characterize   the   approximation   factor   of   the   myopic   policy   to   bound   its   worst - case   performance   loss   with   respect   to   the   optimal   performance . ' ,   ' title ' :   ' On   the   myopic   policy   for   a   class   of   restless   bandit   problems   with   applications   in   dynamic   multichannel   access ' } 
{ ' abstract ' :   ' We   show   that   the   optimum   length - / spl   nu /   guard   sequence   for   block   transmission   over   a   linear   Gaussian - noise   dispersive   channel   with   memory   / spl   nu /   is   a   linear   combination   of   the   N   information   symbols   of   the   block .   A   closed - form   expression   for   the   optimum   guard   sequence   is   derived   subject   to   a   total   average   energy   constraint   on   the   information   and   guard   symbols .   The   achievable   channel   block   throughput   with   the   optimum   guard   sequence   is   compared   with   that   achievable   with   two   common   guard   sequence   types ,   namely   zero   stuffing   and   cyclic   prefix . ' ,   ' title ' :   ' Guard   sequence   optimization   for   block   transmission   over   linear   frequency - selective   channels ' } 
{ ' abstract ' :   " A   modular   program   analysis   considers   components   independently   and   provides   a   succinct   summary   for   each   component ,   which   is   used   when   checking   the   rest   of   the   system .   Consider   a   system   consisting   of   a   library   and   a   client .   A   temporal   summary ,   or     interface   ,   of   the   library   specifies   legal   sequences   of   library   calls .   The   interface   is     safe     if   no   call   sequence   violates   the   library ' s   internal   invariants ;   the   interface   is     permissive     if   it   contains   every   such   sequence .   Modular   program   analysis   requires     full     interfaces ,   which   are   both   safe   and   permissive :   the   client   does   not   cause   errors   in   the   library   if   and   only   if   it   makes   only   sequences   of   library   calls   that   are   allowed   by   the   full   interface   of   the   library . Previous   interface - based   methods   have   focused   on   safe   interfaces ,   which   may   be   too   restrictive   and   thus   reject   good   clients .   We   present   an   algorithm   for   automatically   synthesizing   software   interfaces   that   are   both   safe   and   permissive .   The   algorithm   generates   interfaces   as   graphs   whose   vertices   are   labeled   with   predicates   over   the   library ' s   internal   state ,   and   whose   edges   are   labeled   with   library   calls .   The   interface   state   is   refined   incrementally   until   the   full   interface   is   constructed .   In   other   words ,   the   algorithm   automatically   synthesizes   a   typestate   system   for   the   library ,   against   which   any   client   can   be   checked   for   compatibility .   We   present   an   implementation   of   the   algorithm   which   is   based   on   the   BLAST   model   checker ,   and   we   evaluate   some   case   studies . " ,   ' title ' :   ' Permissive   interfaces ' } 
{ ' abstract ' :   ' In   this   paper ,   we   propose   a   new   method   for   the   motion   planning   problem   of   rigid   object   dexterous   manipulation   with   a   robotic   multi - fingered   hand ,   under   quasi - static   movement   assumption .   This   method   computes   both   object   and   finger   trajectories   as   well   as   the   finger   relocation   sequence .   Its   specificity   is   to   use   a   special   structuring   of   the   research   space   that   allows   to   search   for   paths   directly   in   the   particular   subspace   GS   n     which   is   the   subspace   of   all   the   grasps   that   can   be   achieved   with   n   grasping   fingers .   The   solving   of   the   dexterous   manipulation   planning   problem   is   based   upon   the   exploration   of   this   subspace .   The   proposed   approach   captures   the   connectivity   of   GS   n     in   a   graph   structure .   The   answer   of   the   manipulation   planning   query   is   then   given   by   searching   a   path   in   the   computed   graph .   Simulation   experiments   were   conducted   for   different   dexterous   manipulation   task   examples   to   validate   the   proposed   method . ' ,   ' title ' :   ' Dexterous   manipulation   planning   using   probabilistic   roadmaps   in   continuous   grasp   subspaces ' } 
{ ' abstract ' :   ' This   paper   presents   an   experimental   evaluation   of   different   line   extraction   algorithms   applied   to   2D   laser   scans   for   indoor   environments .   Six   popular   algorithms   in   mobile   robotics   and   computer   vision   are   selected   and   tested .   Real   scan   data   collected   from   two   office   environments   by   using   different   platforms   are   used   in   the   experiments   in   order   to   evaluate   the   algorithms .   Several   comparison   criteria   are   proposed   and   discussed   to   highlight   the   advantages   and   drawbacks   of   each   algorithm ,   including   speed ,   complexity ,   correctness   and   precision .   The   results   of   the   algorithms   are   compared   with   ground   truth   using   standard   statistical   methods .   An   extended   case   study   is   performed   to   further   evaluate   the   algorithms   in   a   SLAM   application . ' ,   ' title ' :   ' A   comparison   of   line   extraction   algorithms   using   2D   range   data   for   indoor   mobile   robotics ' } 
{ ' abstract ' :   ' This   study   investigates   the   use   of   force - stiffness   feedback ,   i . e . ,   a   combination   of   force   offset   and   extra   spring   load ,   in   UAV   tele - operation   with   transmission   time   delay .   The   goal   was   to   further   increase   the   level   of   safety   of   tele - operation   with   a   reduction   in   operator   workload   with   respect   to   force   feedback ,   i . e . ,   using   force   offset   alone .   A   theoretical   analysis   is   given   of   using   force - stiffness   feedback   to   improve   collision   avoidance .   Wave   variables   are   included   to   reduce   time   delay   effects .   An   experiment   was   conducted   to   investigate   the   effects   of   force - stiffness   feedback   on   safety   of   operation ,   operator   performance ,   control   activity ,   and   workload .   Results   indicate   that   force - stiffness   feedback   improves   the   haptic   interface   with   respect   to   force   feedback   alone .   Safety   of   tele - operation   increases   without   increasing   operator   workload   with   respect   to   force   feedback . ' ,   ' title ' :   ' Haptic   interface   in   UAV   tele - operation   using   force - stiffness   feedback ' } 
{ ' abstract ' :   ' Due   to   the   spread   of   the   internet   and   the   ever   increasing   number   of   web   applications ,   the   issue   of   compatibility   across   browsers   has   become   very   important .   This   compatibility   issue   is   also   referred   as   Cross   Browser   Inconsistency   ( XBI )   wherein   same   website   looks   or   behaves   differently   in   different   web   browsers .   In   this   paper   our   aim   is   to   address   this   issue   of   compatibility   and   propose   an   automated   approach   of   detecting   XBIs .   Cross   Browser   Inconsistencies   can   either   be   in   the   content ,   structure   or   behavior   of   the   webpage .   In   order   to   get   a   grasp   of   the   above   mentioned   types   of   inconsistencies ,   we   surveyed   some   random   websites   and   analyzed   them   in   different   browsers .   We   also   studied   the   basic   working   of   browser ,   in   order   to   establish   its   connection   with   the   occurrences   of   XBIs .   Each   browser   has   its   own   rendering   mechanisms ,   which   sometimes   differs   from   standards .   Hence ,   the   execution   of   these   websites   is   different   in   different   browsers .   Finally   we   have   proposed   an   automated   approach   for   XBI   detection . ' ,   ' title ' :   ' An   Automated   Approach   for   Cross - Browser   Inconsistency   ( XBI )   Detection ' } 
{ ' abstract ' :   ' We   present   a   formal   framework   that   combines   high - level   representation   and   causality - based   reasoning   with   low - level   geometric   reasoning   and   motion   planning .   The   frame - work   features   bilateral   interaction   between   task   and   motion   planning ,   and   embeds   geometric   reasoning   in   causal   reasoning ,   thanks   to   several   advantages   inherited   from   its   underlying   components .   In   particular ,   our   choice   of   using   a   causality - based   high - level   formalism   for   describing   action   domains   allows   us   to   represent   ramifications   and   state / transition   constraints ,   and   embed   in   such   formal   domain   descriptions   externally   defined   functions   implemented   in   some   programming   language   ( e . g . ,   C++ ) .   Moreover ,   given   such   a   domain   description ,   the   causal   reasoner   based   on   this   formalism   ( i . e . ,   the   Causal   Calculator )   allows   us   to   compute   optimal   solutions   ( e . g . ,   shortest   plans )   for   elaborate   planning / prediction   problems   with   temporal   constraints .   Utilizing   these   features   of   high - level   representation   and   reasoning ,   we   can   combine   causal   reasoning ,   motion   planning   and   geometric   planning   to   find   feasible   kinematic   solutions   to   task - level   problems .   In   our   framework ,   the   causal   reasoner   guides   the   motion   planner   by   finding   an   optimal   task - plan ;   if   there   is   no   feasible   kinematic   solution   for   that   task - plan   then   the   motion   planner   guides   the   causal   reasoner   by   modifying   the   planning   problem   with   new   temporal   constraints .   Furthermore ,   while   computing   a   task - plan ,   the   causal   reasoner   takes   into   account   geometric   models   and   kinematic   relations   by   means   of   external   predicates   implemented   for   geometric   reasoning   ( e . g . ,   to   check   some   collisions ) ;   in   that   sense   the   geometric   reasoner   guides   the   causal   reasoner   to   find   feasible   kinematic   solutions .   We   illustrate   an   application   of   this   framework   to   robotic   manipulation ,   with   two   pantograph   robots   on   a   complex   assembly   task   that   requires   concurrent   execution   of   actions .   A   short   video   of   this   application   accompanies   the   paper . ' ,   ' title ' :   ' Combining   high - level   causal   reasoning   with   low - level   geometric   reasoning   and   motion   planning   for   robotic   manipulation ' } 
{ ' abstract ' :   ' This   paper   presents   a   novel   template   matching   method   to   detect   and   track   pedestrians   for   people   counting   in   real - time .   Firstly ,   a   novel   background   subtraction   method   is   proposed   for   extracting   all   foreground   objects   from   background .   Then ,   a   shadow   elimination   method   is   used   to   remove   unwanted   shadow   from   the   background .   In   order   to   identify   pedestrians   from   non - pedestrian   objects ,   this   paper   proposed   a   novel   grid - based   template   matching   scheme   to   robustly   verify   each   pedestrian .   Usually ,   a   pedestrian   will   have   different   appearances   at   different   positions .   The   grid - based   approach   can   effectively   reduce   the   perspective   effects   into   a   minimum   since   it   uses   different   templates   to   record   the   appearance   changes   at   each   grid .   When   more   templates   are   used ,   the   detection   process   will   become   more   inefficient .   To   speed   up   its   efficiency ,   an   integral   image   is   used   to   filter   out   all   impossible   candidates   in   advance .   Lastly ,   a   tracking   method   is   applied   to   tracking   the   direction   of   each   moving   pedestrian   so   that   the   real   number   of   passing   people   per   direction   can   be   counted   more   accurately .   Experimental   results   have   proved   that   the   proposed   method   is   robust ,   accurate ,   and   powerful   in   people   counting . ' ,   ' title ' :   ' Grid - based   Template   Matching   for   People   Counting ' } 
{ ' abstract ' :   ' A   tomographic   image   reconstruction   algorithm   that   we   have   been   studying   requires   the   nth - order   Hankel   transform   for   the   nth   function   in   a   series ,   where   n   varies   over   a   set   of   integers .   Unfortunately ,   most   previously   proposed   algorithms   have   either   dealt   with   only   zeroth - order   transforms   or   cannot   be   applied   conveniently   to   our   problem .   We   propose   an   algorithm   for   computing   general   integer - order   Hankel   transforms .   The   algorithm   takes   samples   of   equally   spaced   input   functions   and   gives   equally   spaced   samples   of   the   transforms . ' ,   ' title ' :   ' An   algorithm   for   computing   general   integer - order   Hankel   transforms ' } 
{ ' abstract ' :   ' In   this   paper ,   we   present   a   real - time   approach   that   allows   tracking   deformable   structures   in   3D   ultrasound   sequences .   Our   method   consists   in   obtaining   the   target   displacements   by   combining   robust   dense   motion   estimation   and   mechanical   model   simulation .   We   perform   evaluation   of   our   method   through   simulated   data ,   phantom   data ,   and   real - data .   Results   demonstrate   that   this   novel   approach   has   the   advantage   of   providing   correct   motion   estimation   regarding   different   ultrasound   shortcomings   including   speckle   noise ,   large   shadows   and   ultrasound   gain   variation .   Furthermore ,   we   show   the   good   performance   of   our   method   with   respect   to   state - of - the - art   techniques   by   testing   on   the   3D   databases   provided   by   MICCAI   CLUST ’ 14   and   CLUST ’ 15   challenges . ' ,   ' title ' :   ' Real - time   target   tracking   of   soft   tissues   in   3D   ultrasound   images   based   on   robust   visual   information   and   mechanical   simulation ' } 
{ ' abstract ' :   ' For   two   given   graphs   G1G1   and   G2G2 ,   the   Ramsey   number   R ( G1 , G2 ) R ( G1 , G2 )   is   the   smallest   integer   NN   such   that   for   any   graph   of   order   NN ,   either   GG   contains   a   copy   of   G1G1   or   its   complement   contains   a   copy   of   G2G2 .   Let   CmCm   be   a   cycle   of   length   mm   and   K1 , nK1 , n   a   star   of   order   n + 1n + 1 .   Parsons   ( 1975 )   shows   that   R ( C4 , K1 , n ) ≤ n + ⌊ n − 1 ⌋ + 2   and   if   nn   is   the   square   of   a   prime   power ,   then   the   equality   holds .   In   this   paper ,   by   discussing   the   properties   of   polarity   graphs   whose   vertices   are   points   in   the   projective   planes   over   Galois   fields ,   we   prove   that   R ( C4 , K1 , q2 − t ) = q2 + q − ( t − 1 ) R ( C4 , K1 , q2 − t ) = q2 + q − ( t − 1 )   if   qq   is   an   odd   prime   power ,   1 ≤ t ≤ 2 ⌈ q4 ⌉   and   t ≠ 2 ⌈ q4 ⌉ − 1 ,   which   extends   a   result   on   R ( C4 , K1 , q2 − t ) R ( C4 , K1 , q2 − t )   obtained   by   Parsons   ( 1976 ) . ' ,   ' title ' :   ' Polarity   graphs   and   Ramsey   numbers   for   C   4   versus   stars ' } 
{ ' abstract ' :   ' This   paper   deals   with   the   problem   of   assuring   strict   QoS   guarantees   for   the   end   to   end   connections   that   originate   from   Ethernet   access   network .   It   shows   that   despite   high   link   capacities   in   some   cases   Ethernet   network   might   be   the   reason   of   QoS   deterioration .   The   primary   reason   is   the   lack   of   appropriate   QoS   differentiation   and   traffic   isolation   mechanisms .   The   shared   buffers   and   priority   schedulers   available   in   most   of   Ethernet   switches   appear   to   be   not   sufficient   to   guarantee   strict   QoS .   For   these   cases   new   solution   is   proposed   which   relies   on   additional   traffic   control   mechanisms   available   in   other   network   elements .   Only   additional   mechanism   supporting   typical   functionality   of   Ethernet   switch   can   provide   strict   QoS   guarantees   what   was   verified   in   simulations   studies . ' ,   ' title ' :   ' On   assuring   QoS   in   Ethernet   access   network ' } 
{ ' abstract ' :   ' The   federal   Medicare   regulations   reimburse   hospitals   on   a   pro   rata   share   of   the   hospital \ ' s   cost .   Hence ,   to   meet   its   financial   requirements ,   a   hospital   is   forced   to   shift   more   of   the   financial   burdens   onto   its   private   patients .   This   procedure   has   contributed   to   double   digit   inflation   in   hospital   prices   and   to   proposed   federal   regulation   to   control   the   rate   of   increase   in   hospital   revenues .   In   this   regulatory   environment ,   we   develop   nonlinear   programming   pricing   and   cost   allocation   models   to   aid   hospital   administrators   in   meeting   their   profit   maximizing   and   profit   satisficing   goals .   The   model   enables   administrators   to   explore   tactical   issues   such   as :   i   studying   the   relationship   between   a   voluntary   or   legislated   cap   on   a   hospital \ ' s   total   revenues   and   the   hospital \ ' s   profitability ,   ii   identifying   those   departments   within   the   hospital   that   are   the   most   attractive   candidates   for   cost   reduction   or   cost   containment   efforts ,   and   iii   isolating   those   services   that   should   be   singled   out   by   the   hospital   manager   for   renegotiation   of   the   prospective   or   " customary   and   reasonable "   cap .   Finally ,   the   modeling   approach   is   helpful   in   explaining   the   departmental   cross   subsidies   observed   in   practice ,   and   can   be   of   aid   to   federal   administrators   in   assessing   the   impacts   of   proposed   changes   in   the   Medicare   reimbursement   formula . ' ,   ' title ' :   ' Hospital   Profit   Planning   under   Medicare   Reimbursement ' } 
{ ' abstract ' :   ' We   present   a   ( 4   +   epsilon )   approximation   algorithm   for   weighted   graph   matching   which   applies   in   the   semistreaming ,   sliding   window ,   and   MapReduce   models ;   this   single   algorithm   improves   the   previous   best   algorithm   in   each   model .   The   algorithm   operates   by   reducing   the   maximum - weight   matching   problem   to   a   polylog   number   of   copies   of   the   maximum - cardinality   matching   problem .   The   algorithm   also   extends   to   provide   approximation   guarantees   for   the   more   general   problem   of   finding   weighted   independent   sets   in   p - systems   ( which   include   intersections   of   p   matroids   and   p - bounded   hypergraph   matching ) . ' ,   ' title ' :   ' Improved   Streaming   Algorithms   for   Weighted   Matching ,   via   Unweighted   Matching ' } 
{ ' abstract ' :   ' This   paper   presents   a   novel   approach   to   efficiently   solve   parameter - dependent   ( PD )   linear   matrix   inequality   ( LMI )   problems   for ,   amongst   others ,   linear   parameter - varying   ( LPV )   control   design .   Typically ,   stability   and   performance   is   guaranteed   by   finding   a   PD   Lyapunov   function   such   that   a   PD   LMI   is   feasible   on   a   parameter   domain .   To   solve   the   resulting   semi - infinite   problems ,   we   propose   a   novel   LMI   relaxation   technique   relying   on   B - spline   basis   functions .   This   technique   provides   less   conservative   solutions   and / or   a   reduced   numerical   burden   compared   to   existing   approaches .   Moreover ,   an   elegant   generalization   of   worst - case   optimization   to   the   optimization   of   any   signal   norm   is   obtained   by   expressing   performance   bounds   as   a   function   of   the   system   parameters .   This   generalization   yields   better   performance   bounds   in   a   large   part   of   the   parameter   domain .   Numerical   comparisons   with   the   current   state - of - the - art   demonstrate   the   generality   and   effectiveness   of   our   approach . ' ,   ' title ' :   ' Control   of   linear   parameter - varying   systems   using   B - splines ' } 
{ ' abstract ' :   ' There   is   a   growing   interest   in   simulating   natural   phenomena   in   computer   graphics   applications .   Animating   natural   scenes   in   real   time   is   one   of   the   most   challenging   problems   due   to   the   inherent   complexity   of   their   structure ,   formed   by   millions   of   geometric   entities ,   and   the   interactions   that   happen   within .   An   example   of   natural   scenario   that   is   needed   for   games   or   simulation   programs   are   forests .   Forests   are   difficult   to   render   because   the   huge   amount   of   geometric   entities   and   the   large   amount   of   detail   to   be   represented .   Moreover ,   the   interactions   between   the   objects   ( grass ,   leaves )   and   external   forces   such   as   wind   are   complex   to   model .   In   this   paper   we   concentrate   in   the   rendering   of   falling   leaves   at   low   cost .   We   present   a   technique   that   exploits   graphics   hardware   in   order   to   render   thousands   of   leaves   with   different   falling   paths   in   real   time   and   low   memory   requirements . ' ,   ' title ' :   ' Rendering   falling   leaves   on   graphics   hardware ' } 
{ ' abstract ' :   ' We   previously   presented   DriverDB ,   a   database   that   incorporates   ∼ 6000   cases   of   exome - seq   data ,   in   addition   to   annotation   databases   and   published   bioinformatics   algorithms   dedicated   to   driver   gene / mutation   identification .   The   database   provides   two   points   of   view ,   ‘ Cancer ’   and   ‘ Gene ’ ,   to   help   researchers   visualize   the   relationships   between   cancers   and   driver   genes / mutations .   In   the   updated   DriverDBv2   database   ( http : / / ngs . ym . edu . tw / driverdb )   presented   herein ,   we   incorporated   > 9500   cancer - related   RNA - seq   datasets   and   > 7000   more   exome - seq   datasets   from   The   Cancer   Genome   Atlas   ( TCGA ) ,   International   Cancer   Genome   Consortium   ( ICGC ) ,   and   published   papers .   Seven   additional   computational   algorithms   ( meaning   that   the   updated   database   contains   15   in   total ) ,   which   were   developed   for   driver   gene   identification ,   are   incorporated   into   our   analysis   pipeline ,   and   the   results   are   provided   in   the   ‘ Cancer ’   section .   Furthermore ,   there   are   two   main   new   features ,   ‘ Expression ’   and   ‘ Hotspot ’ ,   in   the   ‘ Gene ’   section .   ‘ Expression ’   displays   two   expression   profiles   of   a   gene   in   terms   of   sample   types   and   mutation   types ,   respectively .   ‘ Hotspot ’   indicates   the   hotspot   mutation   regions   of   a   gene   according   to   the   results   provided   by   four   bioinformatics   tools .   A   new   function ,   ‘ Gene   Set ’ ,   allows   users   to   investigate   the   relationships   among   mutations ,   expression   levels   and   clinical   data   for   a   set   of   genes ,   a   specific   dataset   and   clinical   features . ' ,   ' title ' :   ' DriverDBv2 :   a   database   for   human   cancer   driver   gene   research ' } 
{ ' abstract ' :   ' Thousands   of   deep   and   wide   pipelines   working   concurrently   make   GPGPU   high   power   consuming   parts .   Energy - efficiency   techniques   employ   voltage   overscaling   that   increases   timing   sensitivity   to   variations   and   hence   aggravating   the   energy   use   issues .   This   paper   proposes   a   method   to   increase   spatiotemporal   reuse   of   computational   effort   by   a   combination   of   compilation   and   micro - architectural   design .   An   associative   memristive   memory   ( AMM )   module   is   integrated   with   the   floating   point   units   ( FPUs ) .   Together ,   we   enable   fine - grained   partitioning   of   values   and   find   high - frequency   sets   of   values   for   the   FPUs   by   searching   the   space   of   possible   inputs ,   with   the   help   of   application - specific   profile   feedback .   For   every   kernel   execution ,   the   compiler   pre - stores   these   high - frequent   sets   of   values   in   AMM   modules   - -   representing   partial   functionality   of   the   associated   FPU - -   that   are   concurrently   evaluated   over   two   clock   cycles .   Our   simulation   results   show   high   hit   rates   with   32 - entry   AMM   modules   that   enable   36%   reduction   in   average   energy   use   by   the   kernel   codes .   Compared   to   voltage   overscaling ,   this   technique   enhances   robustness   against   timing   errors   with   39%   average   energy   saving . ' ,   ' title ' :   ' Energy - Efficient   GPGPU   Architectures   via   Collaborative   Compilation   and   Memristive   Memory - Based   Computing ' } 
{ ' abstract ' :   ' Quasi - cyclic   codes   are   renowned   for   their   structural   design   and   low - complexity   shift   register   encoding .   However ,   existing   design   techniques   based   on   difference   families   have   limited   code   size   options   due   to   algebraic   constraints .   We   introduce   in   this   paper   a   notation   of   extended   difference   family   ( EDF )   and   provide   a   systematic   code   design   based   on   EDFs   with   a   high   degree   of   flexibility   in   code   size .   Short / medium - length   codes   of   high   rate   ( / spl   ges /   0.9 )   can   be   easily   constructed . ' ,   ' title ' :   ' Quasi - cyclic   codes   from   extended   difference   families ' } 
{ ' abstract ' :   ' Lexical   cohesion   arises   from   a   chain   of   lexical   items   that   establish   links   between   sentences   in   a   text .   In   this   paper   we   propose   three   different   models   to   capture   lexical   cohesion   for   document - level   machine   translation :   ( a )   a   direct   reward   model   where   translation   hypotheses   are   rewarded   whenever   lexical   cohesion   devices   occur   in   them ,   ( b )   a   conditional   probability   model   where   the   appropriateness   of   using   lexical   cohesion   devices   is   measured ,   and   ( c )   a   mutual   information   trigger   model   where   a   lexical   cohesion   relation   is   considered   as   a   trigger   pair   and   the   strength   of   the   association   between   the   trigger   and   the   triggered   item   is   estimated   by   mutual   information .   We   integrate   the   three   models   into   hierarchical   phrase - based   machine   translation   and   evaluate   their   effectiveness   on   the   NIST   Chinese - English   translation   tasks   with   large - scale   training   data .   Experiment   results   show   that   all   three   models   can   achieve   substantial   improvements   over   the   baseline   and   that   the   mutual   information   trigger   model   performs   better   than   the   others . ' ,   ' title ' :   ' Modeling   lexical   cohesion   for   document - level   machine   translation ' } 
{ ' abstract ' :   ' This   paper   presents   a   lightweight   sketching   system   that   enables   interactive   illustration   of   complex   fluid   systems .   Users   can   sketch   on   a   2.5 - dimensional   ( 2.5 D )   canvas   to   design   the   shapes   and   connections   of   a   fluid   circuit .   These   input   sketches   are   automatically   analyzed   and   abstracted   into   a   hydraulic   graph ,   and   a   new   hybrid   fluid   model   is   used   in   the   background   to   enhance   the   illustrations .   The   system   provides   rich   simple   operations   for   users   to   edit   the   fluid   system   incrementally ,   and   the   new   internal   flow   patterns   can   be   simulated   in   real   time .   Our   system   is   used   to   illustrate   various   fluid   systems   in   medicine ,   biology ,   and   engineering .   We   asked   professional   medical   doctors   to   try   our   system   and   obtained   positive   feedback   from   them . ' ,   ' title ' :   ' Sketch - based   Dynamic   Illustration   of   Fluid   Systems ' } 
{ ' abstract ' :   ' We   present   an   improved   zone   content   classification   method   and   its   performance   evaluation .   We   added   two   new   features   to   the   feature   vector   from   one   previously   published   method   ( Sivaramakrishnan   et   al . ,   1995 ) .   We   assumed   different   independence   relationships   in   two   zone   sets .   We   used   an   optimized   binary   decision   tree   to   estimate   the   maximum   zone   content   class   probability   in   one   set   while   using   the   Viterbi   algorithm   to   find   the   optimal   solution   for   a   zone   sequence   in   the   other   set .   The   training ,   pruning   and   testing   data   set   for   the   algorithm   include   1 , 600   images   drawn   from   the   UWCDROM   III   document   image   database .   The   classifier   is   able   to   classify   each   given   scientific   and   technical   document   zone   into   one   of   the   nine   classes ,   2   text   classes   ( of   font   size   4   -   18pt   and   font   size   19   -   32   pt ) ,   math ,   table ,   halftone ,   map / drawing ,   ruling ,   logo ,   and   others .   Compared   with   our   previous   work   ( Wang   et   al . ,   2000 ) ,   it   raised   the   accuracy   rate   to   98.52%   from   97.53%   and   reduced   the   mean   false   alarm   rate   to   0.53%   from   1.26% . ' ,   ' title ' :   ' Zone   content   classification   and   its   performance   evaluation ' } 
{ ' abstract ' :   ' Big   Data   applications   require   real - time   processing   of   complex   computations   on   streaming   and   static   information .   Applications   such   as   the   diagnosis   of   power   generating   turbines   require   the   integration   of   high   velocity   streaming   and   large   volume   of   static   data   from   multiple   sources .   In   this   paper   we   study   various   optimisations   related   to   efficiently   processing   of   streaming   and   static   information .   We   introduce   novel   indexing   structures   for   stream   processing ,   a   query - planner   component   that   decides   when   their   creation   is   beneficial ,   and   we   examine   precomputed   summarisations   on   archived   measurements   to   accelerate   streaming   and   static   information   processing .   To   put   our   ideas   into   practise ,   we   have   developed   Exa   Stream ,   a   data   stream   management   system   that   is   scalable ,   has   declarative   semantics ,   supports   user   defined   functions ,   and   allows   efficient   execution   of   complex   analytical   queries   on   streaming   and   static   data .   Our   work   is   accompanied   by   an   empirical   evaluation   of   our   optimisation   techniques . ' ,   ' title ' :   ' Real   time   processing   of   streaming   and   static   information ' } 
{ ' abstract ' :   " In   the   last   ten   years ,   speech   recognition   has   evolved   from   a   science   fiction   dream   to   a   widespread   input   method   for   mobile   devices .   In   this   talk ,   I   will   describe   how   speech   recognition   works ,   the   problems   we   have   solved   and   the   challenges   that   remain .   I   will   touch   upon   some   of   Google ' s   main   efforts   in   language   and   pronunciation   modeling ,   and   describe   how   the   adoption   of   neural   networks   for   acoustic   modeling   marked   the   beginning   of   a   technology   revolution   in   the   field ,   with   approaches   such   as   Long   Short   Term   Memory   models   and   Connectionist   Temporal   Classification .   I   will   also   share   my   learnings   on   how   Machine   Learning   and   Human   Knowledge   can   be   harmoniously   combined   to   build   state - of - the - art   technology   that   helps   and   delights   users   across   the   world . " ,   ' title ' :   ' Learnings   and   innovations   in   speech   recognition ' } 
{ ' abstract ' :   ' Nowadays ,   the   explosive   growth   and   variety   of   information   available   on   the   Web   frequently   overwhelms   users   and   leads   users   to   make   poor   decisions .   Consequently ,   recommender   systems   have   become   more   and   more   important   to   assist   people   to   make   decisions   faster .   Among   all   related   techniques ,   collaborative   filtering   approach   is   currently   one   of   the   effective   and   widely   used   techniques   to   build   recommender   systems .   However ,   there   are   major   challenges   like   data   sparsity   and   scalability .   Meanwhile   it   is   hard   to   integrate   demographic   statistical   information   ( Age ,   gender   and   occupation   etc . )   to   collaborative   filtering   model .   Unfortunately ,   it   is   significant   to   take   account   into   these   information ,   especially   user   occupation   when   making   recommendation .   As   we   all   know ,   people   with   different   occupations   may   have   totally   different   tastes .   It   has   been   proved   that   restricted   Boltzmann   machines ( RBM )   model   can   infer   lower - dimensional   representations   automatically   and   is   potential   in   handling   large   and   sparse   dataset .   In   this   paper ,   we   propose   an   improved   User   Occupation   aware   Conditional   Restricted   Boltzmann   Machine   Frame ( UO - CRBMF )   model ,   which   employs   an   improved   RBM   and   takes   full   use   of   user   occupation   information   by   adding   a   conditional   layer   with   user   occupation   information .   Experimental   studies   on   the   standard   benchmark   datasets   of   MovieLens   100k   and   MovieLens   1M   have   shown   its   potential   and   advantages   beyond   baseline   methods . ' ,   ' title ' :   ' User   Occupation   Aware   Conditional   Restricted   Boltzmann   Machine   Based   Recommendation ' } 
{ ' abstract ' :   ' Microservices   complement   approaches   like   DevOps   and   continuous   delivery   in   terms   of   software   architecture .   Along   with   this   architectural   style ,   several   important   deployment   technologies ,   such   as   container - based   virtualization   and   container   orchestration   solutions ,   have   emerged .   These   technologies   allow   to   efficiently   exploit   cloud   platforms ,   providing   a   high   degree   of   scalability ,   availability ,   and   portability   for   microservices .# R ## N ## R ## N # Despite   the   obvious   importance   of   a   sufficient   level   of   performance ,   there   is   still   a   lack   of   performance   engineering   approaches   explicitly   taking   into   account   the   particularities   of   microservices .   In   this   paper ,   we   argue   why   new   solutions   to   performance   engineering   for   microservices   are   needed .   Furthermore ,   we   identify   open   issues   and   outline   possible   research   directions   with   regard   to   performance - aware   testing ,   monitoring ,   and   modeling   of   microservices . ' ,   ' title ' :   ' Performance   Engineering   for   Microservices :   Research   Challenges   and   Directions ' } 
{ ' abstract ' :   ' Intelligent   agents ,   such   as   robots ,   have   to   serve   a   multitude   of   autonomous   functions .   Examples   are ,   e . g . ,   collision   avoidance ,   navigation   and   route   planning ,   active   sensing   of   its   environment ,   or   the   interaction   and   non - verbal   communication   with   people   in   the   extended   reach   space .   Here ,   we   focus   on   the   recognition   of   the   action   of   a   human   agent   based   on   a   biologically   inspired   visual   architecture   of   analyzing   articulated   movements .   The   proposed   processing   architecture   builds   upon   coarsely   segregated   streams   of   sensory   processing   along   different   pathways   which   separately   process   form   and   motion   information   ( Layher   et   al . ,   2014 ) .   Action   recognition   is   performed   in   an   event - based   scheme   by   identifying   representations   of   characteristic   pose   configurations   ( key   poses )   in   an   image   sequence .   In   line   with   perceptual   studies ,   key   poses   are   selected   unsupervised   utilizing   a   feature   driven   criterion   which   combines   extrema   in   the   motion   energy   with   the   horizontal   and   the   vertical   extendedness   of   a   body   shape .   Per   class   representations   of   key   pose   frames   are   learned   using   a   deep   convolutional   neural   network   consisting   of   15   convolutional   layers .   The   network   is   trained   using   the   energy - efficient   deep   neuromorphic   networks   ( Eedn )   framework   ( Esser   et   al . ,   2016 ) ,   which   realizes   the   mapping   of   the   trained   synaptic   weights   onto   the   IBM   Neurosynaptic   System   platform   ( Merolla   et   al . ,   2014 ) .   After   the   mapping ,   the   trained   network   achieves   real - time   capabilities   for   processing   input   streams   and   classify   input   images   at   about   1 , 000   frames   per   second   while   the   computational   stages   only   consume   about   70   mW   of   energy   ( without   spike   transduction ) .   Particularly   regarding   mobile   robotic   systems ,   a   low   energy   profile   might   be   crucial   in   a   variety   application   scenarios .   Cross - validation   results   are   reported   for   two   different   datasets   and   compared   to   state - of - the - art   action   recognition   approaches .   The   results   demonstrate ,   that   ( I )   the   presented   approach   is   on   par   with   other   key   pose   based   methods   described   in   the   literature ,   which   select   key   pose   frames   by   optimizing   classification   accuracy ,   ( II )   compared   to   the   training   on   the   full   set   of   frames ,   representations   trained   on   key   pose   frames   result   in   a   higher   confidence   in   class   assignments ,   and   ( III )   key   pose   representations   show   promising   generalization   capabilities   in   a   cross - dataset   evaluation . ' ,   ' title ' :   ' Real - Time   Biologically   Inspired   Action   Recognition   from   Key   Poses   Using   a   Neuromorphic   Architecture ' } 
{ ' abstract ' :   ' Contents   carried   in   an   image   are   valuable   information   sources   for   many   scientific   and   engineering   applications .   However ,   if   the   image   is   captured   under   low   illumination   conditions   a   large   portion   of   the   image   appears   dark   and   this   heavily   degrades   the   image   quality .   In   order   to   solve   this   problem ,   a   restoration   algorithm   is   developed   here   that   transforms   the   low   input   brightness   to   a   higher   value   using   a   logarithmic   mapping   function .   The   mapping   is   further   refined   by   a   linear   weighting   with   the   input   to   reduce   the   un - necessary   amplification   at   regions   with   high   brightness .   Moreover ,   fine   details   in   the   image   are   preserved   by   applying   the   Retinex   principle   to   extract   and   then   re - insert   object   edges .   Results   from   experiments   using   low   and   normal   illumination   images   have   shown   satisfactory   performances   with   regard   to   the   improvement   in   information   contents   and   the   mitigation   of   viewing   artifacts . ' ,   ' title ' :   ' Logarithmic   profile   mapping   and   Retinex   edge   preserving   for   restoration   of   low   illumination   images ' } 
{ ' abstract ' :   ' We   propose   a   principled   approach   for   the   problem   of   aligning   multiple   partially   overlapping   networks .   The   objective   is   to   map   multiple   graphs   into   a   single   graph   while   preserving   vertex   and   edge   similarities .   The   problem   is   inspired   by   the   task   of   integrating   partial   views   of   a   family   tree   ( genealogical   network )   into   one   unified   network ,   but   it   also   has   applications ,   for   example ,   in   social   and   biological   networks .   Our   approach ,   called   Flan ,   introduces   the   idea   of   generalizing   the   facility   location   problem   by   adding   a   non - linear   term   to   capture   edge   similarities   and   to   infer   the   underlying   entity   network .   The   problem   is   solved   using   an   alternating   optimization   procedure   with   a   Lagrangian   relaxation .   Flan   has   the   advantage   of   being   able   to   leverage   prior   information   on   the   number   of   entities ,   so   that   when   this   information   is   available ,   Flan   is   shown   to   work   robustly   without   the   need   to   use   any   ground   truth   data   for   fine - tuning   method   parameters .   Additionally ,   we   present   three   multiple - network   extensions   to   an   existing   state - of - the - art   pairwise   alignment   method   called   Natalie .   Extensive   experiments   on   synthetic ,   as   well   as   real - world   datasets   on   social   networks   and   genealogical   networks ,   attest   to   the   effectiveness   of   the   proposed   approaches   which   clearly   outperform   a   popular   multiple   network   alignment   method   called   IsoRankN . ' ,   ' title ' :   ' Lagrangian   relaxations   for   multiple   network   alignment ' } 
{ ' abstract ' :   ' Heterogeneous   ultra - dense   networks   enable   ultra - high   data   rates   and   ultra - low   latency   through   the   use   of   dense   sub - 6   GHz   and   millimeter   wave   ( mmWave )   small   cells   with   different   antenna   configurations .   Existing   work   has   widely   studied   spectral   and   energy   efficiency   in   such   networks   and   shown   that   high   spectral   and   energy   efficiency   can   be   achieved .   This   article   investigates   the   benefits   of   heterogeneous   ultra - dense   network   architecture   from   the   perspectives   of   three   promising   technologies ,   i . e . ,   physical   layer   security ,   caching ,   and   wireless   energy   harvesting ,   and   provides   enthusiastic   outlook   towards   application   of   these   technologies   in   heterogeneous   ultra - dense   networks .   Based   on   the   rationale   of   each   technology ,   opportunities   and   challenges   are   identified   to   advance   the   research   in   this   emerging   network . ' ,   ' title ' :   ' A   New   Look   at   Physical   Layer   Security ,   Caching ,   and   Wireless   Energy   Harvesting   for   Heterogeneous   Ultra - dense   Networks ' } 
{ ' abstract ' :   ' We   consider   the   problem   of   joint   modeling   of   videos   and   their   corresponding   textual   descriptions   ( e . g .   sentences   or   phrases ) .   Our   approach   consists   of   three   components :   the   video   representation ,   the   textual   representation ,   and   a   joint   model   that   links   videos   and   text .   Our   video   representation   uses   the   state - of - the - art   deep   3D   ConvNet   to   capture   the   semantic   information   in   the   video .   Our   textual   representation   uses   the   recent   advancement   in   learning   word   and   sentence   vectors   from   large   text   corpus .   The   joint   model   is   learned   to   score   the   correct   ( video ,   text )   pairs   higher   than   the   incorrect   ones .   We   demonstrate   our   approach   in   several   applications :   1 )   retrieving   sentences   given   a   video ;   2 )   retrieving   videos   given   a   sentence ;   3 )   zero - shot   action   recognition   in   videos . ' ,   ' title ' :   ' Beyond   verbs :   Understanding   actions   in   videos   with   text ' } 
{ ' abstract ' :   ' This   paper   presents   a   multi - agent   model   for   simulating   attitude   formation   and   change   based   on   perception   and   communication   in   the   context   of   stabilization   operations .   The   originality   of   our   model   comes   from   ( 1 )   attitude   computation   that   evaluates   information   as   part   of   a   history   relative   to   the   individual   ( 2 )   a   notion   of   co - responsibility   for   attitude   attribution .   We   present   a   military   scenario   of   French   operations   in   Afghanistan   along   with   polls   results   about   the   opinion   of   citizen   toward   present   Forces .   Based   on   these   field   data ,   we   calibrate   the   model   and   show   the   resulting   attitude   dynamics .   We   study   the   sensibility   of   the   model   to   the   co - responsibility   factor . ' ,   ' title ' :   ' From   Field   Data   to   Attitude   Formation ' } 
{ ' abstract ' :   ' This   paper   proposes   two   low - complexity   iterative   algorithms   to   compute   the   capacity   of   a   single - user   multiple - input   multiple - output   channel   with   per - antenna   power   constraint .   The   first   method   results   from   manipulating   the   optimality   conditions   of   the   considered   problem   and   applying   fixed - point   iteration .   In   the   second   approach ,   we   transform   the   considered   problem   into   a   minimax   optimization   program   using   the   well - known   MAC -   BC   duality ,   and   then   solve   it   by   a   novel   alternating   optimization   method .   In   both   proposed   iterative   methods ,   each   iteration   involves   an   optimization   problem   which   can   be   efficiently   solved   by   the   water - filling   algorithm .   The   proposed   iterative   methods   are   provably   convergent .   Complexity   analysis   and   extensive   numerical   experiments   are   carried   out   to   demonstrate   the   superior   performance   of   the   proposed   algorithms   over   an   existing   approach   known   as   the   mode - dropping   algorithm . ' ,   ' title ' :   ' Low - complexity   Approaches   for   MIMO   Capacity   with   Per - antenna   Power   Constraint ' } 
{ ' abstract ' :   ' Inventory - Aware   Pathfinding   is   concerned   with   finding   paths   while   taking   into   account   that   picking   up   items ,   e . g . ,   keys ,   allow   the   character   to   unlock   blocked   pathways ,   e . g . ,   locked   doors .   In   this   work   we   present   a   pruning   method   and   a   preprocessing   method   that   can   improve   significantly   the   scalability   of   such   approaches .   We   apply   our   methods   to   the   recent   approach   of   Inventory - Driven   Jump - Point   Search   ( InvJPS ) .   First ,   we   introduce   InvJPS +   that   allows   to   prune   large   parts   of   the   search   space   by   favoring   short   detours   to   pick   up   items ,   offering   a   trade - off   between   efficiency   and   optimality .   Second ,   we   propose   a   preprocessing   step   that   allows   to   decide   on   runtime   which   items ,   e . g . ,   keys ,   are   worth   using   thus   pruning   potentially   unnecessary   items   before   the   search   starts .   We   show   results   for   combinations   of   the   pruning   and   preprocessing   methods   illustrating   the   best   choices   over   various   scenarios . ' ,   ' title ' :   ' Pruning   and   preprocessing   methods   for   inventory - aware   pathfinding ' } 
{ ' abstract ' :   ' This   paper   proposes   a   method   for   proper   names   extraction   from   Myanmar   text   by   using   latent   Dirichlet   allocation   ( LDA ) .   Our   method   aims   to   extract   proper   names   that   provide   important   information   on   the   contents   of   Myanmar   text .   Our   method   consists   of   two   steps .   In   the   first   step ,   we   extract   topic   words   from   Myanmar   news   articles   by   using   LDA .   In   the   second   step ,   we   make   a   post - processing ,   because   the   resulting   topic   words   contain   some   noisy   words .   Our   post - processing ,   first   of   all ,   eliminates   the   topic   words   whose   prefixes   are   Myanmar   digits   and   suffixes   are   noun   and   verb   particles .   We   then   remove   the   duplicate   words   and   discard   the   topic   words   that   are   contained   in   the   existing   dictionary .   Consequently ,   we   obtain   the   words   as   candidate   of   proper   names ,   namely   personal   names ,   geographical   names ,   unique   object   names ,   organization   names ,   single   event   names ,   and   so   on .   The   evaluation   is   performed   both   from   the   subjective   and   quantitative   perspectives .   From   the   subjective   perspective ,   we   compare   the   accuracy   of   proper   names   extracted   by   our   method   with   those   extracted   by   latent   semantic   indexing   ( LSI )   and   rule - based   method .   It   is   shown   that   both   LS ]   and   our   method   can   improve   the   accuracy   of   those   obtained   by   rule - based   method .   However ,   our   method   can   provide   more   interesting   proper   names   than   LSI .   From   the   quantitative   perspective ,   we   use   the   extracted   proper   names   as   additional   features   in   K - means   clustering .   The   experimental   results   show   that   the   document   clusters   given   by   our   method   are   better   than   those   given   by   LSI   and   rule - based   method   in   precision ,   recall   and   F - score . ' ,   ' title ' :   ' Extraction   of   proper   names   from   myanmar   text   using   latent   dirichlet   allocation ' } 
{ ' abstract ' :   ' Large   scale   assessment   of   aboveground   biomass   ( AGB )   in   tropical   forests   is   often   limited   by   the   saturation   of   remote   sensing   signals   at   high   AGB   values .   Fourier   Transform   Textural   Ordination   ( FOTO )   performs   well   in   quantifying   canopy   texture   from   very   high - resolution   ( VHR )   imagery ,   from   which   stand   structure   parameters   can   be   retrieved   with   no   saturation   effect   for   AGB   values   up   to   650   Mg · ha − 1 .   The   method   is   robust   when   tested   on   wet   evergreen   forests   but   is   more   demanding   when   applied   across   different   forest   types   characterized   by   varying   structures   and   allometries .   The   present   study   focuses   on   a   gradient   of   forest   types   ranging   from   dry   deciduous   to   wet   evergreen   forests   in   the   Western   Ghats   ( WG )   of   India ,   where   we   applied   FOTO   to   Cartosat - 1a   images   with   2.5   m   resolution .   Based   on   21   1 - ha   ground   control   forest   plots ,   we   calibrated   independent   texture – AGB   models   for   the   dry   and   wet   zone   forests   in   the   area ,   as   delineated   from   the   distribution   of   NDVI   values   computed   from   LISS - 4   multispectral   images .   This   stratification   largely   improved   the   relationship   between   texture - derived   and   field - derived   AGB   estimates ,   which   exhibited   a   R2   of   0.82   for   a   mean   rRMSE   of   ca .   17% .   By   inverting   the   texture – AGB   models ,   we   finally   mapped   AGB   predictions   at   1.6 - ha   resolution   over   a   heterogeneous   landscape   of   ca .   1500   km2   in   the   WG ,   with   a   mean   relative   per - pixel   propagated   error   < 20%   for   wet   zone   forests ,   i . e . ,   below   the   recommended   IPCC   criteria   for   Monitoring ,   Reporting   and   Verification   ( MRV )   methods .   The   method   proved   to   perform   well   in   predicting   high - resolution   AGB   values   over   heterogeneous   tropical   landscape   encompassing   diversified   forest   types ,   and   thus   presents   a   promising   option   for   affordable   regional   monitoring   systems   of   greenhouse   gas   ( GhG )   emissions   related   to   forest   degradation . ' ,   ' title ' :   ' Inverting   Aboveground   Biomass – Canopy   Texture   Relationships   in   a   Landscape   of   Forest   Mosaic   in   the   Western   Ghats   of   India   Using   Very   High   Resolution   Cartosat   Imagery ' } 
{ ' abstract ' :   ' Self - driving   vehicle   technologies   are   progressing   rapidly   and   are   expected   to   play   a   significant   role   in   the   future   of   transportation .   One   of   the   main   challenges   for   self - driving   vehicles   on   public   roads   is   the   safe   cooperation   and   collaboration   among   multiple   vehicles   using   sensor - based   perception   and   inter - vehicle   communications .   When   self - driving   vehicles   try   to   occupy   the   same   spatial   area   simultaneously ,   they   might   collide   with   one   another ,   might   become   deadlocked ,   or   might   slam   on   the   brakes   making   it   uncomfortable   or   unsafe   for   passengers   in   a   self - driving   vehicle .   In   this   paper ,   we   study   how   a   self - driving   vehicle   can   safely   navigate   merge   points ,   where   two   lanes   with   different   priorities   meet .   We   present   a   safe   protocol   for   merge   points   named   Autonomous   Vehicle   Protocol   for   Merge   Points ,   where   self - driving   vehicles   use   both   vehicular   communications   and   their   own   perception   systems   for   cooperating   with   other   self - driving   and / or   human - driven   vehicles .   Our   simulation   results   show   that   our   traffic   protocol   has   higher   traffic   throughput ,   compared   to   simple   traffic   protocols ,   while   ensuring   safety . ' ,   ' title ' :   ' A   merging   protocol   for   self - driving   vehicles ' } 
{ ' abstract ' :   ' System   Portfolio   Selection   ( SPS )   problem   is   equivalent   to   multi - objective   optimization   problem ,   with   multi - function   requirements   incommensurable .   In   the   paper ,   the   SPS   problem   is   re - specified   with   a   more   practical   formulation ,   comparing   to   general   portfolio   problem .   Then ,   both   feasible   and   non - inferior   solution   is   re - defined   considering   characteristics   of   SPS   problem ,   specifically ,   four   rules   of   system   function   combinations   are   proposed   according   to   practical   cases .   Then ,   the   instability   of   system   performance   is   involved   in   SPS   problem ,   and   the   robust   theory   is   employed   to   solving   the   uncertainty   of   system   function   values   with   definition   of   robust   non - inferior   solution .   Next ,   the   paper   proposes   an   immediately   updating   algorithm   to   solve   the   problem   of   solution   space   exponentially   growing .   Finally ,   a   case   study   is   used   to   demonstrate   the   usefulness   and   effectiveness   of   the   proposed   approaches .   It   shows   that   the   approach   can   provide   an   efficient   guidance   for   decision - makers   in   the   process   of   making   a   SPS . ' ,   ' title ' :   ' Robust   system   portfolio   selection   with   multi - function   requirements   and   system   instability ' } 
{ ' abstract ' :   ' This   study   explores   the   impact   of   high - photovoltaic   ( PV )   penetration   on   the   inter - area   oscillation   modes   of   large - scale   power   grids .   A   series   of   dynamic   models   with   various   PV   penetration   levels   are   developed   based   on   a   detailed   model   representing   the   U . S .   Eastern   Interconnection   ( EI ) .   Transient   simulations   are   performed   to   investigate   the   change   of   inter - area   oscillation   modes   with   PV   penetration .   The   impact   of   PV   control   strategies   and   parameter   settings   on   inter - area   oscillations   is   studied .   This   paper   finds   that   as   PV   increases ,   the   damping   of   the   dominant   oscillation   mode   decreases   monotonically .   It   is   also   observed   that   the   mode   shape   varies   with   the   PV   control   strategy   and   new   oscillation   modes   may   emerge   under   inappropriate   parameter   settings   in   PV   plant   controls . ' ,   ' title ' :   ' Impact   of   High   PV   Penetration   on   the   Inter - Area   Oscillations   in   the   U . S .   Eastern   Interconnection ' } 
{ ' abstract ' :   ' The   objective   of   this   research   is   to   compare   the   effectiveness   of   different   tracking   devices   underwater .   There   have   been   few   works   in   aquatic   virtual   reality   ( VR )   —   i . e . ,   VR   systems   that   can   be   used   in   a   real   underwater   environment .   Moreover ,   the   works   that   have   been   done   have   noted   limitations   on   tracking   accuracy .   Our   initial   test   results   suggest   that   inertial   measurement   units   work   well   underwater   for   orientation   tracking   but   a   different   approach   is   needed   for   position   tracking .   Towards   this   goal ,   we   have   waterproofed   and   evaluated   several   consumer   tracking   systems   intended   for   gaming   to   determine   the   most   effective   approaches .   First ,   we   informally   tested   infrared   systems   and   fiducial   marker   based   systems ,   which   demonstrated   significant   limitations   of   optical   approaches .   Next ,   we   quantitatively   compared   inertial   measurement   units   ( IMU )   and   a   magnetic   tracking   system   both   above   water   ( as   a   baseline )   and   underwater .   By   comparing   the   devices   rotation   data ,   we   have   discovered   that   the   magnetic   tracking   system   implemented   by   the   Razer   Hydra   is   more   accurate   underwater   as   compared   to   a   phone - based   IMU .   This   suggests   that   magnetic   tracking   systems   should   be   further   explored   for   underwater   VR   applications . ' ,   ' title ' :   ' Towards   usable   underwater   virtual   reality   systems ' } 
{ ' abstract ' :   ' A   faulty   network   GG   is   under   the   conditional   fault   model ,   i . e . , \ xa0every   fault - free   vertex   of   GG   is   incident   to   at   least   two   fault - free   edges .   Let   FFvFFv   and   FFeFFe   be   the   set   of   faulty   vertices   and   faulty   edges   in   FQnFQn ,   respectively .   In   this   paper ,   we   consider   FQnFQn   under   the   conditional   fault   model   and   prove   that   if   | FFv | + | FFe | ≤ 2n − 4 | FFv | + | FFe | ≤ 2n − 4   and   n ≥ 3n ≥ 3 ,   then   FQn − FFv − FFeFQn − FFv − FFe   contains   a   fault - free   cycle   of   every   even   length   from   4   to   2n − 2 | FFv | 2n − 2 | FFv | ;   if   | FFv | + | FFe | ≤ 2n − 5 | FFv | + | FFe | ≤ 2n − 5   and   n ≥ 4n ≥ 4   is   even ,   then   FQn − FFv − FFeFQn − FFv − FFe   contains   a   fault - free   cycle   of   every   odd   length   from   n + 1n + 1   to   2n − 2 | FFv | − 12n − 2 | FFv | − 1 . ' ,   ' title ' :   ' Cycles   embedding   in   folded   hypercubes   under   the   conditional   fault   model ' } 
{ ' abstract ' :   ' Companies   have   invested   considerable   resources   in   the   implementation   of   enterprise   resource   planning   ( ERP )   systems .   The   results   initially   expected   have   rarely   been   reached .   The   optimisation   ( or   efficient   use )   of   such   information   systems   is   nowadays   becoming   a   major   factor   for   firms   striving   to   reach   their   performance   objectives .   After   presenting   a   synthesis   of   several   studies   on   ERP   projects ,   we   build   on   the   findings   of   a   French   investigation   into   the   assessment   and   optimisation   of   ERP   performance .   A   classification   of   company   positions   regarding   their   ERP   use ,   based   on   both   software   maturity   and   strategic   deployment   directions ,   and   an   improvement   process   are   proposed .   Industrial   cases   allow   validation   of   this   approach . ' ,   ' title ' :   ' A   classification   for   better   use   of   ERP   systems ' } 
{ ' abstract ' :   ' This   paper   presents   a   time - domain   biosensor   array   that   uses   a   capacitor - less   current - mode   analog - to - time   converter   ( CMATC )   and   logarithmic   cyclic   time - attenuation - based   TDC   with   discharging   acceleration .   Combining   the   exponential   function   of   the   CMATC   and   logarithmic   function   of   the   proposed   TDC   offers   linear   input - output   characteristics .   The   time - domain   property   enables   bio - imaging   at   a   high   spatial   resolution   and   large   scale   while   maintaining   scalability .   Measurement   results   with   a   0.25 - μ m   test   chip   successfully   demonstrated   linear   input - output   characteristics . ' ,   ' title ' :   ' A   scalable   time - domain   biosensor   array   using   logarithmic   cyclic   time - attenuation - based   TDC   for   high - resolution   and   large - scale   bio - imaging ' } 
{ ' abstract ' :   ' Compared   to   current   mobile   networks ,   next - generation   mobile   networks   are   expected   to   support   higher   numbers   of   simultaneously   connected   devices   and   to   achieve   higher   system   spectrum   efficiency   and   lower   power   consumption .   To   achieve   these   goals ,   we   study   the   multi - sharing   device - to - device   ( D2D )   communication ,   which   allows   any   cellular   user   equipment   to   share   its   radio   resource   with   multiple   D2D   devices .   We   jointly   consider   resource   block   reuse   and   power   control   and   then   develop   the   MISS   algorithm .   Simulation   results   show   that   MISS   performs   very   well   in   terms   of   transmission   power   consumption ,   system   throughput ,   and   the   number   of   permitted   D2D   devices . ' ,   ' title ' :   ' Joint   Resource   Block   Reuse   and   Power   Control   for   Multi - Sharing   Device - to - Device   Communication ' } 
{ ' abstract ' :   ' This   paper   is   concerned   with   event - triggered   H ∞ H ∞   filtering   for   delayed   neural   networks   via   sampled   data .   A   novel   event - triggered   scheme   is   proposed ,   which   can   lead   to   a   significant   reduction   of   the   information   communication   burden   in   the   network ;   the   feature   of   this   scheme   is   that   whether   or   not   the   sampled   data   should   be   transmitted   is   determined   by   the   current   sampled   data   and   the   error   between   the   current   sampled   data   and   the   latest   transmitted   data .   By   constructing   a   proper   Lyapunov – Krasovskii   functional ,   utilizing   the   reciprocally   convex   combination   technique   and   Jensen ’ s   inequality   sufficient   conditions   are   derived   to   ensure   that   the   resultant   filtering   error   system   is   asymptotically   stable .   Based   on   the   derived   H ∞ H ∞   performance   analysis   results ,   the   H ∞ H ∞   filter   design   is   formulated   in   terms   of   Linear   Matrix   Inequalities   ( LMIs ) .   Finally ,   the   proposed   stability   conditions   are   demonstrated   with   numerical   example . ' ,   ' title ' :   ' Event - triggered   H   ∞   filtering   for   delayed   neural   networks   via   sampled - data ' } 
{ ' abstract ' :   ' For   the   double   integrator   with   matched   Lipschitz   disturbances   we   propose   a   continuous   homogeneous   controller   providing   finite - time   stability   of   the   origin .   The   disturbance   is   compensated   exactly   in   finite   time   using   a   discontinuous   function   through   an   integral   action .   Since   the   controller   is   dynamic ,   the   closed   loop   is   a   third   order   system   that   achieves   a   third   order   sliding   mode   in   the   steady   state .   The   stability   and   robustness   properties   of   the   controller   are   proven   using   a   smooth   and   homogeneous   strict   Lyapunov   function   ( LF ) .   In   a   first   stage ,   the   gains   of   the   controller   and   the   LF   are   designed   using   a   method   based   on   Polya ’ s   Theorem .   In   a   second   stage   the   controller ’ s   gains   are   adjusted   through   a   sum   of   squares   representation   of   the   LF . ' ,   ' title ' :   ' Design   of   Continuous   Twisting   Algorithm ' } 
{ ' abstract ' :   ' Big   data   is   now   rapidly   expanding   into   various   domains   such   as   banking ,   insurance   and   e - commerce .   Data   analysis   and   related   studies   have   attracted   more   attentions .   In   health   insurance ,   abuse   of   diagnosis   is   one   of   the   key   fraud   problems ,   which   damages   the   interests   of   insured   people .   To   address   this   issue ,   numbers   of   studies   have   focused   on   this   topic .   This   paper   develops   a   healthcare   fraud   detection   approach   based   on   the   trustworthiness   of   doctors   to   distinguish   fraud   cases   from   normal   records .   Compared   to   conventional   methods ,   our   approach   can   detect   healthcare   fraud   in   a   good   accuracy   by   only   little   feature   information   from   healthcare   data   without   the   violation   of   privacy .   This   approach   combines   a   weighted   HITS   algorithm   with   a   frequent   pattern   mining   algorithm   to   calculate   a   rational   treatment   model   of   a   certain   disease .   In   addition ,   this   paper   also   introduces   the   copy   precision   behavior   in   the   treatment   sequences   of   patients ,   which   is   a   critical   metric   to   learn   the   trustworthiness   of   doctors .   The   numerical   validation   with   a   healthcare   dataset   demonstrates   that   healthcare   fraud   by   misdiagnosis   in   healthcare   treatments   can   be   successfully   detected   by   employing   the   developed   fraud   detection   approach . ' ,   ' title ' :   ' Healthcare   Fraud   Detection   Based   on   Trustworthiness   of   Doctors ' } 
{ ' abstract ' :   ' In   this   paper   we   study   data   collection   in   an   energy   renewable   sensor   network   for   scenarios   such   as   traffic   monitoring   on   busy   highways ,   where   sensors   are   deployed   along   a   predefined   path   ( the   highway )   and   a   mobile   sink   travels   along   the   path   to   collect   data   from   one - hop   sensors   periodically .   As   sensors   are   powered   by   renewable   energy   sources ,   time - varying   characteristics   of   ambient   energy   sources   poses   great   challenges   in   the   design   of   efficient   routing   protocols   for   data   collection   in   such   networks .   In   this   paper   we   first   formulate   a   novel   data   collection   maximization   problem   by   adopting   multi - rate   data   transmissions   and   performing   transmission   time   slot   scheduling ,   and   show   that   the   problem   is   NP - hard .   We   then   devise   an   offline   algorithm   with   a   provable   approximation   ratio   for   the   problem   by   exploiting   the   combinatorial   property   of   the   problem ,   assuming   that   the   harvested   energy   at   each   node   is   given   and   link   communications   in   the   network   are   reliable .   We   also   extend   the   proposed   algorithm   by   minor   modifications   to   a   general   case   of   the   problem   where   the   harvested   energy   at   each   sensor   is   not   known   in   advance   and   link   communications   are   not   reliable .   We   thirdly   develop   a   fast ,   scalable   online   distributed   algorithm   for   the   problem   in   realistic   sensor   networks   in   which   neither   the   global   knowledge   of   the   network   topology   nor   sensor   profiles   such   as   sensor   locations   and   their   harvested   energy   profiles   is   given .   Furthermore ,   we   also   consider   a   special   case   of   the   problem   where   each   node   has   only   a   fixed   transmission   power ,   for   which   we   propose   an   exact   solution   to   the   problem .   We   finally   conduct   extensive   experiments   by   simulations   to   evaluate   the   performance   of   the   proposed   algorithms .   Experimental   results   demonstrate   that   the   proposed   algorithms   are   efficient   and   the   solutions   obtained   are   fractional   of   the   optimum . ' ,   ' title ' :   ' Data   Collection   Maximization   in   Renewable   Sensor   Networks   via   Time - Slot   Scheduling ' } 
{ ' abstract ' :   ' An   increasing   number   of   businesses   are   migrating   their   IT   operations   to   the   cloud .   Likewise   there   is   an   increased   emphasis   on   data   analytics   based   on   multiple   datasets   and   sources   to   derive   information   not   derivable   when   a   dataset   is   mined   in   isolation .   While   ensuring   security   of   data   and   computation   outsourced   to   a   third   party   cloud   service   provider   is   in   itself   challenging ,   supporting   mash - ups   and   analytics   of   data   from   different   parties   hosted   across   different   services   is   even   more   so .   In   this   paper   we   propose   a   cloud - based   service   allowing   multiple   parties   to   perform   secure   multi - party   secure   sum   computation   using   their   clouds   as   delegates .   Our   scheme   provides   data   privacy   both   from   the   delegates   as   well   as   from   the   other   data   owners   under   a   lazy - and - curious   adversary   ( semi - honest )   model .   We   then   describe   how   such   a   secure   sum   primitive   may   be   used   in   various   collaborative ,   cloud - based   distributed   data   mining   tasks   ( classification ,   association   rule   mining   and   clustering ) .   We   implement   a   prototype   and   benchmark   the   service ,   both   as   a   stand - alone   secure   sum   service ,   and   as   a   building   block   for   more   complex   analytics .   The   results   suggest   reasonable   overhead   and   demonstrate   the   practicality   of   carrying   out   privacy   preserved   distributed   analytics   despite   migrating   ( encrypted )   data   to   pos -   sibly   different   and   untrusted   ( semi - honest )   cloud   services . ' ,   ' title ' :   ' Delegated   Secure   Sum   Service   for   Distributed   Data   Mining   in   Multi - Cloud   Settings ' } 
{ ' abstract ' :   ' This   paper   fundamentally   investigates   the   performance   of   evolutionary   multiobjective   optimization   ( EMO )   algorithms   for   computationally   hard   0 - 1   combinatorial   optimization ,   where   a   strict   theoretical   analysis   is   generally   out   of   reach   due   to   the   high   complexity   of   the   underlying   problem .   Based   on   the   examination   of   problem   features   from   a   multiobjective   perspective ,   we   improve   the   understanding   of   the   efficiency   of   a   simple   dominance - based   EMO   algorithm   with   unbounded   archive   for   multiobjective   NK - landscapes   with   correlated   objective   values .   More   particularly ,   we   adopt   a   statistical   approach ,   based   on   simple   and   multiple   linear   regression   analysis ,   to   enquire   the   expected   running   time   of   global   SEMO   with   restart   for   identifying   a   ( 1 + e ) - approximation   of   the   Pareto   set   for   small - size   enumerable   instances .   Our   analysis   provides   further   insights   on   the   EMO   search   behavior   and   on   the   most   important   features   that   characterize   the   difficulty   of   an   instance   for   this   class   of   problems   and   algorithms . ' ,   ' title ' :   ' A   feature - based   performance   analysis   in   evolutionary   multiobjective   optimization ' } 
{ ' abstract ' :   ' Functional   biological   sequences ,   which   typically   come   in   families ,   have   retained   some   level   of   similarity   and   function   during   evolution .   Finding   consensus   regions ,   alignment   of   sequences ,   and   identifying   the   relationship   between   a   sequence   and   a   family   allow   inferences   about   the   function   of   the   sequences .   Profile   hidden   Markov   models   ( HMMs )   are   generally   used   to   identify   those   relationships .   A   profile   HMM   can   be   trained   on   unaligned   members   of   the   family   using   conventional   algorithms   such   as   Baum - Welch ,   Viterbi ,   and   their   modifications .   The   overall   quality   of   the   alignment   depends   on   the   quality   of   the   trained   model .   Unfortunately ,   the   conventional   training   algorithms   converge   to   suboptimal   models   most   of   the   time .   This   work   proposes   a   training   algorithm   that   early   identifies   many   imperfect   models .   The   method   is   based   on   the   Simulated   Annealing   approach   widely   used   in   discrete   optimization   problems .   The   training   algorithm   is   implemented   as   a   component   in   HMMER .   The   performance   of   the   algorithm   is   discussed   on   protein   sequence   data . ' ,   ' title ' :   ' Simulated   annealing   algorithm   with   biased   neighborhood   distribution   for   training   profile   models ' } 
{ ' abstract ' :   ' The   Canny   algorithm   is   a   well   known   edge   detector   that   is   widely   used   in   the   previous   processing   stages   in   several   algorithms   related   to   computer   vision .   An   alternative ,   the   LIP - Canny   algorithm ,   is   based   on   a   robust   mathematical   model   closer   to   the   human   vision   system ,   obtaining   better   results   in   terms   of   edge   detection .   In   this   work   we   describe   LIP - Canny   algorithm   under   the   perspective   from   its   parallelization   and   optimization   by   using   the   NVIDIA   CUDA   framework .   Furthermore ,   we   present   comparative   results   between   an   implementation   of   this   algorithm   using   NVIDIA   CUDA   and   the   analogue   using   a   C / C++   approach . ' ,   ' title ' :   ' Parallelizing   and   optimizing   LIP - canny   using   NVIDIA   CUDA ' } 
{ ' abstract ' :   ' This   paper   presents   an   efficient   Bayesian   blind   multiuser   receiver   for   long   code   multipath   CDMA   systems .   The   proposed   receiver   employs   the   adaptive   sampling   method   for   the   Bayesian   inference   procedure   to   estimate   the   data   symbols   and   multipath   parameters .   Compared   to   the   other   reported   Bayesian   Monte   Carlo   receivers   for   long   code   multipath   CDMA   systems ,   the   proposed   one   achieves   a   faster   convergence   and   a   lower   computational   complexity   to   attain   comparable   performance .   Simulation   results   are   presented   to   demonstrate   the   effectiveness   of   the   proposed   Bayesian   blind   multiuser   receiver . ' ,   ' title ' :   ' Blind   Multiuser   Detection   for   Long   Code   Multipath   DS - CDMA   Systems   with   Bayesian   MC   Techniques ' } 
{ ' abstract ' :   ' Spreadsheets   are   by   far   the   most   prominent   example   of   end - user   programs   of   ample   size   and   substantial   structural   complexity .   In   addition ,   spreadsheets   are   usually   not   tested   very   rigorously   and   thus   comprise   faults .   Locating   faults   is   a   hard   task   due   to   the   size   and   the   structure ,   which   is   usually   not   directly   visible   to   the   user ,   i . e . ,   the   functions   are   hidden   behind   the   cells   and   only   the   computed   values   are   presented .   Hence ,   there   is   a   strong   need   for   debugging   support .   In   this   paper ,   we   adapt   three   program - debugging   approaches   that   have   been   designed   for   more   traditional   procedural   or   object - oriented   programming   languages .   These   techniques   are   Spectrum - based   Fault   Localization ,   Spectrum - Enhanced   Dynamic   Slicing ,   and   Constraint - based   Debugging .   Beside   the   theoretical   foundations ,   we   present   a   more   sophisticated   empirical   evaluation   including   a   comparison   of   these   approaches .   The   empirical   evaluation   shows   that   Sfl   ( Spectrum - based   Fault   Localization )   and   Sendys   ( Spectrum   ENhanced   Dynamic   Slicing )   are   the   most   promising   techniques . ' ,   ' title ' :   ' On   the   empirical   evaluation   of   fault   localization   techniques   for   spreadsheets ' } 
{ ' abstract ' :   ' This   work   provides   elements   to   highlight   the   reliability   challenges   related   to   the   technology   scaling   and   the   BTI   variability .   Through   main   milestones   including   device   reliability   scaling   model   ( for   both   mean   and   spread ) ,   a   discussion   on   the   physical   origin   of   BTI   variability   and   a   digital   IP   failure   rate   analytical   model ,   the   evolution   of   digital   IP   failure   rates   along   the   ITRS   scaling   roadmap   is   assessed .   and   an   analysis   of   the   ITRS   roadmap   on   digital   IP   failure   rates .   This   study   offers   new   perspectives   towards   product   hardening   and   qualification   with   respect   to   both   fresh   and   BTI - related   local   variability ,   especially   in   context   where   Adaptive   Voltage   Scaling   ( AVS )   is   used   to   compensate   for   process   centerings . ' ,   ' title ' :   ' From   BTI   variability   to   product   failure   rate :   A   technology   scaling   perspective ' } 
{ ' abstract ' :   ' In   this   paper   we   discuss   the   problem   of   calculating   the   reachable   states   of   a   dynamical   system   defined   by   ordinary   differential   equations   or   inclusions .   We   present   a   prototype   system   for   approximating   this   set   and   demonstrate   some   experimental   results . ' ,   ' title ' :   ' Reachability   Analysis   via   Face   Lifting ' } 
{ ' abstract ' :   ' By   introducing   the   new   concepts   of   fuzzy     β   - covering   and   fuzzy     β   - neighborhood ,   we   define   two   new   types   of   fuzzy   covering   rough   set   models   which   can   be   regarded   as   bridges   linking   covering   rough   set   theory   and   fuzzy   rough   set   theory .   We   show   the   properties   of   the   two   models ,   and   reveal   the   relationships   between   the   two   models   and   some   others .   Moreover ,   we   present   the   matrix   representations   of   the   newly   defined   lower   and   upper   approximation   operators   so   that   the   calculation   of   lower   and   upper   approximations   of   subsets   can   be   converted   into   operations   on   matrices .   Finally ,   we   generalize   the   models   and   their   matrix   representations   to     L   - fuzzy   covering   rough   sets   which   are   defined   over   fuzzy   lattices . ' ,   ' title ' :   ' Two   fuzzy   covering   rough   set   models   and   their   generalizations   over   fuzzy   lattices ' } 
{ ' abstract ' :   ' Mobile   applications   are   becoming   complex   software   systems   that   must   be   developed   quickly   and   evolve   regularly   to   fit   new   user   requirements   and   execution   contexts .   However ,   addressing   these   constraints   may   result   in   poor   design   choices ,   known   as   antipatterns ,   which   may   degrade   software   quality   and   performance .   Thus ,   the   automatic   detection   of   antipatterns   is   an   important   activity   that   eases   the   future   maintenance   and   evolution   tasks .   Moreover ,   it   helps   developers   to   refactor   their   applications   and   thus ,   to   improve   their   quality .   While   antipatterns   are   well - known   in   object - oriented   applications ,   their   study   in   mobile   applications   is   still   in   their   infancy .   In   this   paper ,   we   presents   a   tooled   approach ,   called   P   aprika   ,   to   analyze   Android   applications   and   to   detect   object - oriented   and   Android - specific   antipatterns   from   binaries   of   applications . ' ,   ' title ' :   ' An   approach   to   detect   Android   antipatterns ' } 
{ ' abstract ' :   ' In   this   paper   we   present   a   new   method   for   object   categorization .   Firstly   an   image   representation   is   obtained   by   the   proposed   hierarchical   learning   method   consisting   of   alternating   between   local   coding   and   maximum   pooling   operations ,   where   the   local   coding   operation   induces   discrimination   while   the   image   descriptor   and   maximum   pooling   operation   induces   invariance   in   hierarchical   architecture .   Then   the   obtained   effective   image   representation   is   passed   to   a   linear   classifier   which   is   suitable   for   large   databases   for   object   categorization .   We   have   demonstrated   that   the   proposed   method   is   robust   to   image   variations   and   has   low   sample   complexity . ' ,   ' title ' :   ' Object   categorization   based   on   hierarchical   learning ' } 
{ ' abstract ' :   ' We   have   previously   proposed   a   howling   canceller   which   cancels   howling   by   using   a   cascade   notch   filter   designed   from   a   distance   between   a   loudspeaker   and   a   microphone .   This   method   utilizes   a   pilot   signal   to   estimate   the   distance .   In   this   paper ,   we   introduce   two   methods   into   the   distance - based   howling   canceller   to   improve   speech   quality .   The   first   one   is   an   adaptive   cascade   notch   filter   which   adaptively   adjusts   the   nulls   to   eliminate   howling   and   to   keep   speech   components .   The   second   one   is   a   silent   pilot   signal   whose   frequencies   exist   in   the   ultrasonic   band ,   and   it   is   inaudible   while   on   transmission .   We   implement   the   proposed   howling   canceller   on   a   DSP   to   evaluate   its   capability .   The   experimental   results   show   that   the   proposed   howling   canceller   improves   speech   quality   in   comparison   to   the   conventional   one . ' ,   ' title ' :   ' A   High   Speech   Quality   Distance - Based   Howling   Canceller   with   Adaptive   Cascade   Notch   Filter   and   Silent   Pilot   Signal ' } 
{ ' abstract ' :   ' Purpose   –   This   paper   aims   to   look   at   how   varying   terminology   is   used   on   school   library   web   sites   and   how   that   compares   to   student   preferences . Design / methodology / approach   –   Provides   research   conduced   by   surveying   practicing   school   librarians   and   k ‐ 12   students . Findings   –   Terminology   varies   greatly   on   school   library   web   sites .   Further ,   students   prefer   common   language   use . Practical   implications   –   Practicing   librarians   may   consider   revising   their   web   sites   in   order   to   make   them   more   accessible   for   their   students . Originality / value   –   This   paper   provides   original   research   into   school   library   web   sites ,   an   area   that   is   lacking . ' ,   ' title ' :   ' School   library   web   site   terminology ' } 
{ ' abstract ' :   ' Recently ,   numerous   multireceiver   identity - based   encryption   or   identity - based   broadcast   encryption   schemes   have   been   introduced   with   bilinear   pairing   and   probabilistic   map - to - point   MTP   function .   As   the   bilinear   pairing   and   MTP   functions   are   expensive   operations ,   any   cryptographic   schemes   based   on   these   operations   experience   high   computational   burden .   The   certificateless   public   key   cryptography   sidesteps   the   private   key   escrow   problem   occurring   in   identity - based   cryptosystem   and   certificate   management   troubles   of   certificate   authority - based   public   key   cryptography   CA - PKC .   We   observed   that   certificateless   multireceiver   encryption   CL - MRE   scheme   without   pairing   and   MTP   hash   function   has   not   yet   been   considered   in   the   literature .   In   this   paper ,   we   proposed   a   bilinear   pairing   and   MTP   hash - function - free   CL - MRE   scheme   with   chosen   ciphertext   attack   resilience .   The   detailed   analyses   provide   evidence   that   our   scheme   achieves   forward   secrecy ,   backward   secrecy ,   and   low   computation   costs   than   others .   The   scheme   also   provides   confidentiality   of   the   message   and   receiver   anonymity   in   the   random   oracle   model   with   the   hardness   of   computational   Diffie - Hellman   problem .   Copyright   ©   2014   John   Wiley   &   Sons ,   Ltd . ' ,   ' title ' :   ' Anonymous   and   provably   secure   certificateless   multireceiver   encryption   without   bilinear   pairing ' } 
{ ' abstract ' :   ' We   study   the   problem   of   approximating   one - dimensional   nonintegrable   codistributions   by   integrable   ones   and   apply   the   resulting   approximations   to   approximate   feedback   linearization   of   single - input   systems .   The   approach   derived   in   this   paper   allows   a   linearizable   nonlinear   system   to   be   found   that   is   close   to   the   given   system   in   a   least - squares   ( L2 )   sense .   A   linearly   controllable   single - input   affine   nonlinear   system   is   feedback   linearizable   if   and   only   if   its   characteristic   distribution   is   involutive   ( hence   integrable )   or ,   equivalently ,   any   characteristic   one - form   ( a   one - form   that   annihilates   the   characteristic   distribution )   is   integrable .   We   study   the   problem   of   finding   ( least - squares   approximate )   integrating   factors   that   make   a   fixed   characteristic   one - form   close   to   being   exact   in   anL2   sense .   A   given   one - form   can   be   decomposed   into   exact   and   inexact   parts   using   the   Hodge   decomposition .   We   derive   an   upper   bound   on   the   size   of   the   inexact   part   of   a   scaled   characteristic   one - form   and   show   that   a   least - squares   integrating   factor   provides   the   minimum   value   for   this   upper   bound .   We   also   consider   higher - order   approximate   integrating   factors   that   scale   a   nonintegrable   one - form   in   a   way   that   the   scaled   form   is   closer   to   being   integrable   inL2   together   with   some   derivatives   and   derive   similar   bounds   for   the   inexact   part .   This   allows   a   linearizable   nonlinear   system   that   is   close   to   the   given   system   in   a   least - squares   ( L2 )   sense   together   with   some   derivatives   to   be   found .   The   Sobolev   embedding   techniques   allow   us   to   obtain   an   upper   bound   on   the   uniform   ( L ∞ )   distance   between   the   nonlinear   system   and   its   linearizable   approximation . ' ,   ' title ' :   ' Least - squares   integration   of   one - dimensional   codistributions   with   application   to   approximate   feedback   linearization ' } 
{ ' abstract ' :   ' Latent   sector   errors   in   disk   drives   affect   only   a   few   data   sectors .   They   occur   silently   and   are   detected   only   when   the   affected   area   is   accessed   again .   If   a   latent   error   is   detected   while   the   storage   system   is   operating   under   reduced   redundancy ,   i . e . ,   during   a   RAID   rebuild ,   then   data   loss   may   occur .   Various   features   such   as   scrubbing   and   intra - disk   data   redundancy   are   proposed   to   detect   and / or   recover   from   latent   errors   and   avoid   data   loss .   While   such   features   enhance   data   availability   in   the   storage   system ,   their   execution   may   cause   performance   degradation .   In   this   paper ,   we   evaluate   the   effectiveness   of   scrubbing   and   intra - disk   data   redundancy   in   improving   data   availability   while   the   overall   goal   is   to   maintain   user   performance   within   predefined   bounds .   We   show   that   by   treating   them   as   low   priority   background   activities   and   scheduling   them   efficiently   during   idle   times ,   these   features   remain   performance - wise   transparent   to   the   storage   system   user   while   still   improving   data   reliability .   Detailed   trace - driven   simulations   show   that   the   mean   time   to   data   loss   ( MTTDL )   improves   by   up   to   5   orders   of   magnitude   if   these   features   are   implemented   independently .   By   scheduling   concurrently   both   scrubbing   and   intra - disk   parity   updates   during   idle   times   in   disk   drives ,   MTTDL   improves   by   as   much   as   8   orders   of   magnitude . ' ,   ' title ' :   ' Enhancing   data   availability   in   disk   drives   through   background   activities ' } 
{ ' abstract ' :   ' Financial   crisis   forecasting   has   been   a   long - standing   challenge   that   often   involves   couplings   between   indicators   of   multiple   markets .   Such   couplings   include   implicit   relations   that   might   not   be   effectively   detected   from   raw   market   observations .   However ,   most   methods   for   crisis   forecasting   rely   directly   on   market   observations   and   might   not   detect   the   hidden   interactions   between   markets .   To   this   end ,   the   authors   explore   coupled   market   state   analysis   ( CMSA ) ,   assuming   that   the   observations   of   markets   are   governed   by   a   collection   of   intra -   and   intercoupled   hidden   market   states .   Accordingly ,   they   built   a   forecaster   based   on   these   coupled   market   states   instead   of   observations . ' ,   ' title ' :   ' Financial   Crisis   Forecasting   via   Coupled   Market   State   Analysis ' } 
{ ' abstract ' :   ' In   this   paper ,   an   “ intelligent ”   isolated   intersection   control   system   was   developed .   The   developed   “ intelligent ”   system   makes   “ real   time ”   decisions   as   to   whether   to   extend   ( and   how   much )   current   green   time .   The   model   developed   is   based   on   the   combination   of   the   dynamic   programming   and   neural   networks .   Many   tests   show   that   the   outcome   ( the   extension   of   the   green   time )   of   the   proposed   neural   network   is   nearly   equal   to   the   best   solution .   Practically   negligible   CPU   times   were   achieved ,   and   were   thus   absolutely   acceptable   for   the   “ real   time ”   application   of   the   developed   algorithm . ' ,   ' title ' :   ' Dynamic   programming — neural   network   real - time   traffic   adaptive   signal   control   algorithm ' } 
{ ' abstract ' :   ' This   issue   features   expanded   versions   of   articles   selected   from   the   2014   AAAI   Conference   on   Innovative   Applications   of   Artificial   Intelligence   held   in   Quebec   City ,   Canada .   We   present   a   selection   of   four   articles   describing   deployed   applications   plus   two   more   articles   that   discuss   work   on   emerging   applications . ' ,   ' title ' :   ' Introduction   to   the   Special   Issue   on   Innovative   Applications   of   Artificial   Intelligence   2014 ' } 
{ ' abstract ' :   ' Although   frequently   used   in   fractal   compression   quadrant - based   classification   exhibits   a   significant   defect   which   has   not   been   described   in   the   literature .   We   give   an   efficient   solution   to   this   problem   by   controlling   the   class   structure   based   on   an   adaptive   threshold .   This   makes   this   classification   technique   a   very   efficient   and   competitive   one   also   for   block   matching   motion   compensation   algorithms   in   video   coding . ' ,   ' title ' :   ' Resolving   a   defect   in   quadrant - based   classification   for   fast   block - matching ' } 
{ ' abstract ' :   ' Where   there   are   infinitely   many   possible   basic   states   of   the   world ,   a   standard   probability   function   must   assign   zero   probability   to   each   state   –   since   any   finite   probability   would   sum   to   over   one .   This   generates   problems   for   any   decision   theory   that   appeals   to   expected   utility   or   related   notions .   For   it   leads   to   the   view   that   a   situation   in   which   one   wins   a   million   dollars   if   any   of   a   thousand   of   the   equally   probable   states   is   realized   has   an   expected   value   of   zero   ( since   each   such   state   has   probability   zero ) .   But   such   a   situation   dominates   the   situation   in   which   one   wins   nothing   no   matter   what   ( which   also   has   an   expected   value   of   zero ) ,   and   so   surely   is   more   desirable .   I   formulate   and   defend   some   principles   for   evaluating   options   where   standard   probability   functions   cannot   strictly   represent   probability   –   and   in   particular   for   where   there   is   an   infinitely   spread ,   uniform   distribution   of   probability .   The   principles   appeal   to   standard   probability   functions ,   but   overcome   at   least   some   of   their   limitations   in   such   cases . ' ,   ' title ' :   ' Standard   decision   theory   corrected ' } 
{ ' abstract ' :   ' Backed   by   the   European   Commission ,   a   consortium   of   partners   from   European   industry ,   financial   institutions ,   and   academia   has   embarked   on   a   research   project   to   develop   the   fundamentals   of   secure   electronic   commerce .   The   goal   of   the   9 - million   ECU   project ,   SEMPER   ( Secure   Electronic   Marketplace   for   Europe ) ,   is   to   provide   the   first   open   and   comprehensive   solutions   for   secure   commerce   over   the   Internet   and   other   public   information   networks .   We   describe   the   objectives   and   summarise   the   initial   architecture   of   SEMPER .   A   wide   range   of   businesses   are   rapidly   moving   to   explore   the   huge   potential   of   net -   worked   information   systems ,   especially   with   the   Internet - based   WWW   ( World - wide   Web ) .   The   Internet ,   which   already   connects   more   than   3   million   computers   and   a   sub -   stantially   larger   number   of   users ,   is   growing   at   a   breathtaking   pace   with   thousands   of   newcomers   every   day .   Although   the   Internet   has   its   roots   in   academia   and   is   still   domi -   nated   by   free - of - charge   information ,   dramatic   changes   are   expected   in   the   near   future .   For   instance ,   the   WWW   will   be   used   for   a   wide   variety   of   electronic   commerce   such   as   on - line   trade   or   delivery   of   advanced   multimedia   information   services .   The   evolution   of   broadband   networks   and   " information   highways "   will   intensify   this   trend .   The   need   for   secure   transactions   in   this   new   business   environment ,   which   involves   networks   available   to   the   general   public ,   has   triggered   a   number   of   related   efforts .   These   initial   developments   are   based   almost   exclusively   in   the   US   and   most   of   them   are   limited   to   proprietary ,   or   otherwise   closed   solutions ,   involving   only   electronic   payment   issues .   In   contrast ,   SEMPER   is   directed   towards   a   comprehensive   solution   for   secure   electronic   commerce ,   considering   legal ,   commercial ,   social ,   and   technical   requirements   as   well   as   different   options   for   an   electronic   marketplace . ' ,   ' title ' :   ' Development   of   a   Secure   Electronic   Marketplace   for   Europe ' } 
{ ' abstract ' :   ' Through   the   use   of   a   global   geometric   symmetry ,   detection   ellipses   are   proposed   in   this   paper .   Based   on   the   geometric   symmetry ,   the   proposed   method   first   locates   candidates   of   ellipses   centers .   In   the   meantime ,   according   to   these   candidate   centers ,   all   feature   points   in   an   input   image   are   grouped   into   several   subimages .   Then ,   for   each   subimage ,   by   using   geometric   properties   again ,   all   ellipses   are   extracted .   The   method   significantly   reduces   the   time   required   to   evaluate   all   possible   parameters   without   using   edge   direction   information .   Experimental   results   are   given   to   show   the   correctness   and   effectiveness   of   the   proposed   method . ' ,   ' title ' :   ' Detection   ellipses   by   finding   lines   of   symmetry   in   the   images   via   an   hough   transform   applied   to   straight   lines ' } 
{ ' abstract ' :   ' Automatic   crawling   of   Rich   Internet   Applications   ( RIAs )   is   a   challenge   because   client - side   code   modifies   the   client   dynamically ,   fetch -   ing   server - side   data   asynchronously .   Most   existing   solutions   model   RIAs   as   state   machines   with   DOMs   as   states   and   JavaScript   events   execution   as   transitions .   This   approach   fails   when   used   with   " real - life " ,   complex   RIAs ,   because   the   size   of   the   produced   model   is   much   too   large   to   be   practical .   In   this   paper ,   we   propose   a   new   method   to   crawl   AJAX - based   RIAs   in   an   efficient   manner   by   detecting   " components " ,   which   are   areas   of   the   DOM   that   are   independent   from   each   other ,   and   by   crawling   each   component   separately .   This   leads   to   a   dramatic   reduction   of   the   required   state   space   for   the   model ,   without   loss   of   content   coverage .   Our   method   does   not   require   prior   knowledge   of   the   RIA   nor   predefined   definition   of   components .   Instead ,   we   infer   the   components   by   observing   the   be -   havior   of   the   RIA   during   crawling .   Our   experimental   results   show   that   our   method   can   index   quickly   and   completely   industrial   RIAs   that   are   simply   out   of   reach   for   traditional   methods . ' ,   ' title ' :   ' Indexing   Rich   Internet   Applications   Using   Components - Based   Crawling ' } 
{ ' abstract ' :   ' One   important   aspect   of   constructing   an   overlay   network   is   how   to   exploit   network   locality   in   the   underlying   network .   In   this   paper ,   we   propose   a   scalable   protocol   for   constructing   an   overlay   network   that   takes   account   of   locality   of   network   hosts .   The   constructed   overlay   network   can   significantly   decrease   the   communication   cost   between   end - hosts .   Our   simulation   results   show   that   the   average   distance   between   a   pair   of   hosts   in   the   constructed   overlay   network   is   only   about   11%   of   the   one   in   a   traditional ,   randomly   connected   overlay   network .   Furthermore ,   our   proposed   overlay   considered   to   be   more   scalable   than   tree - based   or   mesh - based   overlays . ' ,   ' title ' :   ' Measurement - based   construction   of   locality - aware   overlay   networks ' } 
{ ' abstract ' :   ' This   paper   presents   a   low   cost ,   flexible   and   customizable   delay   measurement   system   developed   to   assess   the   performance   of   the   VTPE - hBEB   protocol .   The   proposed   system   can   be   used   to   evaluate   other   communication   protocols   as   well   as   to   measure   the   delay   between   two   repetitive   events . ' ,   ' title ' :   ' Delay   measurement   system   for   real - time   serial   data   streams ' } 
{ ' abstract ' :   " Service   robots   have   become   increasingly   important   subjects   in   our   lives .   However ,   they   are   still   facing   problems   like   adaptability   to   their   users .   While   major   work   has   focused   on   intelligent   service   robots ,   the   proposed   approaches   were   mostly   user   independent .   Our   work   is   part   of   the   FUI - RoboPopuli   project ,   which   concentrates   on   endowing   entertainment   companion   robots   with   adaptive   and   social   behaviour .   In   particular ,   we   are   interested   in   robots   that   are   able   to   learn   and   plan   so   that   they   adapt   and   personalize   their   behaviour   according   to   their   users .   Markov   Decision   Processes   ( MDPs )   are   largely   used   for   adaptive   robots   applications .   However ,   one   challenging   point   is   reducing   the   sample   complexity   required   to   learn   an   MDP   model ,   including   the   reward   function .   In   this   article ,   we   present   our   contribution   regarding   the   representation   and   the   learning   of   the   reward   function   through   analysing   interaction   traces   ( i . e .   the   interaction   history   between   the   robot   and   their   users ,   including   users '   feedback ) .   Our   approach   permits   to   generalise   the   learned   rewards   so   that   when   new   users   are   introduced ,   the   robot   may   quickly   adapt   using   what   it   learned   from   previous   experiences   with   other   users .   We   propose ,   in   this   article ,   two   algorithms   to   learn   the   reward   function .   The   first   is   direct   and   certain ,   the   robot   applies   with   a   user   what   it   learned   during   interaction   with   same   kind   of   users   ( i . e .   users   with   similar   profiles ) .   The   second   algorithm   generalises   what   it   learns   to   be   applied   to   all   kinds   of   users .   Through   simulation ,   we   show   that   the   generalised   algorithm   converges   to   an   optimal   reward   function   with   less   than   half   the   samples   needed   by   the   direct   algorithm . " ,   ' title ' :   " Adaptive   and   Personalised   Robots   -   Learning   from   Users '   Feedback " } 
{ ' abstract ' :   " Researches   of   sensor   networks   collecting   patients '   data   with   computerized   triage   tags ,   called   Triage   Network ,   are   attracting   attention .   The   listening   power   used   in   triage   tags   is   the   major   factor   of   lots   of   energy   consumption ,   and   consumption   of   energy   increases   when   sensor   nodes   always   communicate   with   other   nodes   in   active   state .   Hence ,   we   suppose   that   sensor   nodes   are   put   to   sleep   periodically   to   avoid   running   out   of   battery .   However ,   some   nodes   have   mobility   and   nodes   secede   from   the   network   according   to   patients   conditions   in   Triage   Network .   The   paths   are   failed   and   it   is   needed   to   reconstruct   paths   when   these   forwarding   nodes   move   or   secede   from   network .   Therefore ,   data   arrival   ratio   decreases   and   consumption   of   battery   increases   due   to   reconstruction   of   other   paths .   In   this   paper ,   we   propose   a   data   collection   method   using   two   types   of   forwarding   nodes ,   Stable   Nodes   and   Energy   Efficient   Nodes .   This   method   uses   two   types   of   forwarding   nodes   according   to   priority   of   data   and   avoids   loss   of   high   priority   data ,   improves   the   data   arrival   ratio   and   saves   the   energy   consumption .   We   evaluate   the   proposed   method   and   show   its   effectiveness   using   computer   simulations . " ,   ' title ' :   ' Data   collection   method   using   two   types   of   forwarding   nodes   for   energy   saving   in   triage   network ' } 
{ ' abstract ' :   ' This   paper   introduces   Golay - paired   Hadamard   matrices   for   fast   compressed   sensing   of   sparse   signals   in   the   time   or   spectral   domain .   These   sampling   operators   feature   low - memory   requirement ,   hardware - friendly   implementation   and   fast   computation   in   reconstruction .   We   show   that   they   require   a   nearly   optimal   number   of   measurements   for   faithful   reconstruction   of   a   sparse   signal   in   the   time   or   frequency   domain .   Simulation   results   demonstrate   that   the   proposed   sensing   matrices   offer   a   reconstruction   performance   similar   to   that   of   fully   random   matrices . ' ,   ' title ' :   ' Golay   meets   Hadamard :   Golay - paired   Hadamard   matrices   for   fast   compressed   sensing ' } 
{ ' abstract ' :   ' In   this   technical   note ,   the   problem   of   finite - time   output   regulation   control   for   a   class   of   disturbed   system   under   mismatching   condition   is   investigated   via   a   composite   control   design   manner .   The   composite   controller   is   developed   by   using   a   finite   time   control   technique   and   a   finite   time   disturbance   observer   ( FTDO ) .   A   key   idea   is   to   design   virtual   control   laws   based   on   estimation   values   of   the   disturbances   and   the   ith   ( 1 ≤ i ≤ n - 1   where   n   is   the   order   of   the   system )   order   derivative   of   disturbances .   Finite   time   stability   analysis   for   the   augmented   system   is   presented   by   means   of   Lyapunov   stability   theorems ,   which   shows   that   the   system   output   is   regulated   to   zero   in   finite   time   even   in   the   presence   of   mismatched   disturbances .   A   motion   control   application   demonstrates   the   effectiveness   and   attractive   properties   of   the   proposed   method . ' ,   ' title ' :   ' Continuous   Finite - Time   Output   Regulation   for   Disturbed   Systems   Under   Mismatching   Condition ' } 
{ ' abstract ' :   ' In   this   paper   we   propose   an   approach   for   enhanced   data   protection   in   the   cloud ,   based   upon   accountability   governance .   Specifically ,   the   relationships   between   accountability ,   risk   and   trust   are   analyzed   in   order   to   suggest   characteristics   and   means   to   address   data   governance   issues   involved   when   organizations   or   individuals   adopt   cloud   computing .   This   analysis   takes   into   account   insights   from   a   variety   of   stakeholders   within   cloud   ecosystems   obtained   by   running   an   elicitation   workshop . ' ,   ' title ' :   ' Accountability ,   Risk ,   and   Trust   in   Cloud   Services :   Towards   an   Accountability - Based   Approach   to   Risk   and   Trust   Governance ' } 
{ ' abstract ' :   ' Xue   et   al .   recently   proposed   an   innovative   mutual   authentication   and   key   agreement   scheme   for   wireless   sensor   networks   based   on   temporal   credential   using   smart   cards .   However ,   in   this   paper   we   demonstrate   that   their   scheme   is   vulnerable   to   password   guessing   attacks ,   node   capture   attacks   and   denial - of - service   attacks .   Furthermore   we   show   that   their   scheme   has   some   inconsistencies   which   make   it   less   secure   and   more   computationally   costly   than   originally   presented . ' ,   ' title ' :   ' Notes   on   A   Temporal - Credential - Based   Mutual   Authentication   and   Key   Agreement   Scheme   for   Wireless   Sensor   Networks ' } 
{ ' abstract ' :   ' Persistent   Scatterer   Interferometry   ( PSI )   has   been   widely   used   for   landslide   studies   in   recent   years .   This   paper   investigated   the   spatial   patterns   of   PSI   point   targets   and   landslide   occurrences   in   the   Arno   River   basin   in   Central   Italy .   The   main   purpose   is   to   analyze   whether   spatial   patterns   of   Persistent   Scatterers   ( PS )   can   be   recognized   as   indicators   of   landslide   occurrences   throughout   the   whole   basin .   The   bivariate   K - function   was   employed   to   assess   spatial   relationships   between   PS   and   landslides .   The   PSI   point   targets   were   acquired   from   almost   4   years   ( from   March   2003   to   January   2007 )   of   RADARSAT - 1   images .   The   landslide   inventory   was   collected   from   15   years   ( from     1992 – 2007 )   of   surveying   and   mapping   data ,   mainly   including   remote   sensing   data ,   topographic   maps   and   field   investigations .   The   proposed   approach   is   able   to   assess   spatial   patterns   between   a   variety   of   PS   and   landslides ,   in   particular ,   to   understand   if   PSI   point   targets   are   spatially   clustered   ( spatial   attraction )   or   randomly   distributed   ( spatial   independency )   on   various   types   of   landslides   across   the   basin .   Additionally ,   the   degree   and   scale   distances   of   PS   clustering   on   a   variety   of   landslides   can   be   characterized .   The   results   rejected   the   null   hypothesis   that   PSI   point   targets   appear   to   cluster   similarly   on   four   types   of   landslides   ( slides ,   flows ,   falls   and   creeps )   in   the   Arno   River   basin .   Significant   influence   of   PS   velocities   and   acquisition   orbits   can   be   noticed   on   detecting   landslides   with   different   states   of   activities .   Despite   that   the   assessment   may   be   influenced   by   the   quality   of   landslide   inventory   and   Synthetic   Aperture   Radar   ( SAR )   images ,   the   proposed   approach   is   expected   to   provide   guidelines   for   studies   trying   to   detect   and   investigate   landslide   occurrences   at   a   regional   scale   through   spatial   statistical   analysis   of   PS ,   for   which   an   advanced   understanding   of   the   impact   of   scale   distances   on   landslide   clustering   is   fundamentally   needed . ' ,   ' title ' :   ' Investigating   Spatial   Patterns   of   Persistent   Scatterer   Interferometry   Point   Targets   and   Landslide   Occurrences   in   the   Arno   River   Basin ' } 
{ ' abstract ' :   ' This   article   describes   a   middleware   used   in   display   cluster   of   real   time   visual   simulation   system .   This   middleware   which   based   on   TCP / IP   protocol   provides   the   communication   infrastructure   for   visual   simulation   system .   It   provides   unified   process   logic   and   interfaces   for   various   status   and   frame   data   and   the   packing / unpacking   functions   of   simulation   data   without   concerning   the   details   of   the   data .   We   found   two   classes   of   display   synchronization   problems   and   provided   the   resolution   of   them .   The   middleware   provides   a   group   of   APIs   which   hide   the   details   of   data   packing / unpacking ,   processing   and   transmission   and   meets   the   requirement   of   flexibility ,   efficiency   and   extensibility .   This   middleware   has   been   successfully   implemented   to   the   display   cluster   of   several   tower   simulation   system . ' ,   ' title ' :   ' The   Research   of   High   Level   Data   Communication   Middleware   of   Display   Cluster   Used   in   Real   Time   Simulation   Environment ' } 
{ ' abstract ' :   ' The   scattering   parameters   are   fundamental   in   the   characterization   of   electrical   devices   at   high   frequencies .   They   are   particularly   useful   for   analyzing   multiport   high - frequency   and   microwave   networks .   However ,   they   are   not   adequately   presented   in   most ,   if   not   all ,   microwave   engineering   books .   This   paper   identifies   two   common   deficiencies   in   the   way   scattering   parameters   are   being   presented   in   these   books .   It   provides   additional   information   that   should   supplement   those   books   or   book   chapters   on   scattering   parameters . ' ,   ' title ' :   ' Deficiencies   in   the   way   scattering   parameters   are   taught ' } 
{ ' abstract ' :   ' We   study   the   reliability   maximization   problem   in   WDM   networks   with   random   link   failures .   Reliability   in   these   networks   is   defined   as   the   probability   that   the   logical   network   is   connected ,   and   it   is   determined   by   the   underlying   lightpath   routing   and   the   link   failure   probability .   We   show   that   in   general   the   optimal   lightpath   routing   depends   on   the   link   failure   probability ,   and   characterize   the   properties   of   lightpath   routings   that   maximize   the   reliability   in   different   failure   probability   regimes .   In   particular ,   we   show   that   in   the   low   failure   probability   regime ,   maximizing   the   ` ` cross - layer "   min   cut   of   the   ( layered )   network   maximizes   reliability ,   whereas   in   the   high   failure   probability   regime ,   minimizing   the   spanning   tree   of   the   network   maximizes   reliability .   Motivated   by   these   results ,   we   develop   lightpath   routing   algorithms   for   reliability   maximization . ' ,   ' title ' :   ' Maximizing   Reliability   in   WDM   Networks   through   Lightpath   Routing ' } 
{ ' abstract ' :   ' The   slope   of   the   active   distances   is   an   important   parameter   when   investigating   the   error - correcting   capability   of   convolutional   codes   and   the   distance   behavior   of   concatenated   convolutional   codes .   The   slope   of   the   active   distances   is   equal   to   the   minimum   average   weight   cycle   in   the   state - transition   diagram   of   the   encoder .   A   general   upper   bound   on   the   slope   depending   on   the   free   distance   of   the   convolutional   code   and   new   upper   bounds   on   the   slope   of   special   classes   of   binary   convolutional   codes   are   derived .   Moreover ,   a   search   technique ,   resulting   in   new   tables   of   rate   R = 1 / 2   and   rate   R = 1 / 3   convolutional   encoders   with   high   memories   and   large   active   distance - slopes   is   presented .   Furthermore ,   we   show   that   convolutional   codes   with   large   slopes   can   be   used   to   obtain   new   tailbiting   block   codes   with   large   minimum   distances .   Tables   of   rate   R = 1 / 2   and   rate   R = 1 / 3   tailbiting   codes   with   larger   minimum   distances   than   the   best   previously   known   quasi - cyclic   codes   are   given .   Two   new   tailbiting   codes   also   have   larger   minimum   distances   than   the   best   previously   known   binary   linear   block   codes   with   same   size   and   length .   One   of   them   is   also   superior   in   terms   of   minimum   distance   to   any   previously   known   binary   nonlinear   block   code   with   the   same   set   of   parameters . ' ,   ' title ' :   ' Tailbiting   codes   obtained   via   convolutional   codes   with   large   active   distance - slopes ' } 
{ ' abstract ' :   ' MIMO   wireless   technology   is   required   to   increase   the   data   rates   for   a   broad   range   of   applications ,   including   low   cost   mobile   devices .   In   this   paper   we   present   a   very   low   area   reconfigurable   MIMO   detector   which   achieves   a   high   throughput   of   103Mbps   and   uses   27   Kilo   Gates   when   implemented   in   a   commercial   180nm   CMOS   process .   The   low   area   is   achieved   by   the   proposed   in - place   architecture .   This   architecture   implements   the   K - best   algorithm   and   reduces   area   4 - fold   compared   to   the   widely   used   multi - stage   architecture ,   while   provides   reconfigurability   in   terms   of   antenna   configuration   during   real - time   operation . ' ,   ' title ' :   ' A   low - area   flexible   MIMO   detector   for   WiFi / WiMAX   standards ' } 
{ ' abstract ' :   ' Because   human   cognition   is   creative   and   socially   situated ,   knowledge   accumulates ,   diffuses ,   and   gets   applied   in   new   contexts ,   generating   cultural   analogs   of   phenomena   observed   in   population   genetics   such   as   adaptation   and   drift .   It   is   therefore   commonly   thought   that   elements   of   culture   evolve   through   natural   selection .   However ,   natural   selection   was   proposed   to   explain   how   change   accumulates   despite   lack   of   inheritance   of   acquired   traits ,   as   occurs   with   template - mediated   replication .   It   cannot   accommodate   a   process   with   significant   retention   of   acquired   or   horizontally   ( e . g .   socially )   transmitted   traits .   Moreover ,   elements   of   culture   cannot   be   treated   as   discrete   lineages   because   they   constantly   interact   and   influence   one   another .   It   is   proposed   that   what   evolves   through   culture   is   the   mind ;   ideas   and   artifacts   are   merely   reflections   of   its   current   evolved   state .   Interacting   minds   transform   ( in   part )   through   a   non - Darwinian   autopoietic   process   similar   to   that   by   which   early   life   evolved ,   involving   not   survival   of   the   fittest   but   actualization   of   their   potential . ' ,   ' title ' :   ' The   cultural   evolution   of   socially   situated   cognition ' } 
{ ' abstract ' :   ' Event   Extraction   is   a   complex   and   interesting   topic   in   Information   Extraction   that   includes   event   extraction   methods   from   free   text   or   web   data .   The   result   of   event   extraction   systems   can   be   used   in   several   fields   such   as   risk   analysis   systems ,   online   monitoring   systems   or   decide   support   tools .   In   this   paper ,   we   introduce   a   method   that   combines   lexico   - -   semantic   and   machine   learning   to   extract   event   from   Vietnamese   news .   Furthermore ,   we   concentrate   to   describe   event   online   monitoring   system   named   VnLoc   based   on   the   method   that   was   proposed   above   to   extract   event   in   Vietnamese   language .   Besides ,   in   experiment   phase ,   we   have   evaluated   this   method   based   on   precision ,   recall   and   F1   measure .   At   this   time   of   experiment ,   we   on   investigated   on   three   types   of   event :   FIRE ,   CRIME   and   TRANSPORT   ACCIDENT . ' ,   ' title ' :   ' VnLoc :   A   Real   - -   Time   News   Event   Extraction   Framework   for   Vietnamese ' } 
{ ' abstract ' :   ' Reliability   analysis   using   error   probabilities   for   combinational   logic   circuits   has   been   investigated   widely   in   the   literature .   Reliability   analysis   for   sequential   logic   circuits   using   these   methods   would   be   inaccurate   because   of   existence   of   loops   in   their   architecture .   In   this   paper   a   new   method   based   on   conversion   of   sequential   circuit   to   combinational   one   and   applying   an   iterative   reliability   analysis   is   developed .   A   Monte   Carlo   method - based   reliability   analysis   is   introduced   for   sequential   circuits ,   which   is   used   for   first   method   validation .   Experimental   results   demonstrate   good   accuracy   of   the   method . ' ,   ' title ' :   ' SEQUENTIAL   LOGIC   CIRCUITS   RELIABILITY   ANALYSIS ' } 
{ ' abstract ' :   ' According   to   the   Journey   to   Crime   theory ,   offenders   have   a   directionality   preference ,   in   the   form   of   an   activity   path ,   when   they   are   moving   about   in   their   environment   in   search   for   criminal   activities .   Using   clustering   techniques ,   this   theory   is   tested   using   crime   data   for   the   Province   of   British   Columbia ,   Canada .   The   activities   of   57 , 962   offenders   who   were   either   charged ,   chargeable ,   or   for   whom   charges   were   recommended   were   analyzed   by   mapping   their   offense   locations   with   respect   to   their   home   locations   to   determine   directionality .   Once   directionality   was   established ,   a   unique   clustering   technique ,   based   on   K - Means   clustering   and   modified   for   angles ,   was   applied   to   find   the   number   of   activity   paths   for   each   offender .   Although   the   number   of   activity   paths   varies   from   individual   to   individual ,   the   aggregate   pattern   was   very   consistent   with   theory .   It   was   found   that   people   only   have   a   few   activity   paths ,   even   if   they   are   highly   prolific   offenders . ' ,   ' title ' :   ' How   Many   Ways   Do   Offenders   Travel   - -   Evaluating   the   Activity   Paths   of   Offenders ' } 
{ ' abstract ' :   ' Pulse   Coupled   Neural   Network ( PCNN )   is   widely   used   in   the   field   of   image   processing ,   but   it   is   a   difficult   task   to   define   the   relative   parameters   properly   in   the   research   of   the   applications   of   PCNN .   So   far   the   determination   of   parameters   of   its   model   needs   a   lot   of   experiments .   To   deal   with   the   above   problem ,   a   document   segmentation   based   on   the   improved   PCNN   is   proposed .   It   uses   the   maximum   entropy   function   as   the   fitness   function   of   bacterial   foraging   optimization   algorithm ,   adopts   bacterial   foraging   optimization   algorithm   to   search   the   optimal   parameters ,   and   eliminates   the   trouble   of   manually   set   the   experiment   parameters .   Experimental   results   show   that   the   proposed   algorithm   can   effectively   complete   document   segmentation .   And   result   of   the   segmentation   is   better   than   the   contrast   algorithms .   ©   ( 2014 )   COPYRIGHT   Society   of   Photo - Optical   Instrumentation   Engineers   ( SPIE ) .   Downloading   of   the   abstract   is   permitted   for   personal   use   only . ' ,   ' title ' :   ' PCNN   document   segmentation   method   based   on   bacterial   foraging   optimization   algorithm ' } 
{ ' abstract ' :   ' Undirected   graphical   models   encode   in   a   graph   G   the   dependency   structure   of   a   random   vector   Y .   In   many   applications ,   it   is   of   interest   to   model   Y   given   another   random   vector   X   as   input .   We   refer   to   the   problem   of   estimating   the   graph   G ( x )   of   Y   conditioned   on   X   =   x   as   " graph - valued   regression " .   In   this   paper ,   we   propose   a   semiparametric   method   for   estimating   G ( x )   that   builds   a   tree   on   the   X   space   just   as   in   CART   ( classification   and   regression   trees ) ,   but   at   each   leaf   of   the   tree   estimates   a   graph .   We   call   the   method   " Graph - optimized   CART " ,   or   Go - CART .   We   study   the   theoretical   properties   of   Go - CART   using   dyadic   partitioning   trees ,   establishing   oracle   inequalities   on   risk   minimization   and   tree   partition   consistency .   We   also   demonstrate   the   application   of   Go - CART   to   a   meteorological   dataset ,   showing   how   graph - valued   regression   can   provide   a   useful   tool   for   analyzing   complex   data . ' ,   ' title ' :   ' Graph - Valued   Regression ' } 
{ ' abstract ' :   ' Over   the   last   two   decades ,   doubts   have   been   expressed   about   the   adequacy   of   materialism   as   the   correct   framework   for   explaining   phenomenal   consciousness   ( the   experience   of   saturated   greenness   one   has   when   looking   at   a   lush   lawn ,   for   example ) .   This   paper   reconstructs   a   generic   form   of   the   various   arguments   that   have   been   used   to   defend   the   view   of   the   materialistically   inexplicable   nature   of   consciousness   ( MINC ) .   This   reconstruction   reveals   that   the   arguments   turn   on   an   impoverished   notion   of   explanation .   By   discussing   some   examples   from   the   history   of   science ,   the   paper   shows   that   a   reasonable   notion   of   explanation   has   to   be   wider   than   the   one   utilized   in   the   argument   for   MINC ,   which   opens   the   possibility   for   the   materialistic   explicability   of   consciousness .   The   author   ends   the   paper   by   raising   a   question   about   the   very   intelligibility   of   the   project   of   trying   to   explain   the   so - called   nature   of   consciousness   as   opposed   to   the   regularities   characteristic   of   the   relation   between   states   of   consciousness   and   ... ' ,   ' title ' :   ' On   explaining   phenomenal   consciousness ' } 
{ ' abstract ' :   ' Successful   replication   within   an   infected   host   and   successful   transmission   between   hosts   are   key   to   the   continued   spread   of   most   pathogens .   Competing   selection   pressures   exerted   at   these   different   scales   can   lead   to   evolutionary   trade - offs   between   the   determinants   of   fitness   within   and   between   hosts .   Here ,   we   examine   such   a   trade - off   in   the   context   of   influenza   A   viruses   and   the   differential   pressures   exerted   by   temperature - dependent   virus   persistence .   For   a   panel   of   avian   influenza   A   virus   strains ,   we   find   evidence   for   a   trade - off   between   the   persistence   at   high   versus   low   temperatures .   Combining   a   within - host   model   of   influenza   infection   dynamics   with   a   between - host   transmission   model ,   we   study   how   such   a   trade - off   affects   virus   fitness   on   the   host   population   level .   We   show   that   conclusions   regarding   overall   fitness   are   affected   by   the   type   of   link   assumed   between   the   within -   and   between - host   levels   and   the   main   route   of   transmission   ( direct   or   environmental ) .   The   relative   importance   of   virulence   and   immune   response   mediated   virus   clearance   are   also   found   to   influence   the   fitness   impacts   of   virus   persistence   at   low   versus   high   temperatures .   Based   on   our   results ,   we   predict   that   if   transmission   occurs   mainly   directly   and   scales   linearly   with   virus   load ,   and   virulence   or   immune   responses   are   negligible ,   the   evolutionary   pressure   for   influenza   viruses   to   evolve   toward   good   persistence   at   high   within - host   temperatures   dominates .   For   all   other   scenarios ,   influenza   viruses   with   good   environmental   persistence   at   low   temperatures   seem   to   be   favored . ' ,   ' title ' :   ' A   Multi - scale   Analysis   of   Influenza   A   Virus   Fitness   Trade - offs   due   to   Temperature - dependent   Virus   Persistence ' } 
{ ' abstract ' :   ' Peer - to - Peer   ( P2P )   networks   are   largely   used   for   file - sharing   and   hence   must   provide   efficient   mechanisms   for   searching   the   files   stored   at   various   nodes .   The   existing   structuredP2P   overlays   support   only   ” exact - match ”   look - up   which   is   hardly   sufficient   in   a   file   sharing   network .   This   paper   addresses   the   problem   of   keyword - based   search   in   structured   P2P   networks .   We   propose   a   new   keyword - based   searching   algorithm   which   can   be   implemented   on   top   of   any   structured   P2P   overlay .   We   demonstrate   that   the   proposed   algorithm   achieves   very   good   searching   results   as   it   requires   the   minimum   number   of   messages   to   be   sent   in   order   to   find   all   the   references   to   files   containing   at   least   the   given   set   of   keywords . ' ,   ' title ' :   ' A   Keyword   Search   Algorithm   for   Structured   Peer - to - Peer   Networks ' } 
{ ' abstract ' :   ' In   this   paper ,   we   propose   an   adaptive   power   allocation   method   for   hybrid   relay   systems   that   employ   the   amplify - and - forward   and   decode - and - forward   protocols   simultaneously .   The   total   transmission   power   is   analytically   allocated   to   a   source   and   two   selected   relays   by   the   proposed   power   allocation   criterion   to   maximize   the   overall   received   signal - to - noise   ratio   at   the   destination .   Simulation   results   show   that   the   proposed   scheme   achieves   better   performance   than   that   of   conventional   cooperative   schemes   or   hybrid   systems   with   equal   power   allocation . ' ,   ' title ' :   ' Adaptive   relay   selection   and   power   allocation   for   hybrid   relay   systems ' } 
{ ' abstract ' :   ' The   unitary   rotation   of   square - pixellated   images   is   based   on   the   finite   su ( 2 ) - oscillator   model ,   which   describes   systems   whose   values   for   position ,   momentum   and   energy ,   are   discrete   and   finite .   In   a   two - dimensional   position   space ,   this   allows   the   construction   of   angular   momentum   states ,   orthonormal   and   complete ,   for   which   rotations   are   defined   as   multiplication   by   phases   that   carry   the   rotation   angle .   The   decomposition   of   a   digital   square   images   in   terms   of   these   angular   momentum   states   determines   a   unitary   ( hence   invertible )   rotation   of   the   image ,   whose   kernel   can   be   computed   as   a   four - dimensional   array   of   real   numbers . ' ,   ' title ' :   ' Unitary   rotation   of   square - pixellated   images ' } 
{ ' abstract ' :   ' As   more   mobile   storage   devices   are   used   in   consumer   electronics ,   possibility   of   user   confidential   data   leakage   increases .   To   make   things   worse ,   data   of   deleted   file   in   mobile   storage   such   as   USB   drives   can   be   easily   recovered   and ,   thus ,   can   be   vulnerable   to   data   leakage .   To   prevent   this   type   of   data   leakage ,   efficient   secure   deletion   techniques   are   required   and   we   present   two   secure   deletion   techniques ,   namely   block   cleaning   and   zero   overwriting ,   for   flash   memory   storage .   Also ,   we   propose   cost   and   benefit   models   of   both   techniques .   The   models   imply   an   existence   of   an   efficient   adaptive   hybrid   secure   deletion   scheme   that   applies   one   of   the   techniques   based   on   their   costs   and   benefits   at   given   data   arrangements .   Experimental   results   measured   on   an   embedded   board   show   that   the   adaptive   hybrid   scheme   deletes   data   securely   and   efficiently   for   various   data   patterns   on   flash   memory   storage . ' ,   ' title ' :   ' Models   and   Design   of   an   Adaptive   Hybrid   Scheme   for   Secure   Deletion   of   Data   in   Consumer   Electronics ' } 
{ ' abstract ' :   ' In   heterogeneous   and   dynamic   environments ,   efficient   execution   of   parallel   computations   can   require   mappings   of   tasks   to   processors   whose   performance   is   both   irregular   ( because   of   heterogeneity )   and   time - varying   ( because   of   dynamicity ) .   While   adaptive   domain   decomposition   techniques   have   been   used   to   address   heterogeneous   resource   capabilities ,   temporal   variations   in   those   capabilities   have   seldom   been   considered .   We   propose   a   conservative   scheduling   policy   that   uses   information   about   expected   future   variance   in   resource   capabilities   to   produce   more   efficient   data   mapping   decisions .   We   first   present   techniques ,   based   on   time   series   predictors   that   we   developed   in   previous   work ,   for   predicting   CPU   load   at   some   future   time   point ,   average   CPU   load   for   some   future   time   interval ,   and   variation   of   CPU   load   over   some   future   time   interval .   We   then   present   a   family   of   stochastic   scheduling   algorithms   that   exploit   such   predictions   of   future   availability   and   variability   when   making   data   mapping   decisions .   Finally ,   we   describe   experiments   in   which   we   apply   our   techniques   to   an   astrophysics   application .   The   results   of   these   experiments   demonstrate   that   conservative   scheduling   can   produce   execution   times   that   are   both   significantly   faster   and   less   variable   than   other   techniques . ' ,   ' title ' :   ' Conservative   Scheduling :   Using   Predicted   Variance   to   Improve   Scheduling   Decisions   in   Dynamic   Environments ' } 
{ ' abstract ' :   ' We   consider   a   class   of   restless   multi - armed   bandit   problems   that   arises   in   multi - channel   opportunistic   communications ,   where   channels   are   modeled   as   independent   and   stochastically   identical   Gilbert - Elliot   channels   and   channel   state   observations   are   subject   to   errors .   We   show   that   the   myopic   channel   selection   policy   has   a   semi - universal   structure   that   obviates   the   need   to   know   the   Markovian   transition   probabilities   of   the   channel   states .   Based   on   this   structure ,   we   establish   closed - form   lower   and   upper   bounds   on   the   steady - state   throughput   achieved   by   the   myopic   policy .   Furthermore ,   we   characterize   the   approximation   factor   of   the   myopic   policy   to   bound   its   worst - case   performance   loss   with   respect   to   the   optimal   performance . ' ,   ' title ' :   ' On   the   myopic   policy   for   a   class   of   restless   bandit   problems   with   applications   in   dynamic   multichannel   access ' } 
{ ' abstract ' :   ' We   show   that   the   optimum   length - / spl   nu /   guard   sequence   for   block   transmission   over   a   linear   Gaussian - noise   dispersive   channel   with   memory   / spl   nu /   is   a   linear   combination   of   the   N   information   symbols   of   the   block .   A   closed - form   expression   for   the   optimum   guard   sequence   is   derived   subject   to   a   total   average   energy   constraint   on   the   information   and   guard   symbols .   The   achievable   channel   block   throughput   with   the   optimum   guard   sequence   is   compared   with   that   achievable   with   two   common   guard   sequence   types ,   namely   zero   stuffing   and   cyclic   prefix . ' ,   ' title ' :   ' Guard   sequence   optimization   for   block   transmission   over   linear   frequency - selective   channels ' } 
{ ' abstract ' :   " A   modular   program   analysis   considers   components   independently   and   provides   a   succinct   summary   for   each   component ,   which   is   used   when   checking   the   rest   of   the   system .   Consider   a   system   consisting   of   a   library   and   a   client .   A   temporal   summary ,   or     interface   ,   of   the   library   specifies   legal   sequences   of   library   calls .   The   interface   is     safe     if   no   call   sequence   violates   the   library ' s   internal   invariants ;   the   interface   is     permissive     if   it   contains   every   such   sequence .   Modular   program   analysis   requires     full     interfaces ,   which   are   both   safe   and   permissive :   the   client   does   not   cause   errors   in   the   library   if   and   only   if   it   makes   only   sequences   of   library   calls   that   are   allowed   by   the   full   interface   of   the   library . Previous   interface - based   methods   have   focused   on   safe   interfaces ,   which   may   be   too   restrictive   and   thus   reject   good   clients .   We   present   an   algorithm   for   automatically   synthesizing   software   interfaces   that   are   both   safe   and   permissive .   The   algorithm   generates   interfaces   as   graphs   whose   vertices   are   labeled   with   predicates   over   the   library ' s   internal   state ,   and   whose   edges   are   labeled   with   library   calls .   The   interface   state   is   refined   incrementally   until   the   full   interface   is   constructed .   In   other   words ,   the   algorithm   automatically   synthesizes   a   typestate   system   for   the   library ,   against   which   any   client   can   be   checked   for   compatibility .   We   present   an   implementation   of   the   algorithm   which   is   based   on   the   BLAST   model   checker ,   and   we   evaluate   some   case   studies . " ,   ' title ' :   ' Permissive   interfaces ' } 
{ ' abstract ' :   ' In   this   paper ,   we   propose   a   new   method   for   the   motion   planning   problem   of   rigid   object   dexterous   manipulation   with   a   robotic   multi - fingered   hand ,   under   quasi - static   movement   assumption .   This   method   computes   both   object   and   finger   trajectories   as   well   as   the   finger   relocation   sequence .   Its   specificity   is   to   use   a   special   structuring   of   the   research   space   that   allows   to   search   for   paths   directly   in   the   particular   subspace   GS   n     which   is   the   subspace   of   all   the   grasps   that   can   be   achieved   with   n   grasping   fingers .   The   solving   of   the   dexterous   manipulation   planning   problem   is   based   upon   the   exploration   of   this   subspace .   The   proposed   approach   captures   the   connectivity   of   GS   n     in   a   graph   structure .   The   answer   of   the   manipulation   planning   query   is   then   given   by   searching   a   path   in   the   computed   graph .   Simulation   experiments   were   conducted   for   different   dexterous   manipulation   task   examples   to   validate   the   proposed   method . ' ,   ' title ' :   ' Dexterous   manipulation   planning   using   probabilistic   roadmaps   in   continuous   grasp   subspaces ' } 
{ ' abstract ' :   ' This   paper   presents   an   experimental   evaluation   of   different   line   extraction   algorithms   applied   to   2D   laser   scans   for   indoor   environments .   Six   popular   algorithms   in   mobile   robotics   and   computer   vision   are   selected   and   tested .   Real   scan   data   collected   from   two   office   environments   by   using   different   platforms   are   used   in   the   experiments   in   order   to   evaluate   the   algorithms .   Several   comparison   criteria   are   proposed   and   discussed   to   highlight   the   advantages   and   drawbacks   of   each   algorithm ,   including   speed ,   complexity ,   correctness   and   precision .   The   results   of   the   algorithms   are   compared   with   ground   truth   using   standard   statistical   methods .   An   extended   case   study   is   performed   to   further   evaluate   the   algorithms   in   a   SLAM   application . ' ,   ' title ' :   ' A   comparison   of   line   extraction   algorithms   using   2D   range   data   for   indoor   mobile   robotics ' } 
{ ' abstract ' :   ' This   study   investigates   the   use   of   force - stiffness   feedback ,   i . e . ,   a   combination   of   force   offset   and   extra   spring   load ,   in   UAV   tele - operation   with   transmission   time   delay .   The   goal   was   to   further   increase   the   level   of   safety   of   tele - operation   with   a   reduction   in   operator   workload   with   respect   to   force   feedback ,   i . e . ,   using   force   offset   alone .   A   theoretical   analysis   is   given   of   using   force - stiffness   feedback   to   improve   collision   avoidance .   Wave   variables   are   included   to   reduce   time   delay   effects .   An   experiment   was   conducted   to   investigate   the   effects   of   force - stiffness   feedback   on   safety   of   operation ,   operator   performance ,   control   activity ,   and   workload .   Results   indicate   that   force - stiffness   feedback   improves   the   haptic   interface   with   respect   to   force   feedback   alone .   Safety   of   tele - operation   increases   without   increasing   operator   workload   with   respect   to   force   feedback . ' ,   ' title ' :   ' Haptic   interface   in   UAV   tele - operation   using   force - stiffness   feedback ' } 
{ ' abstract ' :   ' Due   to   the   spread   of   the   internet   and   the   ever   increasing   number   of   web   applications ,   the   issue   of   compatibility   across   browsers   has   become   very   important .   This   compatibility   issue   is   also   referred   as   Cross   Browser   Inconsistency   ( XBI )   wherein   same   website   looks   or   behaves   differently   in   different   web   browsers .   In   this   paper   our   aim   is   to   address   this   issue   of   compatibility   and   propose   an   automated   approach   of   detecting   XBIs .   Cross   Browser   Inconsistencies   can   either   be   in   the   content ,   structure   or   behavior   of   the   webpage .   In   order   to   get   a   grasp   of   the   above   mentioned   types   of   inconsistencies ,   we   surveyed   some   random   websites   and   analyzed   them   in   different   browsers .   We   also   studied   the   basic   working   of   browser ,   in   order   to   establish   its   connection   with   the   occurrences   of   XBIs .   Each   browser   has   its   own   rendering   mechanisms ,   which   sometimes   differs   from   standards .   Hence ,   the   execution   of   these   websites   is   different   in   different   browsers .   Finally   we   have   proposed   an   automated   approach   for   XBI   detection . ' ,   ' title ' :   ' An   Automated   Approach   for   Cross - Browser   Inconsistency   ( XBI )   Detection ' } 
{ ' abstract ' :   ' We   present   a   formal   framework   that   combines   high - level   representation   and   causality - based   reasoning   with   low - level   geometric   reasoning   and   motion   planning .   The   frame - work   features   bilateral   interaction   between   task   and   motion   planning ,   and   embeds   geometric   reasoning   in   causal   reasoning ,   thanks   to   several   advantages   inherited   from   its   underlying   components .   In   particular ,   our   choice   of   using   a   causality - based   high - level   formalism   for   describing   action   domains   allows   us   to   represent   ramifications   and   state / transition   constraints ,   and   embed   in   such   formal   domain   descriptions   externally   defined   functions   implemented   in   some   programming   language   ( e . g . ,   C++ ) .   Moreover ,   given   such   a   domain   description ,   the   causal   reasoner   based   on   this   formalism   ( i . e . ,   the   Causal   Calculator )   allows   us   to   compute   optimal   solutions   ( e . g . ,   shortest   plans )   for   elaborate   planning / prediction   problems   with   temporal   constraints .   Utilizing   these   features   of   high - level   representation   and   reasoning ,   we   can   combine   causal   reasoning ,   motion   planning   and   geometric   planning   to   find   feasible   kinematic   solutions   to   task - level   problems .   In   our   framework ,   the   causal   reasoner   guides   the   motion   planner   by   finding   an   optimal   task - plan ;   if   there   is   no   feasible   kinematic   solution   for   that   task - plan   then   the   motion   planner   guides   the   causal   reasoner   by   modifying   the   planning   problem   with   new   temporal   constraints .   Furthermore ,   while   computing   a   task - plan ,   the   causal   reasoner   takes   into   account   geometric   models   and   kinematic   relations   by   means   of   external   predicates   implemented   for   geometric   reasoning   ( e . g . ,   to   check   some   collisions ) ;   in   that   sense   the   geometric   reasoner   guides   the   causal   reasoner   to   find   feasible   kinematic   solutions .   We   illustrate   an   application   of   this   framework   to   robotic   manipulation ,   with   two   pantograph   robots   on   a   complex   assembly   task   that   requires   concurrent   execution   of   actions .   A   short   video   of   this   application   accompanies   the   paper . ' ,   ' title ' :   ' Combining   high - level   causal   reasoning   with   low - level   geometric   reasoning   and   motion   planning   for   robotic   manipulation ' } 
{ ' abstract ' :   ' This   paper   presents   a   novel   template   matching   method   to   detect   and   track   pedestrians   for   people   counting   in   real - time .   Firstly ,   a   novel   background   subtraction   method   is   proposed   for   extracting   all   foreground   objects   from   background .   Then ,   a   shadow   elimination   method   is   used   to   remove   unwanted   shadow   from   the   background .   In   order   to   identify   pedestrians   from   non - pedestrian   objects ,   this   paper   proposed   a   novel   grid - based   template   matching   scheme   to   robustly   verify   each   pedestrian .   Usually ,   a   pedestrian   will   have   different   appearances   at   different   positions .   The   grid - based   approach   can   effectively   reduce   the   perspective   effects   into   a   minimum   since   it   uses   different   templates   to   record   the   appearance   changes   at   each   grid .   When   more   templates   are   used ,   the   detection   process   will   become   more   inefficient .   To   speed   up   its   efficiency ,   an   integral   image   is   used   to   filter   out   all   impossible   candidates   in   advance .   Lastly ,   a   tracking   method   is   applied   to   tracking   the   direction   of   each   moving   pedestrian   so   that   the   real   number   of   passing   people   per   direction   can   be   counted   more   accurately .   Experimental   results   have   proved   that   the   proposed   method   is   robust ,   accurate ,   and   powerful   in   people   counting . ' ,   ' title ' :   ' Grid - based   Template   Matching   for   People   Counting ' } 
{ ' abstract ' :   ' A   tomographic   image   reconstruction   algorithm   that   we   have   been   studying   requires   the   nth - order   Hankel   transform   for   the   nth   function   in   a   series ,   where   n   varies   over   a   set   of   integers .   Unfortunately ,   most   previously   proposed   algorithms   have   either   dealt   with   only   zeroth - order   transforms   or   cannot   be   applied   conveniently   to   our   problem .   We   propose   an   algorithm   for   computing   general   integer - order   Hankel   transforms .   The   algorithm   takes   samples   of   equally   spaced   input   functions   and   gives   equally   spaced   samples   of   the   transforms . ' ,   ' title ' :   ' An   algorithm   for   computing   general   integer - order   Hankel   transforms ' } 
{ ' abstract ' :   ' In   this   paper ,   we   present   a   real - time   approach   that   allows   tracking   deformable   structures   in   3D   ultrasound   sequences .   Our   method   consists   in   obtaining   the   target   displacements   by   combining   robust   dense   motion   estimation   and   mechanical   model   simulation .   We   perform   evaluation   of   our   method   through   simulated   data ,   phantom   data ,   and   real - data .   Results   demonstrate   that   this   novel   approach   has   the   advantage   of   providing   correct   motion   estimation   regarding   different   ultrasound   shortcomings   including   speckle   noise ,   large   shadows   and   ultrasound   gain   variation .   Furthermore ,   we   show   the   good   performance   of   our   method   with   respect   to   state - of - the - art   techniques   by   testing   on   the   3D   databases   provided   by   MICCAI   CLUST ’ 14   and   CLUST ’ 15   challenges . ' ,   ' title ' :   ' Real - time   target   tracking   of   soft   tissues   in   3D   ultrasound   images   based   on   robust   visual   information   and   mechanical   simulation ' } 
{ ' abstract ' :   ' For   two   given   graphs   G1G1   and   G2G2 ,   the   Ramsey   number   R ( G1 , G2 ) R ( G1 , G2 )   is   the   smallest   integer   NN   such   that   for   any   graph   of   order   NN ,   either   GG   contains   a   copy   of   G1G1   or   its   complement   contains   a   copy   of   G2G2 .   Let   CmCm   be   a   cycle   of   length   mm   and   K1 , nK1 , n   a   star   of   order   n + 1n + 1 .   Parsons   ( 1975 )   shows   that   R ( C4 , K1 , n ) ≤ n + ⌊ n − 1 ⌋ + 2   and   if   nn   is   the   square   of   a   prime   power ,   then   the   equality   holds .   In   this   paper ,   by   discussing   the   properties   of   polarity   graphs   whose   vertices   are   points   in   the   projective   planes   over   Galois   fields ,   we   prove   that   R ( C4 , K1 , q2 − t ) = q2 + q − ( t − 1 ) R ( C4 , K1 , q2 − t ) = q2 + q − ( t − 1 )   if   qq   is   an   odd   prime   power ,   1 ≤ t ≤ 2 ⌈ q4 ⌉   and   t ≠ 2 ⌈ q4 ⌉ − 1 ,   which   extends   a   result   on   R ( C4 , K1 , q2 − t ) R ( C4 , K1 , q2 − t )   obtained   by   Parsons   ( 1976 ) . ' ,   ' title ' :   ' Polarity   graphs   and   Ramsey   numbers   for   C   4   versus   stars ' } 
{ ' abstract ' :   ' This   paper   deals   with   the   problem   of   assuring   strict   QoS   guarantees   for   the   end   to   end   connections   that   originate   from   Ethernet   access   network .   It   shows   that   despite   high   link   capacities   in   some   cases   Ethernet   network   might   be   the   reason   of   QoS   deterioration .   The   primary   reason   is   the   lack   of   appropriate   QoS   differentiation   and   traffic   isolation   mechanisms .   The   shared   buffers   and   priority   schedulers   available   in   most   of   Ethernet   switches   appear   to   be   not   sufficient   to   guarantee   strict   QoS .   For   these   cases   new   solution   is   proposed   which   relies   on   additional   traffic   control   mechanisms   available   in   other   network   elements .   Only   additional   mechanism   supporting   typical   functionality   of   Ethernet   switch   can   provide   strict   QoS   guarantees   what   was   verified   in   simulations   studies . ' ,   ' title ' :   ' On   assuring   QoS   in   Ethernet   access   network ' } 
{ ' abstract ' :   ' The   federal   Medicare   regulations   reimburse   hospitals   on   a   pro   rata   share   of   the   hospital \ ' s   cost .   Hence ,   to   meet   its   financial   requirements ,   a   hospital   is   forced   to   shift   more   of   the   financial   burdens   onto   its   private   patients .   This   procedure   has   contributed   to   double   digit   inflation   in   hospital   prices   and   to   proposed   federal   regulation   to   control   the   rate   of   increase   in   hospital   revenues .   In   this   regulatory   environment ,   we   develop   nonlinear   programming   pricing   and   cost   allocation   models   to   aid   hospital   administrators   in   meeting   their   profit   maximizing   and   profit   satisficing   goals .   The   model   enables   administrators   to   explore   tactical   issues   such   as :   i   studying   the   relationship   between   a   voluntary   or   legislated   cap   on   a   hospital \ ' s   total   revenues   and   the   hospital \ ' s   profitability ,   ii   identifying   those   departments   within   the   hospital   that   are   the   most   attractive   candidates   for   cost   reduction   or   cost   containment   efforts ,   and   iii   isolating   those   services   that   should   be   singled   out   by   the   hospital   manager   for   renegotiation   of   the   prospective   or   " customary   and   reasonable "   cap .   Finally ,   the   modeling   approach   is   helpful   in   explaining   the   departmental   cross   subsidies   observed   in   practice ,   and   can   be   of   aid   to   federal   administrators   in   assessing   the   impacts   of   proposed   changes   in   the   Medicare   reimbursement   formula . ' ,   ' title ' :   ' Hospital   Profit   Planning   under   Medicare   Reimbursement ' } 
{ ' abstract ' :   ' We   present   a   ( 4   +   epsilon )   approximation   algorithm   for   weighted   graph   matching   which   applies   in   the   semistreaming ,   sliding   window ,   and   MapReduce   models ;   this   single   algorithm   improves   the   previous   best   algorithm   in   each   model .   The   algorithm   operates   by   reducing   the   maximum - weight   matching   problem   to   a   polylog   number   of   copies   of   the   maximum - cardinality   matching   problem .   The   algorithm   also   extends   to   provide   approximation   guarantees   for   the   more   general   problem   of   finding   weighted   independent   sets   in   p - systems   ( which   include   intersections   of   p   matroids   and   p - bounded   hypergraph   matching ) . ' ,   ' title ' :   ' Improved   Streaming   Algorithms   for   Weighted   Matching ,   via   Unweighted   Matching ' } 
{ ' abstract ' :   ' This   paper   presents   a   novel   approach   to   efficiently   solve   parameter - dependent   ( PD )   linear   matrix   inequality   ( LMI )   problems   for ,   amongst   others ,   linear   parameter - varying   ( LPV )   control   design .   Typically ,   stability   and   performance   is   guaranteed   by   finding   a   PD   Lyapunov   function   such   that   a   PD   LMI   is   feasible   on   a   parameter   domain .   To   solve   the   resulting   semi - infinite   problems ,   we   propose   a   novel   LMI   relaxation   technique   relying   on   B - spline   basis   functions .   This   technique   provides   less   conservative   solutions   and / or   a   reduced   numerical   burden   compared   to   existing   approaches .   Moreover ,   an   elegant   generalization   of   worst - case   optimization   to   the   optimization   of   any   signal   norm   is   obtained   by   expressing   performance   bounds   as   a   function   of   the   system   parameters .   This   generalization   yields   better   performance   bounds   in   a   large   part   of   the   parameter   domain .   Numerical   comparisons   with   the   current   state - of - the - art   demonstrate   the   generality   and   effectiveness   of   our   approach . ' ,   ' title ' :   ' Control   of   linear   parameter - varying   systems   using   B - splines ' } 
{ ' abstract ' :   ' There   is   a   growing   interest   in   simulating   natural   phenomena   in   computer   graphics   applications .   Animating   natural   scenes   in   real   time   is   one   of   the   most   challenging   problems   due   to   the   inherent   complexity   of   their   structure ,   formed   by   millions   of   geometric   entities ,   and   the   interactions   that   happen   within .   An   example   of   natural   scenario   that   is   needed   for   games   or   simulation   programs   are   forests .   Forests   are   difficult   to   render   because   the   huge   amount   of   geometric   entities   and   the   large   amount   of   detail   to   be   represented .   Moreover ,   the   interactions   between   the   objects   ( grass ,   leaves )   and   external   forces   such   as   wind   are   complex   to   model .   In   this   paper   we   concentrate   in   the   rendering   of   falling   leaves   at   low   cost .   We   present   a   technique   that   exploits   graphics   hardware   in   order   to   render   thousands   of   leaves   with   different   falling   paths   in   real   time   and   low   memory   requirements . ' ,   ' title ' :   ' Rendering   falling   leaves   on   graphics   hardware ' } 
{ ' abstract ' :   ' We   previously   presented   DriverDB ,   a   database   that   incorporates   ∼ 6000   cases   of   exome - seq   data ,   in   addition   to   annotation   databases   and   published   bioinformatics   algorithms   dedicated   to   driver   gene / mutation   identification .   The   database   provides   two   points   of   view ,   ‘ Cancer ’   and   ‘ Gene ’ ,   to   help   researchers   visualize   the   relationships   between   cancers   and   driver   genes / mutations .   In   the   updated   DriverDBv2   database   ( http : / / ngs . ym . edu . tw / driverdb )   presented   herein ,   we   incorporated   > 9500   cancer - related   RNA - seq   datasets   and   > 7000   more   exome - seq   datasets   from   The   Cancer   Genome   Atlas   ( TCGA ) ,   International   Cancer   Genome   Consortium   ( ICGC ) ,   and   published   papers .   Seven   additional   computational   algorithms   ( meaning   that   the   updated   database   contains   15   in   total ) ,   which   were   developed   for   driver   gene   identification ,   are   incorporated   into   our   analysis   pipeline ,   and   the   results   are   provided   in   the   ‘ Cancer ’   section .   Furthermore ,   there   are   two   main   new   features ,   ‘ Expression ’   and   ‘ Hotspot ’ ,   in   the   ‘ Gene ’   section .   ‘ Expression ’   displays   two   expression   profiles   of   a   gene   in   terms   of   sample   types   and   mutation   types ,   respectively .   ‘ Hotspot ’   indicates   the   hotspot   mutation   regions   of   a   gene   according   to   the   results   provided   by   four   bioinformatics   tools .   A   new   function ,   ‘ Gene   Set ’ ,   allows   users   to   investigate   the   relationships   among   mutations ,   expression   levels   and   clinical   data   for   a   set   of   genes ,   a   specific   dataset   and   clinical   features . ' ,   ' title ' :   ' DriverDBv2 :   a   database   for   human   cancer   driver   gene   research ' } 
{ ' abstract ' :   ' Thousands   of   deep   and   wide   pipelines   working   concurrently   make   GPGPU   high   power   consuming   parts .   Energy - efficiency   techniques   employ   voltage   overscaling   that   increases   timing   sensitivity   to   variations   and   hence   aggravating   the   energy   use   issues .   This   paper   proposes   a   method   to   increase   spatiotemporal   reuse   of   computational   effort   by   a   combination   of   compilation   and   micro - architectural   design .   An   associative   memristive   memory   ( AMM )   module   is   integrated   with   the   floating   point   units   ( FPUs ) .   Together ,   we   enable   fine - grained   partitioning   of   values   and   find   high - frequency   sets   of   values   for   the   FPUs   by   searching   the   space   of   possible   inputs ,   with   the   help   of   application - specific   profile   feedback .   For   every   kernel   execution ,   the   compiler   pre - stores   these   high - frequent   sets   of   values   in   AMM   modules   - -   representing   partial   functionality   of   the   associated   FPU - -   that   are   concurrently   evaluated   over   two   clock   cycles .   Our   simulation   results   show   high   hit   rates   with   32 - entry   AMM   modules   that   enable   36%   reduction   in   average   energy   use   by   the   kernel   codes .   Compared   to   voltage   overscaling ,   this   technique   enhances   robustness   against   timing   errors   with   39%   average   energy   saving . ' ,   ' title ' :   ' Energy - Efficient   GPGPU   Architectures   via   Collaborative   Compilation   and   Memristive   Memory - Based   Computing ' } 
{ ' abstract ' :   ' Quasi - cyclic   codes   are   renowned   for   their   structural   design   and   low - complexity   shift   register   encoding .   However ,   existing   design   techniques   based   on   difference   families   have   limited   code   size   options   due   to   algebraic   constraints .   We   introduce   in   this   paper   a   notation   of   extended   difference   family   ( EDF )   and   provide   a   systematic   code   design   based   on   EDFs   with   a   high   degree   of   flexibility   in   code   size .   Short / medium - length   codes   of   high   rate   ( / spl   ges /   0.9 )   can   be   easily   constructed . ' ,   ' title ' :   ' Quasi - cyclic   codes   from   extended   difference   families ' } 
{ ' abstract ' :   ' Lexical   cohesion   arises   from   a   chain   of   lexical   items   that   establish   links   between   sentences   in   a   text .   In   this   paper   we   propose   three   different   models   to   capture   lexical   cohesion   for   document - level   machine   translation :   ( a )   a   direct   reward   model   where   translation   hypotheses   are   rewarded   whenever   lexical   cohesion   devices   occur   in   them ,   ( b )   a   conditional   probability   model   where   the   appropriateness   of   using   lexical   cohesion   devices   is   measured ,   and   ( c )   a   mutual   information   trigger   model   where   a   lexical   cohesion   relation   is   considered   as   a   trigger   pair   and   the   strength   of   the   association   between   the   trigger   and   the   triggered   item   is   estimated   by   mutual   information .   We   integrate   the   three   models   into   hierarchical   phrase - based   machine   translation   and   evaluate   their   effectiveness   on   the   NIST   Chinese - English   translation   tasks   with   large - scale   training   data .   Experiment   results   show   that   all   three   models   can   achieve   substantial   improvements   over   the   baseline   and   that   the   mutual   information   trigger   model   performs   better   than   the   others . ' ,   ' title ' :   ' Modeling   lexical   cohesion   for   document - level   machine   translation ' } 
{ ' abstract ' :   ' This   paper   presents   a   lightweight   sketching   system   that   enables   interactive   illustration   of   complex   fluid   systems .   Users   can   sketch   on   a   2.5 - dimensional   ( 2.5 D )   canvas   to   design   the   shapes   and   connections   of   a   fluid   circuit .   These   input   sketches   are   automatically   analyzed   and   abstracted   into   a   hydraulic   graph ,   and   a   new   hybrid   fluid   model   is   used   in   the   background   to   enhance   the   illustrations .   The   system   provides   rich   simple   operations   for   users   to   edit   the   fluid   system   incrementally ,   and   the   new   internal   flow   patterns   can   be   simulated   in   real   time .   Our   system   is   used   to   illustrate   various   fluid   systems   in   medicine ,   biology ,   and   engineering .   We   asked   professional   medical   doctors   to   try   our   system   and   obtained   positive   feedback   from   them . ' ,   ' title ' :   ' Sketch - based   Dynamic   Illustration   of   Fluid   Systems ' } 
{ ' abstract ' :   ' We   present   an   improved   zone   content   classification   method   and   its   performance   evaluation .   We   added   two   new   features   to   the   feature   vector   from   one   previously   published   method   ( Sivaramakrishnan   et   al . ,   1995 ) .   We   assumed   different   independence   relationships   in   two   zone   sets .   We   used   an   optimized   binary   decision   tree   to   estimate   the   maximum   zone   content   class   probability   in   one   set   while   using   the   Viterbi   algorithm   to   find   the   optimal   solution   for   a   zone   sequence   in   the   other   set .   The   training ,   pruning   and   testing   data   set   for   the   algorithm   include   1 , 600   images   drawn   from   the   UWCDROM   III   document   image   database .   The   classifier   is   able   to   classify   each   given   scientific   and   technical   document   zone   into   one   of   the   nine   classes ,   2   text   classes   ( of   font   size   4   -   18pt   and   font   size   19   -   32   pt ) ,   math ,   table ,   halftone ,   map / drawing ,   ruling ,   logo ,   and   others .   Compared   with   our   previous   work   ( Wang   et   al . ,   2000 ) ,   it   raised   the   accuracy   rate   to   98.52%   from   97.53%   and   reduced   the   mean   false   alarm   rate   to   0.53%   from   1.26% . ' ,   ' title ' :   ' Zone   content   classification   and   its   performance   evaluation ' } 
{ ' abstract ' :   ' Big   Data   applications   require   real - time   processing   of   complex   computations   on   streaming   and   static   information .   Applications   such   as   the   diagnosis   of   power   generating   turbines   require   the   integration   of   high   velocity   streaming   and   large   volume   of   static   data   from   multiple   sources .   In   this   paper   we   study   various   optimisations   related   to   efficiently   processing   of   streaming   and   static   information .   We   introduce   novel   indexing   structures   for   stream   processing ,   a   query - planner   component   that   decides   when   their   creation   is   beneficial ,   and   we   examine   precomputed   summarisations   on   archived   measurements   to   accelerate   streaming   and   static   information   processing .   To   put   our   ideas   into   practise ,   we   have   developed   Exa   Stream ,   a   data   stream   management   system   that   is   scalable ,   has   declarative   semantics ,   supports   user   defined   functions ,   and   allows   efficient   execution   of   complex   analytical   queries   on   streaming   and   static   data .   Our   work   is   accompanied   by   an   empirical   evaluation   of   our   optimisation   techniques . ' ,   ' title ' :   ' Real   time   processing   of   streaming   and   static   information ' } 
{ ' abstract ' :   " In   the   last   ten   years ,   speech   recognition   has   evolved   from   a   science   fiction   dream   to   a   widespread   input   method   for   mobile   devices .   In   this   talk ,   I   will   describe   how   speech   recognition   works ,   the   problems   we   have   solved   and   the   challenges   that   remain .   I   will   touch   upon   some   of   Google ' s   main   efforts   in   language   and   pronunciation   modeling ,   and   describe   how   the   adoption   of   neural   networks   for   acoustic   modeling   marked   the   beginning   of   a   technology   revolution   in   the   field ,   with   approaches   such   as   Long   Short   Term   Memory   models   and   Connectionist   Temporal   Classification .   I   will   also   share   my   learnings   on   how   Machine   Learning   and   Human   Knowledge   can   be   harmoniously   combined   to   build   state - of - the - art   technology   that   helps   and   delights   users   across   the   world . " ,   ' title ' :   ' Learnings   and   innovations   in   speech   recognition ' } 
{ ' abstract ' :   ' Nowadays ,   the   explosive   growth   and   variety   of   information   available   on   the   Web   frequently   overwhelms   users   and   leads   users   to   make   poor   decisions .   Consequently ,   recommender   systems   have   become   more   and   more   important   to   assist   people   to   make   decisions   faster .   Among   all   related   techniques ,   collaborative   filtering   approach   is   currently   one   of   the   effective   and   widely   used   techniques   to   build   recommender   systems .   However ,   there   are   major   challenges   like   data   sparsity   and   scalability .   Meanwhile   it   is   hard   to   integrate   demographic   statistical   information   ( Age ,   gender   and   occupation   etc . )   to   collaborative   filtering   model .   Unfortunately ,   it   is   significant   to   take   account   into   these   information ,   especially   user   occupation   when   making   recommendation .   As   we   all   know ,   people   with   different   occupations   may   have   totally   different   tastes .   It   has   been   proved   that   restricted   Boltzmann   machines ( RBM )   model   can   infer   lower - dimensional   representations   automatically   and   is   potential   in   handling   large   and   sparse   dataset .   In   this   paper ,   we   propose   an   improved   User   Occupation   aware   Conditional   Restricted   Boltzmann   Machine   Frame ( UO - CRBMF )   model ,   which   employs   an   improved   RBM   and   takes   full   use   of   user   occupation   information   by   adding   a   conditional   layer   with   user   occupation   information .   Experimental   studies   on   the   standard   benchmark   datasets   of   MovieLens   100k   and   MovieLens   1M   have   shown   its   potential   and   advantages   beyond   baseline   methods . ' ,   ' title ' :   ' User   Occupation   Aware   Conditional   Restricted   Boltzmann   Machine   Based   Recommendation ' } 
{ ' abstract ' :   ' Microservices   complement   approaches   like   DevOps   and   continuous   delivery   in   terms   of   software   architecture .   Along   with   this   architectural   style ,   several   important   deployment   technologies ,   such   as   container - based   virtualization   and   container   orchestration   solutions ,   have   emerged .   These   technologies   allow   to   efficiently   exploit   cloud   platforms ,   providing   a   high   degree   of   scalability ,   availability ,   and   portability   for   microservices .# R ## N ## R ## N # Despite   the   obvious   importance   of   a   sufficient   level   of   performance ,   there   is   still   a   lack   of   performance   engineering   approaches   explicitly   taking   into   account   the   particularities   of   microservices .   In   this   paper ,   we   argue   why   new   solutions   to   performance   engineering   for   microservices   are   needed .   Furthermore ,   we   identify   open   issues   and   outline   possible   research   directions   with   regard   to   performance - aware   testing ,   monitoring ,   and   modeling   of   microservices . ' ,   ' title ' :   ' Performance   Engineering   for   Microservices :   Research   Challenges   and   Directions ' } 
{ ' abstract ' :   ' Intelligent   agents ,   such   as   robots ,   have   to   serve   a   multitude   of   autonomous   functions .   Examples   are ,   e . g . ,   collision   avoidance ,   navigation   and   route   planning ,   active   sensing   of   its   environment ,   or   the   interaction   and   non - verbal   communication   with   people   in   the   extended   reach   space .   Here ,   we   focus   on   the   recognition   of   the   action   of   a   human   agent   based   on   a   biologically   inspired   visual   architecture   of   analyzing   articulated   movements .   The   proposed   processing   architecture   builds   upon   coarsely   segregated   streams   of   sensory   processing   along   different   pathways   which   separately   process   form   and   motion   information   ( Layher   et   al . ,   2014 ) .   Action   recognition   is   performed   in   an   event - based   scheme   by   identifying   representations   of   characteristic   pose   configurations   ( key   poses )   in   an   image   sequence .   In   line   with   perceptual   studies ,   key   poses   are   selected   unsupervised   utilizing   a   feature   driven   criterion   which   combines   extrema   in   the   motion   energy   with   the   horizontal   and   the   vertical   extendedness   of   a   body   shape .   Per   class   representations   of   key   pose   frames   are   learned   using   a   deep   convolutional   neural   network   consisting   of   15   convolutional   layers .   The   network   is   trained   using   the   energy - efficient   deep   neuromorphic   networks   ( Eedn )   framework   ( Esser   et   al . ,   2016 ) ,   which   realizes   the   mapping   of   the   trained   synaptic   weights   onto   the   IBM   Neurosynaptic   System   platform   ( Merolla   et   al . ,   2014 ) .   After   the   mapping ,   the   trained   network   achieves   real - time   capabilities   for   processing   input   streams   and   classify   input   images   at   about   1 , 000   frames   per   second   while   the   computational   stages   only   consume   about   70   mW   of   energy   ( without   spike   transduction ) .   Particularly   regarding   mobile   robotic   systems ,   a   low   energy   profile   might   be   crucial   in   a   variety   application   scenarios .   Cross - validation   results   are   reported   for   two   different   datasets   and   compared   to   state - of - the - art   action   recognition   approaches .   The   results   demonstrate ,   that   ( I )   the   presented   approach   is   on   par   with   other   key   pose   based   methods   described   in   the   literature ,   which   select   key   pose   frames   by   optimizing   classification   accuracy ,   ( II )   compared   to   the   training   on   the   full   set   of   frames ,   representations   trained   on   key   pose   frames   result   in   a   higher   confidence   in   class   assignments ,   and   ( III )   key   pose   representations   show   promising   generalization   capabilities   in   a   cross - dataset   evaluation . ' ,   ' title ' :   ' Real - Time   Biologically   Inspired   Action   Recognition   from   Key   Poses   Using   a   Neuromorphic   Architecture ' } 
{ ' abstract ' :   ' Contents   carried   in   an   image   are   valuable   information   sources   for   many   scientific   and   engineering   applications .   However ,   if   the   image   is   captured   under   low   illumination   conditions   a   large   portion   of   the   image   appears   dark   and   this   heavily   degrades   the   image   quality .   In   order   to   solve   this   problem ,   a   restoration   algorithm   is   developed   here   that   transforms   the   low   input   brightness   to   a   higher   value   using   a   logarithmic   mapping   function .   The   mapping   is   further   refined   by   a   linear   weighting   with   the   input   to   reduce   the   un - necessary   amplification   at   regions   with   high   brightness .   Moreover ,   fine   details   in   the   image   are   preserved   by   applying   the   Retinex   principle   to   extract   and   then   re - insert   object   edges .   Results   from   experiments   using   low   and   normal   illumination   images   have   shown   satisfactory   performances   with   regard   to   the   improvement   in   information   contents   and   the   mitigation   of   viewing   artifacts . ' ,   ' title ' :   ' Logarithmic   profile   mapping   and   Retinex   edge   preserving   for   restoration   of   low   illumination   images ' } 
{ ' abstract ' :   ' We   propose   a   principled   approach   for   the   problem   of   aligning   multiple   partially   overlapping   networks .   The   objective   is   to   map   multiple   graphs   into   a   single   graph   while   preserving   vertex   and   edge   similarities .   The   problem   is   inspired   by   the   task   of   integrating   partial   views   of   a   family   tree   ( genealogical   network )   into   one   unified   network ,   but   it   also   has   applications ,   for   example ,   in   social   and   biological   networks .   Our   approach ,   called   Flan ,   introduces   the   idea   of   generalizing   the   facility   location   problem   by   adding   a   non - linear   term   to   capture   edge   similarities   and   to   infer   the   underlying   entity   network .   The   problem   is   solved   using   an   alternating   optimization   procedure   with   a   Lagrangian   relaxation .   Flan   has   the   advantage   of   being   able   to   leverage   prior   information   on   the   number   of   entities ,   so   that   when   this   information   is   available ,   Flan   is   shown   to   work   robustly   without   the   need   to   use   any   ground   truth   data   for   fine - tuning   method   parameters .   Additionally ,   we   present   three   multiple - network   extensions   to   an   existing   state - of - the - art   pairwise   alignment   method   called   Natalie .   Extensive   experiments   on   synthetic ,   as   well   as   real - world   datasets   on   social   networks   and   genealogical   networks ,   attest   to   the   effectiveness   of   the   proposed   approaches   which   clearly   outperform   a   popular   multiple   network   alignment   method   called   IsoRankN . ' ,   ' title ' :   ' Lagrangian   relaxations   for   multiple   network   alignment ' } 
{ ' abstract ' :   ' Heterogeneous   ultra - dense   networks   enable   ultra - high   data   rates   and   ultra - low   latency   through   the   use   of   dense   sub - 6   GHz   and   millimeter   wave   ( mmWave )   small   cells   with   different   antenna   configurations .   Existing   work   has   widely   studied   spectral   and   energy   efficiency   in   such   networks   and   shown   that   high   spectral   and   energy   efficiency   can   be   achieved .   This   article   investigates   the   benefits   of   heterogeneous   ultra - dense   network   architecture   from   the   perspectives   of   three   promising   technologies ,   i . e . ,   physical   layer   security ,   caching ,   and   wireless   energy   harvesting ,   and   provides   enthusiastic   outlook   towards   application   of   these   technologies   in   heterogeneous   ultra - dense   networks .   Based   on   the   rationale   of   each   technology ,   opportunities   and   challenges   are   identified   to   advance   the   research   in   this   emerging   network . ' ,   ' title ' :   ' A   New   Look   at   Physical   Layer   Security ,   Caching ,   and   Wireless   Energy   Harvesting   for   Heterogeneous   Ultra - dense   Networks ' } 
{ ' abstract ' :   ' We   consider   the   problem   of   joint   modeling   of   videos   and   their   corresponding   textual   descriptions   ( e . g .   sentences   or   phrases ) .   Our   approach   consists   of   three   components :   the   video   representation ,   the   textual   representation ,   and   a   joint   model   that   links   videos   and   text .   Our   video   representation   uses   the   state - of - the - art   deep   3D   ConvNet   to   capture   the   semantic   information   in   the   video .   Our   textual   representation   uses   the   recent   advancement   in   learning   word   and   sentence   vectors   from   large   text   corpus .   The   joint   model   is   learned   to   score   the   correct   ( video ,   text )   pairs   higher   than   the   incorrect   ones .   We   demonstrate   our   approach   in   several   applications :   1 )   retrieving   sentences   given   a   video ;   2 )   retrieving   videos   given   a   sentence ;   3 )   zero - shot   action   recognition   in   videos . ' ,   ' title ' :   ' Beyond   verbs :   Understanding   actions   in   videos   with   text ' } 
{ ' abstract ' :   ' This   paper   presents   a   multi - agent   model   for   simulating   attitude   formation   and   change   based   on   perception   and   communication   in   the   context   of   stabilization   operations .   The   originality   of   our   model   comes   from   ( 1 )   attitude   computation   that   evaluates   information   as   part   of   a   history   relative   to   the   individual   ( 2 )   a   notion   of   co - responsibility   for   attitude   attribution .   We   present   a   military   scenario   of   French   operations   in   Afghanistan   along   with   polls   results   about   the   opinion   of   citizen   toward   present   Forces .   Based   on   these   field   data ,   we   calibrate   the   model   and   show   the   resulting   attitude   dynamics .   We   study   the   sensibility   of   the   model   to   the   co - responsibility   factor . ' ,   ' title ' :   ' From   Field   Data   to   Attitude   Formation ' } 
{ ' abstract ' :   ' This   paper   proposes   two   low - complexity   iterative   algorithms   to   compute   the   capacity   of   a   single - user   multiple - input   multiple - output   channel   with   per - antenna   power   constraint .   The   first   method   results   from   manipulating   the   optimality   conditions   of   the   considered   problem   and   applying   fixed - point   iteration .   In   the   second   approach ,   we   transform   the   considered   problem   into   a   minimax   optimization   program   using   the   well - known   MAC -   BC   duality ,   and   then   solve   it   by   a   novel   alternating   optimization   method .   In   both   proposed   iterative   methods ,   each   iteration   involves   an   optimization   problem   which   can   be   efficiently   solved   by   the   water - filling   algorithm .   The   proposed   iterative   methods   are   provably   convergent .   Complexity   analysis   and   extensive   numerical   experiments   are   carried   out   to   demonstrate   the   superior   performance   of   the   proposed   algorithms   over   an   existing   approach   known   as   the   mode - dropping   algorithm . ' ,   ' title ' :   ' Low - complexity   Approaches   for   MIMO   Capacity   with   Per - antenna   Power   Constraint ' } 
{ ' abstract ' :   ' Inventory - Aware   Pathfinding   is   concerned   with   finding   paths   while   taking   into   account   that   picking   up   items ,   e . g . ,   keys ,   allow   the   character   to   unlock   blocked   pathways ,   e . g . ,   locked   doors .   In   this   work   we   present   a   pruning   method   and   a   preprocessing   method   that   can   improve   significantly   the   scalability   of   such   approaches .   We   apply   our   methods   to   the   recent   approach   of   Inventory - Driven   Jump - Point   Search   ( InvJPS ) .   First ,   we   introduce   InvJPS +   that   allows   to   prune   large   parts   of   the   search   space   by   favoring   short   detours   to   pick   up   items ,   offering   a   trade - off   between   efficiency   and   optimality .   Second ,   we   propose   a   preprocessing   step   that   allows   to   decide   on   runtime   which   items ,   e . g . ,   keys ,   are   worth   using   thus   pruning   potentially   unnecessary   items   before   the   search   starts .   We   show   results   for   combinations   of   the   pruning   and   preprocessing   methods   illustrating   the   best   choices   over   various   scenarios . ' ,   ' title ' :   ' Pruning   and   preprocessing   methods   for   inventory - aware   pathfinding ' } 
{ ' abstract ' :   ' This   paper   proposes   a   method   for   proper   names   extraction   from   Myanmar   text   by   using   latent   Dirichlet   allocation   ( LDA ) .   Our   method   aims   to   extract   proper   names   that   provide   important   information   on   the   contents   of   Myanmar   text .   Our   method   consists   of   two   steps .   In   the   first   step ,   we   extract   topic   words   from   Myanmar   news   articles   by   using   LDA .   In   the   second   step ,   we   make   a   post - processing ,   because   the   resulting   topic   words   contain   some   noisy   words .   Our   post - processing ,   first   of   all ,   eliminates   the   topic   words   whose   prefixes   are   Myanmar   digits   and   suffixes   are   noun   and   verb   particles .   We   then   remove   the   duplicate   words   and   discard   the   topic   words   that   are   contained   in   the   existing   dictionary .   Consequently ,   we   obtain   the   words   as   candidate   of   proper   names ,   namely   personal   names ,   geographical   names ,   unique   object   names ,   organization   names ,   single   event   names ,   and   so   on .   The   evaluation   is   performed   both   from   the   subjective   and   quantitative   perspectives .   From   the   subjective   perspective ,   we   compare   the   accuracy   of   proper   names   extracted   by   our   method   with   those   extracted   by   latent   semantic   indexing   ( LSI )   and   rule - based   method .   It   is   shown   that   both   LS ]   and   our   method   can   improve   the   accuracy   of   those   obtained   by   rule - based   method .   However ,   our   method   can   provide   more   interesting   proper   names   than   LSI .   From   the   quantitative   perspective ,   we   use   the   extracted   proper   names   as   additional   features   in   K - means   clustering .   The   experimental   results   show   that   the   document   clusters   given   by   our   method   are   better   than   those   given   by   LSI   and   rule - based   method   in   precision ,   recall   and   F - score . ' ,   ' title ' :   ' Extraction   of   proper   names   from   myanmar   text   using   latent   dirichlet   allocation ' } 
{ ' abstract ' :   ' Large   scale   assessment   of   aboveground   biomass   ( AGB )   in   tropical   forests   is   often   limited   by   the   saturation   of   remote   sensing   signals   at   high   AGB   values .   Fourier   Transform   Textural   Ordination   ( FOTO )   performs   well   in   quantifying   canopy   texture   from   very   high - resolution   ( VHR )   imagery ,   from   which   stand   structure   parameters   can   be   retrieved   with   no   saturation   effect   for   AGB   values   up   to   650   Mg · ha − 1 .   The   method   is   robust   when   tested   on   wet   evergreen   forests   but   is   more   demanding   when   applied   across   different   forest   types   characterized   by   varying   structures   and   allometries .   The   present   study   focuses   on   a   gradient   of   forest   types   ranging   from   dry   deciduous   to   wet   evergreen   forests   in   the   Western   Ghats   ( WG )   of   India ,   where   we   applied   FOTO   to   Cartosat - 1a   images   with   2.5   m   resolution .   Based   on   21   1 - ha   ground   control   forest   plots ,   we   calibrated   independent   texture – AGB   models   for   the   dry   and   wet   zone   forests   in   the   area ,   as   delineated   from   the   distribution   of   NDVI   values   computed   from   LISS - 4   multispectral   images .   This   stratification   largely   improved   the   relationship   between   texture - derived   and   field - derived   AGB   estimates ,   which   exhibited   a   R2   of   0.82   for   a   mean   rRMSE   of   ca .   17% .   By   inverting   the   texture – AGB   models ,   we   finally   mapped   AGB   predictions   at   1.6 - ha   resolution   over   a   heterogeneous   landscape   of   ca .   1500   km2   in   the   WG ,   with   a   mean   relative   per - pixel   propagated   error   < 20%   for   wet   zone   forests ,   i . e . ,   below   the   recommended   IPCC   criteria   for   Monitoring ,   Reporting   and   Verification   ( MRV )   methods .   The   method   proved   to   perform   well   in   predicting   high - resolution   AGB   values   over   heterogeneous   tropical   landscape   encompassing   diversified   forest   types ,   and   thus   presents   a   promising   option   for   affordable   regional   monitoring   systems   of   greenhouse   gas   ( GhG )   emissions   related   to   forest   degradation . ' ,   ' title ' :   ' Inverting   Aboveground   Biomass – Canopy   Texture   Relationships   in   a   Landscape   of   Forest   Mosaic   in   the   Western   Ghats   of   India   Using   Very   High   Resolution   Cartosat   Imagery ' } 
{ ' abstract ' :   ' Self - driving   vehicle   technologies   are   progressing   rapidly   and   are   expected   to   play   a   significant   role   in   the   future   of   transportation .   One   of   the   main   challenges   for   self - driving   vehicles   on   public   roads   is   the   safe   cooperation   and   collaboration   among   multiple   vehicles   using   sensor - based   perception   and   inter - vehicle   communications .   When   self - driving   vehicles   try   to   occupy   the   same   spatial   area   simultaneously ,   they   might   collide   with   one   another ,   might   become   deadlocked ,   or   might   slam   on   the   brakes   making   it   uncomfortable   or   unsafe   for   passengers   in   a   self - driving   vehicle .   In   this   paper ,   we   study   how   a   self - driving   vehicle   can   safely   navigate   merge   points ,   where   two   lanes   with   different   priorities   meet .   We   present   a   safe   protocol   for   merge   points   named   Autonomous   Vehicle   Protocol   for   Merge   Points ,   where   self - driving   vehicles   use   both   vehicular   communications   and   their   own   perception   systems   for   cooperating   with   other   self - driving   and / or   human - driven   vehicles .   Our   simulation   results   show   that   our   traffic   protocol   has   higher   traffic   throughput ,   compared   to   simple   traffic   protocols ,   while   ensuring   safety . ' ,   ' title ' :   ' A   merging   protocol   for   self - driving   vehicles ' } 
{ ' abstract ' :   ' System   Portfolio   Selection   ( SPS )   problem   is   equivalent   to   multi - objective   optimization   problem ,   with   multi - function   requirements   incommensurable .   In   the   paper ,   the   SPS   problem   is   re - specified   with   a   more   practical   formulation ,   comparing   to   general   portfolio   problem .   Then ,   both   feasible   and   non - inferior   solution   is   re - defined   considering   characteristics   of   SPS   problem ,   specifically ,   four   rules   of   system   function   combinations   are   proposed   according   to   practical   cases .   Then ,   the   instability   of   system   performance   is   involved   in   SPS   problem ,   and   the   robust   theory   is   employed   to   solving   the   uncertainty   of   system   function   values   with   definition   of   robust   non - inferior   solution .   Next ,   the   paper   proposes   an   immediately   updating   algorithm   to   solve   the   problem   of   solution   space   exponentially   growing .   Finally ,   a   case   study   is   used   to   demonstrate   the   usefulness   and   effectiveness   of   the   proposed   approaches .   It   shows   that   the   approach   can   provide   an   efficient   guidance   for   decision - makers   in   the   process   of   making   a   SPS . ' ,   ' title ' :   ' Robust   system   portfolio   selection   with   multi - function   requirements   and   system   instability ' } 
{ ' abstract ' :   ' This   study   explores   the   impact   of   high - photovoltaic   ( PV )   penetration   on   the   inter - area   oscillation   modes   of   large - scale   power   grids .   A   series   of   dynamic   models   with   various   PV   penetration   levels   are   developed   based   on   a   detailed   model   representing   the   U . S .   Eastern   Interconnection   ( EI ) .   Transient   simulations   are   performed   to   investigate   the   change   of   inter - area   oscillation   modes   with   PV   penetration .   The   impact   of   PV   control   strategies   and   parameter   settings   on   inter - area   oscillations   is   studied .   This   paper   finds   that   as   PV   increases ,   the   damping   of   the   dominant   oscillation   mode   decreases   monotonically .   It   is   also   observed   that   the   mode   shape   varies   with   the   PV   control   strategy   and   new   oscillation   modes   may   emerge   under   inappropriate   parameter   settings   in   PV   plant   controls . ' ,   ' title ' :   ' Impact   of   High   PV   Penetration   on   the   Inter - Area   Oscillations   in   the   U . S .   Eastern   Interconnection ' } 
{ ' abstract ' :   ' The   objective   of   this   research   is   to   compare   the   effectiveness   of   different   tracking   devices   underwater .   There   have   been   few   works   in   aquatic   virtual   reality   ( VR )   —   i . e . ,   VR   systems   that   can   be   used   in   a   real   underwater   environment .   Moreover ,   the   works   that   have   been   done   have   noted   limitations   on   tracking   accuracy .   Our   initial   test   results   suggest   that   inertial   measurement   units   work   well   underwater   for   orientation   tracking   but   a   different   approach   is   needed   for   position   tracking .   Towards   this   goal ,   we   have   waterproofed   and   evaluated   several   consumer   tracking   systems   intended   for   gaming   to   determine   the   most   effective   approaches .   First ,   we   informally   tested   infrared   systems   and   fiducial   marker   based   systems ,   which   demonstrated   significant   limitations   of   optical   approaches .   Next ,   we   quantitatively   compared   inertial   measurement   units   ( IMU )   and   a   magnetic   tracking   system   both   above   water   ( as   a   baseline )   and   underwater .   By   comparing   the   devices   rotation   data ,   we   have   discovered   that   the   magnetic   tracking   system   implemented   by   the   Razer   Hydra   is   more   accurate   underwater   as   compared   to   a   phone - based   IMU .   This   suggests   that   magnetic   tracking   systems   should   be   further   explored   for   underwater   VR   applications . ' ,   ' title ' :   ' Towards   usable   underwater   virtual   reality   systems ' } 
{ ' abstract ' :   ' A   faulty   network   GG   is   under   the   conditional   fault   model ,   i . e . , \ xa0every   fault - free   vertex   of   GG   is   incident   to   at   least   two   fault - free   edges .   Let   FFvFFv   and   FFeFFe   be   the   set   of   faulty   vertices   and   faulty   edges   in   FQnFQn ,   respectively .   In   this   paper ,   we   consider   FQnFQn   under   the   conditional   fault   model   and   prove   that   if   | FFv | + | FFe | ≤ 2n − 4 | FFv | + | FFe | ≤ 2n − 4   and   n ≥ 3n ≥ 3 ,   then   FQn − FFv − FFeFQn − FFv − FFe   contains   a   fault - free   cycle   of   every   even   length   from   4   to   2n − 2 | FFv | 2n − 2 | FFv | ;   if   | FFv | + | FFe | ≤ 2n − 5 | FFv | + | FFe | ≤ 2n − 5   and   n ≥ 4n ≥ 4   is   even ,   then   FQn − FFv − FFeFQn − FFv − FFe   contains   a   fault - free   cycle   of   every   odd   length   from   n + 1n + 1   to   2n − 2 | FFv | − 12n − 2 | FFv | − 1 . ' ,   ' title ' :   ' Cycles   embedding   in   folded   hypercubes   under   the   conditional   fault   model ' } 
{ ' abstract ' :   ' Companies   have   invested   considerable   resources   in   the   implementation   of   enterprise   resource   planning   ( ERP )   systems .   The   results   initially   expected   have   rarely   been   reached .   The   optimisation   ( or   efficient   use )   of   such   information   systems   is   nowadays   becoming   a   major   factor   for   firms   striving   to   reach   their   performance   objectives .   After   presenting   a   synthesis   of   several   studies   on   ERP   projects ,   we   build   on   the   findings   of   a   French   investigation   into   the   assessment   and   optimisation   of   ERP   performance .   A   classification   of   company   positions   regarding   their   ERP   use ,   based   on   both   software   maturity   and   strategic   deployment   directions ,   and   an   improvement   process   are   proposed .   Industrial   cases   allow   validation   of   this   approach . ' ,   ' title ' :   ' A   classification   for   better   use   of   ERP   systems ' } 
{ ' abstract ' :   ' This   paper   presents   a   time - domain   biosensor   array   that   uses   a   capacitor - less   current - mode   analog - to - time   converter   ( CMATC )   and   logarithmic   cyclic   time - attenuation - based   TDC   with   discharging   acceleration .   Combining   the   exponential   function   of   the   CMATC   and   logarithmic   function   of   the   proposed   TDC   offers   linear   input - output   characteristics .   The   time - domain   property   enables   bio - imaging   at   a   high   spatial   resolution   and   large   scale   while   maintaining   scalability .   Measurement   results   with   a   0.25 - μ m   test   chip   successfully   demonstrated   linear   input - output   characteristics . ' ,   ' title ' :   ' A   scalable   time - domain   biosensor   array   using   logarithmic   cyclic   time - attenuation - based   TDC   for   high - resolution   and   large - scale   bio - imaging ' } 
{ ' abstract ' :   ' Compared   to   current   mobile   networks ,   next - generation   mobile   networks   are   expected   to   support   higher   numbers   of   simultaneously   connected   devices   and   to   achieve   higher   system   spectrum   efficiency   and   lower   power   consumption .   To   achieve   these   goals ,   we   study   the   multi - sharing   device - to - device   ( D2D )   communication ,   which   allows   any   cellular   user   equipment   to   share   its   radio   resource   with   multiple   D2D   devices .   We   jointly   consider   resource   block   reuse   and   power   control   and   then   develop   the   MISS   algorithm .   Simulation   results   show   that   MISS   performs   very   well   in   terms   of   transmission   power   consumption ,   system   throughput ,   and   the   number   of   permitted   D2D   devices . ' ,   ' title ' :   ' Joint   Resource   Block   Reuse   and   Power   Control   for   Multi - Sharing   Device - to - Device   Communication ' } 
{ ' abstract ' :   ' This   paper   is   concerned   with   event - triggered   H ∞ H ∞   filtering   for   delayed   neural   networks   via   sampled   data .   A   novel   event - triggered   scheme   is   proposed ,   which   can   lead   to   a   significant   reduction   of   the   information   communication   burden   in   the   network ;   the   feature   of   this   scheme   is   that   whether   or   not   the   sampled   data   should   be   transmitted   is   determined   by   the   current   sampled   data   and   the   error   between   the   current   sampled   data   and   the   latest   transmitted   data .   By   constructing   a   proper   Lyapunov – Krasovskii   functional ,   utilizing   the   reciprocally   convex   combination   technique   and   Jensen ’ s   inequality   sufficient   conditions   are   derived   to   ensure   that   the   resultant   filtering   error   system   is   asymptotically   stable .   Based   on   the   derived   H ∞ H ∞   performance   analysis   results ,   the   H ∞ H ∞   filter   design   is   formulated   in   terms   of   Linear   Matrix   Inequalities   ( LMIs ) .   Finally ,   the   proposed   stability   conditions   are   demonstrated   with   numerical   example . ' ,   ' title ' :   ' Event - triggered   H   ∞   filtering   for   delayed   neural   networks   via   sampled - data ' } 
{ ' abstract ' :   ' For   the   double   integrator   with   matched   Lipschitz   disturbances   we   propose   a   continuous   homogeneous   controller   providing   finite - time   stability   of   the   origin .   The   disturbance   is   compensated   exactly   in   finite   time   using   a   discontinuous   function   through   an   integral   action .   Since   the   controller   is   dynamic ,   the   closed   loop   is   a   third   order   system   that   achieves   a   third   order   sliding   mode   in   the   steady   state .   The   stability   and   robustness   properties   of   the   controller   are   proven   using   a   smooth   and   homogeneous   strict   Lyapunov   function   ( LF ) .   In   a   first   stage ,   the   gains   of   the   controller   and   the   LF   are   designed   using   a   method   based   on   Polya ’ s   Theorem .   In   a   second   stage   the   controller ’ s   gains   are   adjusted   through   a   sum   of   squares   representation   of   the   LF . ' ,   ' title ' :   ' Design   of   Continuous   Twisting   Algorithm ' } 
{ ' abstract ' :   ' Big   data   is   now   rapidly   expanding   into   various   domains   such   as   banking ,   insurance   and   e - commerce .   Data   analysis   and   related   studies   have   attracted   more   attentions .   In   health   insurance ,   abuse   of   diagnosis   is   one   of   the   key   fraud   problems ,   which   damages   the   interests   of   insured   people .   To   address   this   issue ,   numbers   of   studies   have   focused   on   this   topic .   This   paper   develops   a   healthcare   fraud   detection   approach   based   on   the   trustworthiness   of   doctors   to   distinguish   fraud   cases   from   normal   records .   Compared   to   conventional   methods ,   our   approach   can   detect   healthcare   fraud   in   a   good   accuracy   by   only   little   feature   information   from   healthcare   data   without   the   violation   of   privacy .   This   approach   combines   a   weighted   HITS   algorithm   with   a   frequent   pattern   mining   algorithm   to   calculate   a   rational   treatment   model   of   a   certain   disease .   In   addition ,   this   paper   also   introduces   the   copy   precision   behavior   in   the   treatment   sequences   of   patients ,   which   is   a   critical   metric   to   learn   the   trustworthiness   of   doctors .   The   numerical   validation   with   a   healthcare   dataset   demonstrates   that   healthcare   fraud   by   misdiagnosis   in   healthcare   treatments   can   be   successfully   detected   by   employing   the   developed   fraud   detection   approach . ' ,   ' title ' :   ' Healthcare   Fraud   Detection   Based   on   Trustworthiness   of   Doctors ' } 
{ ' abstract ' :   ' In   this   paper   we   study   data   collection   in   an   energy   renewable   sensor   network   for   scenarios   such   as   traffic   monitoring   on   busy   highways ,   where   sensors   are   deployed   along   a   predefined   path   ( the   highway )   and   a   mobile   sink   travels   along   the   path   to   collect   data   from   one - hop   sensors   periodically .   As   sensors   are   powered   by   renewable   energy   sources ,   time - varying   characteristics   of   ambient   energy   sources   poses   great   challenges   in   the   design   of   efficient   routing   protocols   for   data   collection   in   such   networks .   In   this   paper   we   first   formulate   a   novel   data   collection   maximization   problem   by   adopting   multi - rate   data   transmissions   and   performing   transmission   time   slot   scheduling ,   and   show   that   the   problem   is   NP - hard .   We   then   devise   an   offline   algorithm   with   a   provable   approximation   ratio   for   the   problem   by   exploiting   the   combinatorial   property   of   the   problem ,   assuming   that   the   harvested   energy   at   each   node   is   given   and   link   communications   in   the   network   are   reliable .   We   also   extend   the   proposed   algorithm   by   minor   modifications   to   a   general   case   of   the   problem   where   the   harvested   energy   at   each   sensor   is   not   known   in   advance   and   link   communications   are   not   reliable .   We   thirdly   develop   a   fast ,   scalable   online   distributed   algorithm   for   the   problem   in   realistic   sensor   networks   in   which   neither   the   global   knowledge   of   the   network   topology   nor   sensor   profiles   such   as   sensor   locations   and   their   harvested   energy   profiles   is   given .   Furthermore ,   we   also   consider   a   special   case   of   the   problem   where   each   node   has   only   a   fixed   transmission   power ,   for   which   we   propose   an   exact   solution   to   the   problem .   We   finally   conduct   extensive   experiments   by   simulations   to   evaluate   the   performance   of   the   proposed   algorithms .   Experimental   results   demonstrate   that   the   proposed   algorithms   are   efficient   and   the   solutions   obtained   are   fractional   of   the   optimum . ' ,   ' title ' :   ' Data   Collection   Maximization   in   Renewable   Sensor   Networks   via   Time - Slot   Scheduling ' } 
{ ' abstract ' :   ' An   increasing   number   of   businesses   are   migrating   their   IT   operations   to   the   cloud .   Likewise   there   is   an   increased   emphasis   on   data   analytics   based   on   multiple   datasets   and   sources   to   derive   information   not   derivable   when   a   dataset   is   mined   in   isolation .   While   ensuring   security   of   data   and   computation   outsourced   to   a   third   party   cloud   service   provider   is   in   itself   challenging ,   supporting   mash - ups   and   analytics   of   data   from   different   parties   hosted   across   different   services   is   even   more   so .   In   this   paper   we   propose   a   cloud - based   service   allowing   multiple   parties   to   perform   secure   multi - party   secure   sum   computation   using   their   clouds   as   delegates .   Our   scheme   provides   data   privacy   both   from   the   delegates   as   well   as   from   the   other   data   owners   under   a   lazy - and - curious   adversary   ( semi - honest )   model .   We   then   describe   how   such   a   secure   sum   primitive   may   be   used   in   various   collaborative ,   cloud - based   distributed   data   mining   tasks   ( classification ,   association   rule   mining   and   clustering ) .   We   implement   a   prototype   and   benchmark   the   service ,   both   as   a   stand - alone   secure   sum   service ,   and   as   a   building   block   for   more   complex   analytics .   The   results   suggest   reasonable   overhead   and   demonstrate   the   practicality   of   carrying   out   privacy   preserved   distributed   analytics   despite   migrating   ( encrypted )   data   to   pos -   sibly   different   and   untrusted   ( semi - honest )   cloud   services . ' ,   ' title ' :   ' Delegated   Secure   Sum   Service   for   Distributed   Data   Mining   in   Multi - Cloud   Settings ' } 
{ ' abstract ' :   ' This   paper   fundamentally   investigates   the   performance   of   evolutionary   multiobjective   optimization   ( EMO )   algorithms   for   computationally   hard   0 - 1   combinatorial   optimization ,   where   a   strict   theoretical   analysis   is   generally   out   of   reach   due   to   the   high   complexity   of   the   underlying   problem .   Based   on   the   examination   of   problem   features   from   a   multiobjective   perspective ,   we   improve   the   understanding   of   the   efficiency   of   a   simple   dominance - based   EMO   algorithm   with   unbounded   archive   for   multiobjective   NK - landscapes   with   correlated   objective   values .   More   particularly ,   we   adopt   a   statistical   approach ,   based   on   simple   and   multiple   linear   regression   analysis ,   to   enquire   the   expected   running   time   of   global   SEMO   with   restart   for   identifying   a   ( 1 + e ) - approximation   of   the   Pareto   set   for   small - size   enumerable   instances .   Our   analysis   provides   further   insights   on   the   EMO   search   behavior   and   on   the   most   important   features   that   characterize   the   difficulty   of   an   instance   for   this   class   of   problems   and   algorithms . ' ,   ' title ' :   ' A   feature - based   performance   analysis   in   evolutionary   multiobjective   optimization ' } 
{ ' abstract ' :   ' Functional   biological   sequences ,   which   typically   come   in   families ,   have   retained   some   level   of   similarity   and   function   during   evolution .   Finding   consensus   regions ,   alignment   of   sequences ,   and   identifying   the   relationship   between   a   sequence   and   a   family   allow   inferences   about   the   function   of   the   sequences .   Profile   hidden   Markov   models   ( HMMs )   are   generally   used   to   identify   those   relationships .   A   profile   HMM   can   be   trained   on   unaligned   members   of   the   family   using   conventional   algorithms   such   as   Baum - Welch ,   Viterbi ,   and   their   modifications .   The   overall   quality   of   the   alignment   depends   on   the   quality   of   the   trained   model .   Unfortunately ,   the   conventional   training   algorithms   converge   to   suboptimal   models   most   of   the   time .   This   work   proposes   a   training   algorithm   that   early   identifies   many   imperfect   models .   The   method   is   based   on   the   Simulated   Annealing   approach   widely   used   in   discrete   optimization   problems .   The   training   algorithm   is   implemented   as   a   component   in   HMMER .   The   performance   of   the   algorithm   is   discussed   on   protein   sequence   data . ' ,   ' title ' :   ' Simulated   annealing   algorithm   with   biased   neighborhood   distribution   for   training   profile   models ' } 
{ ' abstract ' :   ' The   Canny   algorithm   is   a   well   known   edge   detector   that   is   widely   used   in   the   previous   processing   stages   in   several   algorithms   related   to   computer   vision .   An   alternative ,   the   LIP - Canny   algorithm ,   is   based   on   a   robust   mathematical   model   closer   to   the   human   vision   system ,   obtaining   better   results   in   terms   of   edge   detection .   In   this   work   we   describe   LIP - Canny   algorithm   under   the   perspective   from   its   parallelization   and   optimization   by   using   the   NVIDIA   CUDA   framework .   Furthermore ,   we   present   comparative   results   between   an   implementation   of   this   algorithm   using   NVIDIA   CUDA   and   the   analogue   using   a   C / C++   approach . ' ,   ' title ' :   ' Parallelizing   and   optimizing   LIP - canny   using   NVIDIA   CUDA ' } 
{ ' abstract ' :   ' This   paper   presents   an   efficient   Bayesian   blind   multiuser   receiver   for   long   code   multipath   CDMA   systems .   The   proposed   receiver   employs   the   adaptive   sampling   method   for   the   Bayesian   inference   procedure   to   estimate   the   data   symbols   and   multipath   parameters .   Compared   to   the   other   reported   Bayesian   Monte   Carlo   receivers   for   long   code   multipath   CDMA   systems ,   the   proposed   one   achieves   a   faster   convergence   and   a   lower   computational   complexity   to   attain   comparable   performance .   Simulation   results   are   presented   to   demonstrate   the   effectiveness   of   the   proposed   Bayesian   blind   multiuser   receiver . ' ,   ' title ' :   ' Blind   Multiuser   Detection   for   Long   Code   Multipath   DS - CDMA   Systems   with   Bayesian   MC   Techniques ' } 
{ ' abstract ' :   ' Spreadsheets   are   by   far   the   most   prominent   example   of   end - user   programs   of   ample   size   and   substantial   structural   complexity .   In   addition ,   spreadsheets   are   usually   not   tested   very   rigorously   and   thus   comprise   faults .   Locating   faults   is   a   hard   task   due   to   the   size   and   the   structure ,   which   is   usually   not   directly   visible   to   the   user ,   i . e . ,   the   functions   are   hidden   behind   the   cells   and   only   the   computed   values   are   presented .   Hence ,   there   is   a   strong   need   for   debugging   support .   In   this   paper ,   we   adapt   three   program - debugging   approaches   that   have   been   designed   for   more   traditional   procedural   or   object - oriented   programming   languages .   These   techniques   are   Spectrum - based   Fault   Localization ,   Spectrum - Enhanced   Dynamic   Slicing ,   and   Constraint - based   Debugging .   Beside   the   theoretical   foundations ,   we   present   a   more   sophisticated   empirical   evaluation   including   a   comparison   of   these   approaches .   The   empirical   evaluation   shows   that   Sfl   ( Spectrum - based   Fault   Localization )   and   Sendys   ( Spectrum   ENhanced   Dynamic   Slicing )   are   the   most   promising   techniques . ' ,   ' title ' :   ' On   the   empirical   evaluation   of   fault   localization   techniques   for   spreadsheets ' } 
{ ' abstract ' :   ' This   work   provides   elements   to   highlight   the   reliability   challenges   related   to   the   technology   scaling   and   the   BTI   variability .   Through   main   milestones   including   device   reliability   scaling   model   ( for   both   mean   and   spread ) ,   a   discussion   on   the   physical   origin   of   BTI   variability   and   a   digital   IP   failure   rate   analytical   model ,   the   evolution   of   digital   IP   failure   rates   along   the   ITRS   scaling   roadmap   is   assessed .   and   an   analysis   of   the   ITRS   roadmap   on   digital   IP   failure   rates .   This   study   offers   new   perspectives   towards   product   hardening   and   qualification   with   respect   to   both   fresh   and   BTI - related   local   variability ,   especially   in   context   where   Adaptive   Voltage   Scaling   ( AVS )   is   used   to   compensate   for   process   centerings . ' ,   ' title ' :   ' From   BTI   variability   to   product   failure   rate :   A   technology   scaling   perspective ' } 
{ ' abstract ' :   ' In   this   paper   we   discuss   the   problem   of   calculating   the   reachable   states   of   a   dynamical   system   defined   by   ordinary   differential   equations   or   inclusions .   We   present   a   prototype   system   for   approximating   this   set   and   demonstrate   some   experimental   results . ' ,   ' title ' :   ' Reachability   Analysis   via   Face   Lifting ' } 
{ ' abstract ' :   ' By   introducing   the   new   concepts   of   fuzzy     β   - covering   and   fuzzy     β   - neighborhood ,   we   define   two   new   types   of   fuzzy   covering   rough   set   models   which   can   be   regarded   as   bridges   linking   covering   rough   set   theory   and   fuzzy   rough   set   theory .   We   show   the   properties   of   the   two   models ,   and   reveal   the   relationships   between   the   two   models   and   some   others .   Moreover ,   we   present   the   matrix   representations   of   the   newly   defined   lower   and   upper   approximation   operators   so   that   the   calculation   of   lower   and   upper   approximations   of   subsets   can   be   converted   into   operations   on   matrices .   Finally ,   we   generalize   the   models   and   their   matrix   representations   to     L   - fuzzy   covering   rough   sets   which   are   defined   over   fuzzy   lattices . ' ,   ' title ' :   ' Two   fuzzy   covering   rough   set   models   and   their   generalizations   over   fuzzy   lattices ' } 
{ ' abstract ' :   ' Mobile   applications   are   becoming   complex   software   systems   that   must   be   developed   quickly   and   evolve   regularly   to   fit   new   user   requirements   and   execution   contexts .   However ,   addressing   these   constraints   may   result   in   poor   design   choices ,   known   as   antipatterns ,   which   may   degrade   software   quality   and   performance .   Thus ,   the   automatic   detection   of   antipatterns   is   an   important   activity   that   eases   the   future   maintenance   and   evolution   tasks .   Moreover ,   it   helps   developers   to   refactor   their   applications   and   thus ,   to   improve   their   quality .   While   antipatterns   are   well - known   in   object - oriented   applications ,   their   study   in   mobile   applications   is   still   in   their   infancy .   In   this   paper ,   we   presents   a   tooled   approach ,   called   P   aprika   ,   to   analyze   Android   applications   and   to   detect   object - oriented   and   Android - specific   antipatterns   from   binaries   of   applications . ' ,   ' title ' :   ' An   approach   to   detect   Android   antipatterns ' } 
{ ' abstract ' :   ' In   this   paper   we   present   a   new   method   for   object   categorization .   Firstly   an   image   representation   is   obtained   by   the   proposed   hierarchical   learning   method   consisting   of   alternating   between   local   coding   and   maximum   pooling   operations ,   where   the   local   coding   operation   induces   discrimination   while   the   image   descriptor   and   maximum   pooling   operation   induces   invariance   in   hierarchical   architecture .   Then   the   obtained   effective   image   representation   is   passed   to   a   linear   classifier   which   is   suitable   for   large   databases   for   object   categorization .   We   have   demonstrated   that   the   proposed   method   is   robust   to   image   variations   and   has   low   sample   complexity . ' ,   ' title ' :   ' Object   categorization   based   on   hierarchical   learning ' } 
{ ' abstract ' :   ' We   have   previously   proposed   a   howling   canceller   which   cancels   howling   by   using   a   cascade   notch   filter   designed   from   a   distance   between   a   loudspeaker   and   a   microphone .   This   method   utilizes   a   pilot   signal   to   estimate   the   distance .   In   this   paper ,   we   introduce   two   methods   into   the   distance - based   howling   canceller   to   improve   speech   quality .   The   first   one   is   an   adaptive   cascade   notch   filter   which   adaptively   adjusts   the   nulls   to   eliminate   howling   and   to   keep   speech   components .   The   second   one   is   a   silent   pilot   signal   whose   frequencies   exist   in   the   ultrasonic   band ,   and   it   is   inaudible   while   on   transmission .   We   implement   the   proposed   howling   canceller   on   a   DSP   to   evaluate   its   capability .   The   experimental   results   show   that   the   proposed   howling   canceller   improves   speech   quality   in   comparison   to   the   conventional   one . ' ,   ' title ' :   ' A   High   Speech   Quality   Distance - Based   Howling   Canceller   with   Adaptive   Cascade   Notch   Filter   and   Silent   Pilot   Signal ' } 
{ ' abstract ' :   ' Purpose   –   This   paper   aims   to   look   at   how   varying   terminology   is   used   on   school   library   web   sites   and   how   that   compares   to   student   preferences . Design / methodology / approach   –   Provides   research   conduced   by   surveying   practicing   school   librarians   and   k ‐ 12   students . Findings   –   Terminology   varies   greatly   on   school   library   web   sites .   Further ,   students   prefer   common   language   use . Practical   implications   –   Practicing   librarians   may   consider   revising   their   web   sites   in   order   to   make   them   more   accessible   for   their   students . Originality / value   –   This   paper   provides   original   research   into   school   library   web   sites ,   an   area   that   is   lacking . ' ,   ' title ' :   ' School   library   web   site   terminology ' } 
{ ' abstract ' :   ' Recently ,   numerous   multireceiver   identity - based   encryption   or   identity - based   broadcast   encryption   schemes   have   been   introduced   with   bilinear   pairing   and   probabilistic   map - to - point   MTP   function .   As   the   bilinear   pairing   and   MTP   functions   are   expensive   operations ,   any   cryptographic   schemes   based   on   these   operations   experience   high   computational   burden .   The   certificateless   public   key   cryptography   sidesteps   the   private   key   escrow   problem   occurring   in   identity - based   cryptosystem   and   certificate   management   troubles   of   certificate   authority - based   public   key   cryptography   CA - PKC .   We   observed   that   certificateless   multireceiver   encryption   CL - MRE   scheme   without   pairing   and   MTP   hash   function   has   not   yet   been   considered   in   the   literature .   In   this   paper ,   we   proposed   a   bilinear   pairing   and   MTP   hash - function - free   CL - MRE   scheme   with   chosen   ciphertext   attack   resilience .   The   detailed   analyses   provide   evidence   that   our   scheme   achieves   forward   secrecy ,   backward   secrecy ,   and   low   computation   costs   than   others .   The   scheme   also   provides   confidentiality   of   the   message   and   receiver   anonymity   in   the   random   oracle   model   with   the   hardness   of   computational   Diffie - Hellman   problem .   Copyright   ©   2014   John   Wiley   &   Sons ,   Ltd . ' ,   ' title ' :   ' Anonymous   and   provably   secure   certificateless   multireceiver   encryption   without   bilinear   pairing ' } 
{ ' abstract ' :   ' We   study   the   problem   of   approximating   one - dimensional   nonintegrable   codistributions   by   integrable   ones   and   apply   the   resulting   approximations   to   approximate   feedback   linearization   of   single - input   systems .   The   approach   derived   in   this   paper   allows   a   linearizable   nonlinear   system   to   be   found   that   is   close   to   the   given   system   in   a   least - squares   ( L2 )   sense .   A   linearly   controllable   single - input   affine   nonlinear   system   is   feedback   linearizable   if   and   only   if   its   characteristic   distribution   is   involutive   ( hence   integrable )   or ,   equivalently ,   any   characteristic   one - form   ( a   one - form   that   annihilates   the   characteristic   distribution )   is   integrable .   We   study   the   problem   of   finding   ( least - squares   approximate )   integrating   factors   that   make   a   fixed   characteristic   one - form   close   to   being   exact   in   anL2   sense .   A   given   one - form   can   be   decomposed   into   exact   and   inexact   parts   using   the   Hodge   decomposition .   We   derive   an   upper   bound   on   the   size   of   the   inexact   part   of   a   scaled   characteristic   one - form   and   show   that   a   least - squares   integrating   factor   provides   the   minimum   value   for   this   upper   bound .   We   also   consider   higher - order   approximate   integrating   factors   that   scale   a   nonintegrable   one - form   in   a   way   that   the   scaled   form   is   closer   to   being   integrable   inL2   together   with   some   derivatives   and   derive   similar   bounds   for   the   inexact   part .   This   allows   a   linearizable   nonlinear   system   that   is   close   to   the   given   system   in   a   least - squares   ( L2 )   sense   together   with   some   derivatives   to   be   found .   The   Sobolev   embedding   techniques   allow   us   to   obtain   an   upper   bound   on   the   uniform   ( L ∞ )   distance   between   the   nonlinear   system   and   its   linearizable   approximation . ' ,   ' title ' :   ' Least - squares   integration   of   one - dimensional   codistributions   with   application   to   approximate   feedback   linearization ' } 
{ ' abstract ' :   ' Latent   sector   errors   in   disk   drives   affect   only   a   few   data   sectors .   They   occur   silently   and   are   detected   only   when   the   affected   area   is   accessed   again .   If   a   latent   error   is   detected   while   the   storage   system   is   operating   under   reduced   redundancy ,   i . e . ,   during   a   RAID   rebuild ,   then   data   loss   may   occur .   Various   features   such   as   scrubbing   and   intra - disk   data   redundancy   are   proposed   to   detect   and / or   recover   from   latent   errors   and   avoid   data   loss .   While   such   features   enhance   data   availability   in   the   storage   system ,   their   execution   may   cause   performance   degradation .   In   this   paper ,   we   evaluate   the   effectiveness   of   scrubbing   and   intra - disk   data   redundancy   in   improving   data   availability   while   the   overall   goal   is   to   maintain   user   performance   within   predefined   bounds .   We   show   that   by   treating   them   as   low   priority   background   activities   and   scheduling   them   efficiently   during   idle   times ,   these   features   remain   performance - wise   transparent   to   the   storage   system   user   while   still   improving   data   reliability .   Detailed   trace - driven   simulations   show   that   the   mean   time   to   data   loss   ( MTTDL )   improves   by   up   to   5   orders   of   magnitude   if   these   features   are   implemented   independently .   By   scheduling   concurrently   both   scrubbing   and   intra - disk   parity   updates   during   idle   times   in   disk   drives ,   MTTDL   improves   by   as   much   as   8   orders   of   magnitude . ' ,   ' title ' :   ' Enhancing   data   availability   in   disk   drives   through   background   activities ' } 
{ ' abstract ' :   ' Financial   crisis   forecasting   has   been   a   long - standing   challenge   that   often   involves   couplings   between   indicators   of   multiple   markets .   Such   couplings   include   implicit   relations   that   might   not   be   effectively   detected   from   raw   market   observations .   However ,   most   methods   for   crisis   forecasting   rely   directly   on   market   observations   and   might   not   detect   the   hidden   interactions   between   markets .   To   this   end ,   the   authors   explore   coupled   market   state   analysis   ( CMSA ) ,   assuming   that   the   observations   of   markets   are   governed   by   a   collection   of   intra -   and   intercoupled   hidden   market   states .   Accordingly ,   they   built   a   forecaster   based   on   these   coupled   market   states   instead   of   observations . ' ,   ' title ' :   ' Financial   Crisis   Forecasting   via   Coupled   Market   State   Analysis ' } 
{ ' abstract ' :   ' In   this   paper ,   an   “ intelligent ”   isolated   intersection   control   system   was   developed .   The   developed   “ intelligent ”   system   makes   “ real   time ”   decisions   as   to   whether   to   extend   ( and   how   much )   current   green   time .   The   model   developed   is   based   on   the   combination   of   the   dynamic   programming   and   neural   networks .   Many   tests   show   that   the   outcome   ( the   extension   of   the   green   time )   of   the   proposed   neural   network   is   nearly   equal   to   the   best   solution .   Practically   negligible   CPU   times   were   achieved ,   and   were   thus   absolutely   acceptable   for   the   “ real   time ”   application   of   the   developed   algorithm . ' ,   ' title ' :   ' Dynamic   programming — neural   network   real - time   traffic   adaptive   signal   control   algorithm ' } 
{ ' abstract ' :   ' This   issue   features   expanded   versions   of   articles   selected   from   the   2014   AAAI   Conference   on   Innovative   Applications   of   Artificial   Intelligence   held   in   Quebec   City ,   Canada .   We   present   a   selection   of   four   articles   describing   deployed   applications   plus   two   more   articles   that   discuss   work   on   emerging   applications . ' ,   ' title ' :   ' Introduction   to   the   Special   Issue   on   Innovative   Applications   of   Artificial   Intelligence   2014 ' } 
{ ' abstract ' :   ' Although   frequently   used   in   fractal   compression   quadrant - based   classification   exhibits   a   significant   defect   which   has   not   been   described   in   the   literature .   We   give   an   efficient   solution   to   this   problem   by   controlling   the   class   structure   based   on   an   adaptive   threshold .   This   makes   this   classification   technique   a   very   efficient   and   competitive   one   also   for   block   matching   motion   compensation   algorithms   in   video   coding . ' ,   ' title ' :   ' Resolving   a   defect   in   quadrant - based   classification   for   fast   block - matching ' } 
{ ' abstract ' :   ' Where   there   are   infinitely   many   possible   basic   states   of   the   world ,   a   standard   probability   function   must   assign   zero   probability   to   each   state   –   since   any   finite   probability   would   sum   to   over   one .   This   generates   problems   for   any   decision   theory   that   appeals   to   expected   utility   or   related   notions .   For   it   leads   to   the   view   that   a   situation   in   which   one   wins   a   million   dollars   if   any   of   a   thousand   of   the   equally   probable   states   is   realized   has   an   expected   value   of   zero   ( since   each   such   state   has   probability   zero ) .   But   such   a   situation   dominates   the   situation   in   which   one   wins   nothing   no   matter   what   ( which   also   has   an   expected   value   of   zero ) ,   and   so   surely   is   more   desirable .   I   formulate   and   defend   some   principles   for   evaluating   options   where   standard   probability   functions   cannot   strictly   represent   probability   –   and   in   particular   for   where   there   is   an   infinitely   spread ,   uniform   distribution   of   probability .   The   principles   appeal   to   standard   probability   functions ,   but   overcome   at   least   some   of   their   limitations   in   such   cases . ' ,   ' title ' :   ' Standard   decision   theory   corrected ' } 
{ ' abstract ' :   ' Backed   by   the   European   Commission ,   a   consortium   of   partners   from   European   industry ,   financial   institutions ,   and   academia   has   embarked   on   a   research   project   to   develop   the   fundamentals   of   secure   electronic   commerce .   The   goal   of   the   9 - million   ECU   project ,   SEMPER   ( Secure   Electronic   Marketplace   for   Europe ) ,   is   to   provide   the   first   open   and   comprehensive   solutions   for   secure   commerce   over   the   Internet   and   other   public   information   networks .   We   describe   the   objectives   and   summarise   the   initial   architecture   of   SEMPER .   A   wide   range   of   businesses   are   rapidly   moving   to   explore   the   huge   potential   of   net -   worked   information   systems ,   especially   with   the   Internet - based   WWW   ( World - wide   Web ) .   The   Internet ,   which   already   connects   more   than   3   million   computers   and   a   sub -   stantially   larger   number   of   users ,   is   growing   at   a   breathtaking   pace   with   thousands   of   newcomers   every   day .   Although   the   Internet   has   its   roots   in   academia   and   is   still   domi -   nated   by   free - of - charge   information ,   dramatic   changes   are   expected   in   the   near   future .   For   instance ,   the   WWW   will   be   used   for   a   wide   variety   of   electronic   commerce   such   as   on - line   trade   or   delivery   of   advanced   multimedia   information   services .   The   evolution   of   broadband   networks   and   " information   highways "   will   intensify   this   trend .   The   need   for   secure   transactions   in   this   new   business   environment ,   which   involves   networks   available   to   the   general   public ,   has   triggered   a   number   of   related   efforts .   These   initial   developments   are   based   almost   exclusively   in   the   US   and   most   of   them   are   limited   to   proprietary ,   or   otherwise   closed   solutions ,   involving   only   electronic   payment   issues .   In   contrast ,   SEMPER   is   directed   towards   a   comprehensive   solution   for   secure   electronic   commerce ,   considering   legal ,   commercial ,   social ,   and   technical   requirements   as   well   as   different   options   for   an   electronic   marketplace . ' ,   ' title ' :   ' Development   of   a   Secure   Electronic   Marketplace   for   Europe ' } 
{ ' abstract ' :   ' Through   the   use   of   a   global   geometric   symmetry ,   detection   ellipses   are   proposed   in   this   paper .   Based   on   the   geometric   symmetry ,   the   proposed   method   first   locates   candidates   of   ellipses   centers .   In   the   meantime ,   according   to   these   candidate   centers ,   all   feature   points   in   an   input   image   are   grouped   into   several   subimages .   Then ,   for   each   subimage ,   by   using   geometric   properties   again ,   all   ellipses   are   extracted .   The   method   significantly   reduces   the   time   required   to   evaluate   all   possible   parameters   without   using   edge   direction   information .   Experimental   results   are   given   to   show   the   correctness   and   effectiveness   of   the   proposed   method . ' ,   ' title ' :   ' Detection   ellipses   by   finding   lines   of   symmetry   in   the   images   via   an   hough   transform   applied   to   straight   lines ' } 
{ ' abstract ' :   ' Automatic   crawling   of   Rich   Internet   Applications   ( RIAs )   is   a   challenge   because   client - side   code   modifies   the   client   dynamically ,   fetch -   ing   server - side   data   asynchronously .   Most   existing   solutions   model   RIAs   as   state   machines   with   DOMs   as   states   and   JavaScript   events   execution   as   transitions .   This   approach   fails   when   used   with   " real - life " ,   complex   RIAs ,   because   the   size   of   the   produced   model   is   much   too   large   to   be   practical .   In   this   paper ,   we   propose   a   new   method   to   crawl   AJAX - based   RIAs   in   an   efficient   manner   by   detecting   " components " ,   which   are   areas   of   the   DOM   that   are   independent   from   each   other ,   and   by   crawling   each   component   separately .   This   leads   to   a   dramatic   reduction   of   the   required   state   space   for   the   model ,   without   loss   of   content   coverage .   Our   method   does   not   require   prior   knowledge   of   the   RIA   nor   predefined   definition   of   components .   Instead ,   we   infer   the   components   by   observing   the   be -   havior   of   the   RIA   during   crawling .   Our   experimental   results   show   that   our   method   can   index   quickly   and   completely   industrial   RIAs   that   are   simply   out   of   reach   for   traditional   methods . ' ,   ' title ' :   ' Indexing   Rich   Internet   Applications   Using   Components - Based   Crawling ' } 
{ ' abstract ' :   ' One   important   aspect   of   constructing   an   overlay   network   is   how   to   exploit   network   locality   in   the   underlying   network .   In   this   paper ,   we   propose   a   scalable   protocol   for   constructing   an   overlay   network   that   takes   account   of   locality   of   network   hosts .   The   constructed   overlay   network   can   significantly   decrease   the   communication   cost   between   end - hosts .   Our   simulation   results   show   that   the   average   distance   between   a   pair   of   hosts   in   the   constructed   overlay   network   is   only   about   11%   of   the   one   in   a   traditional ,   randomly   connected   overlay   network .   Furthermore ,   our   proposed   overlay   considered   to   be   more   scalable   than   tree - based   or   mesh - based   overlays . ' ,   ' title ' :   ' Measurement - based   construction   of   locality - aware   overlay   networks ' } 
{ ' abstract ' :   ' This   paper   presents   a   low   cost ,   flexible   and   customizable   delay   measurement   system   developed   to   assess   the   performance   of   the   VTPE - hBEB   protocol .   The   proposed   system   can   be   used   to   evaluate   other   communication   protocols   as   well   as   to   measure   the   delay   between   two   repetitive   events . ' ,   ' title ' :   ' Delay   measurement   system   for   real - time   serial   data   streams ' } 
{ ' abstract ' :   " Service   robots   have   become   increasingly   important   subjects   in   our   lives .   However ,   they   are   still   facing   problems   like   adaptability   to   their   users .   While   major   work   has   focused   on   intelligent   service   robots ,   the   proposed   approaches   were   mostly   user   independent .   Our   work   is   part   of   the   FUI - RoboPopuli   project ,   which   concentrates   on   endowing   entertainment   companion   robots   with   adaptive   and   social   behaviour .   In   particular ,   we   are   interested   in   robots   that   are   able   to   learn   and   plan   so   that   they   adapt   and   personalize   their   behaviour   according   to   their   users .   Markov   Decision   Processes   ( MDPs )   are   largely   used   for   adaptive   robots   applications .   However ,   one   challenging   point   is   reducing   the   sample   complexity   required   to   learn   an   MDP   model ,   including   the   reward   function .   In   this   article ,   we   present   our   contribution   regarding   the   representation   and   the   learning   of   the   reward   function   through   analysing   interaction   traces   ( i . e .   the   interaction   history   between   the   robot   and   their   users ,   including   users '   feedback ) .   Our   approach   permits   to   generalise   the   learned   rewards   so   that   when   new   users   are   introduced ,   the   robot   may   quickly   adapt   using   what   it   learned   from   previous   experiences   with   other   users .   We   propose ,   in   this   article ,   two   algorithms   to   learn   the   reward   function .   The   first   is   direct   and   certain ,   the   robot   applies   with   a   user   what   it   learned   during   interaction   with   same   kind   of   users   ( i . e .   users   with   similar   profiles ) .   The   second   algorithm   generalises   what   it   learns   to   be   applied   to   all   kinds   of   users .   Through   simulation ,   we   show   that   the   generalised   algorithm   converges   to   an   optimal   reward   function   with   less   than   half   the   samples   needed   by   the   direct   algorithm . " ,   ' title ' :   " Adaptive   and   Personalised   Robots   -   Learning   from   Users '   Feedback " } 
{ ' abstract ' :   " Researches   of   sensor   networks   collecting   patients '   data   with   computerized   triage   tags ,   called   Triage   Network ,   are   attracting   attention .   The   listening   power   used   in   triage   tags   is   the   major   factor   of   lots   of   energy   consumption ,   and   consumption   of   energy   increases   when   sensor   nodes   always   communicate   with   other   nodes   in   active   state .   Hence ,   we   suppose   that   sensor   nodes   are   put   to   sleep   periodically   to   avoid   running   out   of   battery .   However ,   some   nodes   have   mobility   and   nodes   secede   from   the   network   according   to   patients   conditions   in   Triage   Network .   The   paths   are   failed   and   it   is   needed   to   reconstruct   paths   when   these   forwarding   nodes   move   or   secede   from   network .   Therefore ,   data   arrival   ratio   decreases   and   consumption   of   battery   increases   due   to   reconstruction   of   other   paths .   In   this   paper ,   we   propose   a   data   collection   method   using   two   types   of   forwarding   nodes ,   Stable   Nodes   and   Energy   Efficient   Nodes .   This   method   uses   two   types   of   forwarding   nodes   according   to   priority   of   data   and   avoids   loss   of   high   priority   data ,   improves   the   data   arrival   ratio   and   saves   the   energy   consumption .   We   evaluate   the   proposed   method   and   show   its   effectiveness   using   computer   simulations . " ,   ' title ' :   ' Data   collection   method   using   two   types   of   forwarding   nodes   for   energy   saving   in   triage   network ' } 
{ ' abstract ' :   ' This   paper   introduces   Golay - paired   Hadamard   matrices   for   fast   compressed   sensing   of   sparse   signals   in   the   time   or   spectral   domain .   These   sampling   operators   feature   low - memory   requirement ,   hardware - friendly   implementation   and   fast   computation   in   reconstruction .   We   show   that   they   require   a   nearly   optimal   number   of   measurements   for   faithful   reconstruction   of   a   sparse   signal   in   the   time   or   frequency   domain .   Simulation   results   demonstrate   that   the   proposed   sensing   matrices   offer   a   reconstruction   performance   similar   to   that   of   fully   random   matrices . ' ,   ' title ' :   ' Golay   meets   Hadamard :   Golay - paired   Hadamard   matrices   for   fast   compressed   sensing ' } 
{ ' abstract ' :   ' In   this   technical   note ,   the   problem   of   finite - time   output   regulation   control   for   a   class   of   disturbed   system   under   mismatching   condition   is   investigated   via   a   composite   control   design   manner .   The   composite   controller   is   developed   by   using   a   finite   time   control   technique   and   a   finite   time   disturbance   observer   ( FTDO ) .   A   key   idea   is   to   design   virtual   control   laws   based   on   estimation   values   of   the   disturbances   and   the   ith   ( 1 ≤ i ≤ n - 1   where   n   is   the   order   of   the   system )   order   derivative   of   disturbances .   Finite   time   stability   analysis   for   the   augmented   system   is   presented   by   means   of   Lyapunov   stability   theorems ,   which   shows   that   the   system   output   is   regulated   to   zero   in   finite   time   even   in   the   presence   of   mismatched   disturbances .   A   motion   control   application   demonstrates   the   effectiveness   and   attractive   properties   of   the   proposed   method . ' ,   ' title ' :   ' Continuous   Finite - Time   Output   Regulation   for   Disturbed   Systems   Under   Mismatching   Condition ' } 
{ ' abstract ' :   ' In   this   paper   we   propose   an   approach   for   enhanced   data   protection   in   the   cloud ,   based   upon   accountability   governance .   Specifically ,   the   relationships   between   accountability ,   risk   and   trust   are   analyzed   in   order   to   suggest   characteristics   and   means   to   address   data   governance   issues   involved   when   organizations   or   individuals   adopt   cloud   computing .   This   analysis   takes   into   account   insights   from   a   variety   of   stakeholders   within   cloud   ecosystems   obtained   by   running   an   elicitation   workshop . ' ,   ' title ' :   ' Accountability ,   Risk ,   and   Trust   in   Cloud   Services :   Towards   an   Accountability - Based   Approach   to   Risk   and   Trust   Governance ' } 
{ ' abstract ' :   ' Xue   et   al .   recently   proposed   an   innovative   mutual   authentication   and   key   agreement   scheme   for   wireless   sensor   networks   based   on   temporal   credential   using   smart   cards .   However ,   in   this   paper   we   demonstrate   that   their   scheme   is   vulnerable   to   password   guessing   attacks ,   node   capture   attacks   and   denial - of - service   attacks .   Furthermore   we   show   that   their   scheme   has   some   inconsistencies   which   make   it   less   secure   and   more   computationally   costly   than   originally   presented . ' ,   ' title ' :   ' Notes   on   A   Temporal - Credential - Based   Mutual   Authentication   and   Key   Agreement   Scheme   for   Wireless   Sensor   Networks ' } 
{ ' abstract ' :   ' Persistent   Scatterer   Interferometry   ( PSI )   has   been   widely   used   for   landslide   studies   in   recent   years .   This   paper   investigated   the   spatial   patterns   of   PSI   point   targets   and   landslide   occurrences   in   the   Arno   River   basin   in   Central   Italy .   The   main   purpose   is   to   analyze   whether   spatial   patterns   of   Persistent   Scatterers   ( PS )   can   be   recognized   as   indicators   of   landslide   occurrences   throughout   the   whole   basin .   The   bivariate   K - function   was   employed   to   assess   spatial   relationships   between   PS   and   landslides .   The   PSI   point   targets   were   acquired   from   almost   4   years   ( from   March   2003   to   January   2007 )   of   RADARSAT - 1   images .   The   landslide   inventory   was   collected   from   15   years   ( from     1992 – 2007 )   of   surveying   and   mapping   data ,   mainly   including   remote   sensing   data ,   topographic   maps   and   field   investigations .   The   proposed   approach   is   able   to   assess   spatial   patterns   between   a   variety   of   PS   and   landslides ,   in   particular ,   to   understand   if   PSI   point   targets   are   spatially   clustered   ( spatial   attraction )   or   randomly   distributed   ( spatial   independency )   on   various   types   of   landslides   across   the   basin .   Additionally ,   the   degree   and   scale   distances   of   PS   clustering   on   a   variety   of   landslides   can   be   characterized .   The   results   rejected   the   null   hypothesis   that   PSI   point   targets   appear   to   cluster   similarly   on   four   types   of   landslides   ( slides ,   flows ,   falls   and   creeps )   in   the   Arno   River   basin .   Significant   influence   of   PS   velocities   and   acquisition   orbits   can   be   noticed   on   detecting   landslides   with   different   states   of   activities .   Despite   that   the   assessment   may   be   influenced   by   the   quality   of   landslide   inventory   and   Synthetic   Aperture   Radar   ( SAR )   images ,   the   proposed   approach   is   expected   to   provide   guidelines   for   studies   trying   to   detect   and   investigate   landslide   occurrences   at   a   regional   scale   through   spatial   statistical   analysis   of   PS ,   for   which   an   advanced   understanding   of   the   impact   of   scale   distances   on   landslide   clustering   is   fundamentally   needed . ' ,   ' title ' :   ' Investigating   Spatial   Patterns   of   Persistent   Scatterer   Interferometry   Point   Targets   and   Landslide   Occurrences   in   the   Arno   River   Basin ' } 
{ ' abstract ' :   ' This   article   describes   a   middleware   used   in   display   cluster   of   real   time   visual   simulation   system .   This   middleware   which   based   on   TCP / IP   protocol   provides   the   communication   infrastructure   for   visual   simulation   system .   It   provides   unified   process   logic   and   interfaces   for   various   status   and   frame   data   and   the   packing / unpacking   functions   of   simulation   data   without   concerning   the   details   of   the   data .   We   found   two   classes   of   display   synchronization   problems   and   provided   the   resolution   of   them .   The   middleware   provides   a   group   of   APIs   which   hide   the   details   of   data   packing / unpacking ,   processing   and   transmission   and   meets   the   requirement   of   flexibility ,   efficiency   and   extensibility .   This   middleware   has   been   successfully   implemented   to   the   display   cluster   of   several   tower   simulation   system . ' ,   ' title ' :   ' The   Research   of   High   Level   Data   Communication   Middleware   of   Display   Cluster   Used   in   Real   Time   Simulation   Environment ' } 
{ ' abstract ' :   ' The   scattering   parameters   are   fundamental   in   the   characterization   of   electrical   devices   at   high   frequencies .   They   are   particularly   useful   for   analyzing   multiport   high - frequency   and   microwave   networks .   However ,   they   are   not   adequately   presented   in   most ,   if   not   all ,   microwave   engineering   books .   This   paper   identifies   two   common   deficiencies   in   the   way   scattering   parameters   are   being   presented   in   these   books .   It   provides   additional   information   that   should   supplement   those   books   or   book   chapters   on   scattering   parameters . ' ,   ' title ' :   ' Deficiencies   in   the   way   scattering   parameters   are   taught ' } 
{ ' abstract ' :   ' We   study   the   reliability   maximization   problem   in   WDM   networks   with   random   link   failures .   Reliability   in   these   networks   is   defined   as   the   probability   that   the   logical   network   is   connected ,   and   it   is   determined   by   the   underlying   lightpath   routing   and   the   link   failure   probability .   We   show   that   in   general   the   optimal   lightpath   routing   depends   on   the   link   failure   probability ,   and   characterize   the   properties   of   lightpath   routings   that   maximize   the   reliability   in   different   failure   probability   regimes .   In   particular ,   we   show   that   in   the   low   failure   probability   regime ,   maximizing   the   ` ` cross - layer "   min   cut   of   the   ( layered )   network   maximizes   reliability ,   whereas   in   the   high   failure   probability   regime ,   minimizing   the   spanning   tree   of   the   network   maximizes   reliability .   Motivated   by   these   results ,   we   develop   lightpath   routing   algorithms   for   reliability   maximization . ' ,   ' title ' :   ' Maximizing   Reliability   in   WDM   Networks   through   Lightpath   Routing ' } 
{ ' abstract ' :   ' The   slope   of   the   active   distances   is   an   important   parameter   when   investigating   the   error - correcting   capability   of   convolutional   codes   and   the   distance   behavior   of   concatenated   convolutional   codes .   The   slope   of   the   active   distances   is   equal   to   the   minimum   average   weight   cycle   in   the   state - transition   diagram   of   the   encoder .   A   general   upper   bound   on   the   slope   depending   on   the   free   distance   of   the   convolutional   code   and   new   upper   bounds   on   the   slope   of   special   classes   of   binary   convolutional   codes   are   derived .   Moreover ,   a   search   technique ,   resulting   in   new   tables   of   rate   R = 1 / 2   and   rate   R = 1 / 3   convolutional   encoders   with   high   memories   and   large   active   distance - slopes   is   presented .   Furthermore ,   we   show   that   convolutional   codes   with   large   slopes   can   be   used   to   obtain   new   tailbiting   block   codes   with   large   minimum   distances .   Tables   of   rate   R = 1 / 2   and   rate   R = 1 / 3   tailbiting   codes   with   larger   minimum   distances   than   the   best   previously   known   quasi - cyclic   codes   are   given .   Two   new   tailbiting   codes   also   have   larger   minimum   distances   than   the   best   previously   known   binary   linear   block   codes   with   same   size   and   length .   One   of   them   is   also   superior   in   terms   of   minimum   distance   to   any   previously   known   binary   nonlinear   block   code   with   the   same   set   of   parameters . ' ,   ' title ' :   ' Tailbiting   codes   obtained   via   convolutional   codes   with   large   active   distance - slopes ' } 
{ ' abstract ' :   ' MIMO   wireless   technology   is   required   to   increase   the   data   rates   for   a   broad   range   of   applications ,   including   low   cost   mobile   devices .   In   this   paper   we   present   a   very   low   area   reconfigurable   MIMO   detector   which   achieves   a   high   throughput   of   103Mbps   and   uses   27   Kilo   Gates   when   implemented   in   a   commercial   180nm   CMOS   process .   The   low   area   is   achieved   by   the   proposed   in - place   architecture .   This   architecture   implements   the   K - best   algorithm   and   reduces   area   4 - fold   compared   to   the   widely   used   multi - stage   architecture ,   while   provides   reconfigurability   in   terms   of   antenna   configuration   during   real - time   operation . ' ,   ' title ' :   ' A   low - area   flexible   MIMO   detector   for   WiFi / WiMAX   standards ' } 
{ ' abstract ' :   ' Because   human   cognition   is   creative   and   socially   situated ,   knowledge   accumulates ,   diffuses ,   and   gets   applied   in   new   contexts ,   generating   cultural   analogs   of   phenomena   observed   in   population   genetics   such   as   adaptation   and   drift .   It   is   therefore   commonly   thought   that   elements   of   culture   evolve   through   natural   selection .   However ,   natural   selection   was   proposed   to   explain   how   change   accumulates   despite   lack   of   inheritance   of   acquired   traits ,   as   occurs   with   template - mediated   replication .   It   cannot   accommodate   a   process   with   significant   retention   of   acquired   or   horizontally   ( e . g .   socially )   transmitted   traits .   Moreover ,   elements   of   culture   cannot   be   treated   as   discrete   lineages   because   they   constantly   interact   and   influence   one   another .   It   is   proposed   that   what   evolves   through   culture   is   the   mind ;   ideas   and   artifacts   are   merely   reflections   of   its   current   evolved   state .   Interacting   minds   transform   ( in   part )   through   a   non - Darwinian   autopoietic   process   similar   to   that   by   which   early   life   evolved ,   involving   not   survival   of   the   fittest   but   actualization   of   their   potential . ' ,   ' title ' :   ' The   cultural   evolution   of   socially   situated   cognition ' } 
{ ' abstract ' :   ' Event   Extraction   is   a   complex   and   interesting   topic   in   Information   Extraction   that   includes   event   extraction   methods   from   free   text   or   web   data .   The   result   of   event   extraction   systems   can   be   used   in   several   fields   such   as   risk   analysis   systems ,   online   monitoring   systems   or   decide   support   tools .   In   this   paper ,   we   introduce   a   method   that   combines   lexico   - -   semantic   and   machine   learning   to   extract   event   from   Vietnamese   news .   Furthermore ,   we   concentrate   to   describe   event   online   monitoring   system   named   VnLoc   based   on   the   method   that   was   proposed   above   to   extract   event   in   Vietnamese   language .   Besides ,   in   experiment   phase ,   we   have   evaluated   this   method   based   on   precision ,   recall   and   F1   measure .   At   this   time   of   experiment ,   we   on   investigated   on   three   types   of   event :   FIRE ,   CRIME   and   TRANSPORT   ACCIDENT . ' ,   ' title ' :   ' VnLoc :   A   Real   - -   Time   News   Event   Extraction   Framework   for   Vietnamese ' } 
{ ' abstract ' :   ' Reliability   analysis   using   error   probabilities   for   combinational   logic   circuits   has   been   investigated   widely   in   the   literature .   Reliability   analysis   for   sequential   logic   circuits   using   these   methods   would   be   inaccurate   because   of   existence   of   loops   in   their   architecture .   In   this   paper   a   new   method   based   on   conversion   of   sequential   circuit   to   combinational   one   and   applying   an   iterative   reliability   analysis   is   developed .   A   Monte   Carlo   method - based   reliability   analysis   is   introduced   for   sequential   circuits ,   which   is   used   for   first   method   validation .   Experimental   results   demonstrate   good   accuracy   of   the   method . ' ,   ' title ' :   ' SEQUENTIAL   LOGIC   CIRCUITS   RELIABILITY   ANALYSIS ' } 
{ ' abstract ' :   ' According   to   the   Journey   to   Crime   theory ,   offenders   have   a   directionality   preference ,   in   the   form   of   an   activity   path ,   when   they   are   moving   about   in   their   environment   in   search   for   criminal   activities .   Using   clustering   techniques ,   this   theory   is   tested   using   crime   data   for   the   Province   of   British   Columbia ,   Canada .   The   activities   of   57 , 962   offenders   who   were   either   charged ,   chargeable ,   or   for   whom   charges   were   recommended   were   analyzed   by   mapping   their   offense   locations   with   respect   to   their   home   locations   to   determine   directionality .   Once   directionality   was   established ,   a   unique   clustering   technique ,   based   on   K - Means   clustering   and   modified   for   angles ,   was   applied   to   find   the   number   of   activity   paths   for   each   offender .   Although   the   number   of   activity   paths   varies   from   individual   to   individual ,   the   aggregate   pattern   was   very   consistent   with   theory .   It   was   found   that   people   only   have   a   few   activity   paths ,   even   if   they   are   highly   prolific   offenders . ' ,   ' title ' :   ' How   Many   Ways   Do   Offenders   Travel   - -   Evaluating   the   Activity   Paths   of   Offenders ' } 
{ ' abstract ' :   ' Pulse   Coupled   Neural   Network ( PCNN )   is   widely   used   in   the   field   of   image   processing ,   but   it   is   a   difficult   task   to   define   the   relative   parameters   properly   in   the   research   of   the   applications   of   PCNN .   So   far   the   determination   of   parameters   of   its   model   needs   a   lot   of   experiments .   To   deal   with   the   above   problem ,   a   document   segmentation   based   on   the   improved   PCNN   is   proposed .   It   uses   the   maximum   entropy   function   as   the   fitness   function   of   bacterial   foraging   optimization   algorithm ,   adopts   bacterial   foraging   optimization   algorithm   to   search   the   optimal   parameters ,   and   eliminates   the   trouble   of   manually   set   the   experiment   parameters .   Experimental   results   show   that   the   proposed   algorithm   can   effectively   complete   document   segmentation .   And   result   of   the   segmentation   is   better   than   the   contrast   algorithms .   ©   ( 2014 )   COPYRIGHT   Society   of   Photo - Optical   Instrumentation   Engineers   ( SPIE ) .   Downloading   of   the   abstract   is   permitted   for   personal   use   only . ' ,   ' title ' :   ' PCNN   document   segmentation   method   based   on   bacterial   foraging   optimization   algorithm ' } 
{ ' abstract ' :   ' Undirected   graphical   models   encode   in   a   graph   G   the   dependency   structure   of   a   random   vector   Y .   In   many   applications ,   it   is   of   interest   to   model   Y   given   another   random   vector   X   as   input .   We   refer   to   the   problem   of   estimating   the   graph   G ( x )   of   Y   conditioned   on   X   =   x   as   " graph - valued   regression " .   In   this   paper ,   we   propose   a   semiparametric   method   for   estimating   G ( x )   that   builds   a   tree   on   the   X   space   just   as   in   CART   ( classification   and   regression   trees ) ,   but   at   each   leaf   of   the   tree   estimates   a   graph .   We   call   the   method   " Graph - optimized   CART " ,   or   Go - CART .   We   study   the   theoretical   properties   of   Go - CART   using   dyadic   partitioning   trees ,   establishing   oracle   inequalities   on   risk   minimization   and   tree   partition   consistency .   We   also   demonstrate   the   application   of   Go - CART   to   a   meteorological   dataset ,   showing   how   graph - valued   regression   can   provide   a   useful   tool   for   analyzing   complex   data . ' ,   ' title ' :   ' Graph - Valued   Regression ' } 
{ ' abstract ' :   ' Over   the   last   two   decades ,   doubts   have   been   expressed   about   the   adequacy   of   materialism   as   the   correct   framework   for   explaining   phenomenal   consciousness   ( the   experience   of   saturated   greenness   one   has   when   looking   at   a   lush   lawn ,   for   example ) .   This   paper   reconstructs   a   generic   form   of   the   various   arguments   that   have   been   used   to   defend   the   view   of   the   materialistically   inexplicable   nature   of   consciousness   ( MINC ) .   This   reconstruction   reveals   that   the   arguments   turn   on   an   impoverished   notion   of   explanation .   By   discussing   some   examples   from   the   history   of   science ,   the   paper   shows   that   a   reasonable   notion   of   explanation   has   to   be   wider   than   the   one   utilized   in   the   argument   for   MINC ,   which   opens   the   possibility   for   the   materialistic   explicability   of   consciousness .   The   author   ends   the   paper   by   raising   a   question   about   the   very   intelligibility   of   the   project   of   trying   to   explain   the   so - called   nature   of   consciousness   as   opposed   to   the   regularities   characteristic   of   the   relation   between   states   of   consciousness   and   ... ' ,   ' title ' :   ' On   explaining   phenomenal   consciousness ' } 
{ ' abstract ' :   ' Successful   replication   within   an   infected   host   and   successful   transmission   between   hosts   are   key   to   the   continued   spread   of   most   pathogens .   Competing   selection   pressures   exerted   at   these   different   scales   can   lead   to   evolutionary   trade - offs   between   the   determinants   of   fitness   within   and   between   hosts .   Here ,   we   examine   such   a   trade - off   in   the   context   of   influenza   A   viruses   and   the   differential   pressures   exerted   by   temperature - dependent   virus   persistence .   For   a   panel   of   avian   influenza   A   virus   strains ,   we   find   evidence   for   a   trade - off   between   the   persistence   at   high   versus   low   temperatures .   Combining   a   within - host   model   of   influenza   infection   dynamics   with   a   between - host   transmission   model ,   we   study   how   such   a   trade - off   affects   virus   fitness   on   the   host   population   level .   We   show   that   conclusions   regarding   overall   fitness   are   affected   by   the   type   of   link   assumed   between   the   within -   and   between - host   levels   and   the   main   route   of   transmission   ( direct   or   environmental ) .   The   relative   importance   of   virulence   and   immune   response   mediated   virus   clearance   are   also   found   to   influence   the   fitness   impacts   of   virus   persistence   at   low   versus   high   temperatures .   Based   on   our   results ,   we   predict   that   if   transmission   occurs   mainly   directly   and   scales   linearly   with   virus   load ,   and   virulence   or   immune   responses   are   negligible ,   the   evolutionary   pressure   for   influenza   viruses   to   evolve   toward   good   persistence   at   high   within - host   temperatures   dominates .   For   all   other   scenarios ,   influenza   viruses   with   good   environmental   persistence   at   low   temperatures   seem   to   be   favored . ' ,   ' title ' :   ' A   Multi - scale   Analysis   of   Influenza   A   Virus   Fitness   Trade - offs   due   to   Temperature - dependent   Virus   Persistence ' } 
{ ' abstract ' :   ' Peer - to - Peer   ( P2P )   networks   are   largely   used   for   file - sharing   and   hence   must   provide   efficient   mechanisms   for   searching   the   files   stored   at   various   nodes .   The   existing   structuredP2P   overlays   support   only   ” exact - match ”   look - up   which   is   hardly   sufficient   in   a   file   sharing   network .   This   paper   addresses   the   problem   of   keyword - based   search   in   structured   P2P   networks .   We   propose   a   new   keyword - based   searching   algorithm   which   can   be   implemented   on   top   of   any   structured   P2P   overlay .   We   demonstrate   that   the   proposed   algorithm   achieves   very   good   searching   results   as   it   requires   the   minimum   number   of   messages   to   be   sent   in   order   to   find   all   the   references   to   files   containing   at   least   the   given   set   of   keywords . ' ,   ' title ' :   ' A   Keyword   Search   Algorithm   for   Structured   Peer - to - Peer   Networks ' } 
{ ' abstract ' :   ' In   this   paper ,   we   propose   an   adaptive   power   allocation   method   for   hybrid   relay   systems   that   employ   the   amplify - and - forward   and   decode - and - forward   protocols   simultaneously .   The   total   transmission   power   is   analytically   allocated   to   a   source   and   two   selected   relays   by   the   proposed   power   allocation   criterion   to   maximize   the   overall   received   signal - to - noise   ratio   at   the   destination .   Simulation   results   show   that   the   proposed   scheme   achieves   better   performance   than   that   of   conventional   cooperative   schemes   or   hybrid   systems   with   equal   power   allocation . ' ,   ' title ' :   ' Adaptive   relay   selection   and   power   allocation   for   hybrid   relay   systems ' } 
{ ' abstract ' :   ' The   unitary   rotation   of   square - pixellated   images   is   based   on   the   finite   su ( 2 ) - oscillator   model ,   which   describes   systems   whose   values   for   position ,   momentum   and   energy ,   are   discrete   and   finite .   In   a   two - dimensional   position   space ,   this   allows   the   construction   of   angular   momentum   states ,   orthonormal   and   complete ,   for   which   rotations   are   defined   as   multiplication   by   phases   that   carry   the   rotation   angle .   The   decomposition   of   a   digital   square   images   in   terms   of   these   angular   momentum   states   determines   a   unitary   ( hence   invertible )   rotation   of   the   image ,   whose   kernel   can   be   computed   as   a   four - dimensional   array   of   real   numbers . ' ,   ' title ' :   ' Unitary   rotation   of   square - pixellated   images ' } 
{ ' abstract ' :   ' As   more   mobile   storage   devices   are   used   in   consumer   electronics ,   possibility   of   user   confidential   data   leakage   increases .   To   make   things   worse ,   data   of   deleted   file   in   mobile   storage   such   as   USB   drives   can   be   easily   recovered   and ,   thus ,   can   be   vulnerable   to   data   leakage .   To   prevent   this   type   of   data   leakage ,   efficient   secure   deletion   techniques   are   required   and   we   present   two   secure   deletion   techniques ,   namely   block   cleaning   and   zero   overwriting ,   for   flash   memory   storage .   Also ,   we   propose   cost   and   benefit   models   of   both   techniques .   The   models   imply   an   existence   of   an   efficient   adaptive   hybrid   secure   deletion   scheme   that   applies   one   of   the   techniques   based   on   their   costs   and   benefits   at   given   data   arrangements .   Experimental   results   measured   on   an   embedded   board   show   that   the   adaptive   hybrid   scheme   deletes   data   securely   and   efficiently   for   various   data   patterns   on   flash   memory   storage . ' ,   ' title ' :   ' Models   and   Design   of   an   Adaptive   Hybrid   Scheme   for   Secure   Deletion   of   Data   in   Consumer   Electronics ' } 
{ ' abstract ' :   ' In   heterogeneous   and   dynamic   environments ,   efficient   execution   of   parallel   computations   can   require   mappings   of   tasks   to   processors   whose   performance   is   both   irregular   ( because   of   heterogeneity )   and   time - varying   ( because   of   dynamicity ) .   While   adaptive   domain   decomposition   techniques   have   been   used   to   address   heterogeneous   resource   capabilities ,   temporal   variations   in   those   capabilities   have   seldom   been   considered .   We   propose   a   conservative   scheduling   policy   that   uses   information   about   expected   future   variance   in   resource   capabilities   to   produce   more   efficient   data   mapping   decisions .   We   first   present   techniques ,   based   on   time   series   predictors   that   we   developed   in   previous   work ,   for   predicting   CPU   load   at   some   future   time   point ,   average   CPU   load   for   some   future   time   interval ,   and   variation   of   CPU   load   over   some   future   time   interval .   We   then   present   a   family   of   stochastic   scheduling   algorithms   that   exploit   such   predictions   of   future   availability   and   variability   when   making   data   mapping   decisions .   Finally ,   we   describe   experiments   in   which   we   apply   our   techniques   to   an   astrophysics   application .   The   results   of   these   experiments   demonstrate   that   conservative   scheduling   can   produce   execution   times   that   are   both   significantly   faster   and   less   variable   than   other   techniques . ' ,   ' title ' :   ' Conservative   Scheduling :   Using   Predicted   Variance   to   Improve   Scheduling   Decisions   in   Dynamic   Environments ' } 
{ ' abstract ' :   ' We   consider   a   class   of   restless   multi - armed   bandit   problems   that   arises   in   multi - channel   opportunistic   communications ,   where   channels   are   modeled   as   independent   and   stochastically   identical   Gilbert - Elliot   channels   and   channel   state   observations   are   subject   to   errors .   We   show   that   the   myopic   channel   selection   policy   has   a   semi - universal   structure   that   obviates   the   need   to   know   the   Markovian   transition   probabilities   of   the   channel   states .   Based   on   this   structure ,   we   establish   closed - form   lower   and   upper   bounds   on   the   steady - state   throughput   achieved   by   the   myopic   policy .   Furthermore ,   we   characterize   the   approximation   factor   of   the   myopic   policy   to   bound   its   worst - case   performance   loss   with   respect   to   the   optimal   performance . ' ,   ' title ' :   ' On   the   myopic   policy   for   a   class   of   restless   bandit   problems   with   applications   in   dynamic   multichannel   access ' } 
{ ' abstract ' :   ' We   show   that   the   optimum   length - / spl   nu /   guard   sequence   for   block   transmission   over   a   linear   Gaussian - noise   dispersive   channel   with   memory   / spl   nu /   is   a   linear   combination   of   the   N   information   symbols   of   the   block .   A   closed - form   expression   for   the   optimum   guard   sequence   is   derived   subject   to   a   total   average   energy   constraint   on   the   information   and   guard   symbols .   The   achievable   channel   block   throughput   with   the   optimum   guard   sequence   is   compared   with   that   achievable   with   two   common   guard   sequence   types ,   namely   zero   stuffing   and   cyclic   prefix . ' ,   ' title ' :   ' Guard   sequence   optimization   for   block   transmission   over   linear   frequency - selective   channels ' } 
{ ' abstract ' :   " A   modular   program   analysis   considers   components   independently   and   provides   a   succinct   summary   for   each   component ,   which   is   used   when   checking   the   rest   of   the   system .   Consider   a   system   consisting   of   a   library   and   a   client .   A   temporal   summary ,   or     interface   ,   of   the   library   specifies   legal   sequences   of   library   calls .   The   interface   is     safe     if   no   call   sequence   violates   the   library ' s   internal   invariants ;   the   interface   is     permissive     if   it   contains   every   such   sequence .   Modular   program   analysis   requires     full     interfaces ,   which   are   both   safe   and   permissive :   the   client   does   not   cause   errors   in   the   library   if   and   only   if   it   makes   only   sequences   of   library   calls   that   are   allowed   by   the   full   interface   of   the   library . Previous   interface - based   methods   have   focused   on   safe   interfaces ,   which   may   be   too   restrictive   and   thus   reject   good   clients .   We   present   an   algorithm   for   automatically   synthesizing   software   interfaces   that   are   both   safe   and   permissive .   The   algorithm   generates   interfaces   as   graphs   whose   vertices   are   labeled   with   predicates   over   the   library ' s   internal   state ,   and   whose   edges   are   labeled   with   library   calls .   The   interface   state   is   refined   incrementally   until   the   full   interface   is   constructed .   In   other   words ,   the   algorithm   automatically   synthesizes   a   typestate   system   for   the   library ,   against   which   any   client   can   be   checked   for   compatibility .   We   present   an   implementation   of   the   algorithm   which   is   based   on   the   BLAST   model   checker ,   and   we   evaluate   some   case   studies . " ,   ' title ' :   ' Permissive   interfaces ' } 
{ ' abstract ' :   ' In   this   paper ,   we   propose   a   new   method   for   the   motion   planning   problem   of   rigid   object   dexterous   manipulation   with   a   robotic   multi - fingered   hand ,   under   quasi - static   movement   assumption .   This   method   computes   both   object   and   finger   trajectories   as   well   as   the   finger   relocation   sequence .   Its   specificity   is   to   use   a   special   structuring   of   the   research   space   that   allows   to   search   for   paths   directly   in   the   particular   subspace   GS   n     which   is   the   subspace   of   all   the   grasps   that   can   be   achieved   with   n   grasping   fingers .   The   solving   of   the   dexterous   manipulation   planning   problem   is   based   upon   the   exploration   of   this   subspace .   The   proposed   approach   captures   the   connectivity   of   GS   n     in   a   graph   structure .   The   answer   of   the   manipulation   planning   query   is   then   given   by   searching   a   path   in   the   computed   graph .   Simulation   experiments   were   conducted   for   different   dexterous   manipulation   task   examples   to   validate   the   proposed   method . ' ,   ' title ' :   ' Dexterous   manipulation   planning   using   probabilistic   roadmaps   in   continuous   grasp   subspaces ' } 
{ ' abstract ' :   ' This   paper   presents   an   experimental   evaluation   of   different   line   extraction   algorithms   applied   to   2D   laser   scans   for   indoor   environments .   Six   popular   algorithms   in   mobile   robotics   and   computer   vision   are   selected   and   tested .   Real   scan   data   collected   from   two   office   environments   by   using   different   platforms   are   used   in   the   experiments   in   order   to   evaluate   the   algorithms .   Several   comparison   criteria   are   proposed   and   discussed   to   highlight   the   advantages   and   drawbacks   of   each   algorithm ,   including   speed ,   complexity ,   correctness   and   precision .   The   results   of   the   algorithms   are   compared   with   ground   truth   using   standard   statistical   methods .   An   extended   case   study   is   performed   to   further   evaluate   the   algorithms   in   a   SLAM   application . ' ,   ' title ' :   ' A   comparison   of   line   extraction   algorithms   using   2D   range   data   for   indoor   mobile   robotics ' } 
{ ' abstract ' :   ' This   study   investigates   the   use   of   force - stiffness   feedback ,   i . e . ,   a   combination   of   force   offset   and   extra   spring   load ,   in   UAV   tele - operation   with   transmission   time   delay .   The   goal   was   to   further   increase   the   level   of   safety   of   tele - operation   with   a   reduction   in   operator   workload   with   respect   to   force   feedback ,   i . e . ,   using   force   offset   alone .   A   theoretical   analysis   is   given   of   using   force - stiffness   feedback   to   improve   collision   avoidance .   Wave   variables   are   included   to   reduce   time   delay   effects .   An   experiment   was   conducted   to   investigate   the   effects   of   force - stiffness   feedback   on   safety   of   operation ,   operator   performance ,   control   activity ,   and   workload .   Results   indicate   that   force - stiffness   feedback   improves   the   haptic   interface   with   respect   to   force   feedback   alone .   Safety   of   tele - operation   increases   without   increasing   operator   workload   with   respect   to   force   feedback . ' ,   ' title ' :   ' Haptic   interface   in   UAV   tele - operation   using   force - stiffness   feedback ' } 
{ ' abstract ' :   ' Due   to   the   spread   of   the   internet   and   the   ever   increasing   number   of   web   applications ,   the   issue   of   compatibility   across   browsers   has   become   very   important .   This   compatibility   issue   is   also   referred   as   Cross   Browser   Inconsistency   ( XBI )   wherein   same   website   looks   or   behaves   differently   in   different   web   browsers .   In   this   paper   our   aim   is   to   address   this   issue   of   compatibility   and   propose   an   automated   approach   of   detecting   XBIs .   Cross   Browser   Inconsistencies   can   either   be   in   the   content ,   structure   or   behavior   of   the   webpage .   In   order   to   get   a   grasp   of   the   above   mentioned   types   of   inconsistencies ,   we   surveyed   some   random   websites   and   analyzed   them   in   different   browsers .   We   also   studied   the   basic   working   of   browser ,   in   order   to   establish   its   connection   with   the   occurrences   of   XBIs .   Each   browser   has   its   own   rendering   mechanisms ,   which   sometimes   differs   from   standards .   Hence ,   the   execution   of   these   websites   is   different   in   different   browsers .   Finally   we   have   proposed   an   automated   approach   for   XBI   detection . ' ,   ' title ' :   ' An   Automated   Approach   for   Cross - Browser   Inconsistency   ( XBI )   Detection ' } 
{ ' abstract ' :   ' We   present   a   formal   framework   that   combines   high - level   representation   and   causality - based   reasoning   with   low - level   geometric   reasoning   and   motion   planning .   The   frame - work   features   bilateral   interaction   between   task   and   motion   planning ,   and   embeds   geometric   reasoning   in   causal   reasoning ,   thanks   to   several   advantages   inherited   from   its   underlying   components .   In   particular ,   our   choice   of   using   a   causality - based   high - level   formalism   for   describing   action   domains   allows   us   to   represent   ramifications   and   state / transition   constraints ,   and   embed   in   such   formal   domain   descriptions   externally   defined   functions   implemented   in   some   programming   language   ( e . g . ,   C++ ) .   Moreover ,   given   such   a   domain   description ,   the   causal   reasoner   based   on   this   formalism   ( i . e . ,   the   Causal   Calculator )   allows   us   to   compute   optimal   solutions   ( e . g . ,   shortest   plans )   for   elaborate   planning / prediction   problems   with   temporal   constraints .   Utilizing   these   features   of   high - level   representation   and   reasoning ,   we   can   combine   causal   reasoning ,   motion   planning   and   geometric   planning   to   find   feasible   kinematic   solutions   to   task - level   problems .   In   our   framework ,   the   causal   reasoner   guides   the   motion   planner   by   finding   an   optimal   task - plan ;   if   there   is   no   feasible   kinematic   solution   for   that   task - plan   then   the   motion   planner   guides   the   causal   reasoner   by   modifying   the   planning   problem   with   new   temporal   constraints .   Furthermore ,   while   computing   a   task - plan ,   the   causal   reasoner   takes   into   account   geometric   models   and   kinematic   relations   by   means   of   external   predicates   implemented   for   geometric   reasoning   ( e . g . ,   to   check   some   collisions ) ;   in   that   sense   the   geometric   reasoner   guides   the   causal   reasoner   to   find   feasible   kinematic   solutions .   We   illustrate   an   application   of   this   framework   to   robotic   manipulation ,   with   two   pantograph   robots   on   a   complex   assembly   task   that   requires   concurrent   execution   of   actions .   A   short   video   of   this   application   accompanies   the   paper . ' ,   ' title ' :   ' Combining   high - level   causal   reasoning   with   low - level   geometric   reasoning   and   motion   planning   for   robotic   manipulation ' } 
{ ' abstract ' :   ' This   paper   presents   a   novel   template   matching   method   to   detect   and   track   pedestrians   for   people   counting   in   real - time .   Firstly ,   a   novel   background   subtraction   method   is   proposed   for   extracting   all   foreground   objects   from   background .   Then ,   a   shadow   elimination   method   is   used   to   remove   unwanted   shadow   from   the   background .   In   order   to   identify   pedestrians   from   non - pedestrian   objects ,   this   paper   proposed   a   novel   grid - based   template   matching   scheme   to   robustly   verify   each   pedestrian .   Usually ,   a   pedestrian   will   have   different   appearances   at   different   positions .   The   grid - based   approach   can   effectively   reduce   the   perspective   effects   into   a   minimum   since   it   uses   different   templates   to   record   the   appearance   changes   at   each   grid .   When   more   templates   are   used ,   the   detection   process   will   become   more   inefficient .   To   speed   up   its   efficiency ,   an   integral   image   is   used   to   filter   out   all   impossible   candidates   in   advance .   Lastly ,   a   tracking   method   is   applied   to   tracking   the   direction   of   each   moving   pedestrian   so   that   the   real   number   of   passing   people   per   direction   can   be   counted   more   accurately .   Experimental   results   have   proved   that   the   proposed   method   is   robust ,   accurate ,   and   powerful   in   people   counting . ' ,   ' title ' :   ' Grid - based   Template   Matching   for   People   Counting ' } 
{ ' abstract ' :   ' A   tomographic   image   reconstruction   algorithm   that   we   have   been   studying   requires   the   nth - order   Hankel   transform   for   the   nth   function   in   a   series ,   where   n   varies   over   a   set   of   integers .   Unfortunately ,   most   previously   proposed   algorithms   have   either   dealt   with   only   zeroth - order   transforms   or   cannot   be   applied   conveniently   to   our   problem .   We   propose   an   algorithm   for   computing   general   integer - order   Hankel   transforms .   The   algorithm   takes   samples   of   equally   spaced   input   functions   and   gives   equally   spaced   samples   of   the   transforms . ' ,   ' title ' :   ' An   algorithm   for   computing   general   integer - order   Hankel   transforms ' } 
{ ' abstract ' :   ' In   this   paper ,   we   present   a   real - time   approach   that   allows   tracking   deformable   structures   in   3D   ultrasound   sequences .   Our   method   consists   in   obtaining   the   target   displacements   by   combining   robust   dense   motion   estimation   and   mechanical   model   simulation .   We   perform   evaluation   of   our   method   through   simulated   data ,   phantom   data ,   and   real - data .   Results   demonstrate   that   this   novel   approach   has   the   advantage   of   providing   correct   motion   estimation   regarding   different   ultrasound   shortcomings   including   speckle   noise ,   large   shadows   and   ultrasound   gain   variation .   Furthermore ,   we   show   the   good   performance   of   our   method   with   respect   to   state - of - the - art   techniques   by   testing   on   the   3D   databases   provided   by   MICCAI   CLUST ’ 14   and   CLUST ’ 15   challenges . ' ,   ' title ' :   ' Real - time   target   tracking   of   soft   tissues   in   3D   ultrasound   images   based   on   robust   visual   information   and   mechanical   simulation ' } 
{ ' abstract ' :   ' For   two   given   graphs   G1G1   and   G2G2 ,   the   Ramsey   number   R ( G1 , G2 ) R ( G1 , G2 )   is   the   smallest   integer   NN   such   that   for   any   graph   of   order   NN ,   either   GG   contains   a   copy   of   G1G1   or   its   complement   contains   a   copy   of   G2G2 .   Let   CmCm   be   a   cycle   of   length   mm   and   K1 , nK1 , n   a   star   of   order   n + 1n + 1 .   Parsons   ( 1975 )   shows   that   R ( C4 , K1 , n ) ≤ n + ⌊ n − 1 ⌋ + 2   and   if   nn   is   the   square   of   a   prime   power ,   then   the   equality   holds .   In   this   paper ,   by   discussing   the   properties   of   polarity   graphs   whose   vertices   are   points   in   the   projective   planes   over   Galois   fields ,   we   prove   that   R ( C4 , K1 , q2 − t ) = q2 + q − ( t − 1 ) R ( C4 , K1 , q2 − t ) = q2 + q − ( t − 1 )   if   qq   is   an   odd   prime   power ,   1 ≤ t ≤ 2 ⌈ q4 ⌉   and   t ≠ 2 ⌈ q4 ⌉ − 1 ,   which   extends   a   result   on   R ( C4 , K1 , q2 − t ) R ( C4 , K1 , q2 − t )   obtained   by   Parsons   ( 1976 ) . ' ,   ' title ' :   ' Polarity   graphs   and   Ramsey   numbers   for   C   4   versus   stars ' } 
{ ' abstract ' :   ' This   paper   deals   with   the   problem   of   assuring   strict   QoS   guarantees   for   the   end   to   end   connections   that   originate   from   Ethernet   access   network .   It   shows   that   despite   high   link   capacities   in   some   cases   Ethernet   network   might   be   the   reason   of   QoS   deterioration .   The   primary   reason   is   the   lack   of   appropriate   QoS   differentiation   and   traffic   isolation   mechanisms .   The   shared   buffers   and   priority   schedulers   available   in   most   of   Ethernet   switches   appear   to   be   not   sufficient   to   guarantee   strict   QoS .   For   these   cases   new   solution   is   proposed   which   relies   on   additional   traffic   control   mechanisms   available   in   other   network   elements .   Only   additional   mechanism   supporting   typical   functionality   of   Ethernet   switch   can   provide   strict   QoS   guarantees   what   was   verified   in   simulations   studies . ' ,   ' title ' :   ' On   assuring   QoS   in   Ethernet   access   network ' } 
{ ' abstract ' :   ' The   federal   Medicare   regulations   reimburse   hospitals   on   a   pro   rata   share   of   the   hospital \ ' s   cost .   Hence ,   to   meet   its   financial   requirements ,   a   hospital   is   forced   to   shift   more   of   the   financial   burdens   onto   its   private   patients .   This   procedure   has   contributed   to   double   digit   inflation   in   hospital   prices   and   to   proposed   federal   regulation   to   control   the   rate   of   increase   in   hospital   revenues .   In   this   regulatory   environment ,   we   develop   nonlinear   programming   pricing   and   cost   allocation   models   to   aid   hospital   administrators   in   meeting   their   profit   maximizing   and   profit   satisficing   goals .   The   model   enables   administrators   to   explore   tactical   issues   such   as :   i   studying   the   relationship   between   a   voluntary   or   legislated   cap   on   a   hospital \ ' s   total   revenues   and   the   hospital \ ' s   profitability ,   ii   identifying   those   departments   within   the   hospital   that   are   the   most   attractive   candidates   for   cost   reduction   or   cost   containment   efforts ,   and   iii   isolating   those   services   that   should   be   singled   out   by   the   hospital   manager   for   renegotiation   of   the   prospective   or   " customary   and   reasonable "   cap .   Finally ,   the   modeling   approach   is   helpful   in   explaining   the   departmental   cross   subsidies   observed   in   practice ,   and   can   be   of   aid   to   federal   administrators   in   assessing   the   impacts   of   proposed   changes   in   the   Medicare   reimbursement   formula . ' ,   ' title ' :   ' Hospital   Profit   Planning   under   Medicare   Reimbursement ' } 
{ ' abstract ' :   ' We   present   a   ( 4   +   epsilon )   approximation   algorithm   for   weighted   graph   matching   which   applies   in   the   semistreaming ,   sliding   window ,   and   MapReduce   models ;   this   single   algorithm   improves   the   previous   best   algorithm   in   each   model .   The   algorithm   operates   by   reducing   the   maximum - weight   matching   problem   to   a   polylog   number   of   copies   of   the   maximum - cardinality   matching   problem .   The   algorithm   also   extends   to   provide   approximation   guarantees   for   the   more   general   problem   of   finding   weighted   independent   sets   in   p - systems   ( which   include   intersections   of   p   matroids   and   p - bounded   hypergraph   matching ) . ' ,   ' title ' :   ' Improved   Streaming   Algorithms   for   Weighted   Matching ,   via   Unweighted   Matching ' } 
{ ' abstract ' :   ' This   paper   presents   a   novel   approach   to   efficiently   solve   parameter - dependent   ( PD )   linear   matrix   inequality   ( LMI )   problems   for ,   amongst   others ,   linear   parameter - varying   ( LPV )   control   design .   Typically ,   stability   and   performance   is   guaranteed   by   finding   a   PD   Lyapunov   function   such   that   a   PD   LMI   is   feasible   on   a   parameter   domain .   To   solve   the   resulting   semi - infinite   problems ,   we   propose   a   novel   LMI   relaxation   technique   relying   on   B - spline   basis   functions .   This   technique   provides   less   conservative   solutions   and / or   a   reduced   numerical   burden   compared   to   existing   approaches .   Moreover ,   an   elegant   generalization   of   worst - case   optimization   to   the   optimization   of   any   signal   norm   is   obtained   by   expressing   performance   bounds   as   a   function   of   the   system   parameters .   This   generalization   yields   better   performance   bounds   in   a   large   part   of   the   parameter   domain .   Numerical   comparisons   with   the   current   state - of - the - art   demonstrate   the   generality   and   effectiveness   of   our   approach . ' ,   ' title ' :   ' Control   of   linear   parameter - varying   systems   using   B - splines ' } 
{ ' abstract ' :   ' There   is   a   growing   interest   in   simulating   natural   phenomena   in   computer   graphics   applications .   Animating   natural   scenes   in   real   time   is   one   of   the   most   challenging   problems   due   to   the   inherent   complexity   of   their   structure ,   formed   by   millions   of   geometric   entities ,   and   the   interactions   that   happen   within .   An   example   of   natural   scenario   that   is   needed   for   games   or   simulation   programs   are   forests .   Forests   are   difficult   to   render   because   the   huge   amount   of   geometric   entities   and   the   large   amount   of   detail   to   be   represented .   Moreover ,   the   interactions   between   the   objects   ( grass ,   leaves )   and   external   forces   such   as   wind   are   complex   to   model .   In   this   paper   we   concentrate   in   the   rendering   of   falling   leaves   at   low   cost .   We   present   a   technique   that   exploits   graphics   hardware   in   order   to   render   thousands   of   leaves   with   different   falling   paths   in   real   time   and   low   memory   requirements . ' ,   ' title ' :   ' Rendering   falling   leaves   on   graphics   hardware ' } 
{ ' abstract ' :   ' We   previously   presented   DriverDB ,   a   database   that   incorporates   ∼ 6000   cases   of   exome - seq   data ,   in   addition   to   annotation   databases   and   published   bioinformatics   algorithms   dedicated   to   driver   gene / mutation   identification .   The   database   provides   two   points   of   view ,   ‘ Cancer ’   and   ‘ Gene ’ ,   to   help   researchers   visualize   the   relationships   between   cancers   and   driver   genes / mutations .   In   the   updated   DriverDBv2   database   ( http : / / ngs . ym . edu . tw / driverdb )   presented   herein ,   we   incorporated   > 9500   cancer - related   RNA - seq   datasets   and   > 7000   more   exome - seq   datasets   from   The   Cancer   Genome   Atlas   ( TCGA ) ,   International   Cancer   Genome   Consortium   ( ICGC ) ,   and   published   papers .   Seven   additional   computational   algorithms   ( meaning   that   the   updated   database   contains   15   in   total ) ,   which   were   developed   for   driver   gene   identification ,   are   incorporated   into   our   analysis   pipeline ,   and   the   results   are   provided   in   the   ‘ Cancer ’   section .   Furthermore ,   there   are   two   main   new   features ,   ‘ Expression ’   and   ‘ Hotspot ’ ,   in   the   ‘ Gene ’   section .   ‘ Expression ’   displays   two   expression   profiles   of   a   gene   in   terms   of   sample   types   and   mutation   types ,   respectively .   ‘ Hotspot ’   indicates   the   hotspot   mutation   regions   of   a   gene   according   to   the   results   provided   by   four   bioinformatics   tools .   A   new   function ,   ‘ Gene   Set ’ ,   allows   users   to   investigate   the   relationships   among   mutations ,   expression   levels   and   clinical   data   for   a   set   of   genes ,   a   specific   dataset   and   clinical   features . ' ,   ' title ' :   ' DriverDBv2 :   a   database   for   human   cancer   driver   gene   research ' } 
{ ' abstract ' :   ' Thousands   of   deep   and   wide   pipelines   working   concurrently   make   GPGPU   high   power   consuming   parts .   Energy - efficiency   techniques   employ   voltage   overscaling   that   increases   timing   sensitivity   to   variations   and   hence   aggravating   the   energy   use   issues .   This   paper   proposes   a   method   to   increase   spatiotemporal   reuse   of   computational   effort   by   a   combination   of   compilation   and   micro - architectural   design .   An   associative   memristive   memory   ( AMM )   module   is   integrated   with   the   floating   point   units   ( FPUs ) .   Together ,   we   enable   fine - grained   partitioning   of   values   and   find   high - frequency   sets   of   values   for   the   FPUs   by   searching   the   space   of   possible   inputs ,   with   the   help   of   application - specific   profile   feedback .   For   every   kernel   execution ,   the   compiler   pre - stores   these   high - frequent   sets   of   values   in   AMM   modules   - -   representing   partial   functionality   of   the   associated   FPU - -   that   are   concurrently   evaluated   over   two   clock   cycles .   Our   simulation   results   show   high   hit   rates   with   32 - entry   AMM   modules   that   enable   36%   reduction   in   average   energy   use   by   the   kernel   codes .   Compared   to   voltage   overscaling ,   this   technique   enhances   robustness   against   timing   errors   with   39%   average   energy   saving . ' ,   ' title ' :   ' Energy - Efficient   GPGPU   Architectures   via   Collaborative   Compilation   and   Memristive   Memory - Based   Computing ' } 
{ ' abstract ' :   ' Quasi - cyclic   codes   are   renowned   for   their   structural   design   and   low - complexity   shift   register   encoding .   However ,   existing   design   techniques   based   on   difference   families   have   limited   code   size   options   due   to   algebraic   constraints .   We   introduce   in   this   paper   a   notation   of   extended   difference   family   ( EDF )   and   provide   a   systematic   code   design   based   on   EDFs   with   a   high   degree   of   flexibility   in   code   size .   Short / medium - length   codes   of   high   rate   ( / spl   ges /   0.9 )   can   be   easily   constructed . ' ,   ' title ' :   ' Quasi - cyclic   codes   from   extended   difference   families ' } 
{ ' abstract ' :   ' Lexical   cohesion   arises   from   a   chain   of   lexical   items   that   establish   links   between   sentences   in   a   text .   In   this   paper   we   propose   three   different   models   to   capture   lexical   cohesion   for   document - level   machine   translation :   ( a )   a   direct   reward   model   where   translation   hypotheses   are   rewarded   whenever   lexical   cohesion   devices   occur   in   them ,   ( b )   a   conditional   probability   model   where   the   appropriateness   of   using   lexical   cohesion   devices   is   measured ,   and   ( c )   a   mutual   information   trigger   model   where   a   lexical   cohesion   relation   is   considered   as   a   trigger   pair   and   the   strength   of   the   association   between   the   trigger   and   the   triggered   item   is   estimated   by   mutual   information .   We   integrate   the   three   models   into   hierarchical   phrase - based   machine   translation   and   evaluate   their   effectiveness   on   the   NIST   Chinese - English   translation   tasks   with   large - scale   training   data .   Experiment   results   show   that   all   three   models   can   achieve   substantial   improvements   over   the   baseline   and   that   the   mutual   information   trigger   model   performs   better   than   the   others . ' ,   ' title ' :   ' Modeling   lexical   cohesion   for   document - level   machine   translation ' } 
{ ' abstract ' :   ' This   paper   presents   a   lightweight   sketching   system   that   enables   interactive   illustration   of   complex   fluid   systems .   Users   can   sketch   on   a   2.5 - dimensional   ( 2.5 D )   canvas   to   design   the   shapes   and   connections   of   a   fluid   circuit .   These   input   sketches   are   automatically   analyzed   and   abstracted   into   a   hydraulic   graph ,   and   a   new   hybrid   fluid   model   is   used   in   the   background   to   enhance   the   illustrations .   The   system   provides   rich   simple   operations   for   users   to   edit   the   fluid   system   incrementally ,   and   the   new   internal   flow   patterns   can   be   simulated   in   real   time .   Our   system   is   used   to   illustrate   various   fluid   systems   in   medicine ,   biology ,   and   engineering .   We   asked   professional   medical   doctors   to   try   our   system   and   obtained   positive   feedback   from   them . ' ,   ' title ' :   ' Sketch - based   Dynamic   Illustration   of   Fluid   Systems ' } 
{ ' abstract ' :   ' We   present   an   improved   zone   content   classification   method   and   its   performance   evaluation .   We   added   two   new   features   to   the   feature   vector   from   one   previously   published   method   ( Sivaramakrishnan   et   al . ,   1995 ) .   We   assumed   different   independence   relationships   in   two   zone   sets .   We   used   an   optimized   binary   decision   tree   to   estimate   the   maximum   zone   content   class   probability   in   one   set   while   using   the   Viterbi   algorithm   to   find   the   optimal   solution   for   a   zone   sequence   in   the   other   set .   The   training ,   pruning   and   testing   data   set   for   the   algorithm   include   1 , 600   images   drawn   from   the   UWCDROM   III   document   image   database .   The   classifier   is   able   to   classify   each   given   scientific   and   technical   document   zone   into   one   of   the   nine   classes ,   2   text   classes   ( of   font   size   4   -   18pt   and   font   size   19   -   32   pt ) ,   math ,   table ,   halftone ,   map / drawing ,   ruling ,   logo ,   and   others .   Compared   with   our   previous   work   ( Wang   et   al . ,   2000 ) ,   it   raised   the   accuracy   rate   to   98.52%   from   97.53%   and   reduced   the   mean   false   alarm   rate   to   0.53%   from   1.26% . ' ,   ' title ' :   ' Zone   content   classification   and   its   performance   evaluation ' } 
{ ' abstract ' :   ' Big   Data   applications   require   real - time   processing   of   complex   computations   on   streaming   and   static   information .   Applications   such   as   the   diagnosis   of   power   generating   turbines   require   the   integration   of   high   velocity   streaming   and   large   volume   of   static   data   from   multiple   sources .   In   this   paper   we   study   various   optimisations   related   to   efficiently   processing   of   streaming   and   static   information .   We   introduce   novel   indexing   structures   for   stream   processing ,   a   query - planner   component   that   decides   when   their   creation   is   beneficial ,   and   we   examine   precomputed   summarisations   on   archived   measurements   to   accelerate   streaming   and   static   information   processing .   To   put   our   ideas   into   practise ,   we   have   developed   Exa   Stream ,   a   data   stream   management   system   that   is   scalable ,   has   declarative   semantics ,   supports   user   defined   functions ,   and   allows   efficient   execution   of   complex   analytical   queries   on   streaming   and   static   data .   Our   work   is   accompanied   by   an   empirical   evaluation   of   our   optimisation   techniques . ' ,   ' title ' :   ' Real   time   processing   of   streaming   and   static   information ' } 
{ ' abstract ' :   " In   the   last   ten   years ,   speech   recognition   has   evolved   from   a   science   fiction   dream   to   a   widespread   input   method   for   mobile   devices .   In   this   talk ,   I   will   describe   how   speech   recognition   works ,   the   problems   we   have   solved   and   the   challenges   that   remain .   I   will   touch   upon   some   of   Google ' s   main   efforts   in   language   and   pronunciation   modeling ,   and   describe   how   the   adoption   of   neural   networks   for   acoustic   modeling   marked   the   beginning   of   a   technology   revolution   in   the   field ,   with   approaches   such   as   Long   Short   Term   Memory   models   and   Connectionist   Temporal   Classification .   I   will   also   share   my   learnings   on   how   Machine   Learning   and   Human   Knowledge   can   be   harmoniously   combined   to   build   state - of - the - art   technology   that   helps   and   delights   users   across   the   world . " ,   ' title ' :   ' Learnings   and   innovations   in   speech   recognition ' } 
{ ' abstract ' :   ' Nowadays ,   the   explosive   growth   and   variety   of   information   available   on   the   Web   frequently   overwhelms   users   and   leads   users   to   make   poor   decisions .   Consequently ,   recommender   systems   have   become   more   and   more   important   to   assist   people   to   make   decisions   faster .   Among   all   related   techniques ,   collaborative   filtering   approach   is   currently   one   of   the   effective   and   widely   used   techniques   to   build   recommender   systems .   However ,   there   are   major   challenges   like   data   sparsity   and   scalability .   Meanwhile   it   is   hard   to   integrate   demographic   statistical   information   ( Age ,   gender   and   occupation   etc . )   to   collaborative   filtering   model .   Unfortunately ,   it   is   significant   to   take   account   into   these   information ,   especially   user   occupation   when   making   recommendation .   As   we   all   know ,   people   with   different   occupations   may   have   totally   different   tastes .   It   has   been   proved   that   restricted   Boltzmann   machines ( RBM )   model   can   infer   lower - dimensional   representations   automatically   and   is   potential   in   handling   large   and   sparse   dataset .   In   this   paper ,   we   propose   an   improved   User   Occupation   aware   Conditional   Restricted   Boltzmann   Machine   Frame ( UO - CRBMF )   model ,   which   employs   an   improved   RBM   and   takes   full   use   of   user   occupation   information   by   adding   a   conditional   layer   with   user   occupation   information .   Experimental   studies   on   the   standard   benchmark   datasets   of   MovieLens   100k   and   MovieLens   1M   have   shown   its   potential   and   advantages   beyond   baseline   methods . ' ,   ' title ' :   ' User   Occupation   Aware   Conditional   Restricted   Boltzmann   Machine   Based   Recommendation ' } 
{ ' abstract ' :   ' Microservices   complement   approaches   like   DevOps   and   continuous   delivery   in   terms   of   software   architecture .   Along   with   this   architectural   style ,   several   important   deployment   technologies ,   such   as   container - based   virtualization   and   container   orchestration   solutions ,   have   emerged .   These   technologies   allow   to   efficiently   exploit   cloud   platforms ,   providing   a   high   degree   of   scalability ,   availability ,   and   portability   for   microservices .# R ## N ## R ## N # Despite   the   obvious   importance   of   a   sufficient   level   of   performance ,   there   is   still   a   lack   of   performance   engineering   approaches   explicitly   taking   into   account   the   particularities   of   microservices .   In   this   paper ,   we   argue   why   new   solutions   to   performance   engineering   for   microservices   are   needed .   Furthermore ,   we   identify   open   issues   and   outline   possible   research   directions   with   regard   to   performance - aware   testing ,   monitoring ,   and   modeling   of   microservices . ' ,   ' title ' :   ' Performance   Engineering   for   Microservices :   Research   Challenges   and   Directions ' } 
{ ' abstract ' :   ' Intelligent   agents ,   such   as   robots ,   have   to   serve   a   multitude   of   autonomous   functions .   Examples   are ,   e . g . ,   collision   avoidance ,   navigation   and   route   planning ,   active   sensing   of   its   environment ,   or   the   interaction   and   non - verbal   communication   with   people   in   the   extended   reach   space .   Here ,   we   focus   on   the   recognition   of   the   action   of   a   human   agent   based   on   a   biologically   inspired   visual   architecture   of   analyzing   articulated   movements .   The   proposed   processing   architecture   builds   upon   coarsely   segregated   streams   of   sensory   processing   along   different   pathways   which   separately   process   form   and   motion   information   ( Layher   et   al . ,   2014 ) .   Action   recognition   is   performed   in   an   event - based   scheme   by   identifying   representations   of   characteristic   pose   configurations   ( key   poses )   in   an   image   sequence .   In   line   with   perceptual   studies ,   key   poses   are   selected   unsupervised   utilizing   a   feature   driven   criterion   which   combines   extrema   in   the   motion   energy   with   the   horizontal   and   the   vertical   extendedness   of   a   body   shape .   Per   class   representations   of   key   pose   frames   are   learned   using   a   deep   convolutional   neural   network   consisting   of   15   convolutional   layers .   The   network   is   trained   using   the   energy - efficient   deep   neuromorphic   networks   ( Eedn )   framework   ( Esser   et   al . ,   2016 ) ,   which   realizes   the   mapping   of   the   trained   synaptic   weights   onto   the   IBM   Neurosynaptic   System   platform   ( Merolla   et   al . ,   2014 ) .   After   the   mapping ,   the   trained   network   achieves   real - time   capabilities   for   processing   input   streams   and   classify   input   images   at   about   1 , 000   frames   per   second   while   the   computational   stages   only   consume   about   70   mW   of   energy   ( without   spike   transduction ) .   Particularly   regarding   mobile   robotic   systems ,   a   low   energy   profile   might   be   crucial   in   a   variety   application   scenarios .   Cross - validation   results   are   reported   for   two   different   datasets   and   compared   to   state - of - the - art   action   recognition   approaches .   The   results   demonstrate ,   that   ( I )   the   presented   approach   is   on   par   with   other   key   pose   based   methods   described   in   the   literature ,   which   select   key   pose   frames   by   optimizing   classification   accuracy ,   ( II )   compared   to   the   training   on   the   full   set   of   frames ,   representations   trained   on   key   pose   frames   result   in   a   higher   confidence   in   class   assignments ,   and   ( III )   key   pose   representations   show   promising   generalization   capabilities   in   a   cross - dataset   evaluation . ' ,   ' title ' :   ' Real - Time   Biologically   Inspired   Action   Recognition   from   Key   Poses   Using   a   Neuromorphic   Architecture ' } 
{ ' abstract ' :   ' Contents   carried   in   an   image   are   valuable   information   sources   for   many   scientific   and   engineering   applications .   However ,   if   the   image   is   captured   under   low   illumination   conditions   a   large   portion   of   the   image   appears   dark   and   this   heavily   degrades   the   image   quality .   In   order   to   solve   this   problem ,   a   restoration   algorithm   is   developed   here   that   transforms   the   low   input   brightness   to   a   higher   value   using   a   logarithmic   mapping   function .   The   mapping   is   further   refined   by   a   linear   weighting   with   the   input   to   reduce   the   un - necessary   amplification   at   regions   with   high   brightness .   Moreover ,   fine   details   in   the   image   are   preserved   by   applying   the   Retinex   principle   to   extract   and   then   re - insert   object   edges .   Results   from   experiments   using   low   and   normal   illumination   images   have   shown   satisfactory   performances   with   regard   to   the   improvement   in   information   contents   and   the   mitigation   of   viewing   artifacts . ' ,   ' title ' :   ' Logarithmic   profile   mapping   and   Retinex   edge   preserving   for   restoration   of   low   illumination   images ' } 
{ ' abstract ' :   ' We   propose   a   principled   approach   for   the   problem   of   aligning   multiple   partially   overlapping   networks .   The   objective   is   to   map   multiple   graphs   into   a   single   graph   while   preserving   vertex   and   edge   similarities .   The   problem   is   inspired   by   the   task   of   integrating   partial   views   of   a   family   tree   ( genealogical   network )   into   one   unified   network ,   but   it   also   has   applications ,   for   example ,   in   social   and   biological   networks .   Our   approach ,   called   Flan ,   introduces   the   idea   of   generalizing   the   facility   location   problem   by   adding   a   non - linear   term   to   capture   edge   similarities   and   to   infer   the   underlying   entity   network .   The   problem   is   solved   using   an   alternating   optimization   procedure   with   a   Lagrangian   relaxation .   Flan   has   the   advantage   of   being   able   to   leverage   prior   information   on   the   number   of   entities ,   so   that   when   this   information   is   available ,   Flan   is   shown   to   work   robustly   without   the   need   to   use   any   ground   truth   data   for   fine - tuning   method   parameters .   Additionally ,   we   present   three   multiple - network   extensions   to   an   existing   state - of - the - art   pairwise   alignment   method   called   Natalie .   Extensive   experiments   on   synthetic ,   as   well   as   real - world   datasets   on   social   networks   and   genealogical   networks ,   attest   to   the   effectiveness   of   the   proposed   approaches   which   clearly   outperform   a   popular   multiple   network   alignment   method   called   IsoRankN . ' ,   ' title ' :   ' Lagrangian   relaxations   for   multiple   network   alignment ' } 
{ ' abstract ' :   ' Heterogeneous   ultra - dense   networks   enable   ultra - high   data   rates   and   ultra - low   latency   through   the   use   of   dense   sub - 6   GHz   and   millimeter   wave   ( mmWave )   small   cells   with   different   antenna   configurations .   Existing   work   has   widely   studied   spectral   and   energy   efficiency   in   such   networks   and   shown   that   high   spectral   and   energy   efficiency   can   be   achieved .   This   article   investigates   the   benefits   of   heterogeneous   ultra - dense   network   architecture   from   the   perspectives   of   three   promising   technologies ,   i . e . ,   physical   layer   security ,   caching ,   and   wireless   energy   harvesting ,   and   provides   enthusiastic   outlook   towards   application   of   these   technologies   in   heterogeneous   ultra - dense   networks .   Based   on   the   rationale   of   each   technology ,   opportunities   and   challenges   are   identified   to   advance   the   research   in   this   emerging   network . ' ,   ' title ' :   ' A   New   Look   at   Physical   Layer   Security ,   Caching ,   and   Wireless   Energy   Harvesting   for   Heterogeneous   Ultra - dense   Networks ' } 
{ ' abstract ' :   ' We   consider   the   problem   of   joint   modeling   of   videos   and   their   corresponding   textual   descriptions   ( e . g .   sentences   or   phrases ) .   Our   approach   consists   of   three   components :   the   video   representation ,   the   textual   representation ,   and   a   joint   model   that   links   videos   and   text .   Our   video   representation   uses   the   state - of - the - art   deep   3D   ConvNet   to   capture   the   semantic   information   in   the   video .   Our   textual   representation   uses   the   recent   advancement   in   learning   word   and   sentence   vectors   from   large   text   corpus .   The   joint   model   is   learned   to   score   the   correct   ( video ,   text )   pairs   higher   than   the   incorrect   ones .   We   demonstrate   our   approach   in   several   applications :   1 )   retrieving   sentences   given   a   video ;   2 )   retrieving   videos   given   a   sentence ;   3 )   zero - shot   action   recognition   in   videos . ' ,   ' title ' :   ' Beyond   verbs :   Understanding   actions   in   videos   with   text ' } 
{ ' abstract ' :   ' This   paper   presents   a   multi - agent   model   for   simulating   attitude   formation   and   change   based   on   perception   and   communication   in   the   context   of   stabilization   operations .   The   originality   of   our   model   comes   from   ( 1 )   attitude   computation   that   evaluates   information   as   part   of   a   history   relative   to   the   individual   ( 2 )   a   notion   of   co - responsibility   for   attitude   attribution .   We   present   a   military   scenario   of   French   operations   in   Afghanistan   along   with   polls   results   about   the   opinion   of   citizen   toward   present   Forces .   Based   on   these   field   data ,   we   calibrate   the   model   and   show   the   resulting   attitude   dynamics .   We   study   the   sensibility   of   the   model   to   the   co - responsibility   factor . ' ,   ' title ' :   ' From   Field   Data   to   Attitude   Formation ' } 
{ ' abstract ' :   ' This   paper   proposes   two   low - complexity   iterative   algorithms   to   compute   the   capacity   of   a   single - user   multiple - input   multiple - output   channel   with   per - antenna   power   constraint .   The   first   method   results   from   manipulating   the   optimality   conditions   of   the   considered   problem   and   applying   fixed - point   iteration .   In   the   second   approach ,   we   transform   the   considered   problem   into   a   minimax   optimization   program   using   the   well - known   MAC -   BC   duality ,   and   then   solve   it   by   a   novel   alternating   optimization   method .   In   both   proposed   iterative   methods ,   each   iteration   involves   an   optimization   problem   which   can   be   efficiently   solved   by   the   water - filling   algorithm .   The   proposed   iterative   methods   are   provably   convergent .   Complexity   analysis   and   extensive   numerical   experiments   are   carried   out   to   demonstrate   the   superior   performance   of   the   proposed   algorithms   over   an   existing   approach   known   as   the   mode - dropping   algorithm . ' ,   ' title ' :   ' Low - complexity   Approaches   for   MIMO   Capacity   with   Per - antenna   Power   Constraint ' } 
{ ' abstract ' :   ' Inventory - Aware   Pathfinding   is   concerned   with   finding   paths   while   taking   into   account   that   picking   up   items ,   e . g . ,   keys ,   allow   the   character   to   unlock   blocked   pathways ,   e . g . ,   locked   doors .   In   this   work   we   present   a   pruning   method   and   a   preprocessing   method   that   can   improve   significantly   the   scalability   of   such   approaches .   We   apply   our   methods   to   the   recent   approach   of   Inventory - Driven   Jump - Point   Search   ( InvJPS ) .   First ,   we   introduce   InvJPS +   that   allows   to   prune   large   parts   of   the   search   space   by   favoring   short   detours   to   pick   up   items ,   offering   a   trade - off   between   efficiency   and   optimality .   Second ,   we   propose   a   preprocessing   step   that   allows   to   decide   on   runtime   which   items ,   e . g . ,   keys ,   are   worth   using   thus   pruning   potentially   unnecessary   items   before   the   search   starts .   We   show   results   for   combinations   of   the   pruning   and   preprocessing   methods   illustrating   the   best   choices   over   various   scenarios . ' ,   ' title ' :   ' Pruning   and   preprocessing   methods   for   inventory - aware   pathfinding ' } 
{ ' abstract ' :   ' This   paper   proposes   a   method   for   proper   names   extraction   from   Myanmar   text   by   using   latent   Dirichlet   allocation   ( LDA ) .   Our   method   aims   to   extract   proper   names   that   provide   important   information   on   the   contents   of   Myanmar   text .   Our   method   consists   of   two   steps .   In   the   first   step ,   we   extract   topic   words   from   Myanmar   news   articles   by   using   LDA .   In   the   second   step ,   we   make   a   post - processing ,   because   the   resulting   topic   words   contain   some   noisy   words .   Our   post - processing ,   first   of   all ,   eliminates   the   topic   words   whose   prefixes   are   Myanmar   digits   and   suffixes   are   noun   and   verb   particles .   We   then   remove   the   duplicate   words   and   discard   the   topic   words   that   are   contained   in   the   existing   dictionary .   Consequently ,   we   obtain   the   words   as   candidate   of   proper   names ,   namely   personal   names ,   geographical   names ,   unique   object   names ,   organization   names ,   single   event   names ,   and   so   on .   The   evaluation   is   performed   both   from   the   subjective   and   quantitative   perspectives .   From   the   subjective   perspective ,   we   compare   the   accuracy   of   proper   names   extracted   by   our   method   with   those   extracted   by   latent   semantic   indexing   ( LSI )   and   rule - based   method .   It   is   shown   that   both   LS ]   and   our   method   can   improve   the   accuracy   of   those   obtained   by   rule - based   method .   However ,   our   method   can   provide   more   interesting   proper   names   than   LSI .   From   the   quantitative   perspective ,   we   use   the   extracted   proper   names   as   additional   features   in   K - means   clustering .   The   experimental   results   show   that   the   document   clusters   given   by   our   method   are   better   than   those   given   by   LSI   and   rule - based   method   in   precision ,   recall   and   F - score . ' ,   ' title ' :   ' Extraction   of   proper   names   from   myanmar   text   using   latent   dirichlet   allocation ' } 
{ ' abstract ' :   ' Large   scale   assessment   of   aboveground   biomass   ( AGB )   in   tropical   forests   is   often   limited   by   the   saturation   of   remote   sensing   signals   at   high   AGB   values .   Fourier   Transform   Textural   Ordination   ( FOTO )   performs   well   in   quantifying   canopy   texture   from   very   high - resolution   ( VHR )   imagery ,   from   which   stand   structure   parameters   can   be   retrieved   with   no   saturation   effect   for   AGB   values   up   to   650   Mg · ha − 1 .   The   method   is   robust   when   tested   on   wet   evergreen   forests   but   is   more   demanding   when   applied   across   different   forest   types   characterized   by   varying   structures   and   allometries .   The   present   study   focuses   on   a   gradient   of   forest   types   ranging   from   dry   deciduous   to   wet   evergreen   forests   in   the   Western   Ghats   ( WG )   of   India ,   where   we   applied   FOTO   to   Cartosat - 1a   images   with   2.5   m   resolution .   Based   on   21   1 - ha   ground   control   forest   plots ,   we   calibrated   independent   texture – AGB   models   for   the   dry   and   wet   zone   forests   in   the   area ,   as   delineated   from   the   distribution   of   NDVI   values   computed   from   LISS - 4   multispectral   images .   This   stratification   largely   improved   the   relationship   between   texture - derived   and   field - derived   AGB   estimates ,   which   exhibited   a   R2   of   0.82   for   a   mean   rRMSE   of   ca .   17% .   By   inverting   the   texture – AGB   models ,   we   finally   mapped   AGB   predictions   at   1.6 - ha   resolution   over   a   heterogeneous   landscape   of   ca .   1500   km2   in   the   WG ,   with   a   mean   relative   per - pixel   propagated   error   < 20%   for   wet   zone   forests ,   i . e . ,   below   the   recommended   IPCC   criteria   for   Monitoring ,   Reporting   and   Verification   ( MRV )   methods .   The   method   proved   to   perform   well   in   predicting   high - resolution   AGB   values   over   heterogeneous   tropical   landscape   encompassing   diversified   forest   types ,   and   thus   presents   a   promising   option   for   affordable   regional   monitoring   systems   of   greenhouse   gas   ( GhG )   emissions   related   to   forest   degradation . ' ,   ' title ' :   ' Inverting   Aboveground   Biomass – Canopy   Texture   Relationships   in   a   Landscape   of   Forest   Mosaic   in   the   Western   Ghats   of   India   Using   Very   High   Resolution   Cartosat   Imagery ' } 
{ ' abstract ' :   ' Self - driving   vehicle   technologies   are   progressing   rapidly   and   are   expected   to   play   a   significant   role   in   the   future   of   transportation .   One   of   the   main   challenges   for   self - driving   vehicles   on   public   roads   is   the   safe   cooperation   and   collaboration   among   multiple   vehicles   using   sensor - based   perception   and   inter - vehicle   communications .   When   self - driving   vehicles   try   to   occupy   the   same   spatial   area   simultaneously ,   they   might   collide   with   one   another ,   might   become   deadlocked ,   or   might   slam   on   the   brakes   making   it   uncomfortable   or   unsafe   for   passengers   in   a   self - driving   vehicle .   In   this   paper ,   we   study   how   a   self - driving   vehicle   can   safely   navigate   merge   points ,   where   two   lanes   with   different   priorities   meet .   We   present   a   safe   protocol   for   merge   points   named   Autonomous   Vehicle   Protocol   for   Merge   Points ,   where   self - driving   vehicles   use   both   vehicular   communications   and   their   own   perception   systems   for   cooperating   with   other   self - driving   and / or   human - driven   vehicles .   Our   simulation   results   show   that   our   traffic   protocol   has   higher   traffic   throughput ,   compared   to   simple   traffic   protocols ,   while   ensuring   safety . ' ,   ' title ' :   ' A   merging   protocol   for   self - driving   vehicles ' } 
{ ' abstract ' :   ' System   Portfolio   Selection   ( SPS )   problem   is   equivalent   to   multi - objective   optimization   problem ,   with   multi - function   requirements   incommensurable .   In   the   paper ,   the   SPS   problem   is   re - specified   with   a   more   practical   formulation ,   comparing   to   general   portfolio   problem .   Then ,   both   feasible   and   non - inferior   solution   is   re - defined   considering   characteristics   of   SPS   problem ,   specifically ,   four   rules   of   system   function   combinations   are   proposed   according   to   practical   cases .   Then ,   the   instability   of   system   performance   is   involved   in   SPS   problem ,   and   the   robust   theory   is   employed   to   solving   the   uncertainty   of   system   function   values   with   definition   of   robust   non - inferior   solution .   Next ,   the   paper   proposes   an   immediately   updating   algorithm   to   solve   the   problem   of   solution   space   exponentially   growing .   Finally ,   a   case   study   is   used   to   demonstrate   the   usefulness   and   effectiveness   of   the   proposed   approaches .   It   shows   that   the   approach   can   provide   an   efficient   guidance   for   decision - makers   in   the   process   of   making   a   SPS . ' ,   ' title ' :   ' Robust   system   portfolio   selection   with   multi - function   requirements   and   system   instability ' } 
{ ' abstract ' :   ' This   study   explores   the   impact   of   high - photovoltaic   ( PV )   penetration   on   the   inter - area   oscillation   modes   of   large - scale   power   grids .   A   series   of   dynamic   models   with   various   PV   penetration   levels   are   developed   based   on   a   detailed   model   representing   the   U . S .   Eastern   Interconnection   ( EI ) .   Transient   simulations   are   performed   to   investigate   the   change   of   inter - area   oscillation   modes   with   PV   penetration .   The   impact   of   PV   control   strategies   and   parameter   settings   on   inter - area   oscillations   is   studied .   This   paper   finds   that   as   PV   increases ,   the   damping   of   the   dominant   oscillation   mode   decreases   monotonically .   It   is   also   observed   that   the   mode   shape   varies   with   the   PV   control   strategy   and   new   oscillation   modes   may   emerge   under   inappropriate   parameter   settings   in   PV   plant   controls . ' ,   ' title ' :   ' Impact   of   High   PV   Penetration   on   the   Inter - Area   Oscillations   in   the   U . S .   Eastern   Interconnection ' } 
{ ' abstract ' :   ' The   objective   of   this   research   is   to   compare   the   effectiveness   of   different   tracking   devices   underwater .   There   have   been   few   works   in   aquatic   virtual   reality   ( VR )   —   i . e . ,   VR   systems   that   can   be   used   in   a   real   underwater   environment .   Moreover ,   the   works   that   have   been   done   have   noted   limitations   on   tracking   accuracy .   Our   initial   test   results   suggest   that   inertial   measurement   units   work   well   underwater   for   orientation   tracking   but   a   different   approach   is   needed   for   position   tracking .   Towards   this   goal ,   we   have   waterproofed   and   evaluated   several   consumer   tracking   systems   intended   for   gaming   to   determine   the   most   effective   approaches .   First ,   we   informally   tested   infrared   systems   and   fiducial   marker   based   systems ,   which   demonstrated   significant   limitations   of   optical   approaches .   Next ,   we   quantitatively   compared   inertial   measurement   units   ( IMU )   and   a   magnetic   tracking   system   both   above   water   ( as   a   baseline )   and   underwater .   By   comparing   the   devices   rotation   data ,   we   have   discovered   that   the   magnetic   tracking   system   implemented   by   the   Razer   Hydra   is   more   accurate   underwater   as   compared   to   a   phone - based   IMU .   This   suggests   that   magnetic   tracking   systems   should   be   further   explored   for   underwater   VR   applications . ' ,   ' title ' :   ' Towards   usable   underwater   virtual   reality   systems ' } 
{ ' abstract ' :   ' A   faulty   network   GG   is   under   the   conditional   fault   model ,   i . e . , \ xa0every   fault - free   vertex   of   GG   is   incident   to   at   least   two   fault - free   edges .   Let   FFvFFv   and   FFeFFe   be   the   set   of   faulty   vertices   and   faulty   edges   in   FQnFQn ,   respectively .   In   this   paper ,   we   consider   FQnFQn   under   the   conditional   fault   model   and   prove   that   if   | FFv | + | FFe | ≤ 2n − 4 | FFv | + | FFe | ≤ 2n − 4   and   n ≥ 3n ≥ 3 ,   then   FQn − FFv − FFeFQn − FFv − FFe   contains   a   fault - free   cycle   of   every   even   length   from   4   to   2n − 2 | FFv | 2n − 2 | FFv | ;   if   | FFv | + | FFe | ≤ 2n − 5 | FFv | + | FFe | ≤ 2n − 5   and   n ≥ 4n ≥ 4   is   even ,   then   FQn − FFv − FFeFQn − FFv − FFe   contains   a   fault - free   cycle   of   every   odd   length   from   n + 1n + 1   to   2n − 2 | FFv | − 12n − 2 | FFv | − 1 . ' ,   ' title ' :   ' Cycles   embedding   in   folded   hypercubes   under   the   conditional   fault   model ' } 
{ ' abstract ' :   ' Companies   have   invested   considerable   resources   in   the   implementation   of   enterprise   resource   planning   ( ERP )   systems .   The   results   initially   expected   have   rarely   been   reached .   The   optimisation   ( or   efficient   use )   of   such   information   systems   is   nowadays   becoming   a   major   factor   for   firms   striving   to   reach   their   performance   objectives .   After   presenting   a   synthesis   of   several   studies   on   ERP   projects ,   we   build   on   the   findings   of   a   French   investigation   into   the   assessment   and   optimisation   of   ERP   performance .   A   classification   of   company   positions   regarding   their   ERP   use ,   based   on   both   software   maturity   and   strategic   deployment   directions ,   and   an   improvement   process   are   proposed .   Industrial   cases   allow   validation   of   this   approach . ' ,   ' title ' :   ' A   classification   for   better   use   of   ERP   systems ' } 
{ ' abstract ' :   ' This   paper   presents   a   time - domain   biosensor   array   that   uses   a   capacitor - less   current - mode   analog - to - time   converter   ( CMATC )   and   logarithmic   cyclic   time - attenuation - based   TDC   with   discharging   acceleration .   Combining   the   exponential   function   of   the   CMATC   and   logarithmic   function   of   the   proposed   TDC   offers   linear   input - output   characteristics .   The   time - domain   property   enables   bio - imaging   at   a   high   spatial   resolution   and   large   scale   while   maintaining   scalability .   Measurement   results   with   a   0.25 - μ m   test   chip   successfully   demonstrated   linear   input - output   characteristics . ' ,   ' title ' :   ' A   scalable   time - domain   biosensor   array   using   logarithmic   cyclic   time - attenuation - based   TDC   for   high - resolution   and   large - scale   bio - imaging ' } 
{ ' abstract ' :   ' Compared   to   current   mobile   networks ,   next - generation   mobile   networks   are   expected   to   support   higher   numbers   of   simultaneously   connected   devices   and   to   achieve   higher   system   spectrum   efficiency   and   lower   power   consumption .   To   achieve   these   goals ,   we   study   the   multi - sharing   device - to - device   ( D2D )   communication ,   which   allows   any   cellular   user   equipment   to   share   its   radio   resource   with   multiple   D2D   devices .   We   jointly   consider   resource   block   reuse   and   power   control   and   then   develop   the   MISS   algorithm .   Simulation   results   show   that   MISS   performs   very   well   in   terms   of   transmission   power   consumption ,   system   throughput ,   and   the   number   of   permitted   D2D   devices . ' ,   ' title ' :   ' Joint   Resource   Block   Reuse   and   Power   Control   for   Multi - Sharing   Device - to - Device   Communication ' } 
{ ' abstract ' :   ' This   paper   is   concerned   with   event - triggered   H ∞ H ∞   filtering   for   delayed   neural   networks   via   sampled   data .   A   novel   event - triggered   scheme   is   proposed ,   which   can   lead   to   a   significant   reduction   of   the   information   communication   burden   in   the   network ;   the   feature   of   this   scheme   is   that   whether   or   not   the   sampled   data   should   be   transmitted   is   determined   by   the   current   sampled   data   and   the   error   between   the   current   sampled   data   and   the   latest   transmitted   data .   By   constructing   a   proper   Lyapunov – Krasovskii   functional ,   utilizing   the   reciprocally   convex   combination   technique   and   Jensen ’ s   inequality   sufficient   conditions   are   derived   to   ensure   that   the   resultant   filtering   error   system   is   asymptotically   stable .   Based   on   the   derived   H ∞ H ∞   performance   analysis   results ,   the   H ∞ H ∞   filter   design   is   formulated   in   terms   of   Linear   Matrix   Inequalities   ( LMIs ) .   Finally ,   the   proposed   stability   conditions   are   demonstrated   with   numerical   example . ' ,   ' title ' :   ' Event - triggered   H   ∞   filtering   for   delayed   neural   networks   via   sampled - data ' } 
{ ' abstract ' :   ' For   the   double   integrator   with   matched   Lipschitz   disturbances   we   propose   a   continuous   homogeneous   controller   providing   finite - time   stability   of   the   origin .   The   disturbance   is   compensated   exactly   in   finite   time   using   a   discontinuous   function   through   an   integral   action .   Since   the   controller   is   dynamic ,   the   closed   loop   is   a   third   order   system   that   achieves   a   third   order   sliding   mode   in   the   steady   state .   The   stability   and   robustness   properties   of   the   controller   are   proven   using   a   smooth   and   homogeneous   strict   Lyapunov   function   ( LF ) .   In   a   first   stage ,   the   gains   of   the   controller   and   the   LF   are   designed   using   a   method   based   on   Polya ’ s   Theorem .   In   a   second   stage   the   controller ’ s   gains   are   adjusted   through   a   sum   of   squares   representation   of   the   LF . ' ,   ' title ' :   ' Design   of   Continuous   Twisting   Algorithm ' } 
{ ' abstract ' :   ' Big   data   is   now   rapidly   expanding   into   various   domains   such   as   banking ,   insurance   and   e - commerce .   Data   analysis   and   related   studies   have   attracted   more   attentions .   In   health   insurance ,   abuse   of   diagnosis   is   one   of   the   key   fraud   problems ,   which   damages   the   interests   of   insured   people .   To   address   this   issue ,   numbers   of   studies   have   focused   on   this   topic .   This   paper   develops   a   healthcare   fraud   detection   approach   based   on   the   trustworthiness   of   doctors   to   distinguish   fraud   cases   from   normal   records .   Compared   to   conventional   methods ,   our   approach   can   detect   healthcare   fraud   in   a   good   accuracy   by   only   little   feature   information   from   healthcare   data   without   the   violation   of   privacy .   This   approach   combines   a   weighted   HITS   algorithm   with   a   frequent   pattern   mining   algorithm   to   calculate   a   rational   treatment   model   of   a   certain   disease .   In   addition ,   this   paper   also   introduces   the   copy   precision   behavior   in   the   treatment   sequences   of   patients ,   which   is   a   critical   metric   to   learn   the   trustworthiness   of   doctors .   The   numerical   validation   with   a   healthcare   dataset   demonstrates   that   healthcare   fraud   by   misdiagnosis   in   healthcare   treatments   can   be   successfully   detected   by   employing   the   developed   fraud   detection   approach . ' ,   ' title ' :   ' Healthcare   Fraud   Detection   Based   on   Trustworthiness   of   Doctors ' } 
{ ' abstract ' :   ' In   this   paper   we   study   data   collection   in   an   energy   renewable   sensor   network   for   scenarios   such   as   traffic   monitoring   on   busy   highways ,   where   sensors   are   deployed   along   a   predefined   path   ( the   highway )   and   a   mobile   sink   travels   along   the   path   to   collect   data   from   one - hop   sensors   periodically .   As   sensors   are   powered   by   renewable   energy   sources ,   time - varying   characteristics   of   ambient   energy   sources   poses   great   challenges   in   the   design   of   efficient   routing   protocols   for   data   collection   in   such   networks .   In   this   paper   we   first   formulate   a   novel   data   collection   maximization   problem   by   adopting   multi - rate   data   transmissions   and   performing   transmission   time   slot   scheduling ,   and   show   that   the   problem   is   NP - hard .   We   then   devise   an   offline   algorithm   with   a   provable   approximation   ratio   for   the   problem   by   exploiting   the   combinatorial   property   of   the   problem ,   assuming   that   the   harvested   energy   at   each   node   is   given   and   link   communications   in   the   network   are   reliable .   We   also   extend   the   proposed   algorithm   by   minor   modifications   to   a   general   case   of   the   problem   where   the   harvested   energy   at   each   sensor   is   not   known   in   advance   and   link   communications   are   not   reliable .   We   thirdly   develop   a   fast ,   scalable   online   distributed   algorithm   for   the   problem   in   realistic   sensor   networks   in   which   neither   the   global   knowledge   of   the   network   topology   nor   sensor   profiles   such   as   sensor   locations   and   their   harvested   energy   profiles   is   given .   Furthermore ,   we   also   consider   a   special   case   of   the   problem   where   each   node   has   only   a   fixed   transmission   power ,   for   which   we   propose   an   exact   solution   to   the   problem .   We   finally   conduct   extensive   experiments   by   simulations   to   evaluate   the   performance   of   the   proposed   algorithms .   Experimental   results   demonstrate   that   the   proposed   algorithms   are   efficient   and   the   solutions   obtained   are   fractional   of   the   optimum . ' ,   ' title ' :   ' Data   Collection   Maximization   in   Renewable   Sensor   Networks   via   Time - Slot   Scheduling ' } 
{ ' abstract ' :   ' An   increasing   number   of   businesses   are   migrating   their   IT   operations   to   the   cloud .   Likewise   there   is   an   increased   emphasis   on   data   analytics   based   on   multiple   datasets   and   sources   to   derive   information   not   derivable   when   a   dataset   is   mined   in   isolation .   While   ensuring   security   of   data   and   computation   outsourced   to   a   third   party   cloud   service   provider   is   in   itself   challenging ,   supporting   mash - ups   and   analytics   of   data   from   different   parties   hosted   across   different   services   is   even   more   so .   In   this   paper   we   propose   a   cloud - based   service   allowing   multiple   parties   to   perform   secure   multi - party   secure   sum   computation   using   their   clouds   as   delegates .   Our   scheme   provides   data   privacy   both   from   the   delegates   as   well   as   from   the   other   data   owners   under   a   lazy - and - curious   adversary   ( semi - honest )   model .   We   then   describe   how   such   a   secure   sum   primitive   may   be   used   in   various   collaborative ,   cloud - based   distributed   data   mining   tasks   ( classification ,   association   rule   mining   and   clustering ) .   We   implement   a   prototype   and   benchmark   the   service ,   both   as   a   stand - alone   secure   sum   service ,   and   as   a   building   block   for   more   complex   analytics .   The   results   suggest   reasonable   overhead   and   demonstrate   the   practicality   of   carrying   out   privacy   preserved   distributed   analytics   despite   migrating   ( encrypted )   data   to   pos -   sibly   different   and   untrusted   ( semi - honest )   cloud   services . ' ,   ' title ' :   ' Delegated   Secure   Sum   Service   for   Distributed   Data   Mining   in   Multi - Cloud   Settings ' } 
{ ' abstract ' :   ' This   paper   fundamentally   investigates   the   performance   of   evolutionary   multiobjective   optimization   ( EMO )   algorithms   for   computationally   hard   0 - 1   combinatorial   optimization ,   where   a   strict   theoretical   analysis   is   generally   out   of   reach   due   to   the   high   complexity   of   the   underlying   problem .   Based   on   the   examination   of   problem   features   from   a   multiobjective   perspective ,   we   improve   the   understanding   of   the   efficiency   of   a   simple   dominance - based   EMO   algorithm   with   unbounded   archive   for   multiobjective   NK - landscapes   with   correlated   objective   values .   More   particularly ,   we   adopt   a   statistical   approach ,   based   on   simple   and   multiple   linear   regression   analysis ,   to   enquire   the   expected   running   time   of   global   SEMO   with   restart   for   identifying   a   ( 1 + e ) - approximation   of   the   Pareto   set   for   small - size   enumerable   instances .   Our   analysis   provides   further   insights   on   the   EMO   search   behavior   and   on   the   most   important   features   that   characterize   the   difficulty   of   an   instance   for   this   class   of   problems   and   algorithms . ' ,   ' title ' :   ' A   feature - based   performance   analysis   in   evolutionary   multiobjective   optimization ' } 
{ ' abstract ' :   ' Functional   biological   sequences ,   which   typically   come   in   families ,   have   retained   some   level   of   similarity   and   function   during   evolution .   Finding   consensus   regions ,   alignment   of   sequences ,   and   identifying   the   relationship   between   a   sequence   and   a   family   allow   inferences   about   the   function   of   the   sequences .   Profile   hidden   Markov   models   ( HMMs )   are   generally   used   to   identify   those   relationships .   A   profile   HMM   can   be   trained   on   unaligned   members   of   the   family   using   conventional   algorithms   such   as   Baum - Welch ,   Viterbi ,   and   their   modifications .   The   overall   quality   of   the   alignment   depends   on   the   quality   of   the   trained   model .   Unfortunately ,   the   conventional   training   algorithms   converge   to   suboptimal   models   most   of   the   time .   This   work   proposes   a   training   algorithm   that   early   identifies   many   imperfect   models .   The   method   is   based   on   the   Simulated   Annealing   approach   widely   used   in   discrete   optimization   problems .   The   training   algorithm   is   implemented   as   a   component   in   HMMER .   The   performance   of   the   algorithm   is   discussed   on   protein   sequence   data . ' ,   ' title ' :   ' Simulated   annealing   algorithm   with   biased   neighborhood   distribution   for   training   profile   models ' } 
{ ' abstract ' :   ' The   Canny   algorithm   is   a   well   known   edge   detector   that   is   widely   used   in   the   previous   processing   stages   in   several   algorithms   related   to   computer   vision .   An   alternative ,   the   LIP - Canny   algorithm ,   is   based   on   a   robust   mathematical   model   closer   to   the   human   vision   system ,   obtaining   better   results   in   terms   of   edge   detection .   In   this   work   we   describe   LIP - Canny   algorithm   under   the   perspective   from   its   parallelization   and   optimization   by   using   the   NVIDIA   CUDA   framework .   Furthermore ,   we   present   comparative   results   between   an   implementation   of   this   algorithm   using   NVIDIA   CUDA   and   the   analogue   using   a   C / C++   approach . ' ,   ' title ' :   ' Parallelizing   and   optimizing   LIP - canny   using   NVIDIA   CUDA ' } 
{ ' abstract ' :   ' This   paper   presents   an   efficient   Bayesian   blind   multiuser   receiver   for   long   code   multipath   CDMA   systems .   The   proposed   receiver   employs   the   adaptive   sampling   method   for   the   Bayesian   inference   procedure   to   estimate   the   data   symbols   and   multipath   parameters .   Compared   to   the   other   reported   Bayesian   Monte   Carlo   receivers   for   long   code   multipath   CDMA   systems ,   the   proposed   one   achieves   a   faster   convergence   and   a   lower   computational   complexity   to   attain   comparable   performance .   Simulation   results   are   presented   to   demonstrate   the   effectiveness   of   the   proposed   Bayesian   blind   multiuser   receiver . ' ,   ' title ' :   ' Blind   Multiuser   Detection   for   Long   Code   Multipath   DS - CDMA   Systems   with   Bayesian   MC   Techniques ' } 
{ ' abstract ' :   ' Spreadsheets   are   by   far   the   most   prominent   example   of   end - user   programs   of   ample   size   and   substantial   structural   complexity .   In   addition ,   spreadsheets   are   usually   not   tested   very   rigorously   and   thus   comprise   faults .   Locating   faults   is   a   hard   task   due   to   the   size   and   the   structure ,   which   is   usually   not   directly   visible   to   the   user ,   i . e . ,   the   functions   are   hidden   behind   the   cells   and   only   the   computed   values   are   presented .   Hence ,   there   is   a   strong   need   for   debugging   support .   In   this   paper ,   we   adapt   three   program - debugging   approaches   that   have   been   designed   for   more   traditional   procedural   or   object - oriented   programming   languages .   These   techniques   are   Spectrum - based   Fault   Localization ,   Spectrum - Enhanced   Dynamic   Slicing ,   and   Constraint - based   Debugging .   Beside   the   theoretical   foundations ,   we   present   a   more   sophisticated   empirical   evaluation   including   a   comparison   of   these   approaches .   The   empirical   evaluation   shows   that   Sfl   ( Spectrum - based   Fault   Localization )   and   Sendys   ( Spectrum   ENhanced   Dynamic   Slicing )   are   the   most   promising   techniques . ' ,   ' title ' :   ' On   the   empirical   evaluation   of   fault   localization   techniques   for   spreadsheets ' } 
{ ' abstract ' :   ' This   work   provides   elements   to   highlight   the   reliability   challenges   related   to   the   technology   scaling   and   the   BTI   variability .   Through   main   milestones   including   device   reliability   scaling   model   ( for   both   mean   and   spread ) ,   a   discussion   on   the   physical   origin   of   BTI   variability   and   a   digital   IP   failure   rate   analytical   model ,   the   evolution   of   digital   IP   failure   rates   along   the   ITRS   scaling   roadmap   is   assessed .   and   an   analysis   of   the   ITRS   roadmap   on   digital   IP   failure   rates .   This   study   offers   new   perspectives   towards   product   hardening   and   qualification   with   respect   to   both   fresh   and   BTI - related   local   variability ,   especially   in   context   where   Adaptive   Voltage   Scaling   ( AVS )   is   used   to   compensate   for   process   centerings . ' ,   ' title ' :   ' From   BTI   variability   to   product   failure   rate :   A   technology   scaling   perspective ' } 
{ ' abstract ' :   ' In   this   paper   we   discuss   the   problem   of   calculating   the   reachable   states   of   a   dynamical   system   defined   by   ordinary   differential   equations   or   inclusions .   We   present   a   prototype   system   for   approximating   this   set   and   demonstrate   some   experimental   results . ' ,   ' title ' :   ' Reachability   Analysis   via   Face   Lifting ' } 
{ ' abstract ' :   ' By   introducing   the   new   concepts   of   fuzzy     β   - covering   and   fuzzy     β   - neighborhood ,   we   define   two   new   types   of   fuzzy   covering   rough   set   models   which   can   be   regarded   as   bridges   linking   covering   rough   set   theory   and   fuzzy   rough   set   theory .   We   show   the   properties   of   the   two   models ,   and   reveal   the   relationships   between   the   two   models   and   some   others .   Moreover ,   we   present   the   matrix   representations   of   the   newly   defined   lower   and   upper   approximation   operators   so   that   the   calculation   of   lower   and   upper   approximations   of   subsets   can   be   converted   into   operations   on   matrices .   Finally ,   we   generalize   the   models   and   their   matrix   representations   to     L   - fuzzy   covering   rough   sets   which   are   defined   over   fuzzy   lattices . ' ,   ' title ' :   ' Two   fuzzy   covering   rough   set   models   and   their   generalizations   over   fuzzy   lattices ' } 
{ ' abstract ' :   ' Mobile   applications   are   becoming   complex   software   systems   that   must   be   developed   quickly   and   evolve   regularly   to   fit   new   user   requirements   and   execution   contexts .   However ,   addressing   these   constraints   may   result   in   poor   design   choices ,   known   as   antipatterns ,   which   may   degrade   software   quality   and   performance .   Thus ,   the   automatic   detection   of   antipatterns   is   an   important   activity   that   eases   the   future   maintenance   and   evolution   tasks .   Moreover ,   it   helps   developers   to   refactor   their   applications   and   thus ,   to   improve   their   quality .   While   antipatterns   are   well - known   in   object - oriented   applications ,   their   study   in   mobile   applications   is   still   in   their   infancy .   In   this   paper ,   we   presents   a   tooled   approach ,   called   P   aprika   ,   to   analyze   Android   applications   and   to   detect   object - oriented   and   Android - specific   antipatterns   from   binaries   of   applications . ' ,   ' title ' :   ' An   approach   to   detect   Android   antipatterns ' } 
{ ' abstract ' :   ' In   this   paper   we   present   a   new   method   for   object   categorization .   Firstly   an   image   representation   is   obtained   by   the   proposed   hierarchical   learning   method   consisting   of   alternating   between   local   coding   and   maximum   pooling   operations ,   where   the   local   coding   operation   induces   discrimination   while   the   image   descriptor   and   maximum   pooling   operation   induces   invariance   in   hierarchical   architecture .   Then   the   obtained   effective   image   representation   is   passed   to   a   linear   classifier   which   is   suitable   for   large   databases   for   object   categorization .   We   have   demonstrated   that   the   proposed   method   is   robust   to   image   variations   and   has   low   sample   complexity . ' ,   ' title ' :   ' Object   categorization   based   on   hierarchical   learning ' } 
{ ' abstract ' :   ' We   have   previously   proposed   a   howling   canceller   which   cancels   howling   by   using   a   cascade   notch   filter   designed   from   a   distance   between   a   loudspeaker   and   a   microphone .   This   method   utilizes   a   pilot   signal   to   estimate   the   distance .   In   this   paper ,   we   introduce   two   methods   into   the   distance - based   howling   canceller   to   improve   speech   quality .   The   first   one   is   an   adaptive   cascade   notch   filter   which   adaptively   adjusts   the   nulls   to   eliminate   howling   and   to   keep   speech   components .   The   second   one   is   a   silent   pilot   signal   whose   frequencies   exist   in   the   ultrasonic   band ,   and   it   is   inaudible   while   on   transmission .   We   implement   the   proposed   howling   canceller   on   a   DSP   to   evaluate   its   capability .   The   experimental   results   show   that   the   proposed   howling   canceller   improves   speech   quality   in   comparison   to   the   conventional   one . ' ,   ' title ' :   ' A   High   Speech   Quality   Distance - Based   Howling   Canceller   with   Adaptive   Cascade   Notch   Filter   and   Silent   Pilot   Signal ' } 
{ ' abstract ' :   ' Purpose   –   This   paper   aims   to   look   at   how   varying   terminology   is   used   on   school   library   web   sites   and   how   that   compares   to   student   preferences . Design / methodology / approach   –   Provides   research   conduced   by   surveying   practicing   school   librarians   and   k ‐ 12   students . Findings   –   Terminology   varies   greatly   on   school   library   web   sites .   Further ,   students   prefer   common   language   use . Practical   implications   –   Practicing   librarians   may   consider   revising   their   web   sites   in   order   to   make   them   more   accessible   for   their   students . Originality / value   –   This   paper   provides   original   research   into   school   library   web   sites ,   an   area   that   is   lacking . ' ,   ' title ' :   ' School   library   web   site   terminology ' } 
{ ' abstract ' :   ' Recently ,   numerous   multireceiver   identity - based   encryption   or   identity - based   broadcast   encryption   schemes   have   been   introduced   with   bilinear   pairing   and   probabilistic   map - to - point   MTP   function .   As   the   bilinear   pairing   and   MTP   functions   are   expensive   operations ,   any   cryptographic   schemes   based   on   these   operations   experience   high   computational   burden .   The   certificateless   public   key   cryptography   sidesteps   the   private   key   escrow   problem   occurring   in   identity - based   cryptosystem   and   certificate   management   troubles   of   certificate   authority - based   public   key   cryptography   CA - PKC .   We   observed   that   certificateless   multireceiver   encryption   CL - MRE   scheme   without   pairing   and   MTP   hash   function   has   not   yet   been   considered   in   the   literature .   In   this   paper ,   we   proposed   a   bilinear   pairing   and   MTP   hash - function - free   CL - MRE   scheme   with   chosen   ciphertext   attack   resilience .   The   detailed   analyses   provide   evidence   that   our   scheme   achieves   forward   secrecy ,   backward   secrecy ,   and   low   computation   costs   than   others .   The   scheme   also   provides   confidentiality   of   the   message   and   receiver   anonymity   in   the   random   oracle   model   with   the   hardness   of   computational   Diffie - Hellman   problem .   Copyright   ©   2014   John   Wiley   &   Sons ,   Ltd . ' ,   ' title ' :   ' Anonymous   and   provably   secure   certificateless   multireceiver   encryption   without   bilinear   pairing ' } 
{ ' abstract ' :   ' We   study   the   problem   of   approximating   one - dimensional   nonintegrable   codistributions   by   integrable   ones   and   apply   the   resulting   approximations   to   approximate   feedback   linearization   of   single - input   systems .   The   approach   derived   in   this   paper   allows   a   linearizable   nonlinear   system   to   be   found   that   is   close   to   the   given   system   in   a   least - squares   ( L2 )   sense .   A   linearly   controllable   single - input   affine   nonlinear   system   is   feedback   linearizable   if   and   only   if   its   characteristic   distribution   is   involutive   ( hence   integrable )   or ,   equivalently ,   any   characteristic   one - form   ( a   one - form   that   annihilates   the   characteristic   distribution )   is   integrable .   We   study   the   problem   of   finding   ( least - squares   approximate )   integrating   factors   that   make   a   fixed   characteristic   one - form   close   to   being   exact   in   anL2   sense .   A   given   one - form   can   be   decomposed   into   exact   and   inexact   parts   using   the   Hodge   decomposition .   We   derive   an   upper   bound   on   the   size   of   the   inexact   part   of   a   scaled   characteristic   one - form   and   show   that   a   least - squares   integrating   factor   provides   the   minimum   value   for   this   upper   bound .   We   also   consider   higher - order   approximate   integrating   factors   that   scale   a   nonintegrable   one - form   in   a   way   that   the   scaled   form   is   closer   to   being   integrable   inL2   together   with   some   derivatives   and   derive   similar   bounds   for   the   inexact   part .   This   allows   a   linearizable   nonlinear   system   that   is   close   to   the   given   system   in   a   least - squares   ( L2 )   sense   together   with   some   derivatives   to   be   found .   The   Sobolev   embedding   techniques   allow   us   to   obtain   an   upper   bound   on   the   uniform   ( L ∞ )   distance   between   the   nonlinear   system   and   its   linearizable   approximation . ' ,   ' title ' :   ' Least - squares   integration   of   one - dimensional   codistributions   with   application   to   approximate   feedback   linearization ' } 
{ ' abstract ' :   ' Latent   sector   errors   in   disk   drives   affect   only   a   few   data   sectors .   They   occur   silently   and   are   detected   only   when   the   affected   area   is   accessed   again .   If   a   latent   error   is   detected   while   the   storage   system   is   operating   under   reduced   redundancy ,   i . e . ,   during   a   RAID   rebuild ,   then   data   loss   may   occur .   Various   features   such   as   scrubbing   and   intra - disk   data   redundancy   are   proposed   to   detect   and / or   recover   from   latent   errors   and   avoid   data   loss .   While   such   features   enhance   data   availability   in   the   storage   system ,   their   execution   may   cause   performance   degradation .   In   this   paper ,   we   evaluate   the   effectiveness   of   scrubbing   and   intra - disk   data   redundancy   in   improving   data   availability   while   the   overall   goal   is   to   maintain   user   performance   within   predefined   bounds .   We   show   that   by   treating   them   as   low   priority   background   activities   and   scheduling   them   efficiently   during   idle   times ,   these   features   remain   performance - wise   transparent   to   the   storage   system   user   while   still   improving   data   reliability .   Detailed   trace - driven   simulations   show   that   the   mean   time   to   data   loss   ( MTTDL )   improves   by   up   to   5   orders   of   magnitude   if   these   features   are   implemented   independently .   By   scheduling   concurrently   both   scrubbing   and   intra - disk   parity   updates   during   idle   times   in   disk   drives ,   MTTDL   improves   by   as   much   as   8   orders   of   magnitude . ' ,   ' title ' :   ' Enhancing   data   availability   in   disk   drives   through   background   activities ' } 
{ ' abstract ' :   ' Financial   crisis   forecasting   has   been   a   long - standing   challenge   that   often   involves   couplings   between   indicators   of   multiple   markets .   Such   couplings   include   implicit   relations   that   might   not   be   effectively   detected   from   raw   market   observations .   However ,   most   methods   for   crisis   forecasting   rely   directly   on   market   observations   and   might   not   detect   the   hidden   interactions   between   markets .   To   this   end ,   the   authors   explore   coupled   market   state   analysis   ( CMSA ) ,   assuming   that   the   observations   of   markets   are   governed   by   a   collection   of   intra -   and   intercoupled   hidden   market   states .   Accordingly ,   they   built   a   forecaster   based   on   these   coupled   market   states   instead   of   observations . ' ,   ' title ' :   ' Financial   Crisis   Forecasting   via   Coupled   Market   State   Analysis ' } 
{ ' abstract ' :   ' In   this   paper ,   an   “ intelligent ”   isolated   intersection   control   system   was   developed .   The   developed   “ intelligent ”   system   makes   “ real   time ”   decisions   as   to   whether   to   extend   ( and   how   much )   current   green   time .   The   model   developed   is   based   on   the   combination   of   the   dynamic   programming   and   neural   networks .   Many   tests   show   that   the   outcome   ( the   extension   of   the   green   time )   of   the   proposed   neural   network   is   nearly   equal   to   the   best   solution .   Practically   negligible   CPU   times   were   achieved ,   and   were   thus   absolutely   acceptable   for   the   “ real   time ”   application   of   the   developed   algorithm . ' ,   ' title ' :   ' Dynamic   programming — neural   network   real - time   traffic   adaptive   signal   control   algorithm ' } 
{ ' abstract ' :   ' This   issue   features   expanded   versions   of   articles   selected   from   the   2014   AAAI   Conference   on   Innovative   Applications   of   Artificial   Intelligence   held   in   Quebec   City ,   Canada .   We   present   a   selection   of   four   articles   describing   deployed   applications   plus   two   more   articles   that   discuss   work   on   emerging   applications . ' ,   ' title ' :   ' Introduction   to   the   Special   Issue   on   Innovative   Applications   of   Artificial   Intelligence   2014 ' } 
{ ' abstract ' :   ' Although   frequently   used   in   fractal   compression   quadrant - based   classification   exhibits   a   significant   defect   which   has   not   been   described   in   the   literature .   We   give   an   efficient   solution   to   this   problem   by   controlling   the   class   structure   based   on   an   adaptive   threshold .   This   makes   this   classification   technique   a   very   efficient   and   competitive   one   also   for   block   matching   motion   compensation   algorithms   in   video   coding . ' ,   ' title ' :   ' Resolving   a   defect   in   quadrant - based   classification   for   fast   block - matching ' } 
{ ' abstract ' :   ' Where   there   are   infinitely   many   possible   basic   states   of   the   world ,   a   standard   probability   function   must   assign   zero   probability   to   each   state   –   since   any   finite   probability   would   sum   to   over   one .   This   generates   problems   for   any   decision   theory   that   appeals   to   expected   utility   or   related   notions .   For   it   leads   to   the   view   that   a   situation   in   which   one   wins   a   million   dollars   if   any   of   a   thousand   of   the   equally   probable   states   is   realized   has   an   expected   value   of   zero   ( since   each   such   state   has   probability   zero ) .   But   such   a   situation   dominates   the   situation   in   which   one   wins   nothing   no   matter   what   ( which   also   has   an   expected   value   of   zero ) ,   and   so   surely   is   more   desirable .   I   formulate   and   defend   some   principles   for   evaluating   options   where   standard   probability   functions   cannot   strictly   represent   probability   –   and   in   particular   for   where   there   is   an   infinitely   spread ,   uniform   distribution   of   probability .   The   principles   appeal   to   standard   probability   functions ,   but   overcome   at   least   some   of   their   limitations   in   such   cases . ' ,   ' title ' :   ' Standard   decision   theory   corrected ' } 
{ ' abstract ' :   ' Backed   by   the   European   Commission ,   a   consortium   of   partners   from   European   industry ,   financial   institutions ,   and   academia   has   embarked   on   a   research   project   to   develop   the   fundamentals   of   secure   electronic   commerce .   The   goal   of   the   9 - million   ECU   project ,   SEMPER   ( Secure   Electronic   Marketplace   for   Europe ) ,   is   to   provide   the   first   open   and   comprehensive   solutions   for   secure   commerce   over   the   Internet   and   other   public   information   networks .   We   describe   the   objectives   and   summarise   the   initial   architecture   of   SEMPER .   A   wide   range   of   businesses   are   rapidly   moving   to   explore   the   huge   potential   of   net -   worked   information   systems ,   especially   with   the   Internet - based   WWW   ( World - wide   Web ) .   The   Internet ,   which   already   connects   more   than   3   million   computers   and   a   sub -   stantially   larger   number   of   users ,   is   growing   at   a   breathtaking   pace   with   thousands   of   newcomers   every   day .   Although   the   Internet   has   its   roots   in   academia   and   is   still   domi -   nated   by   free - of - charge   information ,   dramatic   changes   are   expected   in   the   near   future .   For   instance ,   the   WWW   will   be   used   for   a   wide   variety   of   electronic   commerce   such   as   on - line   trade   or   delivery   of   advanced   multimedia   information   services .   The   evolution   of   broadband   networks   and   " information   highways "   will   intensify   this   trend .   The   need   for   secure   transactions   in   this   new   business   environment ,   which   involves   networks   available   to   the   general   public ,   has   triggered   a   number   of   related   efforts .   These   initial   developments   are   based   almost   exclusively   in   the   US   and   most   of   them   are   limited   to   proprietary ,   or   otherwise   closed   solutions ,   involving   only   electronic   payment   issues .   In   contrast ,   SEMPER   is   directed   towards   a   comprehensive   solution   for   secure   electronic   commerce ,   considering   legal ,   commercial ,   social ,   and   technical   requirements   as   well   as   different   options   for   an   electronic   marketplace . ' ,   ' title ' :   ' Development   of   a   Secure   Electronic   Marketplace   for   Europe ' } 
{ ' abstract ' :   ' Through   the   use   of   a   global   geometric   symmetry ,   detection   ellipses   are   proposed   in   this   paper .   Based   on   the   geometric   symmetry ,   the   proposed   method   first   locates   candidates   of   ellipses   centers .   In   the   meantime ,   according   to   these   candidate   centers ,   all   feature   points   in   an   input   image   are   grouped   into   several   subimages .   Then ,   for   each   subimage ,   by   using   geometric   properties   again ,   all   ellipses   are   extracted .   The   method   significantly   reduces   the   time   required   to   evaluate   all   possible   parameters   without   using   edge   direction   information .   Experimental   results   are   given   to   show   the   correctness   and   effectiveness   of   the   proposed   method . ' ,   ' title ' :   ' Detection   ellipses   by   finding   lines   of   symmetry   in   the   images   via   an   hough   transform   applied   to   straight   lines ' } 
{ ' abstract ' :   ' Automatic   crawling   of   Rich   Internet   Applications   ( RIAs )   is   a   challenge   because   client - side   code   modifies   the   client   dynamically ,   fetch -   ing   server - side   data   asynchronously .   Most   existing   solutions   model   RIAs   as   state   machines   with   DOMs   as   states   and   JavaScript   events   execution   as   transitions .   This   approach   fails   when   used   with   " real - life " ,   complex   RIAs ,   because   the   size   of   the   produced   model   is   much   too   large   to   be   practical .   In   this   paper ,   we   propose   a   new   method   to   crawl   AJAX - based   RIAs   in   an   efficient   manner   by   detecting   " components " ,   which   are   areas   of   the   DOM   that   are   independent   from   each   other ,   and   by   crawling   each   component   separately .   This   leads   to   a   dramatic   reduction   of   the   required   state   space   for   the   model ,   without   loss   of   content   coverage .   Our   method   does   not   require   prior   knowledge   of   the   RIA   nor   predefined   definition   of   components .   Instead ,   we   infer   the   components   by   observing   the   be -   havior   of   the   RIA   during   crawling .   Our   experimental   results   show   that   our   method   can   index   quickly   and   completely   industrial   RIAs   that   are   simply   out   of   reach   for   traditional   methods . ' ,   ' title ' :   ' Indexing   Rich   Internet   Applications   Using   Components - Based   Crawling ' } 
{ ' abstract ' :   ' One   important   aspect   of   constructing   an   overlay   network   is   how   to   exploit   network   locality   in   the   underlying   network .   In   this   paper ,   we   propose   a   scalable   protocol   for   constructing   an   overlay   network   that   takes   account   of   locality   of   network   hosts .   The   constructed   overlay   network   can   significantly   decrease   the   communication   cost   between   end - hosts .   Our   simulation   results   show   that   the   average   distance   between   a   pair   of   hosts   in   the   constructed   overlay   network   is   only   about   11%   of   the   one   in   a   traditional ,   randomly   connected   overlay   network .   Furthermore ,   our   proposed   overlay   considered   to   be   more   scalable   than   tree - based   or   mesh - based   overlays . ' ,   ' title ' :   ' Measurement - based   construction   of   locality - aware   overlay   networks ' } 
{ ' abstract ' :   ' This   paper   presents   a   low   cost ,   flexible   and   customizable   delay   measurement   system   developed   to   assess   the   performance   of   the   VTPE - hBEB   protocol .   The   proposed   system   can   be   used   to   evaluate   other   communication   protocols   as   well   as   to   measure   the   delay   between   two   repetitive   events . ' ,   ' title ' :   ' Delay   measurement   system   for   real - time   serial   data   streams ' } 
{ ' abstract ' :   " Service   robots   have   become   increasingly   important   subjects   in   our   lives .   However ,   they   are   still   facing   problems   like   adaptability   to   their   users .   While   major   work   has   focused   on   intelligent   service   robots ,   the   proposed   approaches   were   mostly   user   independent .   Our   work   is   part   of   the   FUI - RoboPopuli   project ,   which   concentrates   on   endowing   entertainment   companion   robots   with   adaptive   and   social   behaviour .   In   particular ,   we   are   interested   in   robots   that   are   able   to   learn   and   plan   so   that   they   adapt   and   personalize   their   behaviour   according   to   their   users .   Markov   Decision   Processes   ( MDPs )   are   largely   used   for   adaptive   robots   applications .   However ,   one   challenging   point   is   reducing   the   sample   complexity   required   to   learn   an   MDP   model ,   including   the   reward   function .   In   this   article ,   we   present   our   contribution   regarding   the   representation   and   the   learning   of   the   reward   function   through   analysing   interaction   traces   ( i . e .   the   interaction   history   between   the   robot   and   their   users ,   including   users '   feedback ) .   Our   approach   permits   to   generalise   the   learned   rewards   so   that   when   new   users   are   introduced ,   the   robot   may   quickly   adapt   using   what   it   learned   from   previous   experiences   with   other   users .   We   propose ,   in   this   article ,   two   algorithms   to   learn   the   reward   function .   The   first   is   direct   and   certain ,   the   robot   applies   with   a   user   what   it   learned   during   interaction   with   same   kind   of   users   ( i . e .   users   with   similar   profiles ) .   The   second   algorithm   generalises   what   it   learns   to   be   applied   to   all   kinds   of   users .   Through   simulation ,   we   show   that   the   generalised   algorithm   converges   to   an   optimal   reward   function   with   less   than   half   the   samples   needed   by   the   direct   algorithm . " ,   ' title ' :   " Adaptive   and   Personalised   Robots   -   Learning   from   Users '   Feedback " } 
{ ' abstract ' :   " Researches   of   sensor   networks   collecting   patients '   data   with   computerized   triage   tags ,   called   Triage   Network ,   are   attracting   attention .   The   listening   power   used   in   triage   tags   is   the   major   factor   of   lots   of   energy   consumption ,   and   consumption   of   energy   increases   when   sensor   nodes   always   communicate   with   other   nodes   in   active   state .   Hence ,   we   suppose   that   sensor   nodes   are   put   to   sleep   periodically   to   avoid   running   out   of   battery .   However ,   some   nodes   have   mobility   and   nodes   secede   from   the   network   according   to   patients   conditions   in   Triage   Network .   The   paths   are   failed   and   it   is   needed   to   reconstruct   paths   when   these   forwarding   nodes   move   or   secede   from   network .   Therefore ,   data   arrival   ratio   decreases   and   consumption   of   battery   increases   due   to   reconstruction   of   other   paths .   In   this   paper ,   we   propose   a   data   collection   method   using   two   types   of   forwarding   nodes ,   Stable   Nodes   and   Energy   Efficient   Nodes .   This   method   uses   two   types   of   forwarding   nodes   according   to   priority   of   data   and   avoids   loss   of   high   priority   data ,   improves   the   data   arrival   ratio   and   saves   the   energy   consumption .   We   evaluate   the   proposed   method   and   show   its   effectiveness   using   computer   simulations . " ,   ' title ' :   ' Data   collection   method   using   two   types   of   forwarding   nodes   for   energy   saving   in   triage   network ' } 
{ ' abstract ' :   ' This   paper   introduces   Golay - paired   Hadamard   matrices   for   fast   compressed   sensing   of   sparse   signals   in   the   time   or   spectral   domain .   These   sampling   operators   feature   low - memory   requirement ,   hardware - friendly   implementation   and   fast   computation   in   reconstruction .   We   show   that   they   require   a   nearly   optimal   number   of   measurements   for   faithful   reconstruction   of   a   sparse   signal   in   the   time   or   frequency   domain .   Simulation   results   demonstrate   that   the   proposed   sensing   matrices   offer   a   reconstruction   performance   similar   to   that   of   fully   random   matrices . ' ,   ' title ' :   ' Golay   meets   Hadamard :   Golay - paired   Hadamard   matrices   for   fast   compressed   sensing ' } 
{ ' abstract ' :   ' In   this   technical   note ,   the   problem   of   finite - time   output   regulation   control   for   a   class   of   disturbed   system   under   mismatching   condition   is   investigated   via   a   composite   control   design   manner .   The   composite   controller   is   developed   by   using   a   finite   time   control   technique   and   a   finite   time   disturbance   observer   ( FTDO ) .   A   key   idea   is   to   design   virtual   control   laws   based   on   estimation   values   of   the   disturbances   and   the   ith   ( 1 ≤ i ≤ n - 1   where   n   is   the   order   of   the   system )   order   derivative   of   disturbances .   Finite   time   stability   analysis   for   the   augmented   system   is   presented   by   means   of   Lyapunov   stability   theorems ,   which   shows   that   the   system   output   is   regulated   to   zero   in   finite   time   even   in   the   presence   of   mismatched   disturbances .   A   motion   control   application   demonstrates   the   effectiveness   and   attractive   properties   of   the   proposed   method . ' ,   ' title ' :   ' Continuous   Finite - Time   Output   Regulation   for   Disturbed   Systems   Under   Mismatching   Condition ' } 
{ ' abstract ' :   ' In   this   paper   we   propose   an   approach   for   enhanced   data   protection   in   the   cloud ,   based   upon   accountability   governance .   Specifically ,   the   relationships   between   accountability ,   risk   and   trust   are   analyzed   in   order   to   suggest   characteristics   and   means   to   address   data   governance   issues   involved   when   organizations   or   individuals   adopt   cloud   computing .   This   analysis   takes   into   account   insights   from   a   variety   of   stakeholders   within   cloud   ecosystems   obtained   by   running   an   elicitation   workshop . ' ,   ' title ' :   ' Accountability ,   Risk ,   and   Trust   in   Cloud   Services :   Towards   an   Accountability - Based   Approach   to   Risk   and   Trust   Governance ' } 
{ ' abstract ' :   ' Xue   et   al .   recently   proposed   an   innovative   mutual   authentication   and   key   agreement   scheme   for   wireless   sensor   networks   based   on   temporal   credential   using   smart   cards .   However ,   in   this   paper   we   demonstrate   that   their   scheme   is   vulnerable   to   password   guessing   attacks ,   node   capture   attacks   and   denial - of - service   attacks .   Furthermore   we   show   that   their   scheme   has   some   inconsistencies   which   make   it   less   secure   and   more   computationally   costly   than   originally   presented . ' ,   ' title ' :   ' Notes   on   A   Temporal - Credential - Based   Mutual   Authentication   and   Key   Agreement   Scheme   for   Wireless   Sensor   Networks ' } 
{ ' abstract ' :   ' Persistent   Scatterer   Interferometry   ( PSI )   has   been   widely   used   for   landslide   studies   in   recent   years .   This   paper   investigated   the   spatial   patterns   of   PSI   point   targets   and   landslide   occurrences   in   the   Arno   River   basin   in   Central   Italy .   The   main   purpose   is   to   analyze   whether   spatial   patterns   of   Persistent   Scatterers   ( PS )   can   be   recognized   as   indicators   of   landslide   occurrences   throughout   the   whole   basin .   The   bivariate   K - function   was   employed   to   assess   spatial   relationships   between   PS   and   landslides .   The   PSI   point   targets   were   acquired   from   almost   4   years   ( from   March   2003   to   January   2007 )   of   RADARSAT - 1   images .   The   landslide   inventory   was   collected   from   15   years   ( from     1992 – 2007 )   of   surveying   and   mapping   data ,   mainly   including   remote   sensing   data ,   topographic   maps   and   field   investigations .   The   proposed   approach   is   able   to   assess   spatial   patterns   between   a   variety   of   PS   and   landslides ,   in   particular ,   to   understand   if   PSI   point   targets   are   spatially   clustered   ( spatial   attraction )   or   randomly   distributed   ( spatial   independency )   on   various   types   of   landslides   across   the   basin .   Additionally ,   the   degree   and   scale   distances   of   PS   clustering   on   a   variety   of   landslides   can   be   characterized .   The   results   rejected   the   null   hypothesis   that   PSI   point   targets   appear   to   cluster   similarly   on   four   types   of   landslides   ( slides ,   flows ,   falls   and   creeps )   in   the   Arno   River   basin .   Significant   influence   of   PS   velocities   and   acquisition   orbits   can   be   noticed   on   detecting   landslides   with   different   states   of   activities .   Despite   that   the   assessment   may   be   influenced   by   the   quality   of   landslide   inventory   and   Synthetic   Aperture   Radar   ( SAR )   images ,   the   proposed   approach   is   expected   to   provide   guidelines   for   studies   trying   to   detect   and   investigate   landslide   occurrences   at   a   regional   scale   through   spatial   statistical   analysis   of   PS ,   for   which   an   advanced   understanding   of   the   impact   of   scale   distances   on   landslide   clustering   is   fundamentally   needed . ' ,   ' title ' :   ' Investigating   Spatial   Patterns   of   Persistent   Scatterer   Interferometry   Point   Targets   and   Landslide   Occurrences   in   the   Arno   River   Basin ' } 
{ ' abstract ' :   ' This   article   describes   a   middleware   used   in   display   cluster   of   real   time   visual   simulation   system .   This   middleware   which   based   on   TCP / IP   protocol   provides   the   communication   infrastructure   for   visual   simulation   system .   It   provides   unified   process   logic   and   interfaces   for   various   status   and   frame   data   and   the   packing / unpacking   functions   of   simulation   data   without   concerning   the   details   of   the   data .   We   found   two   classes   of   display   synchronization   problems   and   provided   the   resolution   of   them .   The   middleware   provides   a   group   of   APIs   which   hide   the   details   of   data   packing / unpacking ,   processing   and   transmission   and   meets   the   requirement   of   flexibility ,   efficiency   and   extensibility .   This   middleware   has   been   successfully   implemented   to   the   display   cluster   of   several   tower   simulation   system . ' ,   ' title ' :   ' The   Research   of   High   Level   Data   Communication   Middleware   of   Display   Cluster   Used   in   Real   Time   Simulation   Environment ' } 
{ ' abstract ' :   ' The   scattering   parameters   are   fundamental   in   the   characterization   of   electrical   devices   at   high   frequencies .   They   are   particularly   useful   for   analyzing   multiport   high - frequency   and   microwave   networks .   However ,   they   are   not   adequately   presented   in   most ,   if   not   all ,   microwave   engineering   books .   This   paper   identifies   two   common   deficiencies   in   the   way   scattering   parameters   are   being   presented   in   these   books .   It   provides   additional   information   that   should   supplement   those   books   or   book   chapters   on   scattering   parameters . ' ,   ' title ' :   ' Deficiencies   in   the   way   scattering   parameters   are   taught ' } 
{ ' abstract ' :   ' We   study   the   reliability   maximization   problem   in   WDM   networks   with   random   link   failures .   Reliability   in   these   networks   is   defined   as   the   probability   that   the   logical   network   is   connected ,   and   it   is   determined   by   the   underlying   lightpath   routing   and   the   link   failure   probability .   We   show   that   in   general   the   optimal   lightpath   routing   depends   on   the   link   failure   probability ,   and   characterize   the   properties   of   lightpath   routings   that   maximize   the   reliability   in   different   failure   probability   regimes .   In   particular ,   we   show   that   in   the   low   failure   probability   regime ,   maximizing   the   ` ` cross - layer "   min   cut   of   the   ( layered )   network   maximizes   reliability ,   whereas   in   the   high   failure   probability   regime ,   minimizing   the   spanning   tree   of   the   network   maximizes   reliability .   Motivated   by   these   results ,   we   develop   lightpath   routing   algorithms   for   reliability   maximization . ' ,   ' title ' :   ' Maximizing   Reliability   in   WDM   Networks   through   Lightpath   Routing ' } 
{ ' abstract ' :   ' The   slope   of   the   active   distances   is   an   important   parameter   when   investigating   the   error - correcting   capability   of   convolutional   codes   and   the   distance   behavior   of   concatenated   convolutional   codes .   The   slope   of   the   active   distances   is   equal   to   the   minimum   average   weight   cycle   in   the   state - transition   diagram   of   the   encoder .   A   general   upper   bound   on   the   slope   depending   on   the   free   distance   of   the   convolutional   code   and   new   upper   bounds   on   the   slope   of   special   classes   of   binary   convolutional   codes   are   derived .   Moreover ,   a   search   technique ,   resulting   in   new   tables   of   rate   R = 1 / 2   and   rate   R = 1 / 3   convolutional   encoders   with   high   memories   and   large   active   distance - slopes   is   presented .   Furthermore ,   we   show   that   convolutional   codes   with   large   slopes   can   be   used   to   obtain   new   tailbiting   block   codes   with   large   minimum   distances .   Tables   of   rate   R = 1 / 2   and   rate   R = 1 / 3   tailbiting   codes   with   larger   minimum   distances   than   the   best   previously   known   quasi - cyclic   codes   are   given .   Two   new   tailbiting   codes   also   have   larger   minimum   distances   than   the   best   previously   known   binary   linear   block   codes   with   same   size   and   length .   One   of   them   is   also   superior   in   terms   of   minimum   distance   to   any   previously   known   binary   nonlinear   block   code   with   the   same   set   of   parameters . ' ,   ' title ' :   ' Tailbiting   codes   obtained   via   convolutional   codes   with   large   active   distance - slopes ' } 
{ ' abstract ' :   ' MIMO   wireless   technology   is   required   to   increase   the   data   rates   for   a   broad   range   of   applications ,   including   low   cost   mobile   devices .   In   this   paper   we   present   a   very   low   area   reconfigurable   MIMO   detector   which   achieves   a   high   throughput   of   103Mbps   and   uses   27   Kilo   Gates   when   implemented   in   a   commercial   180nm   CMOS   process .   The   low   area   is   achieved   by   the   proposed   in - place   architecture .   This   architecture   implements   the   K - best   algorithm   and   reduces   area   4 - fold   compared   to   the   widely   used   multi - stage   architecture ,   while   provides   reconfigurability   in   terms   of   antenna   configuration   during   real - time   operation . ' ,   ' title ' :   ' A   low - area   flexible   MIMO   detector   for   WiFi / WiMAX   standards ' } 
{ ' abstract ' :   ' Because   human   cognition   is   creative   and   socially   situated ,   knowledge   accumulates ,   diffuses ,   and   gets   applied   in   new   contexts ,   generating   cultural   analogs   of   phenomena   observed   in   population   genetics   such   as   adaptation   and   drift .   It   is   therefore   commonly   thought   that   elements   of   culture   evolve   through   natural   selection .   However ,   natural   selection   was   proposed   to   explain   how   change   accumulates   despite   lack   of   inheritance   of   acquired   traits ,   as   occurs   with   template - mediated   replication .   It   cannot   accommodate   a   process   with   significant   retention   of   acquired   or   horizontally   ( e . g .   socially )   transmitted   traits .   Moreover ,   elements   of   culture   cannot   be   treated   as   discrete   lineages   because   they   constantly   interact   and   influence   one   another .   It   is   proposed   that   what   evolves   through   culture   is   the   mind ;   ideas   and   artifacts   are   merely   reflections   of   its   current   evolved   state .   Interacting   minds   transform   ( in   part )   through   a   non - Darwinian   autopoietic   process   similar   to   that   by   which   early   life   evolved ,   involving   not   survival   of   the   fittest   but   actualization   of   their   potential . ' ,   ' title ' :   ' The   cultural   evolution   of   socially   situated   cognition ' } 
{ ' abstract ' :   ' Event   Extraction   is   a   complex   and   interesting   topic   in   Information   Extraction   that   includes   event   extraction   methods   from   free   text   or   web   data .   The   result   of   event   extraction   systems   can   be   used   in   several   fields   such   as   risk   analysis   systems ,   online   monitoring   systems   or   decide   support   tools .   In   this   paper ,   we   introduce   a   method   that   combines   lexico   - -   semantic   and   machine   learning   to   extract   event   from   Vietnamese   news .   Furthermore ,   we   concentrate   to   describe   event   online   monitoring   system   named   VnLoc   based   on   the   method   that   was   proposed   above   to   extract   event   in   Vietnamese   language .   Besides ,   in   experiment   phase ,   we   have   evaluated   this   method   based   on   precision ,   recall   and   F1   measure .   At   this   time   of   experiment ,   we   on   investigated   on   three   types   of   event :   FIRE ,   CRIME   and   TRANSPORT   ACCIDENT . ' ,   ' title ' :   ' VnLoc :   A   Real   - -   Time   News   Event   Extraction   Framework   for   Vietnamese ' } 
{ ' abstract ' :   ' Reliability   analysis   using   error   probabilities   for   combinational   logic   circuits   has   been   investigated   widely   in   the   literature .   Reliability   analysis   for   sequential   logic   circuits   using   these   methods   would   be   inaccurate   because   of   existence   of   loops   in   their   architecture .   In   this   paper   a   new   method   based   on   conversion   of   sequential   circuit   to   combinational   one   and   applying   an   iterative   reliability   analysis   is   developed .   A   Monte   Carlo   method - based   reliability   analysis   is   introduced   for   sequential   circuits ,   which   is   used   for   first   method   validation .   Experimental   results   demonstrate   good   accuracy   of   the   method . ' ,   ' title ' :   ' SEQUENTIAL   LOGIC   CIRCUITS   RELIABILITY   ANALYSIS ' } 
{ ' abstract ' :   ' According   to   the   Journey   to   Crime   theory ,   offenders   have   a   directionality   preference ,   in   the   form   of   an   activity   path ,   when   they   are   moving   about   in   their   environment   in   search   for   criminal   activities .   Using   clustering   techniques ,   this   theory   is   tested   using   crime   data   for   the   Province   of   British   Columbia ,   Canada .   The   activities   of   57 , 962   offenders   who   were   either   charged ,   chargeable ,   or   for   whom   charges   were   recommended   were   analyzed   by   mapping   their   offense   locations   with   respect   to   their   home   locations   to   determine   directionality .   Once   directionality   was   established ,   a   unique   clustering   technique ,   based   on   K - Means   clustering   and   modified   for   angles ,   was   applied   to   find   the   number   of   activity   paths   for   each   offender .   Although   the   number   of   activity   paths   varies   from   individual   to   individual ,   the   aggregate   pattern   was   very   consistent   with   theory .   It   was   found   that   people   only   have   a   few   activity   paths ,   even   if   they   are   highly   prolific   offenders . ' ,   ' title ' :   ' How   Many   Ways   Do   Offenders   Travel   - -   Evaluating   the   Activity   Paths   of   Offenders ' } 
{ ' abstract ' :   ' Pulse   Coupled   Neural   Network ( PCNN )   is   widely   used   in   the   field   of   image   processing ,   but   it   is   a   difficult   task   to   define   the   relative   parameters   properly   in   the   research   of   the   applications   of   PCNN .   So   far   the   determination   of   parameters   of   its   model   needs   a   lot   of   experiments .   To   deal   with   the   above   problem ,   a   document   segmentation   based   on   the   improved   PCNN   is   proposed .   It   uses   the   maximum   entropy   function   as   the   fitness   function   of   bacterial   foraging   optimization   algorithm ,   adopts   bacterial   foraging   optimization   algorithm   to   search   the   optimal   parameters ,   and   eliminates   the   trouble   of   manually   set   the   experiment   parameters .   Experimental   results   show   that   the   proposed   algorithm   can   effectively   complete   document   segmentation .   And   result   of   the   segmentation   is   better   than   the   contrast   algorithms .   ©   ( 2014 )   COPYRIGHT   Society   of   Photo - Optical   Instrumentation   Engineers   ( SPIE ) .   Downloading   of   the   abstract   is   permitted   for   personal   use   only . ' ,   ' title ' :   ' PCNN   document   segmentation   method   based   on   bacterial   foraging   optimization   algorithm ' } 
{ ' abstract ' :   ' Undirected   graphical   models   encode   in   a   graph   G   the   dependency   structure   of   a   random   vector   Y .   In   many   applications ,   it   is   of   interest   to   model   Y   given   another   random   vector   X   as   input .   We   refer   to   the   problem   of   estimating   the   graph   G ( x )   of   Y   conditioned   on   X   =   x   as   " graph - valued   regression " .   In   this   paper ,   we   propose   a   semiparametric   method   for   estimating   G ( x )   that   builds   a   tree   on   the   X   space   just   as   in   CART   ( classification   and   regression   trees ) ,   but   at   each   leaf   of   the   tree   estimates   a   graph .   We   call   the   method   " Graph - optimized   CART " ,   or   Go - CART .   We   study   the   theoretical   properties   of   Go - CART   using   dyadic   partitioning   trees ,   establishing   oracle   inequalities   on   risk   minimization   and   tree   partition   consistency .   We   also   demonstrate   the   application   of   Go - CART   to   a   meteorological   dataset ,   showing   how   graph - valued   regression   can   provide   a   useful   tool   for   analyzing   complex   data . ' ,   ' title ' :   ' Graph - Valued   Regression ' } 
{ ' abstract ' :   ' Over   the   last   two   decades ,   doubts   have   been   expressed   about   the   adequacy   of   materialism   as   the   correct   framework   for   explaining   phenomenal   consciousness   ( the   experience   of   saturated   greenness   one   has   when   looking   at   a   lush   lawn ,   for   example ) .   This   paper   reconstructs   a   generic   form   of   the   various   arguments   that   have   been   used   to   defend   the   view   of   the   materialistically   inexplicable   nature   of   consciousness   ( MINC ) .   This   reconstruction   reveals   that   the   arguments   turn   on   an   impoverished   notion   of   explanation .   By   discussing   some   examples   from   the   history   of   science ,   the   paper   shows   that   a   reasonable   notion   of   explanation   has   to   be   wider   than   the   one   utilized   in   the   argument   for   MINC ,   which   opens   the   possibility   for   the   materialistic   explicability   of   consciousness .   The   author   ends   the   paper   by   raising   a   question   about   the   very   intelligibility   of   the   project   of   trying   to   explain   the   so - called   nature   of   consciousness   as   opposed   to   the   regularities   characteristic   of   the   relation   between   states   of   consciousness   and   ... ' ,   ' title ' :   ' On   explaining   phenomenal   consciousness ' } 
{ ' abstract ' :   ' Successful   replication   within   an   infected   host   and   successful   transmission   between   hosts   are   key   to   the   continued   spread   of   most   pathogens .   Competing   selection   pressures   exerted   at   these   different   scales   can   lead   to   evolutionary   trade - offs   between   the   determinants   of   fitness   within   and   between   hosts .   Here ,   we   examine   such   a   trade - off   in   the   context   of   influenza   A   viruses   and   the   differential   pressures   exerted   by   temperature - dependent   virus   persistence .   For   a   panel   of   avian   influenza   A   virus   strains ,   we   find   evidence   for   a   trade - off   between   the   persistence   at   high   versus   low   temperatures .   Combining   a   within - host   model   of   influenza   infection   dynamics   with   a   between - host   transmission   model ,   we   study   how   such   a   trade - off   affects   virus   fitness   on   the   host   population   level .   We   show   that   conclusions   regarding   overall   fitness   are   affected   by   the   type   of   link   assumed   between   the   within -   and   between - host   levels   and   the   main   route   of   transmission   ( direct   or   environmental ) .   The   relative   importance   of   virulence   and   immune   response   mediated   virus   clearance   are   also   found   to   influence   the   fitness   impacts   of   virus   persistence   at   low   versus   high   temperatures .   Based   on   our   results ,   we   predict   that   if   transmission   occurs   mainly   directly   and   scales   linearly   with   virus   load ,   and   virulence   or   immune   responses   are   negligible ,   the   evolutionary   pressure   for   influenza   viruses   to   evolve   toward   good   persistence   at   high   within - host   temperatures   dominates .   For   all   other   scenarios ,   influenza   viruses   with   good   environmental   persistence   at   low   temperatures   seem   to   be   favored . ' ,   ' title ' :   ' A   Multi - scale   Analysis   of   Influenza   A   Virus   Fitness   Trade - offs   due   to   Temperature - dependent   Virus   Persistence ' } 
{ ' abstract ' :   ' Peer - to - Peer   ( P2P )   networks   are   largely   used   for   file - sharing   and   hence   must   provide   efficient   mechanisms   for   searching   the   files   stored   at   various   nodes .   The   existing   structuredP2P   overlays   support   only   ” exact - match ”   look - up   which   is   hardly   sufficient   in   a   file   sharing   network .   This   paper   addresses   the   problem   of   keyword - based   search   in   structured   P2P   networks .   We   propose   a   new   keyword - based   searching   algorithm   which   can   be   implemented   on   top   of   any   structured   P2P   overlay .   We   demonstrate   that   the   proposed   algorithm   achieves   very   good   searching   results   as   it   requires   the   minimum   number   of   messages   to   be   sent   in   order   to   find   all   the   references   to   files   containing   at   least   the   given   set   of   keywords . ' ,   ' title ' :   ' A   Keyword   Search   Algorithm   for   Structured   Peer - to - Peer   Networks ' } 
{ ' abstract ' :   ' In   this   paper ,   we   propose   an   adaptive   power   allocation   method   for   hybrid   relay   systems   that   employ   the   amplify - and - forward   and   decode - and - forward   protocols   simultaneously .   The   total   transmission   power   is   analytically   allocated   to   a   source   and   two   selected   relays   by   the   proposed   power   allocation   criterion   to   maximize   the   overall   received   signal - to - noise   ratio   at   the   destination .   Simulation   results   show   that   the   proposed   scheme   achieves   better   performance   than   that   of   conventional   cooperative   schemes   or   hybrid   systems   with   equal   power   allocation . ' ,   ' title ' :   ' Adaptive   relay   selection   and   power   allocation   for   hybrid   relay   systems ' } 
{ ' abstract ' :   ' The   unitary   rotation   of   square - pixellated   images   is   based   on   the   finite   su ( 2 ) - oscillator   model ,   which   describes   systems   whose   values   for   position ,   momentum   and   energy ,   are   discrete   and   finite .   In   a   two - dimensional   position   space ,   this   allows   the   construction   of   angular   momentum   states ,   orthonormal   and   complete ,   for   which   rotations   are   defined   as   multiplication   by   phases   that   carry   the   rotation   angle .   The   decomposition   of   a   digital   square   images   in   terms   of   these   angular   momentum   states   determines   a   unitary   ( hence   invertible )   rotation   of   the   image ,   whose   kernel   can   be   computed   as   a   four - dimensional   array   of   real   numbers . ' ,   ' title ' :   ' Unitary   rotation   of   square - pixellated   images ' } 
{ ' abstract ' :   ' As   more   mobile   storage   devices   are   used   in   consumer   electronics ,   possibility   of   user   confidential   data   leakage   increases .   To   make   things   worse ,   data   of   deleted   file   in   mobile   storage   such   as   USB   drives   can   be   easily   recovered   and ,   thus ,   can   be   vulnerable   to   data   leakage .   To   prevent   this   type   of   data   leakage ,   efficient   secure   deletion   techniques   are   required   and   we   present   two   secure   deletion   techniques ,   namely   block   cleaning   and   zero   overwriting ,   for   flash   memory   storage .   Also ,   we   propose   cost   and   benefit   models   of   both   techniques .   The   models   imply   an   existence   of   an   efficient   adaptive   hybrid   secure   deletion   scheme   that   applies   one   of   the   techniques   based   on   their   costs   and   benefits   at   given   data   arrangements .   Experimental   results   measured   on   an   embedded   board   show   that   the   adaptive   hybrid   scheme   deletes   data   securely   and   efficiently   for   various   data   patterns   on   flash   memory   storage . ' ,   ' title ' :   ' Models   and   Design   of   an   Adaptive   Hybrid   Scheme   for   Secure   Deletion   of   Data   in   Consumer   Electronics ' } 
{ ' abstract ' :   ' In   heterogeneous   and   dynamic   environments ,   efficient   execution   of   parallel   computations   can   require   mappings   of   tasks   to   processors   whose   performance   is   both   irregular   ( because   of   heterogeneity )   and   time - varying   ( because   of   dynamicity ) .   While   adaptive   domain   decomposition   techniques   have   been   used   to   address   heterogeneous   resource   capabilities ,   temporal   variations   in   those   capabilities   have   seldom   been   considered .   We   propose   a   conservative   scheduling   policy   that   uses   information   about   expected   future   variance   in   resource   capabilities   to   produce   more   efficient   data   mapping   decisions .   We   first   present   techniques ,   based   on   time   series   predictors   that   we   developed   in   previous   work ,   for   predicting   CPU   load   at   some   future   time   point ,   average   CPU   load   for   some   future   time   interval ,   and   variation   of   CPU   load   over   some   future   time   interval .   We   then   present   a   family   of   stochastic   scheduling   algorithms   that   exploit   such   predictions   of   future   availability   and   variability   when   making   data   mapping   decisions .   Finally ,   we   describe   experiments   in   which   we   apply   our   techniques   to   an   astrophysics   application .   The   results   of   these   experiments   demonstrate   that   conservative   scheduling   can   produce   execution   times   that   are   both   significantly   faster   and   less   variable   than   other   techniques . ' ,   ' title ' :   ' Conservative   Scheduling :   Using   Predicted   Variance   to   Improve   Scheduling   Decisions   in   Dynamic   Environments ' } 
{ ' abstract ' :   ' We   consider   a   class   of   restless   multi - armed   bandit   problems   that   arises   in   multi - channel   opportunistic   communications ,   where   channels   are   modeled   as   independent   and   stochastically   identical   Gilbert - Elliot   channels   and   channel   state   observations   are   subject   to   errors .   We   show   that   the   myopic   channel   selection   policy   has   a   semi - universal   structure   that   obviates   the   need   to   know   the   Markovian   transition   probabilities   of   the   channel   states .   Based   on   this   structure ,   we   establish   closed - form   lower   and   upper   bounds   on   the   steady - state   throughput   achieved   by   the   myopic   policy .   Furthermore ,   we   characterize   the   approximation   factor   of   the   myopic   policy   to   bound   its   worst - case   performance   loss   with   respect   to   the   optimal   performance . ' ,   ' title ' :   ' On   the   myopic   policy   for   a   class   of   restless   bandit   problems   with   applications   in   dynamic   multichannel   access ' } 
{ ' abstract ' :   ' We   show   that   the   optimum   length - / spl   nu /   guard   sequence   for   block   transmission   over   a   linear   Gaussian - noise   dispersive   channel   with   memory   / spl   nu /   is   a   linear   combination   of   the   N   information   symbols   of   the   block .   A   closed - form   expression   for   the   optimum   guard   sequence   is   derived   subject   to   a   total   average   energy   constraint   on   the   information   and   guard   symbols .   The   achievable   channel   block   throughput   with   the   optimum   guard   sequence   is   compared   with   that   achievable   with   two   common   guard   sequence   types ,   namely   zero   stuffing   and   cyclic   prefix . ' ,   ' title ' :   ' Guard   sequence   optimization   for   block   transmission   over   linear   frequency - selective   channels ' } 
{ ' abstract ' :   " A   modular   program   analysis   considers   components   independently   and   provides   a   succinct   summary   for   each   component ,   which   is   used   when   checking   the   rest   of   the   system .   Consider   a   system   consisting   of   a   library   and   a   client .   A   temporal   summary ,   or     interface   ,   of   the   library   specifies   legal   sequences   of   library   calls .   The   interface   is     safe     if   no   call   sequence   violates   the   library ' s   internal   invariants ;   the   interface   is     permissive     if   it   contains   every   such   sequence .   Modular   program   analysis   requires     full     interfaces ,   which   are   both   safe   and   permissive :   the   client   does   not   cause   errors   in   the   library   if   and   only   if   it   makes   only   sequences   of   library   calls   that   are   allowed   by   the   full   interface   of   the   library . Previous   interface - based   methods   have   focused   on   safe   interfaces ,   which   may   be   too   restrictive   and   thus   reject   good   clients .   We   present   an   algorithm   for   automatically   synthesizing   software   interfaces   that   are   both   safe   and   permissive .   The   algorithm   generates   interfaces   as   graphs   whose   vertices   are   labeled   with   predicates   over   the   library ' s   internal   state ,   and   whose   edges   are   labeled   with   library   calls .   The   interface   state   is   refined   incrementally   until   the   full   interface   is   constructed .   In   other   words ,   the   algorithm   automatically   synthesizes   a   typestate   system   for   the   library ,   against   which   any   client   can   be   checked   for   compatibility .   We   present   an   implementation   of   the   algorithm   which   is   based   on   the   BLAST   model   checker ,   and   we   evaluate   some   case   studies . " ,   ' title ' :   ' Permissive   interfaces ' } 
{ ' abstract ' :   ' In   this   paper ,   we   propose   a   new   method   for   the   motion   planning   problem   of   rigid   object   dexterous   manipulation   with   a   robotic   multi - fingered   hand ,   under   quasi - static   movement   assumption .   This   method   computes   both   object   and   finger   trajectories   as   well   as   the   finger   relocation   sequence .   Its   specificity   is   to   use   a   special   structuring   of   the   research   space   that   allows   to   search   for   paths   directly   in   the   particular   subspace   GS   n     which   is   the   subspace   of   all   the   grasps   that   can   be   achieved   with   n   grasping   fingers .   The   solving   of   the   dexterous   manipulation   planning   problem   is   based   upon   the   exploration   of   this   subspace .   The   proposed   approach   captures   the   connectivity   of   GS   n     in   a   graph   structure .   The   answer   of   the   manipulation   planning   query   is   then   given   by   searching   a   path   in   the   computed   graph .   Simulation   experiments   were   conducted   for   different   dexterous   manipulation   task   examples   to   validate   the   proposed   method . ' ,   ' title ' :   ' Dexterous   manipulation   planning   using   probabilistic   roadmaps   in   continuous   grasp   subspaces ' } 
{ ' abstract ' :   ' This   paper   presents   an   experimental   evaluation   of   different   line   extraction   algorithms   applied   to   2D   laser   scans   for   indoor   environments .   Six   popular   algorithms   in   mobile   robotics   and   computer   vision   are   selected   and   tested .   Real   scan   data   collected   from   two   office   environments   by   using   different   platforms   are   used   in   the   experiments   in   order   to   evaluate   the   algorithms .   Several   comparison   criteria   are   proposed   and   discussed   to   highlight   the   advantages   and   drawbacks   of   each   algorithm ,   including   speed ,   complexity ,   correctness   and   precision .   The   results   of   the   algorithms   are   compared   with   ground   truth   using   standard   statistical   methods .   An   extended   case   study   is   performed   to   further   evaluate   the   algorithms   in   a   SLAM   application . ' ,   ' title ' :   ' A   comparison   of   line   extraction   algorithms   using   2D   range   data   for   indoor   mobile   robotics ' } 
{ ' abstract ' :   ' This   study   investigates   the   use   of   force - stiffness   feedback ,   i . e . ,   a   combination   of   force   offset   and   extra   spring   load ,   in   UAV   tele - operation   with   transmission   time   delay .   The   goal   was   to   further   increase   the   level   of   safety   of   tele - operation   with   a   reduction   in   operator   workload   with   respect   to   force   feedback ,   i . e . ,   using   force   offset   alone .   A   theoretical   analysis   is   given   of   using   force - stiffness   feedback   to   improve   collision   avoidance .   Wave   variables   are   included   to   reduce   time   delay   effects .   An   experiment   was   conducted   to   investigate   the   effects   of   force - stiffness   feedback   on   safety   of   operation ,   operator   performance ,   control   activity ,   and   workload .   Results   indicate   that   force - stiffness   feedback   improves   the   haptic   interface   with   respect   to   force   feedback   alone .   Safety   of   tele - operation   increases   without   increasing   operator   workload   with   respect   to   force   feedback . ' ,   ' title ' :   ' Haptic   interface   in   UAV   tele - operation   using   force - stiffness   feedback ' } 
{ ' abstract ' :   ' Due   to   the   spread   of   the   internet   and   the   ever   increasing   number   of   web   applications ,   the   issue   of   compatibility   across   browsers   has   become   very   important .   This   compatibility   issue   is   also   referred   as   Cross   Browser   Inconsistency   ( XBI )   wherein   same   website   looks   or   behaves   differently   in   different   web   browsers .   In   this   paper   our   aim   is   to   address   this   issue   of   compatibility   and   propose   an   automated   approach   of   detecting   XBIs .   Cross   Browser   Inconsistencies   can   either   be   in   the   content ,   structure   or   behavior   of   the   webpage .   In   order   to   get   a   grasp   of   the   above   mentioned   types   of   inconsistencies ,   we   surveyed   some   random   websites   and   analyzed   them   in   different   browsers .   We   also   studied   the   basic   working   of   browser ,   in   order   to   establish   its   connection   with   the   occurrences   of   XBIs .   Each   browser   has   its   own   rendering   mechanisms ,   which   sometimes   differs   from   standards .   Hence ,   the   execution   of   these   websites   is   different   in   different   browsers .   Finally   we   have   proposed   an   automated   approach   for   XBI   detection . ' ,   ' title ' :   ' An   Automated   Approach   for   Cross - Browser   Inconsistency   ( XBI )   Detection ' } 
{ ' abstract ' :   ' We   present   a   formal   framework   that   combines   high - level   representation   and   causality - based   reasoning   with   low - level   geometric   reasoning   and   motion   planning .   The   frame - work   features   bilateral   interaction   between   task   and   motion   planning ,   and   embeds   geometric   reasoning   in   causal   reasoning ,   thanks   to   several   advantages   inherited   from   its   underlying   components .   In   particular ,   our   choice   of   using   a   causality - based   high - level   formalism   for   describing   action   domains   allows   us   to   represent   ramifications   and   state / transition   constraints ,   and   embed   in   such   formal   domain   descriptions   externally   defined   functions   implemented   in   some   programming   language   ( e . g . ,   C++ ) .   Moreover ,   given   such   a   domain   description ,   the   causal   reasoner   based   on   this   formalism   ( i . e . ,   the   Causal   Calculator )   allows   us   to   compute   optimal   solutions   ( e . g . ,   shortest   plans )   for   elaborate   planning / prediction   problems   with   temporal   constraints .   Utilizing   these   features   of   high - level   representation   and   reasoning ,   we   can   combine   causal   reasoning ,   motion   planning   and   geometric   planning   to   find   feasible   kinematic   solutions   to   task - level   problems .   In   our   framework ,   the   causal   reasoner   guides   the   motion   planner   by   finding   an   optimal   task - plan ;   if   there   is   no   feasible   kinematic   solution   for   that   task - plan   then   the   motion   planner   guides   the   causal   reasoner   by   modifying   the   planning   problem   with   new   temporal   constraints .   Furthermore ,   while   computing   a   task - plan ,   the   causal   reasoner   takes   into   account   geometric   models   and   kinematic   relations   by   means   of   external   predicates   implemented   for   geometric   reasoning   ( e . g . ,   to   check   some   collisions ) ;   in   that   sense   the   geometric   reasoner   guides   the   causal   reasoner   to   find   feasible   kinematic   solutions .   We   illustrate   an   application   of   this   framework   to   robotic   manipulation ,   with   two   pantograph   robots   on   a   complex   assembly   task   that   requires   concurrent   execution   of   actions .   A   short   video   of   this   application   accompanies   the   paper . ' ,   ' title ' :   ' Combining   high - level   causal   reasoning   with   low - level   geometric   reasoning   and   motion   planning   for   robotic   manipulation ' } 
{ ' abstract ' :   ' This   paper   presents   a   novel   template   matching   method   to   detect   and   track   pedestrians   for   people   counting   in   real - time .   Firstly ,   a   novel   background   subtraction   method   is   proposed   for   extracting   all   foreground   objects   from   background .   Then ,   a   shadow   elimination   method   is   used   to   remove   unwanted   shadow   from   the   background .   In   order   to   identify   pedestrians   from   non - pedestrian   objects ,   this   paper   proposed   a   novel   grid - based   template   matching   scheme   to   robustly   verify   each   pedestrian .   Usually ,   a   pedestrian   will   have   different   appearances   at   different   positions .   The   grid - based   approach   can   effectively   reduce   the   perspective   effects   into   a   minimum   since   it   uses   different   templates   to   record   the   appearance   changes   at   each   grid .   When   more   templates   are   used ,   the   detection   process   will   become   more   inefficient .   To   speed   up   its   efficiency ,   an   integral   image   is   used   to   filter   out   all   impossible   candidates   in   advance .   Lastly ,   a   tracking   method   is   applied   to   tracking   the   direction   of   each   moving   pedestrian   so   that   the   real   number   of   passing   people   per   direction   can   be   counted   more   accurately .   Experimental   results   have   proved   that   the   proposed   method   is   robust ,   accurate ,   and   powerful   in   people   counting . ' ,   ' title ' :   ' Grid - based   Template   Matching   for   People   Counting ' } 
{ ' abstract ' :   ' A   tomographic   image   reconstruction   algorithm   that   we   have   been   studying   requires   the   nth - order   Hankel   transform   for   the   nth   function   in   a   series ,   where   n   varies   over   a   set   of   integers .   Unfortunately ,   most   previously   proposed   algorithms   have   either   dealt   with   only   zeroth - order   transforms   or   cannot   be   applied   conveniently   to   our   problem .   We   propose   an   algorithm   for   computing   general   integer - order   Hankel   transforms .   The   algorithm   takes   samples   of   equally   spaced   input   functions   and   gives   equally   spaced   samples   of   the   transforms . ' ,   ' title ' :   ' An   algorithm   for   computing   general   integer - order   Hankel   transforms ' } 
{ ' abstract ' :   ' In   this   paper ,   we   present   a   real - time   approach   that   allows   tracking   deformable   structures   in   3D   ultrasound   sequences .   Our   method   consists   in   obtaining   the   target   displacements   by   combining   robust   dense   motion   estimation   and   mechanical   model   simulation .   We   perform   evaluation   of   our   method   through   simulated   data ,   phantom   data ,   and   real - data .   Results   demonstrate   that   this   novel   approach   has   the   advantage   of   providing   correct   motion   estimation   regarding   different   ultrasound   shortcomings   including   speckle   noise ,   large   shadows   and   ultrasound   gain   variation .   Furthermore ,   we   show   the   good   performance   of   our   method   with   respect   to   state - of - the - art   techniques   by   testing   on   the   3D   databases   provided   by   MICCAI   CLUST ’ 14   and   CLUST ’ 15   challenges . ' ,   ' title ' :   ' Real - time   target   tracking   of   soft   tissues   in   3D   ultrasound   images   based   on   robust   visual   information   and   mechanical   simulation ' } 
{ ' abstract ' :   ' For   two   given   graphs   G1G1   and   G2G2 ,   the   Ramsey   number   R ( G1 , G2 ) R ( G1 , G2 )   is   the   smallest   integer   NN   such   that   for   any   graph   of   order   NN ,   either   GG   contains   a   copy   of   G1G1   or   its   complement   contains   a   copy   of   G2G2 .   Let   CmCm   be   a   cycle   of   length   mm   and   K1 , nK1 , n   a   star   of   order   n + 1n + 1 .   Parsons   ( 1975 )   shows   that   R ( C4 , K1 , n ) ≤ n + ⌊ n − 1 ⌋ + 2   and   if   nn   is   the   square   of   a   prime   power ,   then   the   equality   holds .   In   this   paper ,   by   discussing   the   properties   of   polarity   graphs   whose   vertices   are   points   in   the   projective   planes   over   Galois   fields ,   we   prove   that   R ( C4 , K1 , q2 − t ) = q2 + q − ( t − 1 ) R ( C4 , K1 , q2 − t ) = q2 + q − ( t − 1 )   if   qq   is   an   odd   prime   power ,   1 ≤ t ≤ 2 ⌈ q4 ⌉   and   t ≠ 2 ⌈ q4 ⌉ − 1 ,   which   extends   a   result   on   R ( C4 , K1 , q2 − t ) R ( C4 , K1 , q2 − t )   obtained   by   Parsons   ( 1976 ) . ' ,   ' title ' :   ' Polarity   graphs   and   Ramsey   numbers   for   C   4   versus   stars ' } 
{ ' abstract ' :   ' This   paper   deals   with   the   problem   of   assuring   strict   QoS   guarantees   for   the   end   to   end   connections   that   originate   from   Ethernet   access   network .   It   shows   that   despite   high   link   capacities   in   some   cases   Ethernet   network   might   be   the   reason   of   QoS   deterioration .   The   primary   reason   is   the   lack   of   appropriate   QoS   differentiation   and   traffic   isolation   mechanisms .   The   shared   buffers   and   priority   schedulers   available   in   most   of   Ethernet   switches   appear   to   be   not   sufficient   to   guarantee   strict   QoS .   For   these   cases   new   solution   is   proposed   which   relies   on   additional   traffic   control   mechanisms   available   in   other   network   elements .   Only   additional   mechanism   supporting   typical   functionality   of   Ethernet   switch   can   provide   strict   QoS   guarantees   what   was   verified   in   simulations   studies . ' ,   ' title ' :   ' On   assuring   QoS   in   Ethernet   access   network ' } 
{ ' abstract ' :   ' The   federal   Medicare   regulations   reimburse   hospitals   on   a   pro   rata   share   of   the   hospital \ ' s   cost .   Hence ,   to   meet   its   financial   requirements ,   a   hospital   is   forced   to   shift   more   of   the   financial   burdens   onto   its   private   patients .   This   procedure   has   contributed   to   double   digit   inflation   in   hospital   prices   and   to   proposed   federal   regulation   to   control   the   rate   of   increase   in   hospital   revenues .   In   this   regulatory   environment ,   we   develop   nonlinear   programming   pricing   and   cost   allocation   models   to   aid   hospital   administrators   in   meeting   their   profit   maximizing   and   profit   satisficing   goals .   The   model   enables   administrators   to   explore   tactical   issues   such   as :   i   studying   the   relationship   between   a   voluntary   or   legislated   cap   on   a   hospital \ ' s   total   revenues   and   the   hospital \ ' s   profitability ,   ii   identifying   those   departments   within   the   hospital   that   are   the   most   attractive   candidates   for   cost   reduction   or   cost   containment   efforts ,   and   iii   isolating   those   services   that   should   be   singled   out   by   the   hospital   manager   for   renegotiation   of   the   prospective   or   " customary   and   reasonable "   cap .   Finally ,   the   modeling   approach   is   helpful   in   explaining   the   departmental   cross   subsidies   observed   in   practice ,   and   can   be   of   aid   to   federal   administrators   in   assessing   the   impacts   of   proposed   changes   in   the   Medicare   reimbursement   formula . ' ,   ' title ' :   ' Hospital   Profit   Planning   under   Medicare   Reimbursement ' } 
{ ' abstract ' :   ' We   present   a   ( 4   +   epsilon )   approximation   algorithm   for   weighted   graph   matching   which   applies   in   the   semistreaming ,   sliding   window ,   and   MapReduce   models ;   this   single   algorithm   improves   the   previous   best   algorithm   in   each   model .   The   algorithm   operates   by   reducing   the   maximum - weight   matching   problem   to   a   polylog   number   of   copies   of   the   maximum - cardinality   matching   problem .   The   algorithm   also   extends   to   provide   approximation   guarantees   for   the   more   general   problem   of   finding   weighted   independent   sets   in   p - systems   ( which   include   intersections   of   p   matroids   and   p - bounded   hypergraph   matching ) . ' ,   ' title ' :   ' Improved   Streaming   Algorithms   for   Weighted   Matching ,   via   Unweighted   Matching ' } 
{ ' abstract ' :   ' This   paper   presents   a   novel   approach   to   efficiently   solve   parameter - dependent   ( PD )   linear   matrix   inequality   ( LMI )   problems   for ,   amongst   others ,   linear   parameter - varying   ( LPV )   control   design .   Typically ,   stability   and   performance   is   guaranteed   by   finding   a   PD   Lyapunov   function   such   that   a   PD   LMI   is   feasible   on   a   parameter   domain .   To   solve   the   resulting   semi - infinite   problems ,   we   propose   a   novel   LMI   relaxation   technique   relying   on   B - spline   basis   functions .   This   technique   provides   less   conservative   solutions   and / or   a   reduced   numerical   burden   compared   to   existing   approaches .   Moreover ,   an   elegant   generalization   of   worst - case   optimization   to   the   optimization   of   any   signal   norm   is   obtained   by   expressing   performance   bounds   as   a   function   of   the   system   parameters .   This   generalization   yields   better   performance   bounds   in   a   large   part   of   the   parameter   domain .   Numerical   comparisons   with   the   current   state - of - the - art   demonstrate   the   generality   and   effectiveness   of   our   approach . ' ,   ' title ' :   ' Control   of   linear   parameter - varying   systems   using   B - splines ' } 
{ ' abstract ' :   ' There   is   a   growing   interest   in   simulating   natural   phenomena   in   computer   graphics   applications .   Animating   natural   scenes   in   real   time   is   one   of   the   most   challenging   problems   due   to   the   inherent   complexity   of   their   structure ,   formed   by   millions   of   geometric   entities ,   and   the   interactions   that   happen   within .   An   example   of   natural   scenario   that   is   needed   for   games   or   simulation   programs   are   forests .   Forests   are   difficult   to   render   because   the   huge   amount   of   geometric   entities   and   the   large   amount   of   detail   to   be   represented .   Moreover ,   the   interactions   between   the   objects   ( grass ,   leaves )   and   external   forces   such   as   wind   are   complex   to   model .   In   this   paper   we   concentrate   in   the   rendering   of   falling   leaves   at   low   cost .   We   present   a   technique   that   exploits   graphics   hardware   in   order   to   render   thousands   of   leaves   with   different   falling   paths   in   real   time   and   low   memory   requirements . ' ,   ' title ' :   ' Rendering   falling   leaves   on   graphics   hardware ' } 
{ ' abstract ' :   ' We   previously   presented   DriverDB ,   a   database   that   incorporates   ∼ 6000   cases   of   exome - seq   data ,   in   addition   to   annotation   databases   and   published   bioinformatics   algorithms   dedicated   to   driver   gene / mutation   identification .   The   database   provides   two   points   of   view ,   ‘ Cancer ’   and   ‘ Gene ’ ,   to   help   researchers   visualize   the   relationships   between   cancers   and   driver   genes / mutations .   In   the   updated   DriverDBv2   database   ( http : / / ngs . ym . edu . tw / driverdb )   presented   herein ,   we   incorporated   > 9500   cancer - related   RNA - seq   datasets   and   > 7000   more   exome - seq   datasets   from   The   Cancer   Genome   Atlas   ( TCGA ) ,   International   Cancer   Genome   Consortium   ( ICGC ) ,   and   published   papers .   Seven   additional   computational   algorithms   ( meaning   that   the   updated   database   contains   15   in   total ) ,   which   were   developed   for   driver   gene   identification ,   are   incorporated   into   our   analysis   pipeline ,   and   the   results   are   provided   in   the   ‘ Cancer ’   section .   Furthermore ,   there   are   two   main   new   features ,   ‘ Expression ’   and   ‘ Hotspot ’ ,   in   the   ‘ Gene ’   section .   ‘ Expression ’   displays   two   expression   profiles   of   a   gene   in   terms   of   sample   types   and   mutation   types ,   respectively .   ‘ Hotspot ’   indicates   the   hotspot   mutation   regions   of   a   gene   according   to   the   results   provided   by   four   bioinformatics   tools .   A   new   function ,   ‘ Gene   Set ’ ,   allows   users   to   investigate   the   relationships   among   mutations ,   expression   levels   and   clinical   data   for   a   set   of   genes ,   a   specific   dataset   and   clinical   features . ' ,   ' title ' :   ' DriverDBv2 :   a   database   for   human   cancer   driver   gene   research ' } 
{ ' abstract ' :   ' Thousands   of   deep   and   wide   pipelines   working   concurrently   make   GPGPU   high   power   consuming   parts .   Energy - efficiency   techniques   employ   voltage   overscaling   that   increases   timing   sensitivity   to   variations   and   hence   aggravating   the   energy   use   issues .   This   paper   proposes   a   method   to   increase   spatiotemporal   reuse   of   computational   effort   by   a   combination   of   compilation   and   micro - architectural   design .   An   associative   memristive   memory   ( AMM )   module   is   integrated   with   the   floating   point   units   ( FPUs ) .   Together ,   we   enable   fine - grained   partitioning   of   values   and   find   high - frequency   sets   of   values   for   the   FPUs   by   searching   the   space   of   possible   inputs ,   with   the   help   of   application - specific   profile   feedback .   For   every   kernel   execution ,   the   compiler   pre - stores   these   high - frequent   sets   of   values   in   AMM   modules   - -   representing   partial   functionality   of   the   associated   FPU - -   that   are   concurrently   evaluated   over   two   clock   cycles .   Our   simulation   results   show   high   hit   rates   with   32 - entry   AMM   modules   that   enable   36%   reduction   in   average   energy   use   by   the   kernel   codes .   Compared   to   voltage   overscaling ,   this   technique   enhances   robustness   against   timing   errors   with   39%   average   energy   saving . ' ,   ' title ' :   ' Energy - Efficient   GPGPU   Architectures   via   Collaborative   Compilation   and   Memristive   Memory - Based   Computing ' } 
{ ' abstract ' :   ' Quasi - cyclic   codes   are   renowned   for   their   structural   design   and   low - complexity   shift   register   encoding .   However ,   existing   design   techniques   based   on   difference   families   have   limited   code   size   options   due   to   algebraic   constraints .   We   introduce   in   this   paper   a   notation   of   extended   difference   family   ( EDF )   and   provide   a   systematic   code   design   based   on   EDFs   with   a   high   degree   of   flexibility   in   code   size .   Short / medium - length   codes   of   high   rate   ( / spl   ges /   0.9 )   can   be   easily   constructed . ' ,   ' title ' :   ' Quasi - cyclic   codes   from   extended   difference   families ' } 
{ ' abstract ' :   ' Lexical   cohesion   arises   from   a   chain   of   lexical   items   that   establish   links   between   sentences   in   a   text .   In   this   paper   we   propose   three   different   models   to   capture   lexical   cohesion   for   document - level   machine   translation :   ( a )   a   direct   reward   model   where   translation   hypotheses   are   rewarded   whenever   lexical   cohesion   devices   occur   in   them ,   ( b )   a   conditional   probability   model   where   the   appropriateness   of   using   lexical   cohesion   devices   is   measured ,   and   ( c )   a   mutual   information   trigger   model   where   a   lexical   cohesion   relation   is   considered   as   a   trigger   pair   and   the   strength   of   the   association   between   the   trigger   and   the   triggered   item   is   estimated   by   mutual   information .   We   integrate   the   three   models   into   hierarchical   phrase - based   machine   translation   and   evaluate   their   effectiveness   on   the   NIST   Chinese - English   translation   tasks   with   large - scale   training   data .   Experiment   results   show   that   all   three   models   can   achieve   substantial   improvements   over   the   baseline   and   that   the   mutual   information   trigger   model   performs   better   than   the   others . ' ,   ' title ' :   ' Modeling   lexical   cohesion   for   document - level   machine   translation ' } 
{ ' abstract ' :   ' This   paper   presents   a   lightweight   sketching   system   that   enables   interactive   illustration   of   complex   fluid   systems .   Users   can   sketch   on   a   2.5 - dimensional   ( 2.5 D )   canvas   to   design   the   shapes   and   connections   of   a   fluid   circuit .   These   input   sketches   are   automatically   analyzed   and   abstracted   into   a   hydraulic   graph ,   and   a   new   hybrid   fluid   model   is   used   in   the   background   to   enhance   the   illustrations .   The   system   provides   rich   simple   operations   for   users   to   edit   the   fluid   system   incrementally ,   and   the   new   internal   flow   patterns   can   be   simulated   in   real   time .   Our   system   is   used   to   illustrate   various   fluid   systems   in   medicine ,   biology ,   and   engineering .   We   asked   professional   medical   doctors   to   try   our   system   and   obtained   positive   feedback   from   them . ' ,   ' title ' :   ' Sketch - based   Dynamic   Illustration   of   Fluid   Systems ' } 
{ ' abstract ' :   ' We   present   an   improved   zone   content   classification   method   and   its   performance   evaluation .   We   added   two   new   features   to   the   feature   vector   from   one   previously   published   method   ( Sivaramakrishnan   et   al . ,   1995 ) .   We   assumed   different   independence   relationships   in   two   zone   sets .   We   used   an   optimized   binary   decision   tree   to   estimate   the   maximum   zone   content   class   probability   in   one   set   while   using   the   Viterbi   algorithm   to   find   the   optimal   solution   for   a   zone   sequence   in   the   other   set .   The   training ,   pruning   and   testing   data   set   for   the   algorithm   include   1 , 600   images   drawn   from   the   UWCDROM   III   document   image   database .   The   classifier   is   able   to   classify   each   given   scientific   and   technical   document   zone   into   one   of   the   nine   classes ,   2   text   classes   ( of   font   size   4   -   18pt   and   font   size   19   -   32   pt ) ,   math ,   table ,   halftone ,   map / drawing ,   ruling ,   logo ,   and   others .   Compared   with   our   previous   work   ( Wang   et   al . ,   2000 ) ,   it   raised   the   accuracy   rate   to   98.52%   from   97.53%   and   reduced   the   mean   false   alarm   rate   to   0.53%   from   1.26% . ' ,   ' title ' :   ' Zone   content   classification   and   its   performance   evaluation ' } 
{ ' abstract ' :   ' Big   Data   applications   require   real - time   processing   of   complex   computations   on   streaming   and   static   information .   Applications   such   as   the   diagnosis   of   power   generating   turbines   require   the   integration   of   high   velocity   streaming   and   large   volume   of   static   data   from   multiple   sources .   In   this   paper   we   study   various   optimisations   related   to   efficiently   processing   of   streaming   and   static   information .   We   introduce   novel   indexing   structures   for   stream   processing ,   a   query - planner   component   that   decides   when   their   creation   is   beneficial ,   and   we   examine   precomputed   summarisations   on   archived   measurements   to   accelerate   streaming   and   static   information   processing .   To   put   our   ideas   into   practise ,   we   have   developed   Exa   Stream ,   a   data   stream   management   system   that   is   scalable ,   has   declarative   semantics ,   supports   user   defined   functions ,   and   allows   efficient   execution   of   complex   analytical   queries   on   streaming   and   static   data .   Our   work   is   accompanied   by   an   empirical   evaluation   of   our   optimisation   techniques . ' ,   ' title ' :   ' Real   time   processing   of   streaming   and   static   information ' } 
{ ' abstract ' :   " In   the   last   ten   years ,   speech   recognition   has   evolved   from   a   science   fiction   dream   to   a   widespread   input   method   for   mobile   devices .   In   this   talk ,   I   will   describe   how   speech   recognition   works ,   the   problems   we   have   solved   and   the   challenges   that   remain .   I   will   touch   upon   some   of   Google ' s   main   efforts   in   language   and   pronunciation   modeling ,   and   describe   how   the   adoption   of   neural   networks   for   acoustic   modeling   marked   the   beginning   of   a   technology   revolution   in   the   field ,   with   approaches   such   as   Long   Short   Term   Memory   models   and   Connectionist   Temporal   Classification .   I   will   also   share   my   learnings   on   how   Machine   Learning   and   Human   Knowledge   can   be   harmoniously   combined   to   build   state - of - the - art   technology   that   helps   and   delights   users   across   the   world . " ,   ' title ' :   ' Learnings   and   innovations   in   speech   recognition ' } 
{ ' abstract ' :   ' Nowadays ,   the   explosive   growth   and   variety   of   information   available   on   the   Web   frequently   overwhelms   users   and   leads   users   to   make   poor   decisions .   Consequently ,   recommender   systems   have   become   more   and   more   important   to   assist   people   to   make   decisions   faster .   Among   all   related   techniques ,   collaborative   filtering   approach   is   currently   one   of   the   effective   and   widely   used   techniques   to   build   recommender   systems .   However ,   there   are   major   challenges   like   data   sparsity   and   scalability .   Meanwhile   it   is   hard   to   integrate   demographic   statistical   information   ( Age ,   gender   and   occupation   etc . )   to   collaborative   filtering   model .   Unfortunately ,   it   is   significant   to   take   account   into   these   information ,   especially   user   occupation   when   making   recommendation .   As   we   all   know ,   people   with   different   occupations   may   have   totally   different   tastes .   It   has   been   proved   that   restricted   Boltzmann   machines ( RBM )   model   can   infer   lower - dimensional   representations   automatically   and   is   potential   in   handling   large   and   sparse   dataset .   In   this   paper ,   we   propose   an   improved   User   Occupation   aware   Conditional   Restricted   Boltzmann   Machine   Frame ( UO - CRBMF )   model ,   which   employs   an   improved   RBM   and   takes   full   use   of   user   occupation   information   by   adding   a   conditional   layer   with   user   occupation   information .   Experimental   studies   on   the   standard   benchmark   datasets   of   MovieLens   100k   and   MovieLens   1M   have   shown   its   potential   and   advantages   beyond   baseline   methods . ' ,   ' title ' :   ' User   Occupation   Aware   Conditional   Restricted   Boltzmann   Machine   Based   Recommendation ' } 
{ ' abstract ' :   ' Microservices   complement   approaches   like   DevOps   and   continuous   delivery   in   terms   of   software   architecture .   Along   with   this   architectural   style ,   several   important   deployment   technologies ,   such   as   container - based   virtualization   and   container   orchestration   solutions ,   have   emerged .   These   technologies   allow   to   efficiently   exploit   cloud   platforms ,   providing   a   high   degree   of   scalability ,   availability ,   and   portability   for   microservices .# R ## N ## R ## N # Despite   the   obvious   importance   of   a   sufficient   level   of   performance ,   there   is   still   a   lack   of   performance   engineering   approaches   explicitly   taking   into   account   the   particularities   of   microservices .   In   this   paper ,   we   argue   why   new   solutions   to   performance   engineering   for   microservices   are   needed .   Furthermore ,   we   identify   open   issues   and   outline   possible   research   directions   with   regard   to   performance - aware   testing ,   monitoring ,   and   modeling   of   microservices . ' ,   ' title ' :   ' Performance   Engineering   for   Microservices :   Research   Challenges   and   Directions ' } 
{ ' abstract ' :   ' Intelligent   agents ,   such   as   robots ,   have   to   serve   a   multitude   of   autonomous   functions .   Examples   are ,   e . g . ,   collision   avoidance ,   navigation   and   route   planning ,   active   sensing   of   its   environment ,   or   the   interaction   and   non - verbal   communication   with   people   in   the   extended   reach   space .   Here ,   we   focus   on   the   recognition   of   the   action   of   a   human   agent   based   on   a   biologically   inspired   visual   architecture   of   analyzing   articulated   movements .   The   proposed   processing   architecture   builds   upon   coarsely   segregated   streams   of   sensory   processing   along   different   pathways   which   separately   process   form   and   motion   information   ( Layher   et   al . ,   2014 ) .   Action   recognition   is   performed   in   an   event - based   scheme   by   identifying   representations   of   characteristic   pose   configurations   ( key   poses )   in   an   image   sequence .   In   line   with   perceptual   studies ,   key   poses   are   selected   unsupervised   utilizing   a   feature   driven   criterion   which   combines   extrema   in   the   motion   energy   with   the   horizontal   and   the   vertical   extendedness   of   a   body   shape .   Per   class   representations   of   key   pose   frames   are   learned   using   a   deep   convolutional   neural   network   consisting   of   15   convolutional   layers .   The   network   is   trained   using   the   energy - efficient   deep   neuromorphic   networks   ( Eedn )   framework   ( Esser   et   al . ,   2016 ) ,   which   realizes   the   mapping   of   the   trained   synaptic   weights   onto   the   IBM   Neurosynaptic   System   platform   ( Merolla   et   al . ,   2014 ) .   After   the   mapping ,   the   trained   network   achieves   real - time   capabilities   for   processing   input   streams   and   classify   input   images   at   about   1 , 000   frames   per   second   while   the   computational   stages   only   consume   about   70   mW   of   energy   ( without   spike   transduction ) .   Particularly   regarding   mobile   robotic   systems ,   a   low   energy   profile   might   be   crucial   in   a   variety   application   scenarios .   Cross - validation   results   are   reported   for   two   different   datasets   and   compared   to   state - of - the - art   action   recognition   approaches .   The   results   demonstrate ,   that   ( I )   the   presented   approach   is   on   par   with   other   key   pose   based   methods   described   in   the   literature ,   which   select   key   pose   frames   by   optimizing   classification   accuracy ,   ( II )   compared   to   the   training   on   the   full   set   of   frames ,   representations   trained   on   key   pose   frames   result   in   a   higher   confidence   in   class   assignments ,   and   ( III )   key   pose   representations   show   promising   generalization   capabilities   in   a   cross - dataset   evaluation . ' ,   ' title ' :   ' Real - Time   Biologically   Inspired   Action   Recognition   from   Key   Poses   Using   a   Neuromorphic   Architecture ' } 
{ ' abstract ' :   ' Contents   carried   in   an   image   are   valuable   information   sources   for   many   scientific   and   engineering   applications .   However ,   if   the   image   is   captured   under   low   illumination   conditions   a   large   portion   of   the   image   appears   dark   and   this   heavily   degrades   the   image   quality .   In   order   to   solve   this   problem ,   a   restoration   algorithm   is   developed   here   that   transforms   the   low   input   brightness   to   a   higher   value   using   a   logarithmic   mapping   function .   The   mapping   is   further   refined   by   a   linear   weighting   with   the   input   to   reduce   the   un - necessary   amplification   at   regions   with   high   brightness .   Moreover ,   fine   details   in   the   image   are   preserved   by   applying   the   Retinex   principle   to   extract   and   then   re - insert   object   edges .   Results   from   experiments   using   low   and   normal   illumination   images   have   shown   satisfactory   performances   with   regard   to   the   improvement   in   information   contents   and   the   mitigation   of   viewing   artifacts . ' ,   ' title ' :   ' Logarithmic   profile   mapping   and   Retinex   edge   preserving   for   restoration   of   low   illumination   images ' } 
{ ' abstract ' :   ' We   propose   a   principled   approach   for   the   problem   of   aligning   multiple   partially   overlapping   networks .   The   objective   is   to   map   multiple   graphs   into   a   single   graph   while   preserving   vertex   and   edge   similarities .   The   problem   is   inspired   by   the   task   of   integrating   partial   views   of   a   family   tree   ( genealogical   network )   into   one   unified   network ,   but   it   also   has   applications ,   for   example ,   in   social   and   biological   networks .   Our   approach ,   called   Flan ,   introduces   the   idea   of   generalizing   the   facility   location   problem   by   adding   a   non - linear   term   to   capture   edge   similarities   and   to   infer   the   underlying   entity   network .   The   problem   is   solved   using   an   alternating   optimization   procedure   with   a   Lagrangian   relaxation .   Flan   has   the   advantage   of   being   able   to   leverage   prior   information   on   the   number   of   entities ,   so   that   when   this   information   is   available ,   Flan   is   shown   to   work   robustly   without   the   need   to   use   any   ground   truth   data   for   fine - tuning   method   parameters .   Additionally ,   we   present   three   multiple - network   extensions   to   an   existing   state - of - the - art   pairwise   alignment   method   called   Natalie .   Extensive   experiments   on   synthetic ,   as   well   as   real - world   datasets   on   social   networks   and   genealogical   networks ,   attest   to   the   effectiveness   of   the   proposed   approaches   which   clearly   outperform   a   popular   multiple   network   alignment   method   called   IsoRankN . ' ,   ' title ' :   ' Lagrangian   relaxations   for   multiple   network   alignment ' } 
{ ' abstract ' :   ' Heterogeneous   ultra - dense   networks   enable   ultra - high   data   rates   and   ultra - low   latency   through   the   use   of   dense   sub - 6   GHz   and   millimeter   wave   ( mmWave )   small   cells   with   different   antenna   configurations .   Existing   work   has   widely   studied   spectral   and   energy   efficiency   in   such   networks   and   shown   that   high   spectral   and   energy   efficiency   can   be   achieved .   This   article   investigates   the   benefits   of   heterogeneous   ultra - dense   network   architecture   from   the   perspectives   of   three   promising   technologies ,   i . e . ,   physical   layer   security ,   caching ,   and   wireless   energy   harvesting ,   and   provides   enthusiastic   outlook   towards   application   of   these   technologies   in   heterogeneous   ultra - dense   networks .   Based   on   the   rationale   of   each   technology ,   opportunities   and   challenges   are   identified   to   advance   the   research   in   this   emerging   network . ' ,   ' title ' :   ' A   New   Look   at   Physical   Layer   Security ,   Caching ,   and   Wireless   Energy   Harvesting   for   Heterogeneous   Ultra - dense   Networks ' } 
{ ' abstract ' :   ' We   consider   the   problem   of   joint   modeling   of   videos   and   their   corresponding   textual   descriptions   ( e . g .   sentences   or   phrases ) .   Our   approach   consists   of   three   components :   the   video   representation ,   the   textual   representation ,   and   a   joint   model   that   links   videos   and   text .   Our   video   representation   uses   the   state - of - the - art   deep   3D   ConvNet   to   capture   the   semantic   information   in   the   video .   Our   textual   representation   uses   the   recent   advancement   in   learning   word   and   sentence   vectors   from   large   text   corpus .   The   joint   model   is   learned   to   score   the   correct   ( video ,   text )   pairs   higher   than   the   incorrect   ones .   We   demonstrate   our   approach   in   several   applications :   1 )   retrieving   sentences   given   a   video ;   2 )   retrieving   videos   given   a   sentence ;   3 )   zero - shot   action   recognition   in   videos . ' ,   ' title ' :   ' Beyond   verbs :   Understanding   actions   in   videos   with   text ' } 
{ ' abstract ' :   ' This   paper   presents   a   multi - agent   model   for   simulating   attitude   formation   and   change   based   on   perception   and   communication   in   the   context   of   stabilization   operations .   The   originality   of   our   model   comes   from   ( 1 )   attitude   computation   that   evaluates   information   as   part   of   a   history   relative   to   the   individual   ( 2 )   a   notion   of   co - responsibility   for   attitude   attribution .   We   present   a   military   scenario   of   French   operations   in   Afghanistan   along   with   polls   results   about   the   opinion   of   citizen   toward   present   Forces .   Based   on   these   field   data ,   we   calibrate   the   model   and   show   the   resulting   attitude   dynamics .   We   study   the   sensibility   of   the   model   to   the   co - responsibility   factor . ' ,   ' title ' :   ' From   Field   Data   to   Attitude   Formation ' } 
{ ' abstract ' :   ' This   paper   proposes   two   low - complexity   iterative   algorithms   to   compute   the   capacity   of   a   single - user   multiple - input   multiple - output   channel   with   per - antenna   power   constraint .   The   first   method   results   from   manipulating   the   optimality   conditions   of   the   considered   problem   and   applying   fixed - point   iteration .   In   the   second   approach ,   we   transform   the   considered   problem   into   a   minimax   optimization   program   using   the   well - known   MAC -   BC   duality ,   and   then   solve   it   by   a   novel   alternating   optimization   method .   In   both   proposed   iterative   methods ,   each   iteration   involves   an   optimization   problem   which   can   be   efficiently   solved   by   the   water - filling   algorithm .   The   proposed   iterative   methods   are   provably   convergent .   Complexity   analysis   and   extensive   numerical   experiments   are   carried   out   to   demonstrate   the   superior   performance   of   the   proposed   algorithms   over   an   existing   approach   known   as   the   mode - dropping   algorithm . ' ,   ' title ' :   ' Low - complexity   Approaches   for   MIMO   Capacity   with   Per - antenna   Power   Constraint ' } 
{ ' abstract ' :   ' Inventory - Aware   Pathfinding   is   concerned   with   finding   paths   while   taking   into   account   that   picking   up   items ,   e . g . ,   keys ,   allow   the   character   to   unlock   blocked   pathways ,   e . g . ,   locked   doors .   In   this   work   we   present   a   pruning   method   and   a   preprocessing   method   that   can   improve   significantly   the   scalability   of   such   approaches .   We   apply   our   methods   to   the   recent   approach   of   Inventory - Driven   Jump - Point   Search   ( InvJPS ) .   First ,   we   introduce   InvJPS +   that   allows   to   prune   large   parts   of   the   search   space   by   favoring   short   detours   to   pick   up   items ,   offering   a   trade - off   between   efficiency   and   optimality .   Second ,   we   propose   a   preprocessing   step   that   allows   to   decide   on   runtime   which   items ,   e . g . ,   keys ,   are   worth   using   thus   pruning   potentially   unnecessary   items   before   the   search   starts .   We   show   results   for   combinations   of   the   pruning   and   preprocessing   methods   illustrating   the   best   choices   over   various   scenarios . ' ,   ' title ' :   ' Pruning   and   preprocessing   methods   for   inventory - aware   pathfinding ' } 
{ ' abstract ' :   ' This   paper   proposes   a   method   for   proper   names   extraction   from   Myanmar   text   by   using   latent   Dirichlet   allocation   ( LDA ) .   Our   method   aims   to   extract   proper   names   that   provide   important   information   on   the   contents   of   Myanmar   text .   Our   method   consists   of   two   steps .   In   the   first   step ,   we   extract   topic   words   from   Myanmar   news   articles   by   using   LDA .   In   the   second   step ,   we   make   a   post - processing ,   because   the   resulting   topic   words   contain   some   noisy   words .   Our   post - processing ,   first   of   all ,   eliminates   the   topic   words   whose   prefixes   are   Myanmar   digits   and   suffixes   are   noun   and   verb   particles .   We   then   remove   the   duplicate   words   and   discard   the   topic   words   that   are   contained   in   the   existing   dictionary .   Consequently ,   we   obtain   the   words   as   candidate   of   proper   names ,   namely   personal   names ,   geographical   names ,   unique   object   names ,   organization   names ,   single   event   names ,   and   so   on .   The   evaluation   is   performed   both   from   the   subjective   and   quantitative   perspectives .   From   the   subjective   perspective ,   we   compare   the   accuracy   of   proper   names   extracted   by   our   method   with   those   extracted   by   latent   semantic   indexing   ( LSI )   and   rule - based   method .   It   is   shown   that   both   LS ]   and   our   method   can   improve   the   accuracy   of   those   obtained   by   rule - based   method .   However ,   our   method   can   provide   more   interesting   proper   names   than   LSI .   From   the   quantitative   perspective ,   we   use   the   extracted   proper   names   as   additional   features   in   K - means   clustering .   The   experimental   results   show   that   the   document   clusters   given   by   our   method   are   better   than   those   given   by   LSI   and   rule - based   method   in   precision ,   recall   and   F - score . ' ,   ' title ' :   ' Extraction   of   proper   names   from   myanmar   text   using   latent   dirichlet   allocation ' } 
{ ' abstract ' :   ' Large   scale   assessment   of   aboveground   biomass   ( AGB )   in   tropical   forests   is   often   limited   by   the   saturation   of   remote   sensing   signals   at   high   AGB   values .   Fourier   Transform   Textural   Ordination   ( FOTO )   performs   well   in   quantifying   canopy   texture   from   very   high - resolution   ( VHR )   imagery ,   from   which   stand   structure   parameters   can   be   retrieved   with   no   saturation   effect   for   AGB   values   up   to   650   Mg · ha − 1 .   The   method   is   robust   when   tested   on   wet   evergreen   forests   but   is   more   demanding   when   applied   across   different   forest   types   characterized   by   varying   structures   and   allometries .   The   present   study   focuses   on   a   gradient   of   forest   types   ranging   from   dry   deciduous   to   wet   evergreen   forests   in   the   Western   Ghats   ( WG )   of   India ,   where   we   applied   FOTO   to   Cartosat - 1a   images   with   2.5   m   resolution .   Based   on   21   1 - ha   ground   control   forest   plots ,   we   calibrated   independent   texture – AGB   models   for   the   dry   and   wet   zone   forests   in   the   area ,   as   delineated   from   the   distribution   of   NDVI   values   computed   from   LISS - 4   multispectral   images .   This   stratification   largely   improved   the   relationship   between   texture - derived   and   field - derived   AGB   estimates ,   which   exhibited   a   R2   of   0.82   for   a   mean   rRMSE   of   ca .   17% .   By   inverting   the   texture – AGB   models ,   we   finally   mapped   AGB   predictions   at   1.6 - ha   resolution   over   a   heterogeneous   landscape   of   ca .   1500   km2   in   the   WG ,   with   a   mean   relative   per - pixel   propagated   error   < 20%   for   wet   zone   forests ,   i . e . ,   below   the   recommended   IPCC   criteria   for   Monitoring ,   Reporting   and   Verification   ( MRV )   methods .   The   method   proved   to   perform   well   in   predicting   high - resolution   AGB   values   over   heterogeneous   tropical   landscape   encompassing   diversified   forest   types ,   and   thus   presents   a   promising   option   for   affordable   regional   monitoring   systems   of   greenhouse   gas   ( GhG )   emissions   related   to   forest   degradation . ' ,   ' title ' :   ' Inverting   Aboveground   Biomass – Canopy   Texture   Relationships   in   a   Landscape   of   Forest   Mosaic   in   the   Western   Ghats   of   India   Using   Very   High   Resolution   Cartosat   Imagery ' } 
{ ' abstract ' :   ' Self - driving   vehicle   technologies   are   progressing   rapidly   and   are   expected   to   play   a   significant   role   in   the   future   of   transportation .   One   of   the   main   challenges   for   self - driving   vehicles   on   public   roads   is   the   safe   cooperation   and   collaboration   among   multiple   vehicles   using   sensor - based   perception   and   inter - vehicle   communications .   When   self - driving   vehicles   try   to   occupy   the   same   spatial   area   simultaneously ,   they   might   collide   with   one   another ,   might   become   deadlocked ,   or   might   slam   on   the   brakes   making   it   uncomfortable   or   unsafe   for   passengers   in   a   self - driving   vehicle .   In   this   paper ,   we   study   how   a   self - driving   vehicle   can   safely   navigate   merge   points ,   where   two   lanes   with   different   priorities   meet .   We   present   a   safe   protocol   for   merge   points   named   Autonomous   Vehicle   Protocol   for   Merge   Points ,   where   self - driving   vehicles   use   both   vehicular   communications   and   their   own   perception   systems   for   cooperating   with   other   self - driving   and / or   human - driven   vehicles .   Our   simulation   results   show   that   our   traffic   protocol   has   higher   traffic   throughput ,   compared   to   simple   traffic   protocols ,   while   ensuring   safety . ' ,   ' title ' :   ' A   merging   protocol   for   self - driving   vehicles ' } 
{ ' abstract ' :   ' System   Portfolio   Selection   ( SPS )   problem   is   equivalent   to   multi - objective   optimization   problem ,   with   multi - function   requirements   incommensurable .   In   the   paper ,   the   SPS   problem   is   re - specified   with   a   more   practical   formulation ,   comparing   to   general   portfolio   problem .   Then ,   both   feasible   and   non - inferior   solution   is   re - defined   considering   characteristics   of   SPS   problem ,   specifically ,   four   rules   of   system   function   combinations   are   proposed   according   to   practical   cases .   Then ,   the   instability   of   system   performance   is   involved   in   SPS   problem ,   and   the   robust   theory   is   employed   to   solving   the   uncertainty   of   system   function   values   with   definition   of   robust   non - inferior   solution .   Next ,   the   paper   proposes   an   immediately   updating   algorithm   to   solve   the   problem   of   solution   space   exponentially   growing .   Finally ,   a   case   study   is   used   to   demonstrate   the   usefulness   and   effectiveness   of   the   proposed   approaches .   It   shows   that   the   approach   can   provide   an   efficient   guidance   for   decision - makers   in   the   process   of   making   a   SPS . ' ,   ' title ' :   ' Robust   system   portfolio   selection   with   multi - function   requirements   and   system   instability ' } 
{ ' abstract ' :   ' This   study   explores   the   impact   of   high - photovoltaic   ( PV )   penetration   on   the   inter - area   oscillation   modes   of   large - scale   power   grids .   A   series   of   dynamic   models   with   various   PV   penetration   levels   are   developed   based   on   a   detailed   model   representing   the   U . S .   Eastern   Interconnection   ( EI ) .   Transient   simulations   are   performed   to   investigate   the   change   of   inter - area   oscillation   modes   with   PV   penetration .   The   impact   of   PV   control   strategies   and   parameter   settings   on   inter - area   oscillations   is   studied .   This   paper   finds   that   as   PV   increases ,   the   damping   of   the   dominant   oscillation   mode   decreases   monotonically .   It   is   also   observed   that   the   mode   shape   varies   with   the   PV   control   strategy   and   new   oscillation   modes   may   emerge   under   inappropriate   parameter   settings   in   PV   plant   controls . ' ,   ' title ' :   ' Impact   of   High   PV   Penetration   on   the   Inter - Area   Oscillations   in   the   U . S .   Eastern   Interconnection ' } 
{ ' abstract ' :   ' The   objective   of   this   research   is   to   compare   the   effectiveness   of   different   tracking   devices   underwater .   There   have   been   few   works   in   aquatic   virtual   reality   ( VR )   —   i . e . ,   VR   systems   that   can   be   used   in   a   real   underwater   environment .   Moreover ,   the   works   that   have   been   done   have   noted   limitations   on   tracking   accuracy .   Our   initial   test   results   suggest   that   inertial   measurement   units   work   well   underwater   for   orientation   tracking   but   a   different   approach   is   needed   for   position   tracking .   Towards   this   goal ,   we   have   waterproofed   and   evaluated   several   consumer   tracking   systems   intended   for   gaming   to   determine   the   most   effective   approaches .   First ,   we   informally   tested   infrared   systems   and   fiducial   marker   based   systems ,   which   demonstrated   significant   limitations   of   optical   approaches .   Next ,   we   quantitatively   compared   inertial   measurement   units   ( IMU )   and   a   magnetic   tracking   system   both   above   water   ( as   a   baseline )   and   underwater .   By   comparing   the   devices   rotation   data ,   we   have   discovered   that   the   magnetic   tracking   system   implemented   by   the   Razer   Hydra   is   more   accurate   underwater   as   compared   to   a   phone - based   IMU .   This   suggests   that   magnetic   tracking   systems   should   be   further   explored   for   underwater   VR   applications . ' ,   ' title ' :   ' Towards   usable   underwater   virtual   reality   systems ' } 
{ ' abstract ' :   ' A   faulty   network   GG   is   under   the   conditional   fault   model ,   i . e . , \ xa0every   fault - free   vertex   of   GG   is   incident   to   at   least   two   fault - free   edges .   Let   FFvFFv   and   FFeFFe   be   the   set   of   faulty   vertices   and   faulty   edges   in   FQnFQn ,   respectively .   In   this   paper ,   we   consider   FQnFQn   under   the   conditional   fault   model   and   prove   that   if   | FFv | + | FFe | ≤ 2n − 4 | FFv | + | FFe | ≤ 2n − 4   and   n ≥ 3n ≥ 3 ,   then   FQn − FFv − FFeFQn − FFv − FFe   contains   a   fault - free   cycle   of   every   even   length   from   4   to   2n − 2 | FFv | 2n − 2 | FFv | ;   if   | FFv | + | FFe | ≤ 2n − 5 | FFv | + | FFe | ≤ 2n − 5   and   n ≥ 4n ≥ 4   is   even ,   then   FQn − FFv − FFeFQn − FFv − FFe   contains   a   fault - free   cycle   of   every   odd   length   from   n + 1n + 1   to   2n − 2 | FFv | − 12n − 2 | FFv | − 1 . ' ,   ' title ' :   ' Cycles   embedding   in   folded   hypercubes   under   the   conditional   fault   model ' } 
{ ' abstract ' :   ' Companies   have   invested   considerable   resources   in   the   implementation   of   enterprise   resource   planning   ( ERP )   systems .   The   results   initially   expected   have   rarely   been   reached .   The   optimisation   ( or   efficient   use )   of   such   information   systems   is   nowadays   becoming   a   major   factor   for   firms   striving   to   reach   their   performance   objectives .   After   presenting   a   synthesis   of   several   studies   on   ERP   projects ,   we   build   on   the   findings   of   a   French   investigation   into   the   assessment   and   optimisation   of   ERP   performance .   A   classification   of   company   positions   regarding   their   ERP   use ,   based   on   both   software   maturity   and   strategic   deployment   directions ,   and   an   improvement   process   are   proposed .   Industrial   cases   allow   validation   of   this   approach . ' ,   ' title ' :   ' A   classification   for   better   use   of   ERP   systems ' } 
{ ' abstract ' :   ' This   paper   presents   a   time - domain   biosensor   array   that   uses   a   capacitor - less   current - mode   analog - to - time   converter   ( CMATC )   and   logarithmic   cyclic   time - attenuation - based   TDC   with   discharging   acceleration .   Combining   the   exponential   function   of   the   CMATC   and   logarithmic   function   of   the   proposed   TDC   offers   linear   input - output   characteristics .   The   time - domain   property   enables   bio - imaging   at   a   high   spatial   resolution   and   large   scale   while   maintaining   scalability .   Measurement   results   with   a   0.25 - μ m   test   chip   successfully   demonstrated   linear   input - output   characteristics . ' ,   ' title ' :   ' A   scalable   time - domain   biosensor   array   using   logarithmic   cyclic   time - attenuation - based   TDC   for   high - resolution   and   large - scale   bio - imaging ' } 
{ ' abstract ' :   ' Compared   to   current   mobile   networks ,   next - generation   mobile   networks   are   expected   to   support   higher   numbers   of   simultaneously   connected   devices   and   to   achieve   higher   system   spectrum   efficiency   and   lower   power   consumption .   To   achieve   these   goals ,   we   study   the   multi - sharing   device - to - device   ( D2D )   communication ,   which   allows   any   cellular   user   equipment   to   share   its   radio   resource   with   multiple   D2D   devices .   We   jointly   consider   resource   block   reuse   and   power   control   and   then   develop   the   MISS   algorithm .   Simulation   results   show   that   MISS   performs   very   well   in   terms   of   transmission   power   consumption ,   system   throughput ,   and   the   number   of   permitted   D2D   devices . ' ,   ' title ' :   ' Joint   Resource   Block   Reuse   and   Power   Control   for   Multi - Sharing   Device - to - Device   Communication ' } 
{ ' abstract ' :   ' This   paper   is   concerned   with   event - triggered   H ∞ H ∞   filtering   for   delayed   neural   networks   via   sampled   data .   A   novel   event - triggered   scheme   is   proposed ,   which   can   lead   to   a   significant   reduction   of   the   information   communication   burden   in   the   network ;   the   feature   of   this   scheme   is   that   whether   or   not   the   sampled   data   should   be   transmitted   is   determined   by   the   current   sampled   data   and   the   error   between   the   current   sampled   data   and   the   latest   transmitted   data .   By   constructing   a   proper   Lyapunov – Krasovskii   functional ,   utilizing   the   reciprocally   convex   combination   technique   and   Jensen ’ s   inequality   sufficient   conditions   are   derived   to   ensure   that   the   resultant   filtering   error   system   is   asymptotically   stable .   Based   on   the   derived   H ∞ H ∞   performance   analysis   results ,   the   H ∞ H ∞   filter   design   is   formulated   in   terms   of   Linear   Matrix   Inequalities   ( LMIs ) .   Finally ,   the   proposed   stability   conditions   are   demonstrated   with   numerical   example . ' ,   ' title ' :   ' Event - triggered   H   ∞   filtering   for   delayed   neural   networks   via   sampled - data ' } 
{ ' abstract ' :   ' For   the   double   integrator   with   matched   Lipschitz   disturbances   we   propose   a   continuous   homogeneous   controller   providing   finite - time   stability   of   the   origin .   The   disturbance   is   compensated   exactly   in   finite   time   using   a   discontinuous   function   through   an   integral   action .   Since   the   controller   is   dynamic ,   the   closed   loop   is   a   third   order   system   that   achieves   a   third   order   sliding   mode   in   the   steady   state .   The   stability   and   robustness   properties   of   the   controller   are   proven   using   a   smooth   and   homogeneous   strict   Lyapunov   function   ( LF ) .   In   a   first   stage ,   the   gains   of   the   controller   and   the   LF   are   designed   using   a   method   based   on   Polya ’ s   Theorem .   In   a   second   stage   the   controller ’ s   gains   are   adjusted   through   a   sum   of   squares   representation   of   the   LF . ' ,   ' title ' :   ' Design   of   Continuous   Twisting   Algorithm ' } 
{ ' abstract ' :   ' Big   data   is   now   rapidly   expanding   into   various   domains   such   as   banking ,   insurance   and   e - commerce .   Data   analysis   and   related   studies   have   attracted   more   attentions .   In   health   insurance ,   abuse   of   diagnosis   is   one   of   the   key   fraud   problems ,   which   damages   the   interests   of   insured   people .   To   address   this   issue ,   numbers   of   studies   have   focused   on   this   topic .   This   paper   develops   a   healthcare   fraud   detection   approach   based   on   the   trustworthiness   of   doctors   to   distinguish   fraud   cases   from   normal   records .   Compared   to   conventional   methods ,   our   approach   can   detect   healthcare   fraud   in   a   good   accuracy   by   only   little   feature   information   from   healthcare   data   without   the   violation   of   privacy .   This   approach   combines   a   weighted   HITS   algorithm   with   a   frequent   pattern   mining   algorithm   to   calculate   a   rational   treatment   model   of   a   certain   disease .   In   addition ,   this   paper   also   introduces   the   copy   precision   behavior   in   the   treatment   sequences   of   patients ,   which   is   a   critical   metric   to   learn   the   trustworthiness   of   doctors .   The   numerical   validation   with   a   healthcare   dataset   demonstrates   that   healthcare   fraud   by   misdiagnosis   in   healthcare   treatments   can   be   successfully   detected   by   employing   the   developed   fraud   detection   approach . ' ,   ' title ' :   ' Healthcare   Fraud   Detection   Based   on   Trustworthiness   of   Doctors ' } 
{ ' abstract ' :   ' In   this   paper   we   study   data   collection   in   an   energy   renewable   sensor   network   for   scenarios   such   as   traffic   monitoring   on   busy   highways ,   where   sensors   are   deployed   along   a   predefined   path   ( the   highway )   and   a   mobile   sink   travels   along   the   path   to   collect   data   from   one - hop   sensors   periodically .   As   sensors   are   powered   by   renewable   energy   sources ,   time - varying   characteristics   of   ambient   energy   sources   poses   great   challenges   in   the   design   of   efficient   routing   protocols   for   data   collection   in   such   networks .   In   this   paper   we   first   formulate   a   novel   data   collection   maximization   problem   by   adopting   multi - rate   data   transmissions   and   performing   transmission   time   slot   scheduling ,   and   show   that   the   problem   is   NP - hard .   We   then   devise   an   offline   algorithm   with   a   provable   approximation   ratio   for   the   problem   by   exploiting   the   combinatorial   property   of   the   problem ,   assuming   that   the   harvested   energy   at   each   node   is   given   and   link   communications   in   the   network   are   reliable .   We   also   extend   the   proposed   algorithm   by   minor   modifications   to   a   general   case   of   the   problem   where   the   harvested   energy   at   each   sensor   is   not   known   in   advance   and   link   communications   are   not   reliable .   We   thirdly   develop   a   fast ,   scalable   online   distributed   algorithm   for   the   problem   in   realistic   sensor   networks   in   which   neither   the   global   knowledge   of   the   network   topology   nor   sensor   profiles   such   as   sensor   locations   and   their   harvested   energy   profiles   is   given .   Furthermore ,   we   also   consider   a   special   case   of   the   problem   where   each   node   has   only   a   fixed   transmission   power ,   for   which   we   propose   an   exact   solution   to   the   problem .   We   finally   conduct   extensive   experiments   by   simulations   to   evaluate   the   performance   of   the   proposed   algorithms .   Experimental   results   demonstrate   that   the   proposed   algorithms   are   efficient   and   the   solutions   obtained   are   fractional   of   the   optimum . ' ,   ' title ' :   ' Data   Collection   Maximization   in   Renewable   Sensor   Networks   via   Time - Slot   Scheduling ' } 
{ ' abstract ' :   ' An   increasing   number   of   businesses   are   migrating   their   IT   operations   to   the   cloud .   Likewise   there   is   an   increased   emphasis   on   data   analytics   based   on   multiple   datasets   and   sources   to   derive   information   not   derivable   when   a   dataset   is   mined   in   isolation .   While   ensuring   security   of   data   and   computation   outsourced   to   a   third   party   cloud   service   provider   is   in   itself   challenging ,   supporting   mash - ups   and   analytics   of   data   from   different   parties   hosted   across   different   services   is   even   more   so .   In   this   paper   we   propose   a   cloud - based   service   allowing   multiple   parties   to   perform   secure   multi - party   secure   sum   computation   using   their   clouds   as   delegates .   Our   scheme   provides   data   privacy   both   from   the   delegates   as   well   as   from   the   other   data   owners   under   a   lazy - and - curious   adversary   ( semi - honest )   model .   We   then   describe   how   such   a   secure   sum   primitive   may   be   used   in   various   collaborative ,   cloud - based   distributed   data   mining   tasks   ( classification ,   association   rule   mining   and   clustering ) .   We   implement   a   prototype   and   benchmark   the   service ,   both   as   a   stand - alone   secure   sum   service ,   and   as   a   building   block   for   more   complex   analytics .   The   results   suggest   reasonable   overhead   and   demonstrate   the   practicality   of   carrying   out   privacy   preserved   distributed   analytics   despite   migrating   ( encrypted )   data   to   pos -   sibly   different   and   untrusted   ( semi - honest )   cloud   services . ' ,   ' title ' :   ' Delegated   Secure   Sum   Service   for   Distributed   Data   Mining   in   Multi - Cloud   Settings ' } 
{ ' abstract ' :   ' This   paper   fundamentally   investigates   the   performance   of   evolutionary   multiobjective   optimization   ( EMO )   algorithms   for   computationally   hard   0 - 1   combinatorial   optimization ,   where   a   strict   theoretical   analysis   is   generally   out   of   reach   due   to   the   high   complexity   of   the   underlying   problem .   Based   on   the   examination   of   problem   features   from   a   multiobjective   perspective ,   we   improve   the   understanding   of   the   efficiency   of   a   simple   dominance - based   EMO   algorithm   with   unbounded   archive   for   multiobjective   NK - landscapes   with   correlated   objective   values .   More   particularly ,   we   adopt   a   statistical   approach ,   based   on   simple   and   multiple   linear   regression   analysis ,   to   enquire   the   expected   running   time   of   global   SEMO   with   restart   for   identifying   a   ( 1 + e ) - approximation   of   the   Pareto   set   for   small - size   enumerable   instances .   Our   analysis   provides   further   insights   on   the   EMO   search   behavior   and   on   the   most   important   features   that   characterize   the   difficulty   of   an   instance   for   this   class   of   problems   and   algorithms . ' ,   ' title ' :   ' A   feature - based   performance   analysis   in   evolutionary   multiobjective   optimization ' } 
{ ' abstract ' :   ' Functional   biological   sequences ,   which   typically   come   in   families ,   have   retained   some   level   of   similarity   and   function   during   evolution .   Finding   consensus   regions ,   alignment   of   sequences ,   and   identifying   the   relationship   between   a   sequence   and   a   family   allow   inferences   about   the   function   of   the   sequences .   Profile   hidden   Markov   models   ( HMMs )   are   generally   used   to   identify   those   relationships .   A   profile   HMM   can   be   trained   on   unaligned   members   of   the   family   using   conventional   algorithms   such   as   Baum - Welch ,   Viterbi ,   and   their   modifications .   The   overall   quality   of   the   alignment   depends   on   the   quality   of   the   trained   model .   Unfortunately ,   the   conventional   training   algorithms   converge   to   suboptimal   models   most   of   the   time .   This   work   proposes   a   training   algorithm   that   early   identifies   many   imperfect   models .   The   method   is   based   on   the   Simulated   Annealing   approach   widely   used   in   discrete   optimization   problems .   The   training   algorithm   is   implemented   as   a   component   in   HMMER .   The   performance   of   the   algorithm   is   discussed   on   protein   sequence   data . ' ,   ' title ' :   ' Simulated   annealing   algorithm   with   biased   neighborhood   distribution   for   training   profile   models ' } 
{ ' abstract ' :   ' The   Canny   algorithm   is   a   well   known   edge   detector   that   is   widely   used   in   the   previous   processing   stages   in   several   algorithms   related   to   computer   vision .   An   alternative ,   the   LIP - Canny   algorithm ,   is   based   on   a   robust   mathematical   model   closer   to   the   human   vision   system ,   obtaining   better   results   in   terms   of   edge   detection .   In   this   work   we   describe   LIP - Canny   algorithm   under   the   perspective   from   its   parallelization   and   optimization   by   using   the   NVIDIA   CUDA   framework .   Furthermore ,   we   present   comparative   results   between   an   implementation   of   this   algorithm   using   NVIDIA   CUDA   and   the   analogue   using   a   C / C++   approach . ' ,   ' title ' :   ' Parallelizing   and   optimizing   LIP - canny   using   NVIDIA   CUDA ' } 
{ ' abstract ' :   ' This   paper   presents   an   efficient   Bayesian   blind   multiuser   receiver   for   long   code   multipath   CDMA   systems .   The   proposed   receiver   employs   the   adaptive   sampling   method   for   the   Bayesian   inference   procedure   to   estimate   the   data   symbols   and   multipath   parameters .   Compared   to   the   other   reported   Bayesian   Monte   Carlo   receivers   for   long   code   multipath   CDMA   systems ,   the   proposed   one   achieves   a   faster   convergence   and   a   lower   computational   complexity   to   attain   comparable   performance .   Simulation   results   are   presented   to   demonstrate   the   effectiveness   of   the   proposed   Bayesian   blind   multiuser   receiver . ' ,   ' title ' :   ' Blind   Multiuser   Detection   for   Long   Code   Multipath   DS - CDMA   Systems   with   Bayesian   MC   Techniques ' } 
{ ' abstract ' :   ' Spreadsheets   are   by   far   the   most   prominent   example   of   end - user   programs   of   ample   size   and   substantial   structural   complexity .   In   addition ,   spreadsheets   are   usually   not   tested   very   rigorously   and   thus   comprise   faults .   Locating   faults   is   a   hard   task   due   to   the   size   and   the   structure ,   which   is   usually   not   directly   visible   to   the   user ,   i . e . ,   the   functions   are   hidden   behind   the   cells   and   only   the   computed   values   are   presented .   Hence ,   there   is   a   strong   need   for   debugging   support .   In   this   paper ,   we   adapt   three   program - debugging   approaches   that   have   been   designed   for   more   traditional   procedural   or   object - oriented   programming   languages .   These   techniques   are   Spectrum - based   Fault   Localization ,   Spectrum - Enhanced   Dynamic   Slicing ,   and   Constraint - based   Debugging .   Beside   the   theoretical   foundations ,   we   present   a   more   sophisticated   empirical   evaluation   including   a   comparison   of   these   approaches .   The   empirical   evaluation   shows   that   Sfl   ( Spectrum - based   Fault   Localization )   and   Sendys   ( Spectrum   ENhanced   Dynamic   Slicing )   are   the   most   promising   techniques . ' ,   ' title ' :   ' On   the   empirical   evaluation   of   fault   localization   techniques   for   spreadsheets ' } 
{ ' abstract ' :   ' This   work   provides   elements   to   highlight   the   reliability   challenges   related   to   the   technology   scaling   and   the   BTI   variability .   Through   main   milestones   including   device   reliability   scaling   model   ( for   both   mean   and   spread ) ,   a   discussion   on   the   physical   origin   of   BTI   variability   and   a   digital   IP   failure   rate   analytical   model ,   the   evolution   of   digital   IP   failure   rates   along   the   ITRS   scaling   roadmap   is   assessed .   and   an   analysis   of   the   ITRS   roadmap   on   digital   IP   failure   rates .   This   study   offers   new   perspectives   towards   product   hardening   and   qualification   with   respect   to   both   fresh   and   BTI - related   local   variability ,   especially   in   context   where   Adaptive   Voltage   Scaling   ( AVS )   is   used   to   compensate   for   process   centerings . ' ,   ' title ' :   ' From   BTI   variability   to   product   failure   rate :   A   technology   scaling   perspective ' } 
{ ' abstract ' :   ' In   this   paper   we   discuss   the   problem   of   calculating   the   reachable   states   of   a   dynamical   system   defined   by   ordinary   differential   equations   or   inclusions .   We   present   a   prototype   system   for   approximating   this   set   and   demonstrate   some   experimental   results . ' ,   ' title ' :   ' Reachability   Analysis   via   Face   Lifting ' } 
{ ' abstract ' :   ' By   introducing   the   new   concepts   of   fuzzy     β   - covering   and   fuzzy     β   - neighborhood ,   we   define   two   new   types   of   fuzzy   covering   rough   set   models   which   can   be   regarded   as   bridges   linking   covering   rough   set   theory   and   fuzzy   rough   set   theory .   We   show   the   properties   of   the   two   models ,   and   reveal   the   relationships   between   the   two   models   and   some   others .   Moreover ,   we   present   the   matrix   representations   of   the   newly   defined   lower   and   upper   approximation   operators   so   that   the   calculation   of   lower   and   upper   approximations   of   subsets   can   be   converted   into   operations   on   matrices .   Finally ,   we   generalize   the   models   and   their   matrix   representations   to     L   - fuzzy   covering   rough   sets   which   are   defined   over   fuzzy   lattices . ' ,   ' title ' :   ' Two   fuzzy   covering   rough   set   models   and   their   generalizations   over   fuzzy   lattices ' } 
{ ' abstract ' :   ' Mobile   applications   are   becoming   complex   software   systems   that   must   be   developed   quickly   and   evolve   regularly   to   fit   new   user   requirements   and   execution   contexts .   However ,   addressing   these   constraints   may   result   in   poor   design   choices ,   known   as   antipatterns ,   which   may   degrade   software   quality   and   performance .   Thus ,   the   automatic   detection   of   antipatterns   is   an   important   activity   that   eases   the   future   maintenance   and   evolution   tasks .   Moreover ,   it   helps   developers   to   refactor   their   applications   and   thus ,   to   improve   their   quality .   While   antipatterns   are   well - known   in   object - oriented   applications ,   their   study   in   mobile   applications   is   still   in   their   infancy .   In   this   paper ,   we   presents   a   tooled   approach ,   called   P   aprika   ,   to   analyze   Android   applications   and   to   detect   object - oriented   and   Android - specific   antipatterns   from   binaries   of   applications . ' ,   ' title ' :   ' An   approach   to   detect   Android   antipatterns ' } 
{ ' abstract ' :   ' In   this   paper   we   present   a   new   method   for   object   categorization .   Firstly   an   image   representation   is   obtained   by   the   proposed   hierarchical   learning   method   consisting   of   alternating   between   local   coding   and   maximum   pooling   operations ,   where   the   local   coding   operation   induces   discrimination   while   the   image   descriptor   and   maximum   pooling   operation   induces   invariance   in   hierarchical   architecture .   Then   the   obtained   effective   image   representation   is   passed   to   a   linear   classifier   which   is   suitable   for   large   databases   for   object   categorization .   We   have   demonstrated   that   the   proposed   method   is   robust   to   image   variations   and   has   low   sample   complexity . ' ,   ' title ' :   ' Object   categorization   based   on   hierarchical   learning ' } 
{ ' abstract ' :   ' We   have   previously   proposed   a   howling   canceller   which   cancels   howling   by   using   a   cascade   notch   filter   designed   from   a   distance   between   a   loudspeaker   and   a   microphone .   This   method   utilizes   a   pilot   signal   to   estimate   the   distance .   In   this   paper ,   we   introduce   two   methods   into   the   distance - based   howling   canceller   to   improve   speech   quality .   The   first   one   is   an   adaptive   cascade   notch   filter   which   adaptively   adjusts   the   nulls   to   eliminate   howling   and   to   keep   speech   components .   The   second   one   is   a   silent   pilot   signal   whose   frequencies   exist   in   the   ultrasonic   band ,   and   it   is   inaudible   while   on   transmission .   We   implement   the   proposed   howling   canceller   on   a   DSP   to   evaluate   its   capability .   The   experimental   results   show   that   the   proposed   howling   canceller   improves   speech   quality   in   comparison   to   the   conventional   one . ' ,   ' title ' :   ' A   High   Speech   Quality   Distance - Based   Howling   Canceller   with   Adaptive   Cascade   Notch   Filter   and   Silent   Pilot   Signal ' } 
{ ' abstract ' :   ' Purpose   –   This   paper   aims   to   look   at   how   varying   terminology   is   used   on   school   library   web   sites   and   how   that   compares   to   student   preferences . Design / methodology / approach   –   Provides   research   conduced   by   surveying   practicing   school   librarians   and   k ‐ 12   students . Findings   –   Terminology   varies   greatly   on   school   library   web   sites .   Further ,   students   prefer   common   language   use . Practical   implications   –   Practicing   librarians   may   consider   revising   their   web   sites   in   order   to   make   them   more   accessible   for   their   students . Originality / value   –   This   paper   provides   original   research   into   school   library   web   sites ,   an   area   that   is   lacking . ' ,   ' title ' :   ' School   library   web   site   terminology ' } 
{ ' abstract ' :   ' Recently ,   numerous   multireceiver   identity - based   encryption   or   identity - based   broadcast   encryption   schemes   have   been   introduced   with   bilinear   pairing   and   probabilistic   map - to - point   MTP   function .   As   the   bilinear   pairing   and   MTP   functions   are   expensive   operations ,   any   cryptographic   schemes   based   on   these   operations   experience   high   computational   burden .   The   certificateless   public   key   cryptography   sidesteps   the   private   key   escrow   problem   occurring   in   identity - based   cryptosystem   and   certificate   management   troubles   of   certificate   authority - based   public   key   cryptography   CA - PKC .   We   observed   that   certificateless   multireceiver   encryption   CL - MRE   scheme   without   pairing   and   MTP   hash   function   has   not   yet   been   considered   in   the   literature .   In   this   paper ,   we   proposed   a   bilinear   pairing   and   MTP   hash - function - free   CL - MRE   scheme   with   chosen   ciphertext   attack   resilience .   The   detailed   analyses   provide   evidence   that   our   scheme   achieves   forward   secrecy ,   backward   secrecy ,   and   low   computation   costs   than   others .   The   scheme   also   provides   confidentiality   of   the   message   and   receiver   anonymity   in   the   random   oracle   model   with   the   hardness   of   computational   Diffie - Hellman   problem .   Copyright   ©   2014   John   Wiley   &   Sons ,   Ltd . ' ,   ' title ' :   ' Anonymous   and   provably   secure   certificateless   multireceiver   encryption   without   bilinear   pairing ' } 
{ ' abstract ' :   ' We   study   the   problem   of   approximating   one - dimensional   nonintegrable   codistributions   by   integrable   ones   and   apply   the   resulting   approximations   to   approximate   feedback   linearization   of   single - input   systems .   The   approach   derived   in   this   paper   allows   a   linearizable   nonlinear   system   to   be   found   that   is   close   to   the   given   system   in   a   least - squares   ( L2 )   sense .   A   linearly   controllable   single - input   affine   nonlinear   system   is   feedback   linearizable   if   and   only   if   its   characteristic   distribution   is   involutive   ( hence   integrable )   or ,   equivalently ,   any   characteristic   one - form   ( a   one - form   that   annihilates   the   characteristic   distribution )   is   integrable .   We   study   the   problem   of   finding   ( least - squares   approximate )   integrating   factors   that   make   a   fixed   characteristic   one - form   close   to   being   exact   in   anL2   sense .   A   given   one - form   can   be   decomposed   into   exact   and   inexact   parts   using   the   Hodge   decomposition .   We   derive   an   upper   bound   on   the   size   of   the   inexact   part   of   a   scaled   characteristic   one - form   and   show   that   a   least - squares   integrating   factor   provides   the   minimum   value   for   this   upper   bound .   We   also   consider   higher - order   approximate   integrating   factors   that   scale   a   nonintegrable   one - form   in   a   way   that   the   scaled   form   is   closer   to   being   integrable   inL2   together   with   some   derivatives   and   derive   similar   bounds   for   the   inexact   part .   This   allows   a   linearizable   nonlinear   system   that   is   close   to   the   given   system   in   a   least - squares   ( L2 )   sense   together   with   some   derivatives   to   be   found .   The   Sobolev   embedding   techniques   allow   us   to   obtain   an   upper   bound   on   the   uniform   ( L ∞ )   distance   between   the   nonlinear   system   and   its   linearizable   approximation . ' ,   ' title ' :   ' Least - squares   integration   of   one - dimensional   codistributions   with   application   to   approximate   feedback   linearization ' } 
{ ' abstract ' :   ' Latent   sector   errors   in   disk   drives   affect   only   a   few   data   sectors .   They   occur   silently   and   are   detected   only   when   the   affected   area   is   accessed   again .   If   a   latent   error   is   detected   while   the   storage   system   is   operating   under   reduced   redundancy ,   i . e . ,   during   a   RAID   rebuild ,   then   data   loss   may   occur .   Various   features   such   as   scrubbing   and   intra - disk   data   redundancy   are   proposed   to   detect   and / or   recover   from   latent   errors   and   avoid   data   loss .   While   such   features   enhance   data   availability   in   the   storage   system ,   their   execution   may   cause   performance   degradation .   In   this   paper ,   we   evaluate   the   effectiveness   of   scrubbing   and   intra - disk   data   redundancy   in   improving   data   availability   while   the   overall   goal   is   to   maintain   user   performance   within   predefined   bounds .   We   show   that   by   treating   them   as   low   priority   background   activities   and   scheduling   them   efficiently   during   idle   times ,   these   features   remain   performance - wise   transparent   to   the   storage   system   user   while   still   improving   data   reliability .   Detailed   trace - driven   simulations   show   that   the   mean   time   to   data   loss   ( MTTDL )   improves   by   up   to   5   orders   of   magnitude   if   these   features   are   implemented   independently .   By   scheduling   concurrently   both   scrubbing   and   intra - disk   parity   updates   during   idle   times   in   disk   drives ,   MTTDL   improves   by   as   much   as   8   orders   of   magnitude . ' ,   ' title ' :   ' Enhancing   data   availability   in   disk   drives   through   background   activities ' } 
{ ' abstract ' :   ' Financial   crisis   forecasting   has   been   a   long - standing   challenge   that   often   involves   couplings   between   indicators   of   multiple   markets .   Such   couplings   include   implicit   relations   that   might   not   be   effectively   detected   from   raw   market   observations .   However ,   most   methods   for   crisis   forecasting   rely   directly   on   market   observations   and   might   not   detect   the   hidden   interactions   between   markets .   To   this   end ,   the   authors   explore   coupled   market   state   analysis   ( CMSA ) ,   assuming   that   the   observations   of   markets   are   governed   by   a   collection   of   intra -   and   intercoupled   hidden   market   states .   Accordingly ,   they   built   a   forecaster   based   on   these   coupled   market   states   instead   of   observations . ' ,   ' title ' :   ' Financial   Crisis   Forecasting   via   Coupled   Market   State   Analysis ' } 
{ ' abstract ' :   ' In   this   paper ,   an   “ intelligent ”   isolated   intersection   control   system   was   developed .   The   developed   “ intelligent ”   system   makes   “ real   time ”   decisions   as   to   whether   to   extend   ( and   how   much )   current   green   time .   The   model   developed   is   based   on   the   combination   of   the   dynamic   programming   and   neural   networks .   Many   tests   show   that   the   outcome   ( the   extension   of   the   green   time )   of   the   proposed   neural   network   is   nearly   equal   to   the   best   solution .   Practically   negligible   CPU   times   were   achieved ,   and   were   thus   absolutely   acceptable   for   the   “ real   time ”   application   of   the   developed   algorithm . ' ,   ' title ' :   ' Dynamic   programming — neural   network   real - time   traffic   adaptive   signal   control   algorithm ' } 
{ ' abstract ' :   ' This   issue   features   expanded   versions   of   articles   selected   from   the   2014   AAAI   Conference   on   Innovative   Applications   of   Artificial   Intelligence   held   in   Quebec   City ,   Canada .   We   present   a   selection   of   four   articles   describing   deployed   applications   plus   two   more   articles   that   discuss   work   on   emerging   applications . ' ,   ' title ' :   ' Introduction   to   the   Special   Issue   on   Innovative   Applications   of   Artificial   Intelligence   2014 ' } 
{ ' abstract ' :   ' Although   frequently   used   in   fractal   compression   quadrant - based   classification   exhibits   a   significant   defect   which   has   not   been   described   in   the   literature .   We   give   an   efficient   solution   to   this   problem   by   controlling   the   class   structure   based   on   an   adaptive   threshold .   This   makes   this   classification   technique   a   very   efficient   and   competitive   one   also   for   block   matching   motion   compensation   algorithms   in   video   coding . ' ,   ' title ' :   ' Resolving   a   defect   in   quadrant - based   classification   for   fast   block - matching ' } 
{ ' abstract ' :   ' Where   there   are   infinitely   many   possible   basic   states   of   the   world ,   a   standard   probability   function   must   assign   zero   probability   to   each   state   –   since   any   finite   probability   would   sum   to   over   one .   This   generates   problems   for   any   decision   theory   that   appeals   to   expected   utility   or   related   notions .   For   it   leads   to   the   view   that   a   situation   in   which   one   wins   a   million   dollars   if   any   of   a   thousand   of   the   equally   probable   states   is   realized   has   an   expected   value   of   zero   ( since   each   such   state   has   probability   zero ) .   But   such   a   situation   dominates   the   situation   in   which   one   wins   nothing   no   matter   what   ( which   also   has   an   expected   value   of   zero ) ,   and   so   surely   is   more   desirable .   I   formulate   and   defend   some   principles   for   evaluating   options   where   standard   probability   functions   cannot   strictly   represent   probability   –   and   in   particular   for   where   there   is   an   infinitely   spread ,   uniform   distribution   of   probability .   The   principles   appeal   to   standard   probability   functions ,   but   overcome   at   least   some   of   their   limitations   in   such   cases . ' ,   ' title ' :   ' Standard   decision   theory   corrected ' } 
{ ' abstract ' :   ' Backed   by   the   European   Commission ,   a   consortium   of   partners   from   European   industry ,   financial   institutions ,   and   academia   has   embarked   on   a   research   project   to   develop   the   fundamentals   of   secure   electronic   commerce .   The   goal   of   the   9 - million   ECU   project ,   SEMPER   ( Secure   Electronic   Marketplace   for   Europe ) ,   is   to   provide   the   first   open   and   comprehensive   solutions   for   secure   commerce   over   the   Internet   and   other   public   information   networks .   We   describe   the   objectives   and   summarise   the   initial   architecture   of   SEMPER .   A   wide   range   of   businesses   are   rapidly   moving   to   explore   the   huge   potential   of   net -   worked   information   systems ,   especially   with   the   Internet - based   WWW   ( World - wide   Web ) .   The   Internet ,   which   already   connects   more   than   3   million   computers   and   a   sub -   stantially   larger   number   of   users ,   is   growing   at   a   breathtaking   pace   with   thousands   of   newcomers   every   day .   Although   the   Internet   has   its   roots   in   academia   and   is   still   domi -   nated   by   free - of - charge   information ,   dramatic   changes   are   expected   in   the   near   future .   For   instance ,   the   WWW   will   be   used   for   a   wide   variety   of   electronic   commerce   such   as   on - line   trade   or   delivery   of   advanced   multimedia   information   services .   The   evolution   of   broadband   networks   and   " information   highways "   will   intensify   this   trend .   The   need   for   secure   transactions   in   this   new   business   environment ,   which   involves   networks   available   to   the   general   public ,   has   triggered   a   number   of   related   efforts .   These   initial   developments   are   based   almost   exclusively   in   the   US   and   most   of   them   are   limited   to   proprietary ,   or   otherwise   closed   solutions ,   involving   only   electronic   payment   issues .   In   contrast ,   SEMPER   is   directed   towards   a   comprehensive   solution   for   secure   electronic   commerce ,   considering   legal ,   commercial ,   social ,   and   technical   requirements   as   well   as   different   options   for   an   electronic   marketplace . ' ,   ' title ' :   ' Development   of   a   Secure   Electronic   Marketplace   for   Europe ' } 
{ ' abstract ' :   ' Through   the   use   of   a   global   geometric   symmetry ,   detection   ellipses   are   proposed   in   this   paper .   Based   on   the   geometric   symmetry ,   the   proposed   method   first   locates   candidates   of   ellipses   centers .   In   the   meantime ,   according   to   these   candidate   centers ,   all   feature   points   in   an   input   image   are   grouped   into   several   subimages .   Then ,   for   each   subimage ,   by   using   geometric   properties   again ,   all   ellipses   are   extracted .   The   method   significantly   reduces   the   time   required   to   evaluate   all   possible   parameters   without   using   edge   direction   information .   Experimental   results   are   given   to   show   the   correctness   and   effectiveness   of   the   proposed   method . ' ,   ' title ' :   ' Detection   ellipses   by   finding   lines   of   symmetry   in   the   images   via   an   hough   transform   applied   to   straight   lines ' } 
{ ' abstract ' :   ' Automatic   crawling   of   Rich   Internet   Applications   ( RIAs )   is   a   challenge   because   client - side   code   modifies   the   client   dynamically ,   fetch -   ing   server - side   data   asynchronously .   Most   existing   solutions   model   RIAs   as   state   machines   with   DOMs   as   states   and   JavaScript   events   execution   as   transitions .   This   approach   fails   when   used   with   " real - life " ,   complex   RIAs ,   because   the   size   of   the   produced   model   is   much   too   large   to   be   practical .   In   this   paper ,   we   propose   a   new   method   to   crawl   AJAX - based   RIAs   in   an   efficient   manner   by   detecting   " components " ,   which   are   areas   of   the   DOM   that   are   independent   from   each   other ,   and   by   crawling   each   component   separately .   This   leads   to   a   dramatic   reduction   of   the   required   state   space   for   the   model ,   without   loss   of   content   coverage .   Our   method   does   not   require   prior   knowledge   of   the   RIA   nor   predefined   definition   of   components .   Instead ,   we   infer   the   components   by   observing   the   be -   havior   of   the   RIA   during   crawling .   Our   experimental   results   show   that   our   method   can   index   quickly   and   completely   industrial   RIAs   that   are   simply   out   of   reach   for   traditional   methods . ' ,   ' title ' :   ' Indexing   Rich   Internet   Applications   Using   Components - Based   Crawling ' } 
{ ' abstract ' :   ' One   important   aspect   of   constructing   an   overlay   network   is   how   to   exploit   network   locality   in   the   underlying   network .   In   this   paper ,   we   propose   a   scalable   protocol   for   constructing   an   overlay   network   that   takes   account   of   locality   of   network   hosts .   The   constructed   overlay   network   can   significantly   decrease   the   communication   cost   between   end - hosts .   Our   simulation   results   show   that   the   average   distance   between   a   pair   of   hosts   in   the   constructed   overlay   network   is   only   about   11%   of   the   one   in   a   traditional ,   randomly   connected   overlay   network .   Furthermore ,   our   proposed   overlay   considered   to   be   more   scalable   than   tree - based   or   mesh - based   overlays . ' ,   ' title ' :   ' Measurement - based   construction   of   locality - aware   overlay   networks ' } 
{ ' abstract ' :   ' This   paper   presents   a   low   cost ,   flexible   and   customizable   delay   measurement   system   developed   to   assess   the   performance   of   the   VTPE - hBEB   protocol .   The   proposed   system   can   be   used   to   evaluate   other   communication   protocols   as   well   as   to   measure   the   delay   between   two   repetitive   events . ' ,   ' title ' :   ' Delay   measurement   system   for   real - time   serial   data   streams ' } 
{ ' abstract ' :   " Service   robots   have   become   increasingly   important   subjects   in   our   lives .   However ,   they   are   still   facing   problems   like   adaptability   to   their   users .   While   major   work   has   focused   on   intelligent   service   robots ,   the   proposed   approaches   were   mostly   user   independent .   Our   work   is   part   of   the   FUI - RoboPopuli   project ,   which   concentrates   on   endowing   entertainment   companion   robots   with   adaptive   and   social   behaviour .   In   particular ,   we   are   interested   in   robots   that   are   able   to   learn   and   plan   so   that   they   adapt   and   personalize   their   behaviour   according   to   their   users .   Markov   Decision   Processes   ( MDPs )   are   largely   used   for   adaptive   robots   applications .   However ,   one   challenging   point   is   reducing   the   sample   complexity   required   to   learn   an   MDP   model ,   including   the   reward   function .   In   this   article ,   we   present   our   contribution   regarding   the   representation   and   the   learning   of   the   reward   function   through   analysing   interaction   traces   ( i . e .   the   interaction   history   between   the   robot   and   their   users ,   including   users '   feedback ) .   Our   approach   permits   to   generalise   the   learned   rewards   so   that   when   new   users   are   introduced ,   the   robot   may   quickly   adapt   using   what   it   learned   from   previous   experiences   with   other   users .   We   propose ,   in   this   article ,   two   algorithms   to   learn   the   reward   function .   The   first   is   direct   and   certain ,   the   robot   applies   with   a   user   what   it   learned   during   interaction   with   same   kind   of   users   ( i . e .   users   with   similar   profiles ) .   The   second   algorithm   generalises   what   it   learns   to   be   applied   to   all   kinds   of   users .   Through   simulation ,   we   show   that   the   generalised   algorithm   converges   to   an   optimal   reward   function   with   less   than   half   the   samples   needed   by   the   direct   algorithm . " ,   ' title ' :   " Adaptive   and   Personalised   Robots   -   Learning   from   Users '   Feedback " } 
{ ' abstract ' :   " Researches   of   sensor   networks   collecting   patients '   data   with   computerized   triage   tags ,   called   Triage   Network ,   are   attracting   attention .   The   listening   power   used   in   triage   tags   is   the   major   factor   of   lots   of   energy   consumption ,   and   consumption   of   energy   increases   when   sensor   nodes   always   communicate   with   other   nodes   in   active   state .   Hence ,   we   suppose   that   sensor   nodes   are   put   to   sleep   periodically   to   avoid   running   out   of   battery .   However ,   some   nodes   have   mobility   and   nodes   secede   from   the   network   according   to   patients   conditions   in   Triage   Network .   The   paths   are   failed   and   it   is   needed   to   reconstruct   paths   when   these   forwarding   nodes   move   or   secede   from   network .   Therefore ,   data   arrival   ratio   decreases   and   consumption   of   battery   increases   due   to   reconstruction   of   other   paths .   In   this   paper ,   we   propose   a   data   collection   method   using   two   types   of   forwarding   nodes ,   Stable   Nodes   and   Energy   Efficient   Nodes .   This   method   uses   two   types   of   forwarding   nodes   according   to   priority   of   data   and   avoids   loss   of   high   priority   data ,   improves   the   data   arrival   ratio   and   saves   the   energy   consumption .   We   evaluate   the   proposed   method   and   show   its   effectiveness   using   computer   simulations . " ,   ' title ' :   ' Data   collection   method   using   two   types   of   forwarding   nodes   for   energy   saving   in   triage   network ' } 
{ ' abstract ' :   ' This   paper   introduces   Golay - paired   Hadamard   matrices   for   fast   compressed   sensing   of   sparse   signals   in   the   time   or   spectral   domain .   These   sampling   operators   feature   low - memory   requirement ,   hardware - friendly   implementation   and   fast   computation   in   reconstruction .   We   show   that   they   require   a   nearly   optimal   number   of   measurements   for   faithful   reconstruction   of   a   sparse   signal   in   the   time   or   frequency   domain .   Simulation   results   demonstrate   that   the   proposed   sensing   matrices   offer   a   reconstruction   performance   similar   to   that   of   fully   random   matrices . ' ,   ' title ' :   ' Golay   meets   Hadamard :   Golay - paired   Hadamard   matrices   for   fast   compressed   sensing ' } 
{ ' abstract ' :   ' In   this   technical   note ,   the   problem   of   finite - time   output   regulation   control   for   a   class   of   disturbed   system   under   mismatching   condition   is   investigated   via   a   composite   control   design   manner .   The   composite   controller   is   developed   by   using   a   finite   time   control   technique   and   a   finite   time   disturbance   observer   ( FTDO ) .   A   key   idea   is   to   design   virtual   control   laws   based   on   estimation   values   of   the   disturbances   and   the   ith   ( 1 ≤ i ≤ n - 1   where   n   is   the   order   of   the   system )   order   derivative   of   disturbances .   Finite   time   stability   analysis   for   the   augmented   system   is   presented   by   means   of   Lyapunov   stability   theorems ,   which   shows   that   the   system   output   is   regulated   to   zero   in   finite   time   even   in   the   presence   of   mismatched   disturbances .   A   motion   control   application   demonstrates   the   effectiveness   and   attractive   properties   of   the   proposed   method . ' ,   ' title ' :   ' Continuous   Finite - Time   Output   Regulation   for   Disturbed   Systems   Under   Mismatching   Condition ' } 
{ ' abstract ' :   ' In   this   paper   we   propose   an   approach   for   enhanced   data   protection   in   the   cloud ,   based   upon   accountability   governance .   Specifically ,   the   relationships   between   accountability ,   risk   and   trust   are   analyzed   in   order   to   suggest   characteristics   and   means   to   address   data   governance   issues   involved   when   organizations   or   individuals   adopt   cloud   computing .   This   analysis   takes   into   account   insights   from   a   variety   of   stakeholders   within   cloud   ecosystems   obtained   by   running   an   elicitation   workshop . ' ,   ' title ' :   ' Accountability ,   Risk ,   and   Trust   in   Cloud   Services :   Towards   an   Accountability - Based   Approach   to   Risk   and   Trust   Governance ' } 
{ ' abstract ' :   ' Xue   et   al .   recently   proposed   an   innovative   mutual   authentication   and   key   agreement   scheme   for   wireless   sensor   networks   based   on   temporal   credential   using   smart   cards .   However ,   in   this   paper   we   demonstrate   that   their   scheme   is   vulnerable   to   password   guessing   attacks ,   node   capture   attacks   and   denial - of - service   attacks .   Furthermore   we   show   that   their   scheme   has   some   inconsistencies   which   make   it   less   secure   and   more   computationally   costly   than   originally   presented . ' ,   ' title ' :   ' Notes   on   A   Temporal - Credential - Based   Mutual   Authentication   and   Key   Agreement   Scheme   for   Wireless   Sensor   Networks ' } 
{ ' abstract ' :   ' Persistent   Scatterer   Interferometry   ( PSI )   has   been   widely   used   for   landslide   studies   in   recent   years .   This   paper   investigated   the   spatial   patterns   of   PSI   point   targets   and   landslide   occurrences   in   the   Arno   River   basin   in   Central   Italy .   The   main   purpose   is   to   analyze   whether   spatial   patterns   of   Persistent   Scatterers   ( PS )   can   be   recognized   as   indicators   of   landslide   occurrences   throughout   the   whole   basin .   The   bivariate   K - function   was   employed   to   assess   spatial   relationships   between   PS   and   landslides .   The   PSI   point   targets   were   acquired   from   almost   4   years   ( from   March   2003   to   January   2007 )   of   RADARSAT - 1   images .   The   landslide   inventory   was   collected   from   15   years   ( from     1992 – 2007 )   of   surveying   and   mapping   data ,   mainly   including   remote   sensing   data ,   topographic   maps   and   field   investigations .   The   proposed   approach   is   able   to   assess   spatial   patterns   between   a   variety   of   PS   and   landslides ,   in   particular ,   to   understand   if   PSI   point   targets   are   spatially   clustered   ( spatial   attraction )   or   randomly   distributed   ( spatial   independency )   on   various   types   of   landslides   across   the   basin .   Additionally ,   the   degree   and   scale   distances   of   PS   clustering   on   a   variety   of   landslides   can   be   characterized .   The   results   rejected   the   null   hypothesis   that   PSI   point   targets   appear   to   cluster   similarly   on   four   types   of   landslides   ( slides ,   flows ,   falls   and   creeps )   in   the   Arno   River   basin .   Significant   influence   of   PS   velocities   and   acquisition   orbits   can   be   noticed   on   detecting   landslides   with   different   states   of   activities .   Despite   that   the   assessment   may   be   influenced   by   the   quality   of   landslide   inventory   and   Synthetic   Aperture   Radar   ( SAR )   images ,   the   proposed   approach   is   expected   to   provide   guidelines   for   studies   trying   to   detect   and   investigate   landslide   occurrences   at   a   regional   scale   through   spatial   statistical   analysis   of   PS ,   for   which   an   advanced   understanding   of   the   impact   of   scale   distances   on   landslide   clustering   is   fundamentally   needed . ' ,   ' title ' :   ' Investigating   Spatial   Patterns   of   Persistent   Scatterer   Interferometry   Point   Targets   and   Landslide   Occurrences   in   the   Arno   River   Basin ' } 
{ ' abstract ' :   ' This   article   describes   a   middleware   used   in   display   cluster   of   real   time   visual   simulation   system .   This   middleware   which   based   on   TCP / IP   protocol   provides   the   communication   infrastructure   for   visual   simulation   system .   It   provides   unified   process   logic   and   interfaces   for   various   status   and   frame   data   and   the   packing / unpacking   functions   of   simulation   data   without   concerning   the   details   of   the   data .   We   found   two   classes   of   display   synchronization   problems   and   provided   the   resolution   of   them .   The   middleware   provides   a   group   of   APIs   which   hide   the   details   of   data   packing / unpacking ,   processing   and   transmission   and   meets   the   requirement   of   flexibility ,   efficiency   and   extensibility .   This   middleware   has   been   successfully   implemented   to   the   display   cluster   of   several   tower   simulation   system . ' ,   ' title ' :   ' The   Research   of   High   Level   Data   Communication   Middleware   of   Display   Cluster   Used   in   Real   Time   Simulation   Environment ' } 
{ ' abstract ' :   ' The   scattering   parameters   are   fundamental   in   the   characterization   of   electrical   devices   at   high   frequencies .   They   are   particularly   useful   for   analyzing   multiport   high - frequency   and   microwave   networks .   However ,   they   are   not   adequately   presented   in   most ,   if   not   all ,   microwave   engineering   books .   This   paper   identifies   two   common   deficiencies   in   the   way   scattering   parameters   are   being   presented   in   these   books .   It   provides   additional   information   that   should   supplement   those   books   or   book   chapters   on   scattering   parameters . ' ,   ' title ' :   ' Deficiencies   in   the   way   scattering   parameters   are   taught ' } 
{ ' abstract ' :   ' We   study   the   reliability   maximization   problem   in   WDM   networks   with   random   link   failures .   Reliability   in   these   networks   is   defined   as   the   probability   that   the   logical   network   is   connected ,   and   it   is   determined   by   the   underlying   lightpath   routing   and   the   link   failure   probability .   We   show   that   in   general   the   optimal   lightpath   routing   depends   on   the   link   failure   probability ,   and   characterize   the   properties   of   lightpath   routings   that   maximize   the   reliability   in   different   failure   probability   regimes .   In   particular ,   we   show   that   in   the   low   failure   probability   regime ,   maximizing   the   ` ` cross - layer "   min   cut   of   the   ( layered )   network   maximizes   reliability ,   whereas   in   the   high   failure   probability   regime ,   minimizing   the   spanning   tree   of   the   network   maximizes   reliability .   Motivated   by   these   results ,   we   develop   lightpath   routing   algorithms   for   reliability   maximization . ' ,   ' title ' :   ' Maximizing   Reliability   in   WDM   Networks   through   Lightpath   Routing ' } 
{ ' abstract ' :   ' The   slope   of   the   active   distances   is   an   important   parameter   when   investigating   the   error - correcting   capability   of   convolutional   codes   and   the   distance   behavior   of   concatenated   convolutional   codes .   The   slope   of   the   active   distances   is   equal   to   the   minimum   average   weight   cycle   in   the   state - transition   diagram   of   the   encoder .   A   general   upper   bound   on   the   slope   depending   on   the   free   distance   of   the   convolutional   code   and   new   upper   bounds   on   the   slope   of   special   classes   of   binary   convolutional   codes   are   derived .   Moreover ,   a   search   technique ,   resulting   in   new   tables   of   rate   R = 1 / 2   and   rate   R = 1 / 3   convolutional   encoders   with   high   memories   and   large   active   distance - slopes   is   presented .   Furthermore ,   we   show   that   convolutional   codes   with   large   slopes   can   be   used   to   obtain   new   tailbiting   block   codes   with   large   minimum   distances .   Tables   of   rate   R = 1 / 2   and   rate   R = 1 / 3   tailbiting   codes   with   larger   minimum   distances   than   the   best   previously   known   quasi - cyclic   codes   are   given .   Two   new   tailbiting   codes   also   have   larger   minimum   distances   than   the   best   previously   known   binary   linear   block   codes   with   same   size   and   length .   One   of   them   is   also   superior   in   terms   of   minimum   distance   to   any   previously   known   binary   nonlinear   block   code   with   the   same   set   of   parameters . ' ,   ' title ' :   ' Tailbiting   codes   obtained   via   convolutional   codes   with   large   active   distance - slopes ' } 
{ ' abstract ' :   ' MIMO   wireless   technology   is   required   to   increase   the   data   rates   for   a   broad   range   of   applications ,   including   low   cost   mobile   devices .   In   this   paper   we   present   a   very   low   area   reconfigurable   MIMO   detector   which   achieves   a   high   throughput   of   103Mbps   and   uses   27   Kilo   Gates   when   implemented   in   a   commercial   180nm   CMOS   process .   The   low   area   is   achieved   by   the   proposed   in - place   architecture .   This   architecture   implements   the   K - best   algorithm   and   reduces   area   4 - fold   compared   to   the   widely   used   multi - stage   architecture ,   while   provides   reconfigurability   in   terms   of   antenna   configuration   during   real - time   operation . ' ,   ' title ' :   ' A   low - area   flexible   MIMO   detector   for   WiFi / WiMAX   standards ' } 
{ ' abstract ' :   ' Because   human   cognition   is   creative   and   socially   situated ,   knowledge   accumulates ,   diffuses ,   and   gets   applied   in   new   contexts ,   generating   cultural   analogs   of   phenomena   observed   in   population   genetics   such   as   adaptation   and   drift .   It   is   therefore   commonly   thought   that   elements   of   culture   evolve   through   natural   selection .   However ,   natural   selection   was   proposed   to   explain   how   change   accumulates   despite   lack   of   inheritance   of   acquired   traits ,   as   occurs   with   template - mediated   replication .   It   cannot   accommodate   a   process   with   significant   retention   of   acquired   or   horizontally   ( e . g .   socially )   transmitted   traits .   Moreover ,   elements   of   culture   cannot   be   treated   as   discrete   lineages   because   they   constantly   interact   and   influence   one   another .   It   is   proposed   that   what   evolves   through   culture   is   the   mind ;   ideas   and   artifacts   are   merely   reflections   of   its   current   evolved   state .   Interacting   minds   transform   ( in   part )   through   a   non - Darwinian   autopoietic   process   similar   to   that   by   which   early   life   evolved ,   involving   not   survival   of   the   fittest   but   actualization   of   their   potential . ' ,   ' title ' :   ' The   cultural   evolution   of   socially   situated   cognition ' } 
{ ' abstract ' :   ' Event   Extraction   is   a   complex   and   interesting   topic   in   Information   Extraction   that   includes   event   extraction   methods   from   free   text   or   web   data .   The   result   of   event   extraction   systems   can   be   used   in   several   fields   such   as   risk   analysis   systems ,   online   monitoring   systems   or   decide   support   tools .   In   this   paper ,   we   introduce   a   method   that   combines   lexico   - -   semantic   and   machine   learning   to   extract   event   from   Vietnamese   news .   Furthermore ,   we   concentrate   to   describe   event   online   monitoring   system   named   VnLoc   based   on   the   method   that   was   proposed   above   to   extract   event   in   Vietnamese   language .   Besides ,   in   experiment   phase ,   we   have   evaluated   this   method   based   on   precision ,   recall   and   F1   measure .   At   this   time   of   experiment ,   we   on   investigated   on   three   types   of   event :   FIRE ,   CRIME   and   TRANSPORT   ACCIDENT . ' ,   ' title ' :   ' VnLoc :   A   Real   - -   Time   News   Event   Extraction   Framework   for   Vietnamese ' } 
{ ' abstract ' :   ' Reliability   analysis   using   error   probabilities   for   combinational   logic   circuits   has   been   investigated   widely   in   the   literature .   Reliability   analysis   for   sequential   logic   circuits   using   these   methods   would   be   inaccurate   because   of   existence   of   loops   in   their   architecture .   In   this   paper   a   new   method   based   on   conversion   of   sequential   circuit   to   combinational   one   and   applying   an   iterative   reliability   analysis   is   developed .   A   Monte   Carlo   method - based   reliability   analysis   is   introduced   for   sequential   circuits ,   which   is   used   for   first   method   validation .   Experimental   results   demonstrate   good   accuracy   of   the   method . ' ,   ' title ' :   ' SEQUENTIAL   LOGIC   CIRCUITS   RELIABILITY   ANALYSIS ' } 
{ ' abstract ' :   ' According   to   the   Journey   to   Crime   theory ,   offenders   have   a   directionality   preference ,   in   the   form   of   an   activity   path ,   when   they   are   moving   about   in   their   environment   in   search   for   criminal   activities .   Using   clustering   techniques ,   this   theory   is   tested   using   crime   data   for   the   Province   of   British   Columbia ,   Canada .   The   activities   of   57 , 962   offenders   who   were   either   charged ,   chargeable ,   or   for   whom   charges   were   recommended   were   analyzed   by   mapping   their   offense   locations   with   respect   to   their   home   locations   to   determine   directionality .   Once   directionality   was   established ,   a   unique   clustering   technique ,   based   on   K - Means   clustering   and   modified   for   angles ,   was   applied   to   find   the   number   of   activity   paths   for   each   offender .   Although   the   number   of   activity   paths   varies   from   individual   to   individual ,   the   aggregate   pattern   was   very   consistent   with   theory .   It   was   found   that   people   only   have   a   few   activity   paths ,   even   if   they   are   highly   prolific   offenders . ' ,   ' title ' :   ' How   Many   Ways   Do   Offenders   Travel   - -   Evaluating   the   Activity   Paths   of   Offenders ' } 
{ ' abstract ' :   ' Pulse   Coupled   Neural   Network ( PCNN )   is   widely   used   in   the   field   of   image   processing ,   but   it   is   a   difficult   task   to   define   the   relative   parameters   properly   in   the   research   of   the   applications   of   PCNN .   So   far   the   determination   of   parameters   of   its   model   needs   a   lot   of   experiments .   To   deal   with   the   above   problem ,   a   document   segmentation   based   on   the   improved   PCNN   is   proposed .   It   uses   the   maximum   entropy   function   as   the   fitness   function   of   bacterial   foraging   optimization   algorithm ,   adopts   bacterial   foraging   optimization   algorithm   to   search   the   optimal   parameters ,   and   eliminates   the   trouble   of   manually   set   the   experiment   parameters .   Experimental   results   show   that   the   proposed   algorithm   can   effectively   complete   document   segmentation .   And   result   of   the   segmentation   is   better   than   the   contrast   algorithms .   ©   ( 2014 )   COPYRIGHT   Society   of   Photo - Optical   Instrumentation   Engineers   ( SPIE ) .   Downloading   of   the   abstract   is   permitted   for   personal   use   only . ' ,   ' title ' :   ' PCNN   document   segmentation   method   based   on   bacterial   foraging   optimization   algorithm ' } 
{ ' abstract ' :   ' Undirected   graphical   models   encode   in   a   graph   G   the   dependency   structure   of   a   random   vector   Y .   In   many   applications ,   it   is   of   interest   to   model   Y   given   another   random   vector   X   as   input .   We   refer   to   the   problem   of   estimating   the   graph   G ( x )   of   Y   conditioned   on   X   =   x   as   " graph - valued   regression " .   In   this   paper ,   we   propose   a   semiparametric   method   for   estimating   G ( x )   that   builds   a   tree   on   the   X   space   just   as   in   CART   ( classification   and   regression   trees ) ,   but   at   each   leaf   of   the   tree   estimates   a   graph .   We   call   the   method   " Graph - optimized   CART " ,   or   Go - CART .   We   study   the   theoretical   properties   of   Go - CART   using   dyadic   partitioning   trees ,   establishing   oracle   inequalities   on   risk   minimization   and   tree   partition   consistency .   We   also   demonstrate   the   application   of   Go - CART   to   a   meteorological   dataset ,   showing   how   graph - valued   regression   can   provide   a   useful   tool   for   analyzing   complex   data . ' ,   ' title ' :   ' Graph - Valued   Regression ' } 
{ ' abstract ' :   ' Over   the   last   two   decades ,   doubts   have   been   expressed   about   the   adequacy   of   materialism   as   the   correct   framework   for   explaining   phenomenal   consciousness   ( the   experience   of   saturated   greenness   one   has   when   looking   at   a   lush   lawn ,   for   example ) .   This   paper   reconstructs   a   generic   form   of   the   various   arguments   that   have   been   used   to   defend   the   view   of   the   materialistically   inexplicable   nature   of   consciousness   ( MINC ) .   This   reconstruction   reveals   that   the   arguments   turn   on   an   impoverished   notion   of   explanation .   By   discussing   some   examples   from   the   history   of   science ,   the   paper   shows   that   a   reasonable   notion   of   explanation   has   to   be   wider   than   the   one   utilized   in   the   argument   for   MINC ,   which   opens   the   possibility   for   the   materialistic   explicability   of   consciousness .   The   author   ends   the   paper   by   raising   a   question   about   the   very   intelligibility   of   the   project   of   trying   to   explain   the   so - called   nature   of   consciousness   as   opposed   to   the   regularities   characteristic   of   the   relation   between   states   of   consciousness   and   ... ' ,   ' title ' :   ' On   explaining   phenomenal   consciousness ' } 
{ ' abstract ' :   ' Successful   replication   within   an   infected   host   and   successful   transmission   between   hosts   are   key   to   the   continued   spread   of   most   pathogens .   Competing   selection   pressures   exerted   at   these   different   scales   can   lead   to   evolutionary   trade - offs   between   the   determinants   of   fitness   within   and   between   hosts .   Here ,   we   examine   such   a   trade - off   in   the   context   of   influenza   A   viruses   and   the   differential   pressures   exerted   by   temperature - dependent   virus   persistence .   For   a   panel   of   avian   influenza   A   virus   strains ,   we   find   evidence   for   a   trade - off   between   the   persistence   at   high   versus   low   temperatures .   Combining   a   within - host   model   of   influenza   infection   dynamics   with   a   between - host   transmission   model ,   we   study   how   such   a   trade - off   affects   virus   fitness   on   the   host   population   level .   We   show   that   conclusions   regarding   overall   fitness   are   affected   by   the   type   of   link   assumed   between   the   within -   and   between - host   levels   and   the   main   route   of   transmission   ( direct   or   environmental ) .   The   relative   importance   of   virulence   and   immune   response   mediated   virus   clearance   are   also   found   to   influence   the   fitness   impacts   of   virus   persistence   at   low   versus   high   temperatures .   Based   on   our   results ,   we   predict   that   if   transmission   occurs   mainly   directly   and   scales   linearly   with   virus   load ,   and   virulence   or   immune   responses   are   negligible ,   the   evolutionary   pressure   for   influenza   viruses   to   evolve   toward   good   persistence   at   high   within - host   temperatures   dominates .   For   all   other   scenarios ,   influenza   viruses   with   good   environmental   persistence   at   low   temperatures   seem   to   be   favored . ' ,   ' title ' :   ' A   Multi - scale   Analysis   of   Influenza   A   Virus   Fitness   Trade - offs   due   to   Temperature - dependent   Virus   Persistence ' } 
{ ' abstract ' :   ' Peer - to - Peer   ( P2P )   networks   are   largely   used   for   file - sharing   and   hence   must   provide   efficient   mechanisms   for   searching   the   files   stored   at   various   nodes .   The   existing   structuredP2P   overlays   support   only   ” exact - match ”   look - up   which   is   hardly   sufficient   in   a   file   sharing   network .   This   paper   addresses   the   problem   of   keyword - based   search   in   structured   P2P   networks .   We   propose   a   new   keyword - based   searching   algorithm   which   can   be   implemented   on   top   of   any   structured   P2P   overlay .   We   demonstrate   that   the   proposed   algorithm   achieves   very   good   searching   results   as   it   requires   the   minimum   number   of   messages   to   be   sent   in   order   to   find   all   the   references   to   files   containing   at   least   the   given   set   of   keywords . ' ,   ' title ' :   ' A   Keyword   Search   Algorithm   for   Structured   Peer - to - Peer   Networks ' } 
{ ' abstract ' :   ' In   this   paper ,   we   propose   an   adaptive   power   allocation   method   for   hybrid   relay   systems   that   employ   the   amplify - and - forward   and   decode - and - forward   protocols   simultaneously .   The   total   transmission   power   is   analytically   allocated   to   a   source   and   two   selected   relays   by   the   proposed   power   allocation   criterion   to   maximize   the   overall   received   signal - to - noise   ratio   at   the   destination .   Simulation   results   show   that   the   proposed   scheme   achieves   better   performance   than   that   of   conventional   cooperative   schemes   or   hybrid   systems   with   equal   power   allocation . ' ,   ' title ' :   ' Adaptive   relay   selection   and   power   allocation   for   hybrid   relay   systems ' } 
{ ' abstract ' :   ' The   unitary   rotation   of   square - pixellated   images   is   based   on   the   finite   su ( 2 ) - oscillator   model ,   which   describes   systems   whose   values   for   position ,   momentum   and   energy ,   are   discrete   and   finite .   In   a   two - dimensional   position   space ,   this   allows   the   construction   of   angular   momentum   states ,   orthonormal   and   complete ,   for   which   rotations   are   defined   as   multiplication   by   phases   that   carry   the   rotation   angle .   The   decomposition   of   a   digital   square   images   in   terms   of   these   angular   momentum   states   determines   a   unitary   ( hence   invertible )   rotation   of   the   image ,   whose   kernel   can   be   computed   as   a   four - dimensional   array   of   real   numbers . ' ,   ' title ' :   ' Unitary   rotation   of   square - pixellated   images ' } 
{ ' abstract ' :   ' As   more   mobile   storage   devices   are   used   in   consumer   electronics ,   possibility   of   user   confidential   data   leakage   increases .   To   make   things   worse ,   data   of   deleted   file   in   mobile   storage   such   as   USB   drives   can   be   easily   recovered   and ,   thus ,   can   be   vulnerable   to   data   leakage .   To   prevent   this   type   of   data   leakage ,   efficient   secure   deletion   techniques   are   required   and   we   present   two   secure   deletion   techniques ,   namely   block   cleaning   and   zero   overwriting ,   for   flash   memory   storage .   Also ,   we   propose   cost   and   benefit   models   of   both   techniques .   The   models   imply   an   existence   of   an   efficient   adaptive   hybrid   secure   deletion   scheme   that   applies   one   of   the   techniques   based   on   their   costs   and   benefits   at   given   data   arrangements .   Experimental   results   measured   on   an   embedded   board   show   that   the   adaptive   hybrid   scheme   deletes   data   securely   and   efficiently   for   various   data   patterns   on   flash   memory   storage . ' ,   ' title ' :   ' Models   and   Design   of   an   Adaptive   Hybrid   Scheme   for   Secure   Deletion   of   Data   in   Consumer   Electronics ' } 
{ ' abstract ' :   ' In   heterogeneous   and   dynamic   environments ,   efficient   execution   of   parallel   computations   can   require   mappings   of   tasks   to   processors   whose   performance   is   both   irregular   ( because   of   heterogeneity )   and   time - varying   ( because   of   dynamicity ) .   While   adaptive   domain   decomposition   techniques   have   been   used   to   address   heterogeneous   resource   capabilities ,   temporal   variations   in   those   capabilities   have   seldom   been   considered .   We   propose   a   conservative   scheduling   policy   that   uses   information   about   expected   future   variance   in   resource   capabilities   to   produce   more   efficient   data   mapping   decisions .   We   first   present   techniques ,   based   on   time   series   predictors   that   we   developed   in   previous   work ,   for   predicting   CPU   load   at   some   future   time   point ,   average   CPU   load   for   some   future   time   interval ,   and   variation   of   CPU   load   over   some   future   time   interval .   We   then   present   a   family   of   stochastic   scheduling   algorithms   that   exploit   such   predictions   of   future   availability   and   variability   when   making   data   mapping   decisions .   Finally ,   we   describe   experiments   in   which   we   apply   our   techniques   to   an   astrophysics   application .   The   results   of   these   experiments   demonstrate   that   conservative   scheduling   can   produce   execution   times   that   are   both   significantly   faster   and   less   variable   than   other   techniques . ' ,   ' title ' :   ' Conservative   Scheduling :   Using   Predicted   Variance   to   Improve   Scheduling   Decisions   in   Dynamic   Environments ' } 
{ ' abstract ' :   ' We   consider   a   class   of   restless   multi - armed   bandit   problems   that   arises   in   multi - channel   opportunistic   communications ,   where   channels   are   modeled   as   independent   and   stochastically   identical   Gilbert - Elliot   channels   and   channel   state   observations   are   subject   to   errors .   We   show   that   the   myopic   channel   selection   policy   has   a   semi - universal   structure   that   obviates   the   need   to   know   the   Markovian   transition   probabilities   of   the   channel   states .   Based   on   this   structure ,   we   establish   closed - form   lower   and   upper   bounds   on   the   steady - state   throughput   achieved   by   the   myopic   policy .   Furthermore ,   we   characterize   the   approximation   factor   of   the   myopic   policy   to   bound   its   worst - case   performance   loss   with   respect   to   the   optimal   performance . ' ,   ' title ' :   ' On   the   myopic   policy   for   a   class   of   restless   bandit   problems   with   applications   in   dynamic   multichannel   access ' } 
{ ' abstract ' :   ' We   show   that   the   optimum   length - / spl   nu /   guard   sequence   for   block   transmission   over   a   linear   Gaussian - noise   dispersive   channel   with   memory   / spl   nu /   is   a   linear   combination   of   the   N   information   symbols   of   the   block .   A   closed - form   expression   for   the   optimum   guard   sequence   is   derived   subject   to   a   total   average   energy   constraint   on   the   information   and   guard   symbols .   The   achievable   channel   block   throughput   with   the   optimum   guard   sequence   is   compared   with   that   achievable   with   two   common   guard   sequence   types ,   namely   zero   stuffing   and   cyclic   prefix . ' ,   ' title ' :   ' Guard   sequence   optimization   for   block   transmission   over   linear   frequency - selective   channels ' } 
{ ' abstract ' :   " A   modular   program   analysis   considers   components   independently   and   provides   a   succinct   summary   for   each   component ,   which   is   used   when   checking   the   rest   of   the   system .   Consider   a   system   consisting   of   a   library   and   a   client .   A   temporal   summary ,   or     interface   ,   of   the   library   specifies   legal   sequences   of   library   calls .   The   interface   is     safe     if   no   call   sequence   violates   the   library ' s   internal   invariants ;   the   interface   is     permissive     if   it   contains   every   such   sequence .   Modular   program   analysis   requires     full     interfaces ,   which   are   both   safe   and   permissive :   the   client   does   not   cause   errors   in   the   library   if   and   only   if   it   makes   only   sequences   of   library   calls   that   are   allowed   by   the   full   interface   of   the   library . Previous   interface - based   methods   have   focused   on   safe   interfaces ,   which   may   be   too   restrictive   and   thus   reject   good   clients .   We   present   an   algorithm   for   automatically   synthesizing   software   interfaces   that   are   both   safe   and   permissive .   The   algorithm   generates   interfaces   as   graphs   whose   vertices   are   labeled   with   predicates   over   the   library ' s   internal   state ,   and   whose   edges   are   labeled   with   library   calls .   The   interface   state   is   refined   incrementally   until   the   full   interface   is   constructed .   In   other   words ,   the   algorithm   automatically   synthesizes   a   typestate   system   for   the   library ,   against   which   any   client   can   be   checked   for   compatibility .   We   present   an   implementation   of   the   algorithm   which   is   based   on   the   BLAST   model   checker ,   and   we   evaluate   some   case   studies . " ,   ' title ' :   ' Permissive   interfaces ' } 
{ ' abstract ' :   ' In   this   paper ,   we   propose   a   new   method   for   the   motion   planning   problem   of   rigid   object   dexterous   manipulation   with   a   robotic   multi - fingered   hand ,   under   quasi - static   movement   assumption .   This   method   computes   both   object   and   finger   trajectories   as   well   as   the   finger   relocation   sequence .   Its   specificity   is   to   use   a   special   structuring   of   the   research   space   that   allows   to   search   for   paths   directly   in   the   particular   subspace   GS   n     which   is   the   subspace   of   all   the   grasps   that   can   be   achieved   with   n   grasping   fingers .   The   solving   of   the   dexterous   manipulation   planning   problem   is   based   upon   the   exploration   of   this   subspace .   The   proposed   approach   captures   the   connectivity   of   GS   n     in   a   graph   structure .   The   answer   of   the   manipulation   planning   query   is   then   given   by   searching   a   path   in   the   computed   graph .   Simulation   experiments   were   conducted   for   different   dexterous   manipulation   task   examples   to   validate   the   proposed   method . ' ,   ' title ' :   ' Dexterous   manipulation   planning   using   probabilistic   roadmaps   in   continuous   grasp   subspaces ' } 
{ ' abstract ' :   ' This   paper   presents   an   experimental   evaluation   of   different   line   extraction   algorithms   applied   to   2D   laser   scans   for   indoor   environments .   Six   popular   algorithms   in   mobile   robotics   and   computer   vision   are   selected   and   tested .   Real   scan   data   collected   from   two   office   environments   by   using   different   platforms   are   used   in   the   experiments   in   order   to   evaluate   the   algorithms .   Several   comparison   criteria   are   proposed   and   discussed   to   highlight   the   advantages   and   drawbacks   of   each   algorithm ,   including   speed ,   complexity ,   correctness   and   precision .   The   results   of   the   algorithms   are   compared   with   ground   truth   using   standard   statistical   methods .   An   extended   case   study   is   performed   to   further   evaluate   the   algorithms   in   a   SLAM   application . ' ,   ' title ' :   ' A   comparison   of   line   extraction   algorithms   using   2D   range   data   for   indoor   mobile   robotics ' } 
{ ' abstract ' :   ' This   study   investigates   the   use   of   force - stiffness   feedback ,   i . e . ,   a   combination   of   force   offset   and   extra   spring   load ,   in   UAV   tele - operation   with   transmission   time   delay .   The   goal   was   to   further   increase   the   level   of   safety   of   tele - operation   with   a   reduction   in   operator   workload   with   respect   to   force   feedback ,   i . e . ,   using   force   offset   alone .   A   theoretical   analysis   is   given   of   using   force - stiffness   feedback   to   improve   collision   avoidance .   Wave   variables   are   included   to   reduce   time   delay   effects .   An   experiment   was   conducted   to   investigate   the   effects   of   force - stiffness   feedback   on   safety   of   operation ,   operator   performance ,   control   activity ,   and   workload .   Results   indicate   that   force - stiffness   feedback   improves   the   haptic   interface   with   respect   to   force   feedback   alone .   Safety   of   tele - operation   increases   without   increasing   operator   workload   with   respect   to   force   feedback . ' ,   ' title ' :   ' Haptic   interface   in   UAV   tele - operation   using   force - stiffness   feedback ' } 
{ ' abstract ' :   ' Due   to   the   spread   of   the   internet   and   the   ever   increasing   number   of   web   applications ,   the   issue   of   compatibility   across   browsers   has   become   very   important .   This   compatibility   issue   is   also   referred   as   Cross   Browser   Inconsistency   ( XBI )   wherein   same   website   looks   or   behaves   differently   in   different   web   browsers .   In   this   paper   our   aim   is   to   address   this   issue   of   compatibility   and   propose   an   automated   approach   of   detecting   XBIs .   Cross   Browser   Inconsistencies   can   either   be   in   the   content ,   structure   or   behavior   of   the   webpage .   In   order   to   get   a   grasp   of   the   above   mentioned   types   of   inconsistencies ,   we   surveyed   some   random   websites   and   analyzed   them   in   different   browsers .   We   also   studied   the   basic   working   of   browser ,   in   order   to   establish   its   connection   with   the   occurrences   of   XBIs .   Each   browser   has   its   own   rendering   mechanisms ,   which   sometimes   differs   from   standards .   Hence ,   the   execution   of   these   websites   is   different   in   different   browsers .   Finally   we   have   proposed   an   automated   approach   for   XBI   detection . ' ,   ' title ' :   ' An   Automated   Approach   for   Cross - Browser   Inconsistency   ( XBI )   Detection ' } 
{ ' abstract ' :   ' We   present   a   formal   framework   that   combines   high - level   representation   and   causality - based   reasoning   with   low - level   geometric   reasoning   and   motion   planning .   The   frame - work   features   bilateral   interaction   between   task   and   motion   planning ,   and   embeds   geometric   reasoning   in   causal   reasoning ,   thanks   to   several   advantages   inherited   from   its   underlying   components .   In   particular ,   our   choice   of   using   a   causality - based   high - level   formalism   for   describing   action   domains   allows   us   to   represent   ramifications   and   state / transition   constraints ,   and   embed   in   such   formal   domain   descriptions   externally   defined   functions   implemented   in   some   programming   language   ( e . g . ,   C++ ) .   Moreover ,   given   such   a   domain   description ,   the   causal   reasoner   based   on   this   formalism   ( i . e . ,   the   Causal   Calculator )   allows   us   to   compute   optimal   solutions   ( e . g . ,   shortest   plans )   for   elaborate   planning / prediction   problems   with   temporal   constraints .   Utilizing   these   features   of   high - level   representation   and   reasoning ,   we   can   combine   causal   reasoning ,   motion   planning   and   geometric   planning   to   find   feasible   kinematic   solutions   to   task - level   problems .   In   our   framework ,   the   causal   reasoner   guides   the   motion   planner   by   finding   an   optimal   task - plan ;   if   there   is   no   feasible   kinematic   solution   for   that   task - plan   then   the   motion   planner   guides   the   causal   reasoner   by   modifying   the   planning   problem   with   new   temporal   constraints .   Furthermore ,   while   computing   a   task - plan ,   the   causal   reasoner   takes   into   account   geometric   models   and   kinematic   relations   by   means   of   external   predicates   implemented   for   geometric   reasoning   ( e . g . ,   to   check   some   collisions ) ;   in   that   sense   the   geometric   reasoner   guides   the   causal   reasoner   to   find   feasible   kinematic   solutions .   We   illustrate   an   application   of   this   framework   to   robotic   manipulation ,   with   two   pantograph   robots   on   a   complex   assembly   task   that   requires   concurrent   execution   of   actions .   A   short   video   of   this   application   accompanies   the   paper . ' ,   ' title ' :   ' Combining   high - level   causal   reasoning   with   low - level   geometric   reasoning   and   motion   planning   for   robotic   manipulation ' } 
{ ' abstract ' :   ' This   paper   presents   a   novel   template   matching   method   to   detect   and   track   pedestrians   for   people   counting   in   real - time .   Firstly ,   a   novel   background   subtraction   method   is   proposed   for   extracting   all   foreground   objects   from   background .   Then ,   a   shadow   elimination   method   is   used   to   remove   unwanted   shadow   from   the   background .   In   order   to   identify   pedestrians   from   non - pedestrian   objects ,   this   paper   proposed   a   novel   grid - based   template   matching   scheme   to   robustly   verify   each   pedestrian .   Usually ,   a   pedestrian   will   have   different   appearances   at   different   positions .   The   grid - based   approach   can   effectively   reduce   the   perspective   effects   into   a   minimum   since   it   uses   different   templates   to   record   the   appearance   changes   at   each   grid .   When   more   templates   are   used ,   the   detection   process   will   become   more   inefficient .   To   speed   up   its   efficiency ,   an   integral   image   is   used   to   filter   out   all   impossible   candidates   in   advance .   Lastly ,   a   tracking   method   is   applied   to   tracking   the   direction   of   each   moving   pedestrian   so   that   the   real   number   of   passing   people   per   direction   can   be   counted   more   accurately .   Experimental   results   have   proved   that   the   proposed   method   is   robust ,   accurate ,   and   powerful   in   people   counting . ' ,   ' title ' :   ' Grid - based   Template   Matching   for   People   Counting ' } 
{ ' abstract ' :   ' A   tomographic   image   reconstruction   algorithm   that   we   have   been   studying   requires   the   nth - order   Hankel   transform   for   the   nth   function   in   a   series ,   where   n   varies   over   a   set   of   integers .   Unfortunately ,   most   previously   proposed   algorithms   have   either   dealt   with   only   zeroth - order   transforms   or   cannot   be   applied   conveniently   to   our   problem .   We   propose   an   algorithm   for   computing   general   integer - order   Hankel   transforms .   The   algorithm   takes   samples   of   equally   spaced   input   functions   and   gives   equally   spaced   samples   of   the   transforms . ' ,   ' title ' :   ' An   algorithm   for   computing   general   integer - order   Hankel   transforms ' } 
{ ' abstract ' :   ' In   this   paper ,   we   present   a   real - time   approach   that   allows   tracking   deformable   structures   in   3D   ultrasound   sequences .   Our   method   consists   in   obtaining   the   target   displacements   by   combining   robust   dense   motion   estimation   and   mechanical   model   simulation .   We   perform   evaluation   of   our   method   through   simulated   data ,   phantom   data ,   and   real - data .   Results   demonstrate   that   this   novel   approach   has   the   advantage   of   providing   correct   motion   estimation   regarding   different   ultrasound   shortcomings   including   speckle   noise ,   large   shadows   and   ultrasound   gain   variation .   Furthermore ,   we   show   the   good   performance   of   our   method   with   respect   to   state - of - the - art   techniques   by   testing   on   the   3D   databases   provided   by   MICCAI   CLUST ’ 14   and   CLUST ’ 15   challenges . ' ,   ' title ' :   ' Real - time   target   tracking   of   soft   tissues   in   3D   ultrasound   images   based   on   robust   visual   information   and   mechanical   simulation ' } 
{ ' abstract ' :   ' For   two   given   graphs   G1G1   and   G2G2 ,   the   Ramsey   number   R ( G1 , G2 ) R ( G1 , G2 )   is   the   smallest   integer   NN   such   that   for   any   graph   of   order   NN ,   either   GG   contains   a   copy   of   G1G1   or   its   complement   contains   a   copy   of   G2G2 .   Let   CmCm   be   a   cycle   of   length   mm   and   K1 , nK1 , n   a   star   of   order   n + 1n + 1 .   Parsons   ( 1975 )   shows   that   R ( C4 , K1 , n ) ≤ n + ⌊ n − 1 ⌋ + 2   and   if   nn   is   the   square   of   a   prime   power ,   then   the   equality   holds .   In   this   paper ,   by   discussing   the   properties   of   polarity   graphs   whose   vertices   are   points   in   the   projective   planes   over   Galois   fields ,   we   prove   that   R ( C4 , K1 , q2 − t ) = q2 + q − ( t − 1 ) R ( C4 , K1 , q2 − t ) = q2 + q − ( t − 1 )   if   qq   is   an   odd   prime   power ,   1 ≤ t ≤ 2 ⌈ q4 ⌉   and   t ≠ 2 ⌈ q4 ⌉ − 1 ,   which   extends   a   result   on   R ( C4 , K1 , q2 − t ) R ( C4 , K1 , q2 − t )   obtained   by   Parsons   ( 1976 ) . ' ,   ' title ' :   ' Polarity   graphs   and   Ramsey   numbers   for   C   4   versus   stars ' } 
{ ' abstract ' :   ' This   paper   deals   with   the   problem   of   assuring   strict   QoS   guarantees   for   the   end   to   end   connections   that   originate   from   Ethernet   access   network .   It   shows   that   despite   high   link   capacities   in   some   cases   Ethernet   network   might   be   the   reason   of   QoS   deterioration .   The   primary   reason   is   the   lack   of   appropriate   QoS   differentiation   and   traffic   isolation   mechanisms .   The   shared   buffers   and   priority   schedulers   available   in   most   of   Ethernet   switches   appear   to   be   not   sufficient   to   guarantee   strict   QoS .   For   these   cases   new   solution   is   proposed   which   relies   on   additional   traffic   control   mechanisms   available   in   other   network   elements .   Only   additional   mechanism   supporting   typical   functionality   of   Ethernet   switch   can   provide   strict   QoS   guarantees   what   was   verified   in   simulations   studies . ' ,   ' title ' :   ' On   assuring   QoS   in   Ethernet   access   network ' } 
{ ' abstract ' :   ' The   federal   Medicare   regulations   reimburse   hospitals   on   a   pro   rata   share   of   the   hospital \ ' s   cost .   Hence ,   to   meet   its   financial   requirements ,   a   hospital   is   forced   to   shift   more   of   the   financial   burdens   onto   its   private   patients .   This   procedure   has   contributed   to   double   digit   inflation   in   hospital   prices   and   to   proposed   federal   regulation   to   control   the   rate   of   increase   in   hospital   revenues .   In   this   regulatory   environment ,   we   develop   nonlinear   programming   pricing   and   cost   allocation   models   to   aid   hospital   administrators   in   meeting   their   profit   maximizing   and   profit   satisficing   goals .   The   model   enables   administrators   to   explore   tactical   issues   such   as :   i   studying   the   relationship   between   a   voluntary   or   legislated   cap   on   a   hospital \ ' s   total   revenues   and   the   hospital \ ' s   profitability ,   ii   identifying   those   departments   within   the   hospital   that   are   the   most   attractive   candidates   for   cost   reduction   or   cost   containment   efforts ,   and   iii   isolating   those   services   that   should   be   singled   out   by   the   hospital   manager   for   renegotiation   of   the   prospective   or   " customary   and   reasonable "   cap .   Finally ,   the   modeling   approach   is   helpful   in   explaining   the   departmental   cross   subsidies   observed   in   practice ,   and   can   be   of   aid   to   federal   administrators   in   assessing   the   impacts   of   proposed   changes   in   the   Medicare   reimbursement   formula . ' ,   ' title ' :   ' Hospital   Profit   Planning   under   Medicare   Reimbursement ' } 
{ ' abstract ' :   ' We   present   a   ( 4   +   epsilon )   approximation   algorithm   for   weighted   graph   matching   which   applies   in   the   semistreaming ,   sliding   window ,   and   MapReduce   models ;   this   single   algorithm   improves   the   previous   best   algorithm   in   each   model .   The   algorithm   operates   by   reducing   the   maximum - weight   matching   problem   to   a   polylog   number   of   copies   of   the   maximum - cardinality   matching   problem .   The   algorithm   also   extends   to   provide   approximation   guarantees   for   the   more   general   problem   of   finding   weighted   independent   sets   in   p - systems   ( which   include   intersections   of   p   matroids   and   p - bounded   hypergraph   matching ) . ' ,   ' title ' :   ' Improved   Streaming   Algorithms   for   Weighted   Matching ,   via   Unweighted   Matching ' } 
{ ' abstract ' :   ' This   paper   presents   a   novel   approach   to   efficiently   solve   parameter - dependent   ( PD )   linear   matrix   inequality   ( LMI )   problems   for ,   amongst   others ,   linear   parameter - varying   ( LPV )   control   design .   Typically ,   stability   and   performance   is   guaranteed   by   finding   a   PD   Lyapunov   function   such   that   a   PD   LMI   is   feasible   on   a   parameter   domain .   To   solve   the   resulting   semi - infinite   problems ,   we   propose   a   novel   LMI   relaxation   technique   relying   on   B - spline   basis   functions .   This   technique   provides   less   conservative   solutions   and / or   a   reduced   numerical   burden   compared   to   existing   approaches .   Moreover ,   an   elegant   generalization   of   worst - case   optimization   to   the   optimization   of   any   signal   norm   is   obtained   by   expressing   performance   bounds   as   a   function   of   the   system   parameters .   This   generalization   yields   better   performance   bounds   in   a   large   part   of   the   parameter   domain .   Numerical   comparisons   with   the   current   state - of - the - art   demonstrate   the   generality   and   effectiveness   of   our   approach . ' ,   ' title ' :   ' Control   of   linear   parameter - varying   systems   using   B - splines ' } 
{ ' abstract ' :   ' There   is   a   growing   interest   in   simulating   natural   phenomena   in   computer   graphics   applications .   Animating   natural   scenes   in   real   time   is   one   of   the   most   challenging   problems   due   to   the   inherent   complexity   of   their   structure ,   formed   by   millions   of   geometric   entities ,   and   the   interactions   that   happen   within .   An   example   of   natural   scenario   that   is   needed   for   games   or   simulation   programs   are   forests .   Forests   are   difficult   to   render   because   the   huge   amount   of   geometric   entities   and   the   large   amount   of   detail   to   be   represented .   Moreover ,   the   interactions   between   the   objects   ( grass ,   leaves )   and   external   forces   such   as   wind   are   complex   to   model .   In   this   paper   we   concentrate   in   the   rendering   of   falling   leaves   at   low   cost .   We   present   a   technique   that   exploits   graphics   hardware   in   order   to   render   thousands   of   leaves   with   different   falling   paths   in   real   time   and   low   memory   requirements . ' ,   ' title ' :   ' Rendering   falling   leaves   on   graphics   hardware ' } 
{ ' abstract ' :   ' We   previously   presented   DriverDB ,   a   database   that   incorporates   ∼ 6000   cases   of   exome - seq   data ,   in   addition   to   annotation   databases   and   published   bioinformatics   algorithms   dedicated   to   driver   gene / mutation   identification .   The   database   provides   two   points   of   view ,   ‘ Cancer ’   and   ‘ Gene ’ ,   to   help   researchers   visualize   the   relationships   between   cancers   and   driver   genes / mutations .   In   the   updated   DriverDBv2   database   ( http : / / ngs . ym . edu . tw / driverdb )   presented   herein ,   we   incorporated   > 9500   cancer - related   RNA - seq   datasets   and   > 7000   more   exome - seq   datasets   from   The   Cancer   Genome   Atlas   ( TCGA ) ,   International   Cancer   Genome   Consortium   ( ICGC ) ,   and   published   papers .   Seven   additional   computational   algorithms   ( meaning   that   the   updated   database   contains   15   in   total ) ,   which   were   developed   for   driver   gene   identification ,   are   incorporated   into   our   analysis   pipeline ,   and   the   results   are   provided   in   the   ‘ Cancer ’   section .   Furthermore ,   there   are   two   main   new   features ,   ‘ Expression ’   and   ‘ Hotspot ’ ,   in   the   ‘ Gene ’   section .   ‘ Expression ’   displays   two   expression   profiles   of   a   gene   in   terms   of   sample   types   and   mutation   types ,   respectively .   ‘ Hotspot ’   indicates   the   hotspot   mutation   regions   of   a   gene   according   to   the   results   provided   by   four   bioinformatics   tools .   A   new   function ,   ‘ Gene   Set ’ ,   allows   users   to   investigate   the   relationships   among   mutations ,   expression   levels   and   clinical   data   for   a   set   of   genes ,   a   specific   dataset   and   clinical   features . ' ,   ' title ' :   ' DriverDBv2 :   a   database   for   human   cancer   driver   gene   research ' } 
{ ' abstract ' :   ' Thousands   of   deep   and   wide   pipelines   working   concurrently   make   GPGPU   high   power   consuming   parts .   Energy - efficiency   techniques   employ   voltage   overscaling   that   increases   timing   sensitivity   to   variations   and   hence   aggravating   the   energy   use   issues .   This   paper   proposes   a   method   to   increase   spatiotemporal   reuse   of   computational   effort   by   a   combination   of   compilation   and   micro - architectural   design .   An   associative   memristive   memory   ( AMM )   module   is   integrated   with   the   floating   point   units   ( FPUs ) .   Together ,   we   enable   fine - grained   partitioning   of   values   and   find   high - frequency   sets   of   values   for   the   FPUs   by   searching   the   space   of   possible   inputs ,   with   the   help   of   application - specific   profile   feedback .   For   every   kernel   execution ,   the   compiler   pre - stores   these   high - frequent   sets   of   values   in   AMM   modules   - -   representing   partial   functionality   of   the   associated   FPU - -   that   are   concurrently   evaluated   over   two   clock   cycles .   Our   simulation   results   show   high   hit   rates   with   32 - entry   AMM   modules   that   enable   36%   reduction   in   average   energy   use   by   the   kernel   codes .   Compared   to   voltage   overscaling ,   this   technique   enhances   robustness   against   timing   errors   with   39%   average   energy   saving . ' ,   ' title ' :   ' Energy - Efficient   GPGPU   Architectures   via   Collaborative   Compilation   and   Memristive   Memory - Based   Computing ' } 
{ ' abstract ' :   ' Quasi - cyclic   codes   are   renowned   for   their   structural   design   and   low - complexity   shift   register   encoding .   However ,   existing   design   techniques   based   on   difference   families   have   limited   code   size   options   due   to   algebraic   constraints .   We   introduce   in   this   paper   a   notation   of   extended   difference   family   ( EDF )   and   provide   a   systematic   code   design   based   on   EDFs   with   a   high   degree   of   flexibility   in   code   size .   Short / medium - length   codes   of   high   rate   ( / spl   ges /   0.9 )   can   be   easily   constructed . ' ,   ' title ' :   ' Quasi - cyclic   codes   from   extended   difference   families ' } 
{ ' abstract ' :   ' Lexical   cohesion   arises   from   a   chain   of   lexical   items   that   establish   links   between   sentences   in   a   text .   In   this   paper   we   propose   three   different   models   to   capture   lexical   cohesion   for   document - level   machine   translation :   ( a )   a   direct   reward   model   where   translation   hypotheses   are   rewarded   whenever   lexical   cohesion   devices   occur   in   them ,   ( b )   a   conditional   probability   model   where   the   appropriateness   of   using   lexical   cohesion   devices   is   measured ,   and   ( c )   a   mutual   information   trigger   model   where   a   lexical   cohesion   relation   is   considered   as   a   trigger   pair   and   the   strength   of   the   association   between   the   trigger   and   the   triggered   item   is   estimated   by   mutual   information .   We   integrate   the   three   models   into   hierarchical   phrase - based   machine   translation   and   evaluate   their   effectiveness   on   the   NIST   Chinese - English   translation   tasks   with   large - scale   training   data .   Experiment   results   show   that   all   three   models   can   achieve   substantial   improvements   over   the   baseline   and   that   the   mutual   information   trigger   model   performs   better   than   the   others . ' ,   ' title ' :   ' Modeling   lexical   cohesion   for   document - level   machine   translation ' } 
{ ' abstract ' :   ' This   paper   presents   a   lightweight   sketching   system   that   enables   interactive   illustration   of   complex   fluid   systems .   Users   can   sketch   on   a   2.5 - dimensional   ( 2.5 D )   canvas   to   design   the   shapes   and   connections   of   a   fluid   circuit .   These   input   sketches   are   automatically   analyzed   and   abstracted   into   a   hydraulic   graph ,   and   a   new   hybrid   fluid   model   is   used   in   the   background   to   enhance   the   illustrations .   The   system   provides   rich   simple   operations   for   users   to   edit   the   fluid   system   incrementally ,   and   the   new   internal   flow   patterns   can   be   simulated   in   real   time .   Our   system   is   used   to   illustrate   various   fluid   systems   in   medicine ,   biology ,   and   engineering .   We   asked   professional   medical   doctors   to   try   our   system   and   obtained   positive   feedback   from   them . ' ,   ' title ' :   ' Sketch - based   Dynamic   Illustration   of   Fluid   Systems ' } 
{ ' abstract ' :   ' We   present   an   improved   zone   content   classification   method   and   its   performance   evaluation .   We   added   two   new   features   to   the   feature   vector   from   one   previously   published   method   ( Sivaramakrishnan   et   al . ,   1995 ) .   We   assumed   different   independence   relationships   in   two   zone   sets .   We   used   an   optimized   binary   decision   tree   to   estimate   the   maximum   zone   content   class   probability   in   one   set   while   using   the   Viterbi   algorithm   to   find   the   optimal   solution   for   a   zone   sequence   in   the   other   set .   The   training ,   pruning   and   testing   data   set   for   the   algorithm   include   1 , 600   images   drawn   from   the   UWCDROM   III   document   image   database .   The   classifier   is   able   to   classify   each   given   scientific   and   technical   document   zone   into   one   of   the   nine   classes ,   2   text   classes   ( of   font   size   4   -   18pt   and   font   size   19   -   32   pt ) ,   math ,   table ,   halftone ,   map / drawing ,   ruling ,   logo ,   and   others .   Compared   with   our   previous   work   ( Wang   et   al . ,   2000 ) ,   it   raised   the   accuracy   rate   to   98.52%   from   97.53%   and   reduced   the   mean   false   alarm   rate   to   0.53%   from   1.26% . ' ,   ' title ' :   ' Zone   content   classification   and   its   performance   evaluation ' } 
{ ' abstract ' :   ' Big   Data   applications   require   real - time   processing   of   complex   computations   on   streaming   and   static   information .   Applications   such   as   the   diagnosis   of   power   generating   turbines   require   the   integration   of   high   velocity   streaming   and   large   volume   of   static   data   from   multiple   sources .   In   this   paper   we   study   various   optimisations   related   to   efficiently   processing   of   streaming   and   static   information .   We   introduce   novel   indexing   structures   for   stream   processing ,   a   query - planner   component   that   decides   when   their   creation   is   beneficial ,   and   we   examine   precomputed   summarisations   on   archived   measurements   to   accelerate   streaming   and   static   information   processing .   To   put   our   ideas   into   practise ,   we   have   developed   Exa   Stream ,   a   data   stream   management   system   that   is   scalable ,   has   declarative   semantics ,   supports   user   defined   functions ,   and   allows   efficient   execution   of   complex   analytical   queries   on   streaming   and   static   data .   Our   work   is   accompanied   by   an   empirical   evaluation   of   our   optimisation   techniques . ' ,   ' title ' :   ' Real   time   processing   of   streaming   and   static   information ' } 
{ ' abstract ' :   " In   the   last   ten   years ,   speech   recognition   has   evolved   from   a   science   fiction   dream   to   a   widespread   input   method   for   mobile   devices .   In   this   talk ,   I   will   describe   how   speech   recognition   works ,   the   problems   we   have   solved   and   the   challenges   that   remain .   I   will   touch   upon   some   of   Google ' s   main   efforts   in   language   and   pronunciation   modeling ,   and   describe   how   the   adoption   of   neural   networks   for   acoustic   modeling   marked   the   beginning   of   a   technology   revolution   in   the   field ,   with   approaches   such   as   Long   Short   Term   Memory   models   and   Connectionist   Temporal   Classification .   I   will   also   share   my   learnings   on   how   Machine   Learning   and   Human   Knowledge   can   be   harmoniously   combined   to   build   state - of - the - art   technology   that   helps   and   delights   users   across   the   world . " ,   ' title ' :   ' Learnings   and   innovations   in   speech   recognition ' } 
{ ' abstract ' :   ' Nowadays ,   the   explosive   growth   and   variety   of   information   available   on   the   Web   frequently   overwhelms   users   and   leads   users   to   make   poor   decisions .   Consequently ,   recommender   systems   have   become   more   and   more   important   to   assist   people   to   make   decisions   faster .   Among   all   related   techniques ,   collaborative   filtering   approach   is   currently   one   of   the   effective   and   widely   used   techniques   to   build   recommender   systems .   However ,   there   are   major   challenges   like   data   sparsity   and   scalability .   Meanwhile   it   is   hard   to   integrate   demographic   statistical   information   ( Age ,   gender   and   occupation   etc . )   to   collaborative   filtering   model .   Unfortunately ,   it   is   significant   to   take   account   into   these   information ,   especially   user   occupation   when   making   recommendation .   As   we   all   know ,   people   with   different   occupations   may   have   totally   different   tastes .   It   has   been   proved   that   restricted   Boltzmann   machines ( RBM )   model   can   infer   lower - dimensional   representations   automatically   and   is   potential   in   handling   large   and   sparse   dataset .   In   this   paper ,   we   propose   an   improved   User   Occupation   aware   Conditional   Restricted   Boltzmann   Machine   Frame ( UO - CRBMF )   model ,   which   employs   an   improved   RBM   and   takes   full   use   of   user   occupation   information   by   adding   a   conditional   layer   with   user   occupation   information .   Experimental   studies   on   the   standard   benchmark   datasets   of   MovieLens   100k   and   MovieLens   1M   have   shown   its   potential   and   advantages   beyond   baseline   methods . ' ,   ' title ' :   ' User   Occupation   Aware   Conditional   Restricted   Boltzmann   Machine   Based   Recommendation ' } 
{ ' abstract ' :   ' Microservices   complement   approaches   like   DevOps   and   continuous   delivery   in   terms   of   software   architecture .   Along   with   this   architectural   style ,   several   important   deployment   technologies ,   such   as   container - based   virtualization   and   container   orchestration   solutions ,   have   emerged .   These   technologies   allow   to   efficiently   exploit   cloud   platforms ,   providing   a   high   degree   of   scalability ,   availability ,   and   portability   for   microservices .# R ## N ## R ## N # Despite   the   obvious   importance   of   a   sufficient   level   of   performance ,   there   is   still   a   lack   of   performance   engineering   approaches   explicitly   taking   into   account   the   particularities   of   microservices .   In   this   paper ,   we   argue   why   new   solutions   to   performance   engineering   for   microservices   are   needed .   Furthermore ,   we   identify   open   issues   and   outline   possible   research   directions   with   regard   to   performance - aware   testing ,   monitoring ,   and   modeling   of   microservices . ' ,   ' title ' :   ' Performance   Engineering   for   Microservices :   Research   Challenges   and   Directions ' } 
{ ' abstract ' :   ' Intelligent   agents ,   such   as   robots ,   have   to   serve   a   multitude   of   autonomous   functions .   Examples   are ,   e . g . ,   collision   avoidance ,   navigation   and   route   planning ,   active   sensing   of   its   environment ,   or   the   interaction   and   non - verbal   communication   with   people   in   the   extended   reach   space .   Here ,   we   focus   on   the   recognition   of   the   action   of   a   human   agent   based   on   a   biologically   inspired   visual   architecture   of   analyzing   articulated   movements .   The   proposed   processing   architecture   builds   upon   coarsely   segregated   streams   of   sensory   processing   along   different   pathways   which   separately   process   form   and   motion   information   ( Layher   et   al . ,   2014 ) .   Action   recognition   is   performed   in   an   event - based   scheme   by   identifying   representations   of   characteristic   pose   configurations   ( key   poses )   in   an   image   sequence .   In   line   with   perceptual   studies ,   key   poses   are   selected   unsupervised   utilizing   a   feature   driven   criterion   which   combines   extrema   in   the   motion   energy   with   the   horizontal   and   the   vertical   extendedness   of   a   body   shape .   Per   class   representations   of   key   pose   frames   are   learned   using   a   deep   convolutional   neural   network   consisting   of   15   convolutional   layers .   The   network   is   trained   using   the   energy - efficient   deep   neuromorphic   networks   ( Eedn )   framework   ( Esser   et   al . ,   2016 ) ,   which   realizes   the   mapping   of   the   trained   synaptic   weights   onto   the   IBM   Neurosynaptic   System   platform   ( Merolla   et   al . ,   2014 ) .   After   the   mapping ,   the   trained   network   achieves   real - time   capabilities   for   processing   input   streams   and   classify   input   images   at   about   1 , 000   frames   per   second   while   the   computational   stages   only   consume   about   70   mW   of   energy   ( without   spike   transduction ) .   Particularly   regarding   mobile   robotic   systems ,   a   low   energy   profile   might   be   crucial   in   a   variety   application   scenarios .   Cross - validation   results   are   reported   for   two   different   datasets   and   compared   to   state - of - the - art   action   recognition   approaches .   The   results   demonstrate ,   that   ( I )   the   presented   approach   is   on   par   with   other   key   pose   based   methods   described   in   the   literature ,   which   select   key   pose   frames   by   optimizing   classification   accuracy ,   ( II )   compared   to   the   training   on   the   full   set   of   frames ,   representations   trained   on   key   pose   frames   result   in   a   higher   confidence   in   class   assignments ,   and   ( III )   key   pose   representations   show   promising   generalization   capabilities   in   a   cross - dataset   evaluation . ' ,   ' title ' :   ' Real - Time   Biologically   Inspired   Action   Recognition   from   Key   Poses   Using   a   Neuromorphic   Architecture ' } 
{ ' abstract ' :   ' Contents   carried   in   an   image   are   valuable   information   sources   for   many   scientific   and   engineering   applications .   However ,   if   the   image   is   captured   under   low   illumination   conditions   a   large   portion   of   the   image   appears   dark   and   this   heavily   degrades   the   image   quality .   In   order   to   solve   this   problem ,   a   restoration   algorithm   is   developed   here   that   transforms   the   low   input   brightness   to   a   higher   value   using   a   logarithmic   mapping   function .   The   mapping   is   further   refined   by   a   linear   weighting   with   the   input   to   reduce   the   un - necessary   amplification   at   regions   with   high   brightness .   Moreover ,   fine   details   in   the   image   are   preserved   by   applying   the   Retinex   principle   to   extract   and   then   re - insert   object   edges .   Results   from   experiments   using   low   and   normal   illumination   images   have   shown   satisfactory   performances   with   regard   to   the   improvement   in   information   contents   and   the   mitigation   of   viewing   artifacts . ' ,   ' title ' :   ' Logarithmic   profile   mapping   and   Retinex   edge   preserving   for   restoration   of   low   illumination   images ' } 
{ ' abstract ' :   ' We   propose   a   principled   approach   for   the   problem   of   aligning   multiple   partially   overlapping   networks .   The   objective   is   to   map   multiple   graphs   into   a   single   graph   while   preserving   vertex   and   edge   similarities .   The   problem   is   inspired   by   the   task   of   integrating   partial   views   of   a   family   tree   ( genealogical   network )   into   one   unified   network ,   but   it   also   has   applications ,   for   example ,   in   social   and   biological   networks .   Our   approach ,   called   Flan ,   introduces   the   idea   of   generalizing   the   facility   location   problem   by   adding   a   non - linear   term   to   capture   edge   similarities   and   to   infer   the   underlying   entity   network .   The   problem   is   solved   using   an   alternating   optimization   procedure   with   a   Lagrangian   relaxation .   Flan   has   the   advantage   of   being   able   to   leverage   prior   information   on   the   number   of   entities ,   so   that   when   this   information   is   available ,   Flan   is   shown   to   work   robustly   without   the   need   to   use   any   ground   truth   data   for   fine - tuning   method   parameters .   Additionally ,   we   present   three   multiple - network   extensions   to   an   existing   state - of - the - art   pairwise   alignment   method   called   Natalie .   Extensive   experiments   on   synthetic ,   as   well   as   real - world   datasets   on   social   networks   and   genealogical   networks ,   attest   to   the   effectiveness   of   the   proposed   approaches   which   clearly   outperform   a   popular   multiple   network   alignment   method   called   IsoRankN . ' ,   ' title ' :   ' Lagrangian   relaxations   for   multiple   network   alignment ' } 
{ ' abstract ' :   ' Heterogeneous   ultra - dense   networks   enable   ultra - high   data   rates   and   ultra - low   latency   through   the   use   of   dense   sub - 6   GHz   and   millimeter   wave   ( mmWave )   small   cells   with   different   antenna   configurations .   Existing   work   has   widely   studied   spectral   and   energy   efficiency   in   such   networks   and   shown   that   high   spectral   and   energy   efficiency   can   be   achieved .   This   article   investigates   the   benefits   of   heterogeneous   ultra - dense   network   architecture   from   the   perspectives   of   three   promising   technologies ,   i . e . ,   physical   layer   security ,   caching ,   and   wireless   energy   harvesting ,   and   provides   enthusiastic   outlook   towards   application   of   these   technologies   in   heterogeneous   ultra - dense   networks .   Based   on   the   rationale   of   each   technology ,   opportunities   and   challenges   are   identified   to   advance   the   research   in   this   emerging   network . ' ,   ' title ' :   ' A   New   Look   at   Physical   Layer   Security ,   Caching ,   and   Wireless   Energy   Harvesting   for   Heterogeneous   Ultra - dense   Networks ' } 
{ ' abstract ' :   ' We   consider   the   problem   of   joint   modeling   of   videos   and   their   corresponding   textual   descriptions   ( e . g .   sentences   or   phrases ) .   Our   approach   consists   of   three   components :   the   video   representation ,   the   textual   representation ,   and   a   joint   model   that   links   videos   and   text .   Our   video   representation   uses   the   state - of - the - art   deep   3D   ConvNet   to   capture   the   semantic   information   in   the   video .   Our   textual   representation   uses   the   recent   advancement   in   learning   word   and   sentence   vectors   from   large   text   corpus .   The   joint   model   is   learned   to   score   the   correct   ( video ,   text )   pairs   higher   than   the   incorrect   ones .   We   demonstrate   our   approach   in   several   applications :   1 )   retrieving   sentences   given   a   video ;   2 )   retrieving   videos   given   a   sentence ;   3 )   zero - shot   action   recognition   in   videos . ' ,   ' title ' :   ' Beyond   verbs :   Understanding   actions   in   videos   with   text ' } 
{ ' abstract ' :   ' This   paper   presents   a   multi - agent   model   for   simulating   attitude   formation   and   change   based   on   perception   and   communication   in   the   context   of   stabilization   operations .   The   originality   of   our   model   comes   from   ( 1 )   attitude   computation   that   evaluates   information   as   part   of   a   history   relative   to   the   individual   ( 2 )   a   notion   of   co - responsibility   for   attitude   attribution .   We   present   a   military   scenario   of   French   operations   in   Afghanistan   along   with   polls   results   about   the   opinion   of   citizen   toward   present   Forces .   Based   on   these   field   data ,   we   calibrate   the   model   and   show   the   resulting   attitude   dynamics .   We   study   the   sensibility   of   the   model   to   the   co - responsibility   factor . ' ,   ' title ' :   ' From   Field   Data   to   Attitude   Formation ' } 
{ ' abstract ' :   ' This   paper   proposes   two   low - complexity   iterative   algorithms   to   compute   the   capacity   of   a   single - user   multiple - input   multiple - output   channel   with   per - antenna   power   constraint .   The   first   method   results   from   manipulating   the   optimality   conditions   of   the   considered   problem   and   applying   fixed - point   iteration .   In   the   second   approach ,   we   transform   the   considered   problem   into   a   minimax   optimization   program   using   the   well - known   MAC -   BC   duality ,   and   then   solve   it   by   a   novel   alternating   optimization   method .   In   both   proposed   iterative   methods ,   each   iteration   involves   an   optimization   problem   which   can   be   efficiently   solved   by   the   water - filling   algorithm .   The   proposed   iterative   methods   are   provably   convergent .   Complexity   analysis   and   extensive   numerical   experiments   are   carried   out   to   demonstrate   the   superior   performance   of   the   proposed   algorithms   over   an   existing   approach   known   as   the   mode - dropping   algorithm . ' ,   ' title ' :   ' Low - complexity   Approaches   for   MIMO   Capacity   with   Per - antenna   Power   Constraint ' } 
{ ' abstract ' :   ' Inventory - Aware   Pathfinding   is   concerned   with   finding   paths   while   taking   into   account   that   picking   up   items ,   e . g . ,   keys ,   allow   the   character   to   unlock   blocked   pathways ,   e . g . ,   locked   doors .   In   this   work   we   present   a   pruning   method   and   a   preprocessing   method   that   can   improve   significantly   the   scalability   of   such   approaches .   We   apply   our   methods   to   the   recent   approach   of   Inventory - Driven   Jump - Point   Search   ( InvJPS ) .   First ,   we   introduce   InvJPS +   that   allows   to   prune   large   parts   of   the   search   space   by   favoring   short   detours   to   pick   up   items ,   offering   a   trade - off   between   efficiency   and   optimality .   Second ,   we   propose   a   preprocessing   step   that   allows   to   decide   on   runtime   which   items ,   e . g . ,   keys ,   are   worth   using   thus   pruning   potentially   unnecessary   items   before   the   search   starts .   We   show   results   for   combinations   of   the   pruning   and   preprocessing   methods   illustrating   the   best   choices   over   various   scenarios . ' ,   ' title ' :   ' Pruning   and   preprocessing   methods   for   inventory - aware   pathfinding ' } 
{ ' abstract ' :   ' This   paper   proposes   a   method   for   proper   names   extraction   from   Myanmar   text   by   using   latent   Dirichlet   allocation   ( LDA ) .   Our   method   aims   to   extract   proper   names   that   provide   important   information   on   the   contents   of   Myanmar   text .   Our   method   consists   of   two   steps .   In   the   first   step ,   we   extract   topic   words   from   Myanmar   news   articles   by   using   LDA .   In   the   second   step ,   we   make   a   post - processing ,   because   the   resulting   topic   words   contain   some   noisy   words .   Our   post - processing ,   first   of   all ,   eliminates   the   topic   words   whose   prefixes   are   Myanmar   digits   and   suffixes   are   noun   and   verb   particles .   We   then   remove   the   duplicate   words   and   discard   the   topic   words   that   are   contained   in   the   existing   dictionary .   Consequently ,   we   obtain   the   words   as   candidate   of   proper   names ,   namely   personal   names ,   geographical   names ,   unique   object   names ,   organization   names ,   single   event   names ,   and   so   on .   The   evaluation   is   performed   both   from   the   subjective   and   quantitative   perspectives .   From   the   subjective   perspective ,   we   compare   the   accuracy   of   proper   names   extracted   by   our   method   with   those   extracted   by   latent   semantic   indexing   ( LSI )   and   rule - based   method .   It   is   shown   that   both   LS ]   and   our   method   can   improve   the   accuracy   of   those   obtained   by   rule - based   method .   However ,   our   method   can   provide   more   interesting   proper   names   than   LSI .   From   the   quantitative   perspective ,   we   use   the   extracted   proper   names   as   additional   features   in   K - means   clustering .   The   experimental   results   show   that   the   document   clusters   given   by   our   method   are   better   than   those   given   by   LSI   and   rule - based   method   in   precision ,   recall   and   F - score . ' ,   ' title ' :   ' Extraction   of   proper   names   from   myanmar   text   using   latent   dirichlet   allocation ' } 
{ ' abstract ' :   ' Large   scale   assessment   of   aboveground   biomass   ( AGB )   in   tropical   forests   is   often   limited   by   the   saturation   of   remote   sensing   signals   at   high   AGB   values .   Fourier   Transform   Textural   Ordination   ( FOTO )   performs   well   in   quantifying   canopy   texture   from   very   high - resolution   ( VHR )   imagery ,   from   which   stand   structure   parameters   can   be   retrieved   with   no   saturation   effect   for   AGB   values   up   to   650   Mg · ha − 1 .   The   method   is   robust   when   tested   on   wet   evergreen   forests   but   is   more   demanding   when   applied   across   different   forest   types   characterized   by   varying   structures   and   allometries .   The   present   study   focuses   on   a   gradient   of   forest   types   ranging   from   dry   deciduous   to   wet   evergreen   forests   in   the   Western   Ghats   ( WG )   of   India ,   where   we   applied   FOTO   to   Cartosat - 1a   images   with   2.5   m   resolution .   Based   on   21   1 - ha   ground   control   forest   plots ,   we   calibrated   independent   texture – AGB   models   for   the   dry   and   wet   zone   forests   in   the   area ,   as   delineated   from   the   distribution   of   NDVI   values   computed   from   LISS - 4   multispectral   images .   This   stratification   largely   improved   the   relationship   between   texture - derived   and   field - derived   AGB   estimates ,   which   exhibited   a   R2   of   0.82   for   a   mean   rRMSE   of   ca .   17% .   By   inverting   the   texture – AGB   models ,   we   finally   mapped   AGB   predictions   at   1.6 - ha   resolution   over   a   heterogeneous   landscape   of   ca .   1500   km2   in   the   WG ,   with   a   mean   relative   per - pixel   propagated   error   < 20%   for   wet   zone   forests ,   i . e . ,   below   the   recommended   IPCC   criteria   for   Monitoring ,   Reporting   and   Verification   ( MRV )   methods .   The   method   proved   to   perform   well   in   predicting   high - resolution   AGB   values   over   heterogeneous   tropical   landscape   encompassing   diversified   forest   types ,   and   thus   presents   a   promising   option   for   affordable   regional   monitoring   systems   of   greenhouse   gas   ( GhG )   emissions   related   to   forest   degradation . ' ,   ' title ' :   ' Inverting   Aboveground   Biomass – Canopy   Texture   Relationships   in   a   Landscape   of   Forest   Mosaic   in   the   Western   Ghats   of   India   Using   Very   High   Resolution   Cartosat   Imagery ' } 
{ ' abstract ' :   ' Self - driving   vehicle   technologies   are   progressing   rapidly   and   are   expected   to   play   a   significant   role   in   the   future   of   transportation .   One   of   the   main   challenges   for   self - driving   vehicles   on   public   roads   is   the   safe   cooperation   and   collaboration   among   multiple   vehicles   using   sensor - based   perception   and   inter - vehicle   communications .   When   self - driving   vehicles   try   to   occupy   the   same   spatial   area   simultaneously ,   they   might   collide   with   one   another ,   might   become   deadlocked ,   or   might   slam   on   the   brakes   making   it   uncomfortable   or   unsafe   for   passengers   in   a   self - driving   vehicle .   In   this   paper ,   we   study   how   a   self - driving   vehicle   can   safely   navigate   merge   points ,   where   two   lanes   with   different   priorities   meet .   We   present   a   safe   protocol   for   merge   points   named   Autonomous   Vehicle   Protocol   for   Merge   Points ,   where   self - driving   vehicles   use   both   vehicular   communications   and   their   own   perception   systems   for   cooperating   with   other   self - driving   and / or   human - driven   vehicles .   Our   simulation   results   show   that   our   traffic   protocol   has   higher   traffic   throughput ,   compared   to   simple   traffic   protocols ,   while   ensuring   safety . ' ,   ' title ' :   ' A   merging   protocol   for   self - driving   vehicles ' } 
{ ' abstract ' :   ' System   Portfolio   Selection   ( SPS )   problem   is   equivalent   to   multi - objective   optimization   problem ,   with   multi - function   requirements   incommensurable .   In   the   paper ,   the   SPS   problem   is   re - specified   with   a   more   practical   formulation ,   comparing   to   general   portfolio   problem .   Then ,   both   feasible   and   non - inferior   solution   is   re - defined   considering   characteristics   of   SPS   problem ,   specifically ,   four   rules   of   system   function   combinations   are   proposed   according   to   practical   cases .   Then ,   the   instability   of   system   performance   is   involved   in   SPS   problem ,   and   the   robust   theory   is   employed   to   solving   the   uncertainty   of   system   function   values   with   definition   of   robust   non - inferior   solution .   Next ,   the   paper   proposes   an   immediately   updating   algorithm   to   solve   the   problem   of   solution   space   exponentially   growing .   Finally ,   a   case   study   is   used   to   demonstrate   the   usefulness   and   effectiveness   of   the   proposed   approaches .   It   shows   that   the   approach   can   provide   an   efficient   guidance   for   decision - makers   in   the   process   of   making   a   SPS . ' ,   ' title ' :   ' Robust   system   portfolio   selection   with   multi - function   requirements   and   system   instability ' } 
{ ' abstract ' :   ' This   study   explores   the   impact   of   high - photovoltaic   ( PV )   penetration   on   the   inter - area   oscillation   modes   of   large - scale   power   grids .   A   series   of   dynamic   models   with   various   PV   penetration   levels   are   developed   based   on   a   detailed   model   representing   the   U . S .   Eastern   Interconnection   ( EI ) .   Transient   simulations   are   performed   to   investigate   the   change   of   inter - area   oscillation   modes   with   PV   penetration .   The   impact   of   PV   control   strategies   and   parameter   settings   on   inter - area   oscillations   is   studied .   This   paper   finds   that   as   PV   increases ,   the   damping   of   the   dominant   oscillation   mode   decreases   monotonically .   It   is   also   observed   that   the   mode   shape   varies   with   the   PV   control   strategy   and   new   oscillation   modes   may   emerge   under   inappropriate   parameter   settings   in   PV   plant   controls . ' ,   ' title ' :   ' Impact   of   High   PV   Penetration   on   the   Inter - Area   Oscillations   in   the   U . S .   Eastern   Interconnection ' } 
{ ' abstract ' :   ' The   objective   of   this   research   is   to   compare   the   effectiveness   of   different   tracking   devices   underwater .   There   have   been   few   works   in   aquatic   virtual   reality   ( VR )   —   i . e . ,   VR   systems   that   can   be   used   in   a   real   underwater   environment .   Moreover ,   the   works   that   have   been   done   have   noted   limitations   on   tracking   accuracy .   Our   initial   test   results   suggest   that   inertial   measurement   units   work   well   underwater   for   orientation   tracking   but   a   different   approach   is   needed   for   position   tracking .   Towards   this   goal ,   we   have   waterproofed   and   evaluated   several   consumer   tracking   systems   intended   for   gaming   to   determine   the   most   effective   approaches .   First ,   we   informally   tested   infrared   systems   and   fiducial   marker   based   systems ,   which   demonstrated   significant   limitations   of   optical   approaches .   Next ,   we   quantitatively   compared   inertial   measurement   units   ( IMU )   and   a   magnetic   tracking   system   both   above   water   ( as   a   baseline )   and   underwater .   By   comparing   the   devices   rotation   data ,   we   have   discovered   that   the   magnetic   tracking   system   implemented   by   the   Razer   Hydra   is   more   accurate   underwater   as   compared   to   a   phone - based   IMU .   This   suggests   that   magnetic   tracking   systems   should   be   further   explored   for   underwater   VR   applications . ' ,   ' title ' :   ' Towards   usable   underwater   virtual   reality   systems ' } 
{ ' abstract ' :   ' A   faulty   network   GG   is   under   the   conditional   fault   model ,   i . e . , \ xa0every   fault - free   vertex   of   GG   is   incident   to   at   least   two   fault - free   edges .   Let   FFvFFv   and   FFeFFe   be   the   set   of   faulty   vertices   and   faulty   edges   in   FQnFQn ,   respectively .   In   this   paper ,   we   consider   FQnFQn   under   the   conditional   fault   model   and   prove   that   if   | FFv | + | FFe | ≤ 2n − 4 | FFv | + | FFe | ≤ 2n − 4   and   n ≥ 3n ≥ 3 ,   then   FQn − FFv − FFeFQn − FFv − FFe   contains   a   fault - free   cycle   of   every   even   length   from   4   to   2n − 2 | FFv | 2n − 2 | FFv | ;   if   | FFv | + | FFe | ≤ 2n − 5 | FFv | + | FFe | ≤ 2n − 5   and   n ≥ 4n ≥ 4   is   even ,   then   FQn − FFv − FFeFQn − FFv − FFe   contains   a   fault - free   cycle   of   every   odd   length   from   n + 1n + 1   to   2n − 2 | FFv | − 12n − 2 | FFv | − 1 . ' ,   ' title ' :   ' Cycles   embedding   in   folded   hypercubes   under   the   conditional   fault   model ' } 
{ ' abstract ' :   ' Companies   have   invested   considerable   resources   in   the   implementation   of   enterprise   resource   planning   ( ERP )   systems .   The   results   initially   expected   have   rarely   been   reached .   The   optimisation   ( or   efficient   use )   of   such   information   systems   is   nowadays   becoming   a   major   factor   for   firms   striving   to   reach   their   performance   objectives .   After   presenting   a   synthesis   of   several   studies   on   ERP   projects ,   we   build   on   the   findings   of   a   French   investigation   into   the   assessment   and   optimisation   of   ERP   performance .   A   classification   of   company   positions   regarding   their   ERP   use ,   based   on   both   software   maturity   and   strategic   deployment   directions ,   and   an   improvement   process   are   proposed .   Industrial   cases   allow   validation   of   this   approach . ' ,   ' title ' :   ' A   classification   for   better   use   of   ERP   systems ' } 
{ ' abstract ' :   ' This   paper   presents   a   time - domain   biosensor   array   that   uses   a   capacitor - less   current - mode   analog - to - time   converter   ( CMATC )   and   logarithmic   cyclic   time - attenuation - based   TDC   with   discharging   acceleration .   Combining   the   exponential   function   of   the   CMATC   and   logarithmic   function   of   the   proposed   TDC   offers   linear   input - output   characteristics .   The   time - domain   property   enables   bio - imaging   at   a   high   spatial   resolution   and   large   scale   while   maintaining   scalability .   Measurement   results   with   a   0.25 - μ m   test   chip   successfully   demonstrated   linear   input - output   characteristics . ' ,   ' title ' :   ' A   scalable   time - domain   biosensor   array   using   logarithmic   cyclic   time - attenuation - based   TDC   for   high - resolution   and   large - scale   bio - imaging ' } 
{ ' abstract ' :   ' Compared   to   current   mobile   networks ,   next - generation   mobile   networks   are   expected   to   support   higher   numbers   of   simultaneously   connected   devices   and   to   achieve   higher   system   spectrum   efficiency   and   lower   power   consumption .   To   achieve   these   goals ,   we   study   the   multi - sharing   device - to - device   ( D2D )   communication ,   which   allows   any   cellular   user   equipment   to   share   its   radio   resource   with   multiple   D2D   devices .   We   jointly   consider   resource   block   reuse   and   power   control   and   then   develop   the   MISS   algorithm .   Simulation   results   show   that   MISS   performs   very   well   in   terms   of   transmission   power   consumption ,   system   throughput ,   and   the   number   of   permitted   D2D   devices . ' ,   ' title ' :   ' Joint   Resource   Block   Reuse   and   Power   Control   for   Multi - Sharing   Device - to - Device   Communication ' } 
{ ' abstract ' :   ' This   paper   is   concerned   with   event - triggered   H ∞ H ∞   filtering   for   delayed   neural   networks   via   sampled   data .   A   novel   event - triggered   scheme   is   proposed ,   which   can   lead   to   a   significant   reduction   of   the   information   communication   burden   in   the   network ;   the   feature   of   this   scheme   is   that   whether   or   not   the   sampled   data   should   be   transmitted   is   determined   by   the   current   sampled   data   and   the   error   between   the   current   sampled   data   and   the   latest   transmitted   data .   By   constructing   a   proper   Lyapunov – Krasovskii   functional ,   utilizing   the   reciprocally   convex   combination   technique   and   Jensen ’ s   inequality   sufficient   conditions   are   derived   to   ensure   that   the   resultant   filtering   error   system   is   asymptotically   stable .   Based   on   the   derived   H ∞ H ∞   performance   analysis   results ,   the   H ∞ H ∞   filter   design   is   formulated   in   terms   of   Linear   Matrix   Inequalities   ( LMIs ) .   Finally ,   the   proposed   stability   conditions   are   demonstrated   with   numerical   example . ' ,   ' title ' :   ' Event - triggered   H   ∞   filtering   for   delayed   neural   networks   via   sampled - data ' } 
{ ' abstract ' :   ' For   the   double   integrator   with   matched   Lipschitz   disturbances   we   propose   a   continuous   homogeneous   controller   providing   finite - time   stability   of   the   origin .   The   disturbance   is   compensated   exactly   in   finite   time   using   a   discontinuous   function   through   an   integral   action .   Since   the   controller   is   dynamic ,   the   closed   loop   is   a   third   order   system   that   achieves   a   third   order   sliding   mode   in   the   steady   state .   The   stability   and   robustness   properties   of   the   controller   are   proven   using   a   smooth   and   homogeneous   strict   Lyapunov   function   ( LF ) .   In   a   first   stage ,   the   gains   of   the   controller   and   the   LF   are   designed   using   a   method   based   on   Polya ’ s   Theorem .   In   a   second   stage   the   controller ’ s   gains   are   adjusted   through   a   sum   of   squares   representation   of   the   LF . ' ,   ' title ' :   ' Design   of   Continuous   Twisting   Algorithm ' } 
{ ' abstract ' :   ' Big   data   is   now   rapidly   expanding   into   various   domains   such   as   banking ,   insurance   and   e - commerce .   Data   analysis   and   related   studies   have   attracted   more   attentions .   In   health   insurance ,   abuse   of   diagnosis   is   one   of   the   key   fraud   problems ,   which   damages   the   interests   of   insured   people .   To   address   this   issue ,   numbers   of   studies   have   focused   on   this   topic .   This   paper   develops   a   healthcare   fraud   detection   approach   based   on   the   trustworthiness   of   doctors   to   distinguish   fraud   cases   from   normal   records .   Compared   to   conventional   methods ,   our   approach   can   detect   healthcare   fraud   in   a   good   accuracy   by   only   little   feature   information   from   healthcare   data   without   the   violation   of   privacy .   This   approach   combines   a   weighted   HITS   algorithm   with   a   frequent   pattern   mining   algorithm   to   calculate   a   rational   treatment   model   of   a   certain   disease .   In   addition ,   this   paper   also   introduces   the   copy   precision   behavior   in   the   treatment   sequences   of   patients ,   which   is   a   critical   metric   to   learn   the   trustworthiness   of   doctors .   The   numerical   validation   with   a   healthcare   dataset   demonstrates   that   healthcare   fraud   by   misdiagnosis   in   healthcare   treatments   can   be   successfully   detected   by   employing   the   developed   fraud   detection   approach . ' ,   ' title ' :   ' Healthcare   Fraud   Detection   Based   on   Trustworthiness   of   Doctors ' } 
